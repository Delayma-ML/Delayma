{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the GPU device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Architecture of Baseline Model:\n",
    "\n",
    "1. Layer 1: Linear layer- Input: 46, Output: 16\n",
    "2. Activation Function: ReLU\n",
    "3. Layer 2: Linear layer- Input: 16, Output: 4\n",
    "4. Activation Function: ReLU\n",
    "5. Layer 3: Linear layer- Input: 4, Output: 1\n",
    "\n",
    "* Loss Function: MSELoss\n",
    "* Optimizer: SGD Optimizer\n",
    "* Learning Rate: 1e-5\n",
    "* Epochs: 50\n",
    "* Batch Size: 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column details - \n",
    "\n",
    "\n",
    "# FL_DATE,OP_CARRIER,OP_CARRIER_FL_NUM,ORIGIN,DEST,ARR_DELAY,DEP_DELAY,CANCELLED,DISTANCE\n",
    "# FL_DATE -- flight date (yyyy-mm-dd)\n",
    "# OP_CARRIER -- carrier code\n",
    "# OP_CARRIER_FL_NUM -- flight number\n",
    "# ORIGIN -- origin place \n",
    "# DEST -- destination place\n",
    "# CRS_DEP_TIME -- scheduled departure time (hhmm)\n",
    "# DEP_TIME -- actual departure time (hhmm)\n",
    "# DEP_DELAY -- departure delay (minutes)\n",
    "# TAXI_OUT -- taxi out time (minutes)\n",
    "# WHEELS_OFF -- wheels off time (hhmm)\n",
    "# WHEELS_ON -- wheels on time (hhmm)\n",
    "# TAXI_IN -- taxi in time (minutes)\n",
    "# CRS_ARR_TIME -- scheduled arrival time (hhmm)\n",
    "# ARR_TIME -- actual arrival time (hhmm)\n",
    "# ARR_DELAY -- arrival delay (minutes)\n",
    "# CANCELLED -- was the flight cancelled?\n",
    "# CANCELLATION_CODE \n",
    "# DIVERTED -- was the flight diverted? (1 = yes, 0 = no)\n",
    "# CRS_ELAPSED_TIME -- scheduled elapsed time (minutes)\n",
    "# ACTUAL_ELAPSED_TIME -- actual elapsed time (minutes)\n",
    "# AIR_TIME -- air time (minutes)\n",
    "# DISTANCE -- distance (miles)\n",
    "# CARRIER_DELAY -- carrier delay (minutes)\n",
    "# WEATHER_DELAY -- weather delay (minutes)\n",
    "# NAS_DELAY -- NAS delay (minutes)\n",
    "# SECURITY_DELAY -- security delay (minutes)\n",
    "# LATE_AIRCRAFT_DELAY -- late aircraft delay (minutes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FL_DATE</th>\n",
       "      <th>OP_CARRIER</th>\n",
       "      <th>OP_CARRIER_FL_NUM</th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>DEST</th>\n",
       "      <th>CRS_DEP_TIME</th>\n",
       "      <th>DEP_TIME</th>\n",
       "      <th>DEP_DELAY</th>\n",
       "      <th>TAXI_OUT</th>\n",
       "      <th>WHEELS_OFF</th>\n",
       "      <th>...</th>\n",
       "      <th>DIVERTED</th>\n",
       "      <th>CRS_ELAPSED_TIME</th>\n",
       "      <th>ACTUAL_ELAPSED_TIME</th>\n",
       "      <th>AIR_TIME</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>CARRIER_DELAY</th>\n",
       "      <th>WEATHER_DELAY</th>\n",
       "      <th>NAS_DELAY</th>\n",
       "      <th>SECURITY_DELAY</th>\n",
       "      <th>LATE_AIRCRAFT_DELAY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>OO</td>\n",
       "      <td>6439</td>\n",
       "      <td>CWA</td>\n",
       "      <td>EAU</td>\n",
       "      <td>2305.0</td>\n",
       "      <td>1939.0</td>\n",
       "      <td>-206.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1954.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-06-16</td>\n",
       "      <td>AS</td>\n",
       "      <td>66</td>\n",
       "      <td>YAK</td>\n",
       "      <td>JNU</td>\n",
       "      <td>1845.0</td>\n",
       "      <td>1822.0</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1826.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-02-10</td>\n",
       "      <td>OO</td>\n",
       "      <td>4551</td>\n",
       "      <td>RAP</td>\n",
       "      <td>SLC</td>\n",
       "      <td>1645.0</td>\n",
       "      <td>1624.0</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1640.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>508.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>OH</td>\n",
       "      <td>6593</td>\n",
       "      <td>DCA</td>\n",
       "      <td>IND</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1940.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1947.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>499.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-07-01</td>\n",
       "      <td>UA</td>\n",
       "      <td>828</td>\n",
       "      <td>JAC</td>\n",
       "      <td>DEN</td>\n",
       "      <td>1506.0</td>\n",
       "      <td>1447.0</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1501.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      FL_DATE OP_CARRIER  OP_CARRIER_FL_NUM ORIGIN DEST  CRS_DEP_TIME  \\\n",
       "0  2010-12-31         OO               6439    CWA  EAU        2305.0   \n",
       "1  2010-06-16         AS                 66    YAK  JNU        1845.0   \n",
       "2  2010-02-10         OO               4551    RAP  SLC        1645.0   \n",
       "3  2010-01-01         OH               6593    DCA  IND        2000.0   \n",
       "4  2010-07-01         UA                828    JAC  DEN        1506.0   \n",
       "\n",
       "   DEP_TIME  DEP_DELAY  TAXI_OUT  WHEELS_OFF  ...  DIVERTED  CRS_ELAPSED_TIME  \\\n",
       "0    1939.0     -206.0      15.0      1954.0  ...       0.0              38.0   \n",
       "1    1822.0      -23.0       4.0      1826.0  ...       0.0              48.0   \n",
       "2    1624.0      -21.0      16.0      1640.0  ...       0.0             106.0   \n",
       "3    1940.0      -20.0       7.0      1947.0  ...       0.0             120.0   \n",
       "4    1447.0      -19.0      14.0      1501.0  ...       0.0              90.0   \n",
       "\n",
       "   ACTUAL_ELAPSED_TIME  AIR_TIME  DISTANCE  CARRIER_DELAY WEATHER_DELAY  \\\n",
       "0                 52.0      32.0      90.0            NaN           NaN   \n",
       "1                 38.0      30.0     199.0            NaN           NaN   \n",
       "2                102.0      80.0     508.0            NaN           NaN   \n",
       "3                 92.0      77.0     499.0            NaN           NaN   \n",
       "4                 79.0      60.0     406.0            NaN           NaN   \n",
       "\n",
       "   NAS_DELAY  SECURITY_DELAY  LATE_AIRCRAFT_DELAY  \n",
       "0        NaN             NaN                  NaN  \n",
       "1        NaN             NaN                  NaN  \n",
       "2        NaN             NaN                  NaN  \n",
       "3        NaN             NaN                  NaN  \n",
       "4        NaN             NaN                  NaN  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import data\n",
    "data = pd.read_csv('2010-17_all_labels.csv', skiprows=0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['FL_DATE', 'OP_CARRIER', 'OP_CARRIER_FL_NUM', 'ORIGIN', 'DEST',\n",
       "       'CRS_DEP_TIME', 'DEP_TIME', 'DEP_DELAY', 'TAXI_OUT', 'WHEELS_OFF',\n",
       "       'WHEELS_ON', 'TAXI_IN', 'CRS_ARR_TIME', 'ARR_TIME', 'ARR_DELAY',\n",
       "       'CANCELLED', 'CANCELLATION_CODE', 'DIVERTED', 'CRS_ELAPSED_TIME',\n",
       "       'ACTUAL_ELAPSED_TIME', 'AIR_TIME', 'DISTANCE', 'CARRIER_DELAY',\n",
       "       'WEATHER_DELAY', 'NAS_DELAY', 'SECURITY_DELAY', 'LATE_AIRCRAFT_DELAY'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "328\n",
      "329\n",
      "335\n"
     ]
    }
   ],
   "source": [
    "# data.head()\n",
    "# count number of unique OP_CARRIER, ORIGIN, DEST, and total number of unique places\n",
    "print(len(data['OP_CARRIER'].unique()))\n",
    "print(len(data['ORIGIN'].unique()))\n",
    "print(len(data['DEST'].unique()))\n",
    "origin = data['ORIGIN'].unique()\n",
    "dest = data['DEST'].unique()\n",
    "origin = np.append(origin, dest)\n",
    "origin = np.unique(origin)\n",
    "print(len(origin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for implementing cyclic encoding of categorical variables\n",
    "def encode(data, col, max_val):\n",
    "    data[col + '_sin'] = np.sin(2 * np.pi * data[col]/max_val)\n",
    "    data[col + '_cos'] = np.cos(2 * np.pi * data[col]/max_val)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill up all the missing values in the column 'CARRIER_DELAY', 'WEATHER_DELAY', 'NAS_DELAY', 'SECURITY_DELAY', 'LATE_AIRCRAFT_DELAY' with 0\n",
    "data['CARRIER_DELAY'] = data['CARRIER_DELAY'].fillna(0)\n",
    "data['WEATHER_DELAY'] = data['WEATHER_DELAY'].fillna(0)\n",
    "data['NAS_DELAY'] = data['NAS_DELAY'].fillna(0)\n",
    "data['SECURITY_DELAY'] = data['SECURITY_DELAY'].fillna(0)\n",
    "data['LATE_AIRCRAFT_DELAY'] = data['LATE_AIRCRAFT_DELAY'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data of the form dd-mm-yyyy into day, month and year columns\n",
    "data.head()\n",
    "data['FL_DAY'] = data['FL_DATE'].map(lambda x: x.split('-')[2])\n",
    "data['FL_MONTH'] = data['FL_DATE'].map(lambda x: x.split('-')[1])\n",
    "data['FL_YEAR'] = data['FL_DATE'].map(lambda x: x.split('-')[0])\n",
    "data['FL_YEAR'] = data['FL_YEAR'].astype(int)\n",
    "data['FL_MONTH'] = data['FL_MONTH'].astype(int)\n",
    "data['FL_DAY'] = data['FL_DAY'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the columns where time is not available, that is, where the flight was cancelled\n",
    "data = data.dropna(subset=['ARR_TIME', 'DEP_TIME', 'DEP_DELAY', 'ARR_DELAY', 'CRS_DEP_TIME', 'CRS_ARR_TIME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the CRS_DEP_TIME into hours and minutes\n",
    "data['CRS_DEP_HOUR'] = data['CRS_DEP_TIME'].map(lambda x: int(x/100))\n",
    "data['CRS_DEP_MIN'] = data['CRS_DEP_TIME'].map(lambda x: int(x%100))\n",
    "# split the DEP_TIME into hours and minutes\n",
    "data['DEP_TIME_HOUR'] = data['DEP_TIME'].map(lambda x: int(x/100))\n",
    "data['DEP_TIME_MIN'] = data['DEP_TIME'].map(lambda x: int(x%100))\n",
    "# split the WHEELS_OFF into hours and minutes\n",
    "data['WHEELS_OFF_HOUR'] = data['WHEELS_OFF'].map(lambda x: int(x/100))\n",
    "data['WHEELS_OFF_MIN'] = data['WHEELS_OFF'].map(lambda x: int(x%100))\n",
    "# split the WHEELS_ON into hours and minutes\n",
    "data['WHEELS_ON_HOUR'] = data['WHEELS_ON'].map(lambda x: int(x/100))\n",
    "data['WHEELS_ON_MIN'] = data['WHEELS_ON'].map(lambda x: int(x%100))\n",
    "# split the CRS_ARR_TIME into hours and minutes\n",
    "data['CRS_ARR_HOUR'] = data['CRS_ARR_TIME'].map(lambda x: int(x/100))\n",
    "data['CRS_ARR_MIN'] = data['CRS_ARR_TIME'].map(lambda x: int(x%100))\n",
    "# split the ARR_TIME into hours and minutes\n",
    "data['ARR_TIME_HOUR'] = data['ARR_TIME'].map(lambda x: int(x/100))\n",
    "data['ARR_TIME_MIN'] = data['ARR_TIME'].map(lambda x: int(x%100))\n",
    "# drop the columns that are not required- CRS_DEP_TIME, DEP_TIME, WHEELS_OFF, WHEELS_ON, CRS_ARR_TIME, ARR_TIME\n",
    "data = data.drop(columns=['CRS_DEP_TIME', 'DEP_TIME', 'WHEELS_OFF', 'WHEELS_ON', 'CRS_ARR_TIME', 'ARR_TIME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['FL_DATE', 'OP_CARRIER', 'OP_CARRIER_FL_NUM', 'ORIGIN', 'DEST',\n",
       "       'DEP_DELAY', 'TAXI_OUT', 'TAXI_IN', 'ARR_DELAY', 'CANCELLED',\n",
       "       'CANCELLATION_CODE', 'DIVERTED', 'CRS_ELAPSED_TIME',\n",
       "       'ACTUAL_ELAPSED_TIME', 'AIR_TIME', 'DISTANCE', 'CARRIER_DELAY',\n",
       "       'WEATHER_DELAY', 'NAS_DELAY', 'SECURITY_DELAY', 'LATE_AIRCRAFT_DELAY',\n",
       "       'FL_DAY', 'FL_MONTH', 'FL_YEAR', 'CRS_DEP_HOUR', 'CRS_DEP_MIN',\n",
       "       'DEP_TIME_HOUR', 'DEP_TIME_MIN', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MIN',\n",
       "       'WHEELS_ON_HOUR', 'WHEELS_ON_MIN', 'CRS_ARR_HOUR', 'CRS_ARR_MIN',\n",
       "       'ARR_TIME_HOUR', 'ARR_TIME_MIN'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# columns of the dataset\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cyclic feature encoding \n",
    "data = encode(data, 'CRS_DEP_HOUR', 24)\n",
    "data = encode(data, 'CRS_DEP_MIN', 60)\n",
    "data = encode(data, 'DEP_TIME_HOUR', 24)\n",
    "data = encode(data, 'DEP_TIME_MIN', 60)\n",
    "data = encode(data, 'WHEELS_OFF_HOUR', 24)\n",
    "data = encode(data, 'WHEELS_OFF_MIN', 60)\n",
    "data = encode(data, 'WHEELS_ON_HOUR', 24)\n",
    "data = encode(data, 'WHEELS_ON_MIN', 60)\n",
    "data = encode(data, 'CRS_ARR_HOUR', 24)\n",
    "data = encode(data, 'CRS_ARR_MIN', 60)\n",
    "data = encode(data, 'ARR_TIME_HOUR', 24)\n",
    "data = encode(data, 'ARR_TIME_MIN', 60)\n",
    "# reduce FL_MONTH and FL_DAY by 1\n",
    "data['FL_MONTH'] = data['FL_MONTH'] - 1\n",
    "data['FL_DAY'] = data['FL_DAY'] - 1\n",
    "# cyclic feature encoding for FL_MONTH and FL_DAY\n",
    "data = encode(data, 'FL_MONTH', 12)\n",
    "data = encode(data, 'FL_DAY', 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47032, 50)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FL_DATE</th>\n",
       "      <th>OP_CARRIER</th>\n",
       "      <th>OP_CARRIER_FL_NUM</th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>DEST</th>\n",
       "      <th>DEP_DELAY</th>\n",
       "      <th>TAXI_OUT</th>\n",
       "      <th>TAXI_IN</th>\n",
       "      <th>ARR_DELAY</th>\n",
       "      <th>CANCELLED</th>\n",
       "      <th>...</th>\n",
       "      <th>CRS_ARR_MIN_sin</th>\n",
       "      <th>CRS_ARR_MIN_cos</th>\n",
       "      <th>ARR_TIME_HOUR_sin</th>\n",
       "      <th>ARR_TIME_HOUR_cos</th>\n",
       "      <th>ARR_TIME_MIN_sin</th>\n",
       "      <th>ARR_TIME_MIN_cos</th>\n",
       "      <th>FL_MONTH_sin</th>\n",
       "      <th>FL_MONTH_cos</th>\n",
       "      <th>FL_DAY_sin</th>\n",
       "      <th>FL_DAY_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>OO</td>\n",
       "      <td>6439</td>\n",
       "      <td>CWA</td>\n",
       "      <td>EAU</td>\n",
       "      <td>-206.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.978148</td>\n",
       "      <td>-0.207912</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>-0.104528</td>\n",
       "      <td>-0.994522</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.201299</td>\n",
       "      <td>0.979530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-06-16</td>\n",
       "      <td>AS</td>\n",
       "      <td>66</td>\n",
       "      <td>YAK</td>\n",
       "      <td>JNU</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.309017</td>\n",
       "      <td>-0.951057</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>2.588190e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.101168</td>\n",
       "      <td>-0.994869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-02-10</td>\n",
       "      <td>OO</td>\n",
       "      <td>4551</td>\n",
       "      <td>RAP</td>\n",
       "      <td>SLC</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.104528</td>\n",
       "      <td>-0.994522</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "      <td>0.587785</td>\n",
       "      <td>0.809017</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.968077</td>\n",
       "      <td>-0.250653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>OH</td>\n",
       "      <td>6593</td>\n",
       "      <td>DCA</td>\n",
       "      <td>IND</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>7.071068e-01</td>\n",
       "      <td>0.951057</td>\n",
       "      <td>0.309017</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-07-01</td>\n",
       "      <td>UA</td>\n",
       "      <td>828</td>\n",
       "      <td>JAC</td>\n",
       "      <td>DEN</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.587785</td>\n",
       "      <td>-0.809017</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>0.587785</td>\n",
       "      <td>0.809017</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      FL_DATE OP_CARRIER  OP_CARRIER_FL_NUM ORIGIN DEST  DEP_DELAY  TAXI_OUT  \\\n",
       "0  2010-12-31         OO               6439    CWA  EAU     -206.0      15.0   \n",
       "1  2010-06-16         AS                 66    YAK  JNU      -23.0       4.0   \n",
       "2  2010-02-10         OO               4551    RAP  SLC      -21.0      16.0   \n",
       "3  2010-01-01         OH               6593    DCA  IND      -20.0       7.0   \n",
       "4  2010-07-01         UA                828    JAC  DEN      -19.0      14.0   \n",
       "\n",
       "   TAXI_IN  ARR_DELAY  CANCELLED  ... CRS_ARR_MIN_sin  CRS_ARR_MIN_cos  \\\n",
       "0      5.0     -192.0        0.0  ...       -0.978148        -0.207912   \n",
       "1      4.0      -33.0        0.0  ...       -0.309017        -0.951057   \n",
       "2      6.0      -25.0        0.0  ...       -0.104528        -0.994522   \n",
       "3      8.0      -48.0        0.0  ...        0.000000         1.000000   \n",
       "4      5.0      -30.0        0.0  ...       -0.587785        -0.809017   \n",
       "\n",
       "   ARR_TIME_HOUR_sin  ARR_TIME_HOUR_cos  ARR_TIME_MIN_sin  ARR_TIME_MIN_cos  \\\n",
       "0          -0.866025       5.000000e-01         -0.104528         -0.994522   \n",
       "1          -0.965926       2.588190e-01          0.000000          1.000000   \n",
       "2          -1.000000      -1.836970e-16          0.587785          0.809017   \n",
       "3          -0.707107       7.071068e-01          0.951057          0.309017   \n",
       "4          -0.866025      -5.000000e-01          0.587785          0.809017   \n",
       "\n",
       "   FL_MONTH_sin  FL_MONTH_cos  FL_DAY_sin  FL_DAY_cos  \n",
       "0 -5.000000e-01      0.866025   -0.201299    0.979530  \n",
       "1  5.000000e-01     -0.866025    0.101168   -0.994869  \n",
       "2  5.000000e-01      0.866025    0.968077   -0.250653  \n",
       "3  0.000000e+00      1.000000    0.000000    1.000000  \n",
       "4  1.224647e-16     -1.000000    0.000000    1.000000  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop the columns that are not required- CRS_DEP_TIME, DEP_TIME, WHEELS_OFF, WHEELS_ON, CRS_ARR_TIME, ARR_TIME\n",
    "data = data.drop(columns=['CRS_DEP_HOUR', 'CRS_DEP_MIN', 'DEP_TIME_HOUR', 'DEP_TIME_MIN', 'WHEELS_OFF_HOUR', 'WHEELS_OFF_MIN', 'WHEELS_ON_HOUR', 'WHEELS_ON_MIN', 'CRS_ARR_HOUR', 'CRS_ARR_MIN', 'ARR_TIME_HOUR', 'ARR_TIME_MIN', 'FL_MONTH', 'FL_DAY'])\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FL_DATE                    0\n",
      "OP_CARRIER                 0\n",
      "OP_CARRIER_FL_NUM          0\n",
      "ORIGIN                     0\n",
      "DEST                       0\n",
      "DEP_DELAY                  0\n",
      "TAXI_OUT                   0\n",
      "TAXI_IN                    0\n",
      "ARR_DELAY                  0\n",
      "CANCELLED                  0\n",
      "CANCELLATION_CODE      47032\n",
      "DIVERTED                   0\n",
      "CRS_ELAPSED_TIME           0\n",
      "ACTUAL_ELAPSED_TIME        0\n",
      "AIR_TIME                   0\n",
      "DISTANCE                   0\n",
      "CARRIER_DELAY              0\n",
      "WEATHER_DELAY              0\n",
      "NAS_DELAY                  0\n",
      "SECURITY_DELAY             0\n",
      "LATE_AIRCRAFT_DELAY        0\n",
      "FL_YEAR                    0\n",
      "CRS_DEP_HOUR_sin           0\n",
      "CRS_DEP_HOUR_cos           0\n",
      "CRS_DEP_MIN_sin            0\n",
      "CRS_DEP_MIN_cos            0\n",
      "DEP_TIME_HOUR_sin          0\n",
      "DEP_TIME_HOUR_cos          0\n",
      "DEP_TIME_MIN_sin           0\n",
      "DEP_TIME_MIN_cos           0\n",
      "WHEELS_OFF_HOUR_sin        0\n",
      "WHEELS_OFF_HOUR_cos        0\n",
      "WHEELS_OFF_MIN_sin         0\n",
      "WHEELS_OFF_MIN_cos         0\n",
      "WHEELS_ON_HOUR_sin         0\n",
      "WHEELS_ON_HOUR_cos         0\n",
      "WHEELS_ON_MIN_sin          0\n",
      "WHEELS_ON_MIN_cos          0\n",
      "CRS_ARR_HOUR_sin           0\n",
      "CRS_ARR_HOUR_cos           0\n",
      "CRS_ARR_MIN_sin            0\n",
      "CRS_ARR_MIN_cos            0\n",
      "ARR_TIME_HOUR_sin          0\n",
      "ARR_TIME_HOUR_cos          0\n",
      "ARR_TIME_MIN_sin           0\n",
      "ARR_TIME_MIN_cos           0\n",
      "FL_MONTH_sin               0\n",
      "FL_MONTH_cos               0\n",
      "FL_DAY_sin                 0\n",
      "FL_DAY_cos                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# count number of null values in each column\n",
    "nulls = data.isnull().sum()\n",
    "nulls[nulls > 0]\n",
    "print(nulls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47032, 47)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OP_CARRIER</th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>DEST</th>\n",
       "      <th>DEP_DELAY</th>\n",
       "      <th>TAXI_OUT</th>\n",
       "      <th>TAXI_IN</th>\n",
       "      <th>ARR_DELAY</th>\n",
       "      <th>CANCELLED</th>\n",
       "      <th>DIVERTED</th>\n",
       "      <th>CRS_ELAPSED_TIME</th>\n",
       "      <th>...</th>\n",
       "      <th>CRS_ARR_MIN_sin</th>\n",
       "      <th>CRS_ARR_MIN_cos</th>\n",
       "      <th>ARR_TIME_HOUR_sin</th>\n",
       "      <th>ARR_TIME_HOUR_cos</th>\n",
       "      <th>ARR_TIME_MIN_sin</th>\n",
       "      <th>ARR_TIME_MIN_cos</th>\n",
       "      <th>FL_MONTH_sin</th>\n",
       "      <th>FL_MONTH_cos</th>\n",
       "      <th>FL_DAY_sin</th>\n",
       "      <th>FL_DAY_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OO</td>\n",
       "      <td>CWA</td>\n",
       "      <td>EAU</td>\n",
       "      <td>-206.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.978148</td>\n",
       "      <td>-0.207912</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>-0.104528</td>\n",
       "      <td>-0.994522</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.201299</td>\n",
       "      <td>0.979530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AS</td>\n",
       "      <td>YAK</td>\n",
       "      <td>JNU</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.309017</td>\n",
       "      <td>-0.951057</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>2.588190e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.101168</td>\n",
       "      <td>-0.994869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OO</td>\n",
       "      <td>RAP</td>\n",
       "      <td>SLC</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.104528</td>\n",
       "      <td>-0.994522</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "      <td>0.587785</td>\n",
       "      <td>0.809017</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.968077</td>\n",
       "      <td>-0.250653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OH</td>\n",
       "      <td>DCA</td>\n",
       "      <td>IND</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>7.071068e-01</td>\n",
       "      <td>0.951057</td>\n",
       "      <td>0.309017</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UA</td>\n",
       "      <td>JAC</td>\n",
       "      <td>DEN</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.587785</td>\n",
       "      <td>-0.809017</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>0.587785</td>\n",
       "      <td>0.809017</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  OP_CARRIER ORIGIN DEST  DEP_DELAY  TAXI_OUT  TAXI_IN  ARR_DELAY  CANCELLED  \\\n",
       "0         OO    CWA  EAU     -206.0      15.0      5.0     -192.0        0.0   \n",
       "1         AS    YAK  JNU      -23.0       4.0      4.0      -33.0        0.0   \n",
       "2         OO    RAP  SLC      -21.0      16.0      6.0      -25.0        0.0   \n",
       "3         OH    DCA  IND      -20.0       7.0      8.0      -48.0        0.0   \n",
       "4         UA    JAC  DEN      -19.0      14.0      5.0      -30.0        0.0   \n",
       "\n",
       "   DIVERTED  CRS_ELAPSED_TIME  ...  CRS_ARR_MIN_sin  CRS_ARR_MIN_cos  \\\n",
       "0       0.0              38.0  ...        -0.978148        -0.207912   \n",
       "1       0.0              48.0  ...        -0.309017        -0.951057   \n",
       "2       0.0             106.0  ...        -0.104528        -0.994522   \n",
       "3       0.0             120.0  ...         0.000000         1.000000   \n",
       "4       0.0              90.0  ...        -0.587785        -0.809017   \n",
       "\n",
       "   ARR_TIME_HOUR_sin  ARR_TIME_HOUR_cos  ARR_TIME_MIN_sin  ARR_TIME_MIN_cos  \\\n",
       "0          -0.866025       5.000000e-01         -0.104528         -0.994522   \n",
       "1          -0.965926       2.588190e-01          0.000000          1.000000   \n",
       "2          -1.000000      -1.836970e-16          0.587785          0.809017   \n",
       "3          -0.707107       7.071068e-01          0.951057          0.309017   \n",
       "4          -0.866025      -5.000000e-01          0.587785          0.809017   \n",
       "\n",
       "   FL_MONTH_sin  FL_MONTH_cos  FL_DAY_sin  FL_DAY_cos  \n",
       "0 -5.000000e-01      0.866025   -0.201299    0.979530  \n",
       "1  5.000000e-01     -0.866025    0.101168   -0.994869  \n",
       "2  5.000000e-01      0.866025    0.968077   -0.250653  \n",
       "3  0.000000e+00      1.000000    0.000000    1.000000  \n",
       "4  1.224647e-16     -1.000000    0.000000    1.000000  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# since all the values of the column \"CANCELLATION_CODE\" are null, we can drop this column\n",
    "data = data.drop(columns=['CANCELLATION_CODE'])\n",
    "# FL_DATE column already split and handled, so dropping it\n",
    "data = data.drop(columns=['FL_DATE'])\n",
    "# OP_CARRIER_FL_NUM is the flight number, so dropping it\n",
    "data = data.drop(columns=['OP_CARRIER_FL_NUM'])\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['OP_CARRIER', 'ORIGIN', 'DEST', 'DEP_DELAY', 'TAXI_OUT', 'TAXI_IN',\n",
       "       'ARR_DELAY', 'CANCELLED', 'DIVERTED', 'CRS_ELAPSED_TIME',\n",
       "       'ACTUAL_ELAPSED_TIME', 'AIR_TIME', 'DISTANCE', 'CARRIER_DELAY',\n",
       "       'WEATHER_DELAY', 'NAS_DELAY', 'SECURITY_DELAY', 'LATE_AIRCRAFT_DELAY',\n",
       "       'FL_YEAR', 'CRS_DEP_HOUR_sin', 'CRS_DEP_HOUR_cos', 'CRS_DEP_MIN_sin',\n",
       "       'CRS_DEP_MIN_cos', 'DEP_TIME_HOUR_sin', 'DEP_TIME_HOUR_cos',\n",
       "       'DEP_TIME_MIN_sin', 'DEP_TIME_MIN_cos', 'WHEELS_OFF_HOUR_sin',\n",
       "       'WHEELS_OFF_HOUR_cos', 'WHEELS_OFF_MIN_sin', 'WHEELS_OFF_MIN_cos',\n",
       "       'WHEELS_ON_HOUR_sin', 'WHEELS_ON_HOUR_cos', 'WHEELS_ON_MIN_sin',\n",
       "       'WHEELS_ON_MIN_cos', 'CRS_ARR_HOUR_sin', 'CRS_ARR_HOUR_cos',\n",
       "       'CRS_ARR_MIN_sin', 'CRS_ARR_MIN_cos', 'ARR_TIME_HOUR_sin',\n",
       "       'ARR_TIME_HOUR_cos', 'ARR_TIME_MIN_sin', 'ARR_TIME_MIN_cos',\n",
       "       'FL_MONTH_sin', 'FL_MONTH_cos', 'FL_DAY_sin', 'FL_DAY_cos'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=['DEP_DELAY'])\n",
    "y = data['DEP_DELAY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoding for OP_CARRIER, ORIGIN, DEST\n",
    "label_encoder_op_carrier = LabelEncoder()\n",
    "label_encoder_origin = LabelEncoder()\n",
    "label_encoder_dest = LabelEncoder()\n",
    "X['OP_CARRIER'] = label_encoder_op_carrier.fit_transform(X['OP_CARRIER'])\n",
    "X['ORIGIN'] = label_encoder_origin.fit_transform(X['ORIGIN'])\n",
    "X['DEST'] = label_encoder_dest.fit_transform(X['DEST'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37625, 46)\n",
      "(9407, 46)\n",
      "(37625,)\n",
      "(9407,)\n"
     ]
    }
   ],
   "source": [
    "# splitting dataset into training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting dataframe to numpy array\n",
    "X_train = X_train.to_numpy()\n",
    "X_test = X_test.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "y_test = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardization of data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "y_test = y_test.reshape(-1, 1)\n",
    "y_train = scaler.fit_transform(y_train)\n",
    "y_test = scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting numpy arrays to tensors\n",
    "X_train = torch.from_numpy(X_train)\n",
    "X_test = torch.from_numpy(X_test)\n",
    "y_train = torch.from_numpy(y_train)\n",
    "y_test = torch.from_numpy(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to float32\n",
    "X_train = X_train.float()\n",
    "X_test = X_test.float()\n",
    "y_train = y_train.float()\n",
    "y_test = y_test.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move tensors to GPU if CUDA is available\n",
    "X_train = X_train.to(device)\n",
    "X_test = X_test.to(device)\n",
    "y_train = y_train.to(device)\n",
    "y_test = y_test.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_features = X_train.shape[1]\n",
    "num_of_epochs = 50\n",
    "learning_rate = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch: 1/37625 (0.003%), Loss: 0.7531\n",
      "Epoch: 1, Batch: 257/37625 (0.683%), Loss: 2.1716\n",
      "Epoch: 1, Batch: 513/37625 (1.363%), Loss: 0.7550\n",
      "Epoch: 1, Batch: 769/37625 (2.044%), Loss: 0.7654\n",
      "Epoch: 1, Batch: 1025/37625 (2.724%), Loss: 0.7176\n",
      "Epoch: 1, Batch: 1281/37625 (3.405%), Loss: 2.2964\n",
      "Epoch: 1, Batch: 1537/37625 (4.085%), Loss: 1.3421\n",
      "Epoch: 1, Batch: 1793/37625 (4.765%), Loss: 0.6744\n",
      "Epoch: 1, Batch: 2049/37625 (5.446%), Loss: 0.8329\n",
      "Epoch: 1, Batch: 2305/37625 (6.126%), Loss: 1.0550\n",
      "Epoch: 1, Batch: 2561/37625 (6.807%), Loss: 0.7967\n",
      "Epoch: 1, Batch: 2817/37625 (7.487%), Loss: 0.9537\n",
      "Epoch: 1, Batch: 3073/37625 (8.167%), Loss: 0.7640\n",
      "Epoch: 1, Batch: 3329/37625 (8.848%), Loss: 1.1554\n",
      "Epoch: 1, Batch: 3585/37625 (9.528%), Loss: 4.2511\n",
      "Epoch: 1, Batch: 3841/37625 (10.209%), Loss: 0.5564\n",
      "Epoch: 1, Batch: 4097/37625 (10.889%), Loss: 0.5779\n",
      "Epoch: 1, Batch: 4353/37625 (11.569%), Loss: 0.9957\n",
      "Epoch: 1, Batch: 4609/37625 (12.250%), Loss: 0.8405\n",
      "Epoch: 1, Batch: 4865/37625 (12.930%), Loss: 0.7491\n",
      "Epoch: 1, Batch: 5121/37625 (13.611%), Loss: 1.4480\n",
      "Epoch: 1, Batch: 5377/37625 (14.291%), Loss: 0.6869\n",
      "Epoch: 1, Batch: 5633/37625 (14.971%), Loss: 0.9412\n",
      "Epoch: 1, Batch: 5889/37625 (15.652%), Loss: 0.9944\n",
      "Epoch: 1, Batch: 6145/37625 (16.332%), Loss: 0.8078\n",
      "Epoch 00026: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch: 1, Batch: 6401/37625 (17.013%), Loss: 0.8118\n",
      "Epoch: 1, Batch: 6657/37625 (17.693%), Loss: 0.7170\n",
      "Epoch: 1, Batch: 6913/37625 (18.373%), Loss: 3.1607\n",
      "Epoch: 1, Batch: 7169/37625 (19.054%), Loss: 1.3386\n",
      "Epoch: 1, Batch: 7425/37625 (19.734%), Loss: 1.1465\n",
      "Epoch: 1, Batch: 7681/37625 (20.415%), Loss: 0.7549\n",
      "Epoch: 1, Batch: 7937/37625 (21.095%), Loss: 0.8517\n",
      "Epoch: 1, Batch: 8193/37625 (21.775%), Loss: 1.0049\n",
      "Epoch: 1, Batch: 8449/37625 (22.456%), Loss: 1.6124\n",
      "Epoch: 1, Batch: 8705/37625 (23.136%), Loss: 1.3313\n",
      "Epoch: 1, Batch: 8961/37625 (23.817%), Loss: 0.8281\n",
      "Epoch 00037: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch: 1, Batch: 9217/37625 (24.497%), Loss: 1.0499\n",
      "Epoch: 1, Batch: 9473/37625 (25.177%), Loss: 0.9268\n",
      "Epoch: 1, Batch: 9729/37625 (25.858%), Loss: 0.7823\n",
      "Epoch: 1, Batch: 9985/37625 (26.538%), Loss: 1.7446\n",
      "Epoch: 1, Batch: 10241/37625 (27.219%), Loss: 0.9077\n",
      "Epoch: 1, Batch: 10497/37625 (27.899%), Loss: 0.6421\n",
      "Epoch: 1, Batch: 10753/37625 (28.579%), Loss: 0.8739\n",
      "Epoch: 1, Batch: 11009/37625 (29.260%), Loss: 0.6508\n",
      "Epoch: 1, Batch: 11265/37625 (29.940%), Loss: 1.0111\n",
      "Epoch: 1, Batch: 11521/37625 (30.621%), Loss: 1.0696\n",
      "Epoch: 1, Batch: 11777/37625 (31.301%), Loss: 0.7431\n",
      "Epoch 00048: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch: 1, Batch: 12033/37625 (31.981%), Loss: 0.7646\n",
      "Epoch: 1, Batch: 12289/37625 (32.662%), Loss: 1.2434\n",
      "Epoch: 1, Batch: 12545/37625 (33.342%), Loss: 0.8103\n",
      "Epoch: 1, Batch: 12801/37625 (34.023%), Loss: 0.8837\n",
      "Epoch: 1, Batch: 13057/37625 (34.703%), Loss: 0.8307\n",
      "Epoch: 1, Batch: 13313/37625 (35.383%), Loss: 0.6088\n",
      "Epoch: 1, Batch: 13569/37625 (36.064%), Loss: 0.9936\n",
      "Epoch: 1, Batch: 13825/37625 (36.744%), Loss: 0.7370\n",
      "Epoch: 1, Batch: 14081/37625 (37.425%), Loss: 0.9854\n",
      "Epoch: 1, Batch: 14337/37625 (38.105%), Loss: 1.0101\n",
      "Epoch: 1, Batch: 14593/37625 (38.785%), Loss: 1.4228\n",
      "Epoch: 1, Batch: 14849/37625 (39.466%), Loss: 1.0988\n",
      "Epoch: 1, Batch: 15105/37625 (40.146%), Loss: 3.5037\n",
      "Epoch: 1, Batch: 15361/37625 (40.827%), Loss: 0.8790\n",
      "Epoch: 1, Batch: 15617/37625 (41.507%), Loss: 1.2925\n",
      "Epoch: 1, Batch: 15873/37625 (42.187%), Loss: 1.1878\n",
      "Epoch: 1, Batch: 16129/37625 (42.868%), Loss: 0.6558\n",
      "Epoch: 1, Batch: 16385/37625 (43.548%), Loss: 0.7901\n",
      "Epoch: 1, Batch: 16641/37625 (44.229%), Loss: 0.9496\n",
      "Epoch: 1, Batch: 16897/37625 (44.909%), Loss: 1.0251\n",
      "Epoch: 1, Batch: 17153/37625 (45.589%), Loss: 1.6332\n",
      "Epoch: 1, Batch: 17409/37625 (46.270%), Loss: 0.6481\n",
      "Epoch: 1, Batch: 17665/37625 (46.950%), Loss: 0.5399\n",
      "Epoch: 1, Batch: 17921/37625 (47.631%), Loss: 0.6240\n",
      "Epoch: 1, Batch: 18177/37625 (48.311%), Loss: 1.4857\n",
      "Epoch: 1, Batch: 18433/37625 (48.991%), Loss: 0.6783\n",
      "Epoch: 1, Batch: 18689/37625 (49.672%), Loss: 0.7534\n",
      "Epoch: 1, Batch: 18945/37625 (50.352%), Loss: 0.5039\n",
      "Epoch: 1, Batch: 19201/37625 (51.033%), Loss: 0.7242\n",
      "Epoch: 1, Batch: 19457/37625 (51.713%), Loss: 0.9706\n",
      "Epoch: 1, Batch: 19713/37625 (52.393%), Loss: 1.8439\n",
      "Epoch: 1, Batch: 19969/37625 (53.074%), Loss: 1.0448\n",
      "Epoch: 1, Batch: 20225/37625 (53.754%), Loss: 1.4358\n",
      "Epoch: 1, Batch: 20481/37625 (54.435%), Loss: 5.0282\n",
      "Epoch: 1, Batch: 20737/37625 (55.115%), Loss: 1.2337\n",
      "Epoch: 1, Batch: 20993/37625 (55.795%), Loss: 0.5544\n",
      "Epoch: 1, Batch: 21249/37625 (56.476%), Loss: 0.9917\n",
      "Epoch: 1, Batch: 21505/37625 (57.156%), Loss: 0.7505\n",
      "Epoch: 1, Batch: 21761/37625 (57.837%), Loss: 0.6745\n",
      "Epoch: 1, Batch: 22017/37625 (58.517%), Loss: 0.9662\n",
      "Epoch: 1, Batch: 22273/37625 (59.197%), Loss: 0.8401\n",
      "Epoch: 1, Batch: 22529/37625 (59.878%), Loss: 0.9787\n",
      "Epoch: 1, Batch: 22785/37625 (60.558%), Loss: 0.7804\n",
      "Epoch: 1, Batch: 23041/37625 (61.239%), Loss: 0.9918\n",
      "Epoch: 1, Batch: 23297/37625 (61.919%), Loss: 0.8118\n",
      "Epoch: 1, Batch: 23553/37625 (62.599%), Loss: 0.8817\n",
      "Epoch: 1, Batch: 23809/37625 (63.280%), Loss: 0.6610\n",
      "Epoch: 1, Batch: 24065/37625 (63.960%), Loss: 2.3846\n",
      "Epoch: 1, Batch: 24321/37625 (64.641%), Loss: 0.8029\n",
      "Epoch: 1, Batch: 24577/37625 (65.321%), Loss: 0.9281\n",
      "Epoch: 1, Batch: 24833/37625 (66.001%), Loss: 1.0589\n",
      "Epoch: 1, Batch: 25089/37625 (66.682%), Loss: 1.0180\n",
      "Epoch: 1, Batch: 25345/37625 (67.362%), Loss: 0.7175\n",
      "Epoch: 1, Batch: 25601/37625 (68.043%), Loss: 2.6111\n",
      "Epoch: 1, Batch: 25857/37625 (68.723%), Loss: 1.4681\n",
      "Epoch: 1, Batch: 26113/37625 (69.403%), Loss: 1.9055\n",
      "Epoch: 1, Batch: 26369/37625 (70.084%), Loss: 0.7670\n",
      "Epoch: 1, Batch: 26625/37625 (70.764%), Loss: 0.8316\n",
      "Epoch: 1, Batch: 26881/37625 (71.445%), Loss: 0.8430\n",
      "Epoch: 1, Batch: 27137/37625 (72.125%), Loss: 1.1574\n",
      "Epoch: 1, Batch: 27393/37625 (72.805%), Loss: 1.5354\n",
      "Epoch: 1, Batch: 27649/37625 (73.486%), Loss: 2.4076\n",
      "Epoch: 1, Batch: 27905/37625 (74.166%), Loss: 1.7429\n",
      "Epoch: 1, Batch: 28161/37625 (74.847%), Loss: 0.8174\n",
      "Epoch: 1, Batch: 28417/37625 (75.527%), Loss: 1.2390\n",
      "Epoch: 1, Batch: 28673/37625 (76.207%), Loss: 0.8116\n",
      "Epoch: 1, Batch: 28929/37625 (76.888%), Loss: 0.7942\n",
      "Epoch: 1, Batch: 29185/37625 (77.568%), Loss: 1.0879\n",
      "Epoch: 1, Batch: 29441/37625 (78.249%), Loss: 0.6267\n",
      "Epoch: 1, Batch: 29697/37625 (78.929%), Loss: 1.1748\n",
      "Epoch: 1, Batch: 29953/37625 (79.609%), Loss: 0.7534\n",
      "Epoch: 1, Batch: 30209/37625 (80.290%), Loss: 0.9452\n",
      "Epoch: 1, Batch: 30465/37625 (80.970%), Loss: 0.6892\n",
      "Epoch: 1, Batch: 30721/37625 (81.650%), Loss: 0.8757\n",
      "Epoch: 1, Batch: 30977/37625 (82.331%), Loss: 0.9343\n",
      "Epoch: 1, Batch: 31233/37625 (83.011%), Loss: 0.8090\n",
      "Epoch: 1, Batch: 31489/37625 (83.692%), Loss: 0.7439\n",
      "Epoch: 1, Batch: 31745/37625 (84.372%), Loss: 1.0612\n",
      "Epoch: 1, Batch: 32001/37625 (85.052%), Loss: 0.9054\n",
      "Epoch: 1, Batch: 32257/37625 (85.733%), Loss: 0.9285\n",
      "Epoch: 1, Batch: 32513/37625 (86.413%), Loss: 0.9404\n",
      "Epoch: 1, Batch: 32769/37625 (87.094%), Loss: 1.8905\n",
      "Epoch: 1, Batch: 33025/37625 (87.774%), Loss: 1.4221\n",
      "Epoch: 1, Batch: 33281/37625 (88.454%), Loss: 0.9164\n",
      "Epoch: 1, Batch: 33537/37625 (89.135%), Loss: 6.0995\n",
      "Epoch: 1, Batch: 33793/37625 (89.815%), Loss: 0.8267\n",
      "Epoch: 1, Batch: 34049/37625 (90.496%), Loss: 0.5869\n",
      "Epoch: 1, Batch: 34305/37625 (91.176%), Loss: 1.1488\n",
      "Epoch: 1, Batch: 34561/37625 (91.856%), Loss: 0.6282\n",
      "Epoch: 1, Batch: 34817/37625 (92.537%), Loss: 1.1828\n",
      "Epoch: 1, Batch: 35073/37625 (93.217%), Loss: 0.7223\n",
      "Epoch: 1, Batch: 35329/37625 (93.898%), Loss: 0.7523\n",
      "Epoch: 1, Batch: 35585/37625 (94.578%), Loss: 0.8636\n",
      "Epoch: 1, Batch: 35841/37625 (95.258%), Loss: 0.6129\n",
      "Epoch: 1, Batch: 36097/37625 (95.939%), Loss: 0.8721\n",
      "Epoch: 1, Batch: 36353/37625 (96.619%), Loss: 0.9363\n",
      "Epoch: 1, Batch: 36609/37625 (97.300%), Loss: 0.7775\n",
      "Epoch: 1, Batch: 36865/37625 (97.980%), Loss: 0.9944\n",
      "Epoch: 1, Batch: 37121/37625 (98.660%), Loss: 0.7275\n",
      "Epoch: 1, Batch: 37377/37625 (99.341%), Loss: 0.9516\n",
      "Epoch: 2, Batch: 1/37625 (0.003%), Loss: 0.5516\n",
      "Epoch: 2, Batch: 257/37625 (0.683%), Loss: 0.8462\n",
      "Epoch: 2, Batch: 513/37625 (1.363%), Loss: 0.7445\n",
      "Epoch: 2, Batch: 769/37625 (2.044%), Loss: 1.4298\n",
      "Epoch: 2, Batch: 1025/37625 (2.724%), Loss: 1.4019\n",
      "Epoch: 2, Batch: 1281/37625 (3.405%), Loss: 0.5974\n",
      "Epoch: 2, Batch: 1537/37625 (4.085%), Loss: 1.7261\n",
      "Epoch: 2, Batch: 1793/37625 (4.765%), Loss: 0.7328\n",
      "Epoch: 2, Batch: 2049/37625 (5.446%), Loss: 0.9660\n",
      "Epoch: 2, Batch: 2305/37625 (6.126%), Loss: 0.6296\n",
      "Epoch: 2, Batch: 2561/37625 (6.807%), Loss: 3.6537\n",
      "Epoch: 2, Batch: 2817/37625 (7.487%), Loss: 2.6053\n",
      "Epoch: 2, Batch: 3073/37625 (8.167%), Loss: 0.8596\n",
      "Epoch: 2, Batch: 3329/37625 (8.848%), Loss: 0.8226\n",
      "Epoch: 2, Batch: 3585/37625 (9.528%), Loss: 0.7125\n",
      "Epoch: 2, Batch: 3841/37625 (10.209%), Loss: 1.1194\n",
      "Epoch: 2, Batch: 4097/37625 (10.889%), Loss: 0.9568\n",
      "Epoch: 2, Batch: 4353/37625 (11.569%), Loss: 0.9343\n",
      "Epoch: 2, Batch: 4609/37625 (12.250%), Loss: 0.8009\n",
      "Epoch: 2, Batch: 4865/37625 (12.930%), Loss: 0.8564\n",
      "Epoch: 2, Batch: 5121/37625 (13.611%), Loss: 0.7577\n",
      "Epoch: 2, Batch: 5377/37625 (14.291%), Loss: 0.9310\n",
      "Epoch: 2, Batch: 5633/37625 (14.971%), Loss: 0.8314\n",
      "Epoch: 2, Batch: 5889/37625 (15.652%), Loss: 0.8232\n",
      "Epoch: 2, Batch: 6145/37625 (16.332%), Loss: 0.6365\n",
      "Epoch: 2, Batch: 6401/37625 (17.013%), Loss: 1.0409\n",
      "Epoch: 2, Batch: 6657/37625 (17.693%), Loss: 0.7518\n",
      "Epoch: 2, Batch: 6913/37625 (18.373%), Loss: 0.6461\n",
      "Epoch: 2, Batch: 7169/37625 (19.054%), Loss: 1.6394\n",
      "Epoch: 2, Batch: 7425/37625 (19.734%), Loss: 0.7856\n",
      "Epoch: 2, Batch: 7681/37625 (20.415%), Loss: 0.9223\n",
      "Epoch: 2, Batch: 7937/37625 (21.095%), Loss: 0.7426\n",
      "Epoch: 2, Batch: 8193/37625 (21.775%), Loss: 0.9610\n",
      "Epoch: 2, Batch: 8449/37625 (22.456%), Loss: 1.0881\n",
      "Epoch: 2, Batch: 8705/37625 (23.136%), Loss: 0.6677\n",
      "Epoch: 2, Batch: 8961/37625 (23.817%), Loss: 1.0613\n",
      "Epoch: 2, Batch: 9217/37625 (24.497%), Loss: 0.6042\n",
      "Epoch: 2, Batch: 9473/37625 (25.177%), Loss: 1.0074\n",
      "Epoch: 2, Batch: 9729/37625 (25.858%), Loss: 0.6621\n",
      "Epoch: 2, Batch: 9985/37625 (26.538%), Loss: 1.8677\n",
      "Epoch: 2, Batch: 10241/37625 (27.219%), Loss: 0.7193\n",
      "Epoch: 2, Batch: 10497/37625 (27.899%), Loss: 0.8540\n",
      "Epoch: 2, Batch: 10753/37625 (28.579%), Loss: 1.0952\n",
      "Epoch: 2, Batch: 11009/37625 (29.260%), Loss: 0.7129\n",
      "Epoch: 2, Batch: 11265/37625 (29.940%), Loss: 1.2997\n",
      "Epoch: 2, Batch: 11521/37625 (30.621%), Loss: 0.5216\n",
      "Epoch: 2, Batch: 11777/37625 (31.301%), Loss: 0.9014\n",
      "Epoch: 2, Batch: 12033/37625 (31.981%), Loss: 4.8782\n",
      "Epoch: 2, Batch: 12289/37625 (32.662%), Loss: 0.5681\n",
      "Epoch: 2, Batch: 12545/37625 (33.342%), Loss: 0.6609\n",
      "Epoch: 2, Batch: 12801/37625 (34.023%), Loss: 0.9213\n",
      "Epoch: 2, Batch: 13057/37625 (34.703%), Loss: 5.1902\n",
      "Epoch: 2, Batch: 13313/37625 (35.383%), Loss: 0.9391\n",
      "Epoch: 2, Batch: 13569/37625 (36.064%), Loss: 0.7626\n",
      "Epoch: 2, Batch: 13825/37625 (36.744%), Loss: 0.9025\n",
      "Epoch: 2, Batch: 14081/37625 (37.425%), Loss: 1.2286\n",
      "Epoch: 2, Batch: 14337/37625 (38.105%), Loss: 0.7795\n",
      "Epoch: 2, Batch: 14593/37625 (38.785%), Loss: 1.1144\n",
      "Epoch: 2, Batch: 14849/37625 (39.466%), Loss: 1.0787\n",
      "Epoch: 2, Batch: 15105/37625 (40.146%), Loss: 1.4711\n",
      "Epoch: 2, Batch: 15361/37625 (40.827%), Loss: 1.0723\n",
      "Epoch: 2, Batch: 15617/37625 (41.507%), Loss: 0.8896\n",
      "Epoch: 2, Batch: 15873/37625 (42.187%), Loss: 1.3753\n",
      "Epoch: 2, Batch: 16129/37625 (42.868%), Loss: 1.1169\n",
      "Epoch: 2, Batch: 16385/37625 (43.548%), Loss: 0.5881\n",
      "Epoch: 2, Batch: 16641/37625 (44.229%), Loss: 1.1107\n",
      "Epoch: 2, Batch: 16897/37625 (44.909%), Loss: 0.5413\n",
      "Epoch: 2, Batch: 17153/37625 (45.589%), Loss: 0.7695\n",
      "Epoch: 2, Batch: 17409/37625 (46.270%), Loss: 1.1095\n",
      "Epoch: 2, Batch: 17665/37625 (46.950%), Loss: 1.9475\n",
      "Epoch: 2, Batch: 17921/37625 (47.631%), Loss: 0.8869\n",
      "Epoch: 2, Batch: 18177/37625 (48.311%), Loss: 0.8507\n",
      "Epoch: 2, Batch: 18433/37625 (48.991%), Loss: 0.6199\n",
      "Epoch: 2, Batch: 18689/37625 (49.672%), Loss: 0.6763\n",
      "Epoch: 2, Batch: 18945/37625 (50.352%), Loss: 0.7001\n",
      "Epoch: 2, Batch: 19201/37625 (51.033%), Loss: 0.7725\n",
      "Epoch: 2, Batch: 19457/37625 (51.713%), Loss: 1.1096\n",
      "Epoch: 2, Batch: 19713/37625 (52.393%), Loss: 1.2149\n",
      "Epoch: 2, Batch: 19969/37625 (53.074%), Loss: 0.8059\n",
      "Epoch: 2, Batch: 20225/37625 (53.754%), Loss: 2.0897\n",
      "Epoch: 2, Batch: 20481/37625 (54.435%), Loss: 2.1952\n",
      "Epoch: 2, Batch: 20737/37625 (55.115%), Loss: 0.7248\n",
      "Epoch: 2, Batch: 20993/37625 (55.795%), Loss: 1.0042\n",
      "Epoch: 2, Batch: 21249/37625 (56.476%), Loss: 1.4297\n",
      "Epoch: 2, Batch: 21505/37625 (57.156%), Loss: 1.3953\n",
      "Epoch: 2, Batch: 21761/37625 (57.837%), Loss: 0.6276\n",
      "Epoch: 2, Batch: 22017/37625 (58.517%), Loss: 1.5393\n",
      "Epoch: 2, Batch: 22273/37625 (59.197%), Loss: 1.1742\n",
      "Epoch: 2, Batch: 22529/37625 (59.878%), Loss: 0.8933\n",
      "Epoch: 2, Batch: 22785/37625 (60.558%), Loss: 1.3435\n",
      "Epoch: 2, Batch: 23041/37625 (61.239%), Loss: 0.8506\n",
      "Epoch: 2, Batch: 23297/37625 (61.919%), Loss: 0.9985\n",
      "Epoch: 2, Batch: 23553/37625 (62.599%), Loss: 1.0181\n",
      "Epoch: 2, Batch: 23809/37625 (63.280%), Loss: 1.1376\n",
      "Epoch: 2, Batch: 24065/37625 (63.960%), Loss: 0.7086\n",
      "Epoch: 2, Batch: 24321/37625 (64.641%), Loss: 0.6668\n",
      "Epoch: 2, Batch: 24577/37625 (65.321%), Loss: 0.7893\n",
      "Epoch: 2, Batch: 24833/37625 (66.001%), Loss: 0.6026\n",
      "Epoch: 2, Batch: 25089/37625 (66.682%), Loss: 1.7286\n",
      "Epoch: 2, Batch: 25345/37625 (67.362%), Loss: 3.4536\n",
      "Epoch: 2, Batch: 25601/37625 (68.043%), Loss: 0.7660\n",
      "Epoch: 2, Batch: 25857/37625 (68.723%), Loss: 0.7416\n",
      "Epoch: 2, Batch: 26113/37625 (69.403%), Loss: 0.6234\n",
      "Epoch: 2, Batch: 26369/37625 (70.084%), Loss: 0.7728\n",
      "Epoch: 2, Batch: 26625/37625 (70.764%), Loss: 0.7908\n",
      "Epoch: 2, Batch: 26881/37625 (71.445%), Loss: 0.7486\n",
      "Epoch: 2, Batch: 27137/37625 (72.125%), Loss: 0.9918\n",
      "Epoch: 2, Batch: 27393/37625 (72.805%), Loss: 0.6392\n",
      "Epoch: 2, Batch: 27649/37625 (73.486%), Loss: 1.3960\n",
      "Epoch: 2, Batch: 27905/37625 (74.166%), Loss: 5.8053\n",
      "Epoch: 2, Batch: 28161/37625 (74.847%), Loss: 0.7593\n",
      "Epoch: 2, Batch: 28417/37625 (75.527%), Loss: 0.8518\n",
      "Epoch: 2, Batch: 28673/37625 (76.207%), Loss: 0.8521\n",
      "Epoch: 2, Batch: 28929/37625 (76.888%), Loss: 0.8343\n",
      "Epoch: 2, Batch: 29185/37625 (77.568%), Loss: 0.6957\n",
      "Epoch: 2, Batch: 29441/37625 (78.249%), Loss: 0.5940\n",
      "Epoch: 2, Batch: 29697/37625 (78.929%), Loss: 0.5267\n",
      "Epoch: 2, Batch: 29953/37625 (79.609%), Loss: 1.4803\n",
      "Epoch: 2, Batch: 30209/37625 (80.290%), Loss: 0.9311\n",
      "Epoch: 2, Batch: 30465/37625 (80.970%), Loss: 1.7542\n",
      "Epoch: 2, Batch: 30721/37625 (81.650%), Loss: 1.1561\n",
      "Epoch: 2, Batch: 30977/37625 (82.331%), Loss: 0.8933\n",
      "Epoch: 2, Batch: 31233/37625 (83.011%), Loss: 1.1898\n",
      "Epoch: 2, Batch: 31489/37625 (83.692%), Loss: 0.6137\n",
      "Epoch: 2, Batch: 31745/37625 (84.372%), Loss: 0.9825\n",
      "Epoch: 2, Batch: 32001/37625 (85.052%), Loss: 2.1562\n",
      "Epoch: 2, Batch: 32257/37625 (85.733%), Loss: 1.7907\n",
      "Epoch: 2, Batch: 32513/37625 (86.413%), Loss: 0.6627\n",
      "Epoch: 2, Batch: 32769/37625 (87.094%), Loss: 0.6826\n",
      "Epoch: 2, Batch: 33025/37625 (87.774%), Loss: 0.8327\n",
      "Epoch: 2, Batch: 33281/37625 (88.454%), Loss: 0.5734\n",
      "Epoch: 2, Batch: 33537/37625 (89.135%), Loss: 0.5718\n",
      "Epoch: 2, Batch: 33793/37625 (89.815%), Loss: 0.9914\n",
      "Epoch: 2, Batch: 34049/37625 (90.496%), Loss: 0.8364\n",
      "Epoch: 2, Batch: 34305/37625 (91.176%), Loss: 1.0244\n",
      "Epoch: 2, Batch: 34561/37625 (91.856%), Loss: 0.8731\n",
      "Epoch: 2, Batch: 34817/37625 (92.537%), Loss: 1.2648\n",
      "Epoch: 2, Batch: 35073/37625 (93.217%), Loss: 0.7302\n",
      "Epoch: 2, Batch: 35329/37625 (93.898%), Loss: 0.6435\n",
      "Epoch: 2, Batch: 35585/37625 (94.578%), Loss: 1.0907\n",
      "Epoch: 2, Batch: 35841/37625 (95.258%), Loss: 0.8463\n",
      "Epoch: 2, Batch: 36097/37625 (95.939%), Loss: 2.4970\n",
      "Epoch: 2, Batch: 36353/37625 (96.619%), Loss: 0.9726\n",
      "Epoch: 2, Batch: 36609/37625 (97.300%), Loss: 1.7086\n",
      "Epoch: 2, Batch: 36865/37625 (97.980%), Loss: 1.1987\n",
      "Epoch: 2, Batch: 37121/37625 (98.660%), Loss: 0.9521\n",
      "Epoch: 2, Batch: 37377/37625 (99.341%), Loss: 0.9790\n",
      "Epoch: 3, Batch: 1/37625 (0.003%), Loss: 1.6659\n",
      "Epoch: 3, Batch: 257/37625 (0.683%), Loss: 0.7952\n",
      "Epoch: 3, Batch: 513/37625 (1.363%), Loss: 0.6519\n",
      "Epoch: 3, Batch: 769/37625 (2.044%), Loss: 2.0734\n",
      "Epoch: 3, Batch: 1025/37625 (2.724%), Loss: 1.0459\n",
      "Epoch: 3, Batch: 1281/37625 (3.405%), Loss: 0.7023\n",
      "Epoch: 3, Batch: 1537/37625 (4.085%), Loss: 0.8561\n",
      "Epoch: 3, Batch: 1793/37625 (4.765%), Loss: 0.7672\n",
      "Epoch: 3, Batch: 2049/37625 (5.446%), Loss: 0.7912\n",
      "Epoch: 3, Batch: 2305/37625 (6.126%), Loss: 0.7795\n",
      "Epoch: 3, Batch: 2561/37625 (6.807%), Loss: 1.3607\n",
      "Epoch: 3, Batch: 2817/37625 (7.487%), Loss: 0.6920\n",
      "Epoch: 3, Batch: 3073/37625 (8.167%), Loss: 1.1044\n",
      "Epoch: 3, Batch: 3329/37625 (8.848%), Loss: 1.4955\n",
      "Epoch: 3, Batch: 3585/37625 (9.528%), Loss: 0.9009\n",
      "Epoch: 3, Batch: 3841/37625 (10.209%), Loss: 1.4191\n",
      "Epoch: 3, Batch: 4097/37625 (10.889%), Loss: 0.8015\n",
      "Epoch: 3, Batch: 4353/37625 (11.569%), Loss: 1.2806\n",
      "Epoch: 3, Batch: 4609/37625 (12.250%), Loss: 1.8374\n",
      "Epoch: 3, Batch: 4865/37625 (12.930%), Loss: 5.0775\n",
      "Epoch: 3, Batch: 5121/37625 (13.611%), Loss: 0.7225\n",
      "Epoch: 3, Batch: 5377/37625 (14.291%), Loss: 1.0532\n",
      "Epoch: 3, Batch: 5633/37625 (14.971%), Loss: 1.7768\n",
      "Epoch: 3, Batch: 5889/37625 (15.652%), Loss: 0.7444\n",
      "Epoch: 3, Batch: 6145/37625 (16.332%), Loss: 0.6555\n",
      "Epoch: 3, Batch: 6401/37625 (17.013%), Loss: 2.3818\n",
      "Epoch: 3, Batch: 6657/37625 (17.693%), Loss: 0.6471\n",
      "Epoch: 3, Batch: 6913/37625 (18.373%), Loss: 0.7344\n",
      "Epoch: 3, Batch: 7169/37625 (19.054%), Loss: 0.8825\n",
      "Epoch: 3, Batch: 7425/37625 (19.734%), Loss: 1.2705\n",
      "Epoch: 3, Batch: 7681/37625 (20.415%), Loss: 5.3040\n",
      "Epoch: 3, Batch: 7937/37625 (21.095%), Loss: 1.0192\n",
      "Epoch: 3, Batch: 8193/37625 (21.775%), Loss: 3.1953\n",
      "Epoch: 3, Batch: 8449/37625 (22.456%), Loss: 0.8547\n",
      "Epoch: 3, Batch: 8705/37625 (23.136%), Loss: 2.4864\n",
      "Epoch: 3, Batch: 8961/37625 (23.817%), Loss: 1.1469\n",
      "Epoch: 3, Batch: 9217/37625 (24.497%), Loss: 0.9685\n",
      "Epoch: 3, Batch: 9473/37625 (25.177%), Loss: 0.8840\n",
      "Epoch: 3, Batch: 9729/37625 (25.858%), Loss: 1.3245\n",
      "Epoch: 3, Batch: 9985/37625 (26.538%), Loss: 1.0620\n",
      "Epoch: 3, Batch: 10241/37625 (27.219%), Loss: 0.8226\n",
      "Epoch: 3, Batch: 10497/37625 (27.899%), Loss: 0.6418\n",
      "Epoch: 3, Batch: 10753/37625 (28.579%), Loss: 1.0063\n",
      "Epoch: 3, Batch: 11009/37625 (29.260%), Loss: 0.8261\n",
      "Epoch: 3, Batch: 11265/37625 (29.940%), Loss: 1.1641\n",
      "Epoch: 3, Batch: 11521/37625 (30.621%), Loss: 0.6964\n",
      "Epoch: 3, Batch: 11777/37625 (31.301%), Loss: 0.7699\n",
      "Epoch: 3, Batch: 12033/37625 (31.981%), Loss: 0.9305\n",
      "Epoch: 3, Batch: 12289/37625 (32.662%), Loss: 0.7963\n",
      "Epoch: 3, Batch: 12545/37625 (33.342%), Loss: 1.4686\n",
      "Epoch: 3, Batch: 12801/37625 (34.023%), Loss: 0.6699\n",
      "Epoch: 3, Batch: 13057/37625 (34.703%), Loss: 0.6256\n",
      "Epoch: 3, Batch: 13313/37625 (35.383%), Loss: 1.0141\n",
      "Epoch: 3, Batch: 13569/37625 (36.064%), Loss: 1.3936\n",
      "Epoch: 3, Batch: 13825/37625 (36.744%), Loss: 1.1047\n",
      "Epoch: 3, Batch: 14081/37625 (37.425%), Loss: 0.7128\n",
      "Epoch: 3, Batch: 14337/37625 (38.105%), Loss: 0.7149\n",
      "Epoch: 3, Batch: 14593/37625 (38.785%), Loss: 0.7292\n",
      "Epoch: 3, Batch: 14849/37625 (39.466%), Loss: 0.7548\n",
      "Epoch: 3, Batch: 15105/37625 (40.146%), Loss: 4.2217\n",
      "Epoch: 3, Batch: 15361/37625 (40.827%), Loss: 0.6995\n",
      "Epoch: 3, Batch: 15617/37625 (41.507%), Loss: 1.0612\n",
      "Epoch: 3, Batch: 15873/37625 (42.187%), Loss: 1.0282\n",
      "Epoch: 3, Batch: 16129/37625 (42.868%), Loss: 2.7291\n",
      "Epoch: 3, Batch: 16385/37625 (43.548%), Loss: 1.0620\n",
      "Epoch: 3, Batch: 16641/37625 (44.229%), Loss: 1.5030\n",
      "Epoch: 3, Batch: 16897/37625 (44.909%), Loss: 0.9082\n",
      "Epoch: 3, Batch: 17153/37625 (45.589%), Loss: 0.5769\n",
      "Epoch: 3, Batch: 17409/37625 (46.270%), Loss: 1.2550\n",
      "Epoch: 3, Batch: 17665/37625 (46.950%), Loss: 3.4678\n",
      "Epoch: 3, Batch: 17921/37625 (47.631%), Loss: 1.3047\n",
      "Epoch: 3, Batch: 18177/37625 (48.311%), Loss: 1.2229\n",
      "Epoch: 3, Batch: 18433/37625 (48.991%), Loss: 0.6375\n",
      "Epoch: 3, Batch: 18689/37625 (49.672%), Loss: 0.5213\n",
      "Epoch: 3, Batch: 18945/37625 (50.352%), Loss: 1.3153\n",
      "Epoch: 3, Batch: 19201/37625 (51.033%), Loss: 0.6374\n",
      "Epoch: 3, Batch: 19457/37625 (51.713%), Loss: 0.8459\n",
      "Epoch: 3, Batch: 19713/37625 (52.393%), Loss: 0.6101\n",
      "Epoch: 3, Batch: 19969/37625 (53.074%), Loss: 1.3372\n",
      "Epoch: 3, Batch: 20225/37625 (53.754%), Loss: 0.6259\n",
      "Epoch: 3, Batch: 20481/37625 (54.435%), Loss: 0.8402\n",
      "Epoch: 3, Batch: 20737/37625 (55.115%), Loss: 0.8813\n",
      "Epoch: 3, Batch: 20993/37625 (55.795%), Loss: 1.0666\n",
      "Epoch: 3, Batch: 21249/37625 (56.476%), Loss: 0.8171\n",
      "Epoch: 3, Batch: 21505/37625 (57.156%), Loss: 1.2737\n",
      "Epoch: 3, Batch: 21761/37625 (57.837%), Loss: 0.6194\n",
      "Epoch: 3, Batch: 22017/37625 (58.517%), Loss: 0.9904\n",
      "Epoch: 3, Batch: 22273/37625 (59.197%), Loss: 0.9522\n",
      "Epoch: 3, Batch: 22529/37625 (59.878%), Loss: 0.8598\n",
      "Epoch: 3, Batch: 22785/37625 (60.558%), Loss: 0.6302\n",
      "Epoch: 3, Batch: 23041/37625 (61.239%), Loss: 0.7885\n",
      "Epoch: 3, Batch: 23297/37625 (61.919%), Loss: 0.5855\n",
      "Epoch: 3, Batch: 23553/37625 (62.599%), Loss: 1.9214\n",
      "Epoch: 3, Batch: 23809/37625 (63.280%), Loss: 0.8676\n",
      "Epoch: 3, Batch: 24065/37625 (63.960%), Loss: 0.6639\n",
      "Epoch: 3, Batch: 24321/37625 (64.641%), Loss: 0.7446\n",
      "Epoch: 3, Batch: 24577/37625 (65.321%), Loss: 0.6540\n",
      "Epoch: 3, Batch: 24833/37625 (66.001%), Loss: 0.6187\n",
      "Epoch: 3, Batch: 25089/37625 (66.682%), Loss: 0.9334\n",
      "Epoch: 3, Batch: 25345/37625 (67.362%), Loss: 1.8070\n",
      "Epoch: 3, Batch: 25601/37625 (68.043%), Loss: 0.6254\n",
      "Epoch: 3, Batch: 25857/37625 (68.723%), Loss: 0.9467\n",
      "Epoch: 3, Batch: 26113/37625 (69.403%), Loss: 0.9414\n",
      "Epoch: 3, Batch: 26369/37625 (70.084%), Loss: 0.6745\n",
      "Epoch: 3, Batch: 26625/37625 (70.764%), Loss: 0.7714\n",
      "Epoch: 3, Batch: 26881/37625 (71.445%), Loss: 1.0584\n",
      "Epoch: 3, Batch: 27137/37625 (72.125%), Loss: 0.8106\n",
      "Epoch: 3, Batch: 27393/37625 (72.805%), Loss: 0.7217\n",
      "Epoch: 3, Batch: 27649/37625 (73.486%), Loss: 1.0128\n",
      "Epoch: 3, Batch: 27905/37625 (74.166%), Loss: 0.5509\n",
      "Epoch: 3, Batch: 28161/37625 (74.847%), Loss: 0.4659\n",
      "Epoch: 3, Batch: 28417/37625 (75.527%), Loss: 0.8017\n",
      "Epoch: 3, Batch: 28673/37625 (76.207%), Loss: 1.1163\n",
      "Epoch: 3, Batch: 28929/37625 (76.888%), Loss: 0.8384\n",
      "Epoch: 3, Batch: 29185/37625 (77.568%), Loss: 0.8536\n",
      "Epoch: 3, Batch: 29441/37625 (78.249%), Loss: 1.0522\n",
      "Epoch: 3, Batch: 29697/37625 (78.929%), Loss: 1.0684\n",
      "Epoch: 3, Batch: 29953/37625 (79.609%), Loss: 0.6908\n",
      "Epoch: 3, Batch: 30209/37625 (80.290%), Loss: 0.9162\n",
      "Epoch: 3, Batch: 30465/37625 (80.970%), Loss: 0.6864\n",
      "Epoch: 3, Batch: 30721/37625 (81.650%), Loss: 0.5807\n",
      "Epoch: 3, Batch: 30977/37625 (82.331%), Loss: 0.5613\n",
      "Epoch: 3, Batch: 31233/37625 (83.011%), Loss: 0.8798\n",
      "Epoch: 3, Batch: 31489/37625 (83.692%), Loss: 1.7643\n",
      "Epoch: 3, Batch: 31745/37625 (84.372%), Loss: 0.7984\n",
      "Epoch: 3, Batch: 32001/37625 (85.052%), Loss: 2.4217\n",
      "Epoch: 3, Batch: 32257/37625 (85.733%), Loss: 1.7777\n",
      "Epoch: 3, Batch: 32513/37625 (86.413%), Loss: 0.8760\n",
      "Epoch: 3, Batch: 32769/37625 (87.094%), Loss: 1.0178\n",
      "Epoch: 3, Batch: 33025/37625 (87.774%), Loss: 1.7670\n",
      "Epoch: 3, Batch: 33281/37625 (88.454%), Loss: 0.7666\n",
      "Epoch: 3, Batch: 33537/37625 (89.135%), Loss: 0.5956\n",
      "Epoch: 3, Batch: 33793/37625 (89.815%), Loss: 1.3708\n",
      "Epoch: 3, Batch: 34049/37625 (90.496%), Loss: 0.8216\n",
      "Epoch: 3, Batch: 34305/37625 (91.176%), Loss: 0.9083\n",
      "Epoch: 3, Batch: 34561/37625 (91.856%), Loss: 0.8240\n",
      "Epoch: 3, Batch: 34817/37625 (92.537%), Loss: 0.6562\n",
      "Epoch: 3, Batch: 35073/37625 (93.217%), Loss: 1.3028\n",
      "Epoch: 3, Batch: 35329/37625 (93.898%), Loss: 0.7707\n",
      "Epoch: 3, Batch: 35585/37625 (94.578%), Loss: 0.8488\n",
      "Epoch: 3, Batch: 35841/37625 (95.258%), Loss: 1.3208\n",
      "Epoch: 3, Batch: 36097/37625 (95.939%), Loss: 0.7220\n",
      "Epoch: 3, Batch: 36353/37625 (96.619%), Loss: 1.2177\n",
      "Epoch: 3, Batch: 36609/37625 (97.300%), Loss: 0.7127\n",
      "Epoch: 3, Batch: 36865/37625 (97.980%), Loss: 0.8445\n",
      "Epoch: 3, Batch: 37121/37625 (98.660%), Loss: 1.2545\n",
      "Epoch: 3, Batch: 37377/37625 (99.341%), Loss: 1.6637\n",
      "Epoch: 4, Batch: 1/37625 (0.003%), Loss: 0.7709\n",
      "Epoch: 4, Batch: 257/37625 (0.683%), Loss: 0.8590\n",
      "Epoch: 4, Batch: 513/37625 (1.363%), Loss: 0.9607\n",
      "Epoch: 4, Batch: 769/37625 (2.044%), Loss: 1.1585\n",
      "Epoch: 4, Batch: 1025/37625 (2.724%), Loss: 0.8861\n",
      "Epoch: 4, Batch: 1281/37625 (3.405%), Loss: 1.0441\n",
      "Epoch: 4, Batch: 1537/37625 (4.085%), Loss: 1.0382\n",
      "Epoch: 4, Batch: 1793/37625 (4.765%), Loss: 0.9365\n",
      "Epoch: 4, Batch: 2049/37625 (5.446%), Loss: 0.7278\n",
      "Epoch: 4, Batch: 2305/37625 (6.126%), Loss: 1.0348\n",
      "Epoch: 4, Batch: 2561/37625 (6.807%), Loss: 1.0103\n",
      "Epoch: 4, Batch: 2817/37625 (7.487%), Loss: 1.1497\n",
      "Epoch: 4, Batch: 3073/37625 (8.167%), Loss: 0.9894\n",
      "Epoch: 4, Batch: 3329/37625 (8.848%), Loss: 3.3843\n",
      "Epoch: 4, Batch: 3585/37625 (9.528%), Loss: 0.8426\n",
      "Epoch: 4, Batch: 3841/37625 (10.209%), Loss: 0.7687\n",
      "Epoch: 4, Batch: 4097/37625 (10.889%), Loss: 4.5815\n",
      "Epoch: 4, Batch: 4353/37625 (11.569%), Loss: 0.7016\n",
      "Epoch: 4, Batch: 4609/37625 (12.250%), Loss: 1.1006\n",
      "Epoch: 4, Batch: 4865/37625 (12.930%), Loss: 0.7381\n",
      "Epoch: 4, Batch: 5121/37625 (13.611%), Loss: 0.9862\n",
      "Epoch: 4, Batch: 5377/37625 (14.291%), Loss: 0.9546\n",
      "Epoch: 4, Batch: 5633/37625 (14.971%), Loss: 0.8215\n",
      "Epoch: 4, Batch: 5889/37625 (15.652%), Loss: 0.5836\n",
      "Epoch: 4, Batch: 6145/37625 (16.332%), Loss: 0.8886\n",
      "Epoch: 4, Batch: 6401/37625 (17.013%), Loss: 1.1163\n",
      "Epoch: 4, Batch: 6657/37625 (17.693%), Loss: 1.2306\n",
      "Epoch: 4, Batch: 6913/37625 (18.373%), Loss: 0.9411\n",
      "Epoch: 4, Batch: 7169/37625 (19.054%), Loss: 0.7701\n",
      "Epoch: 4, Batch: 7425/37625 (19.734%), Loss: 0.8786\n",
      "Epoch: 4, Batch: 7681/37625 (20.415%), Loss: 1.3966\n",
      "Epoch: 4, Batch: 7937/37625 (21.095%), Loss: 2.1725\n",
      "Epoch: 4, Batch: 8193/37625 (21.775%), Loss: 0.8062\n",
      "Epoch: 4, Batch: 8449/37625 (22.456%), Loss: 0.7022\n",
      "Epoch: 4, Batch: 8705/37625 (23.136%), Loss: 0.5415\n",
      "Epoch: 4, Batch: 8961/37625 (23.817%), Loss: 0.9418\n",
      "Epoch: 4, Batch: 9217/37625 (24.497%), Loss: 0.8902\n",
      "Epoch: 4, Batch: 9473/37625 (25.177%), Loss: 0.6963\n",
      "Epoch: 4, Batch: 9729/37625 (25.858%), Loss: 0.5020\n",
      "Epoch: 4, Batch: 9985/37625 (26.538%), Loss: 0.7581\n",
      "Epoch: 4, Batch: 10241/37625 (27.219%), Loss: 0.8526\n",
      "Epoch: 4, Batch: 10497/37625 (27.899%), Loss: 0.5782\n",
      "Epoch: 4, Batch: 10753/37625 (28.579%), Loss: 1.9057\n",
      "Epoch: 4, Batch: 11009/37625 (29.260%), Loss: 1.7554\n",
      "Epoch: 4, Batch: 11265/37625 (29.940%), Loss: 2.6829\n",
      "Epoch: 4, Batch: 11521/37625 (30.621%), Loss: 1.2449\n",
      "Epoch: 4, Batch: 11777/37625 (31.301%), Loss: 0.9698\n",
      "Epoch: 4, Batch: 12033/37625 (31.981%), Loss: 0.9842\n",
      "Epoch: 4, Batch: 12289/37625 (32.662%), Loss: 0.8138\n",
      "Epoch: 4, Batch: 12545/37625 (33.342%), Loss: 0.8180\n",
      "Epoch: 4, Batch: 12801/37625 (34.023%), Loss: 1.7085\n",
      "Epoch: 4, Batch: 13057/37625 (34.703%), Loss: 0.6716\n",
      "Epoch: 4, Batch: 13313/37625 (35.383%), Loss: 0.7615\n",
      "Epoch: 4, Batch: 13569/37625 (36.064%), Loss: 1.0360\n",
      "Epoch: 4, Batch: 13825/37625 (36.744%), Loss: 1.7638\n",
      "Epoch: 4, Batch: 14081/37625 (37.425%), Loss: 1.5718\n",
      "Epoch: 4, Batch: 14337/37625 (38.105%), Loss: 0.7846\n",
      "Epoch: 4, Batch: 14593/37625 (38.785%), Loss: 1.1557\n",
      "Epoch: 4, Batch: 14849/37625 (39.466%), Loss: 0.6321\n",
      "Epoch: 4, Batch: 15105/37625 (40.146%), Loss: 0.7291\n",
      "Epoch: 4, Batch: 15361/37625 (40.827%), Loss: 0.8736\n",
      "Epoch: 4, Batch: 15617/37625 (41.507%), Loss: 2.7527\n",
      "Epoch: 4, Batch: 15873/37625 (42.187%), Loss: 0.9579\n",
      "Epoch: 4, Batch: 16129/37625 (42.868%), Loss: 0.9202\n",
      "Epoch: 4, Batch: 16385/37625 (43.548%), Loss: 0.9277\n",
      "Epoch: 4, Batch: 16641/37625 (44.229%), Loss: 0.9457\n",
      "Epoch: 4, Batch: 16897/37625 (44.909%), Loss: 3.0909\n",
      "Epoch: 4, Batch: 17153/37625 (45.589%), Loss: 0.7418\n",
      "Epoch: 4, Batch: 17409/37625 (46.270%), Loss: 0.9980\n",
      "Epoch: 4, Batch: 17665/37625 (46.950%), Loss: 0.9642\n",
      "Epoch: 4, Batch: 17921/37625 (47.631%), Loss: 0.7198\n",
      "Epoch: 4, Batch: 18177/37625 (48.311%), Loss: 0.6530\n",
      "Epoch: 4, Batch: 18433/37625 (48.991%), Loss: 0.9108\n",
      "Epoch: 4, Batch: 18689/37625 (49.672%), Loss: 1.7645\n",
      "Epoch: 4, Batch: 18945/37625 (50.352%), Loss: 1.1311\n",
      "Epoch: 4, Batch: 19201/37625 (51.033%), Loss: 0.9195\n",
      "Epoch: 4, Batch: 19457/37625 (51.713%), Loss: 0.8017\n",
      "Epoch: 4, Batch: 19713/37625 (52.393%), Loss: 1.2455\n",
      "Epoch: 4, Batch: 19969/37625 (53.074%), Loss: 0.6565\n",
      "Epoch: 4, Batch: 20225/37625 (53.754%), Loss: 1.0236\n",
      "Epoch: 4, Batch: 20481/37625 (54.435%), Loss: 0.9073\n",
      "Epoch: 4, Batch: 20737/37625 (55.115%), Loss: 0.8215\n",
      "Epoch: 4, Batch: 20993/37625 (55.795%), Loss: 0.8499\n",
      "Epoch: 4, Batch: 21249/37625 (56.476%), Loss: 1.1750\n",
      "Epoch: 4, Batch: 21505/37625 (57.156%), Loss: 0.6662\n",
      "Epoch: 4, Batch: 21761/37625 (57.837%), Loss: 1.0749\n",
      "Epoch: 4, Batch: 22017/37625 (58.517%), Loss: 0.9956\n",
      "Epoch: 4, Batch: 22273/37625 (59.197%), Loss: 1.2159\n",
      "Epoch: 4, Batch: 22529/37625 (59.878%), Loss: 0.6772\n",
      "Epoch: 4, Batch: 22785/37625 (60.558%), Loss: 0.7885\n",
      "Epoch: 4, Batch: 23041/37625 (61.239%), Loss: 2.3326\n",
      "Epoch: 4, Batch: 23297/37625 (61.919%), Loss: 0.8166\n",
      "Epoch: 4, Batch: 23553/37625 (62.599%), Loss: 0.8876\n",
      "Epoch: 4, Batch: 23809/37625 (63.280%), Loss: 1.6654\n",
      "Epoch: 4, Batch: 24065/37625 (63.960%), Loss: 0.4779\n",
      "Epoch: 4, Batch: 24321/37625 (64.641%), Loss: 0.5261\n",
      "Epoch: 4, Batch: 24577/37625 (65.321%), Loss: 0.9134\n",
      "Epoch: 4, Batch: 24833/37625 (66.001%), Loss: 1.1214\n",
      "Epoch: 4, Batch: 25089/37625 (66.682%), Loss: 0.8517\n",
      "Epoch: 4, Batch: 25345/37625 (67.362%), Loss: 0.8054\n",
      "Epoch: 4, Batch: 25601/37625 (68.043%), Loss: 0.8109\n",
      "Epoch: 4, Batch: 25857/37625 (68.723%), Loss: 0.6958\n",
      "Epoch: 4, Batch: 26113/37625 (69.403%), Loss: 0.8886\n",
      "Epoch: 4, Batch: 26369/37625 (70.084%), Loss: 0.5648\n",
      "Epoch: 4, Batch: 26625/37625 (70.764%), Loss: 0.8051\n",
      "Epoch: 4, Batch: 26881/37625 (71.445%), Loss: 1.1738\n",
      "Epoch: 4, Batch: 27137/37625 (72.125%), Loss: 1.1243\n",
      "Epoch: 4, Batch: 27393/37625 (72.805%), Loss: 0.8413\n",
      "Epoch: 4, Batch: 27649/37625 (73.486%), Loss: 0.6301\n",
      "Epoch: 4, Batch: 27905/37625 (74.166%), Loss: 0.8413\n",
      "Epoch: 4, Batch: 28161/37625 (74.847%), Loss: 1.0369\n",
      "Epoch: 4, Batch: 28417/37625 (75.527%), Loss: 1.9309\n",
      "Epoch: 4, Batch: 28673/37625 (76.207%), Loss: 1.1058\n",
      "Epoch: 4, Batch: 28929/37625 (76.888%), Loss: 5.0820\n",
      "Epoch: 4, Batch: 29185/37625 (77.568%), Loss: 0.9450\n",
      "Epoch: 4, Batch: 29441/37625 (78.249%), Loss: 0.7222\n",
      "Epoch: 4, Batch: 29697/37625 (78.929%), Loss: 0.5504\n",
      "Epoch: 4, Batch: 29953/37625 (79.609%), Loss: 1.7690\n",
      "Epoch: 4, Batch: 30209/37625 (80.290%), Loss: 1.4454\n",
      "Epoch: 4, Batch: 30465/37625 (80.970%), Loss: 0.9423\n",
      "Epoch: 4, Batch: 30721/37625 (81.650%), Loss: 1.2065\n",
      "Epoch: 4, Batch: 30977/37625 (82.331%), Loss: 0.8718\n",
      "Epoch: 4, Batch: 31233/37625 (83.011%), Loss: 0.5501\n",
      "Epoch: 4, Batch: 31489/37625 (83.692%), Loss: 0.9043\n",
      "Epoch: 4, Batch: 31745/37625 (84.372%), Loss: 1.3439\n",
      "Epoch: 4, Batch: 32001/37625 (85.052%), Loss: 0.6901\n",
      "Epoch: 4, Batch: 32257/37625 (85.733%), Loss: 1.4869\n",
      "Epoch: 4, Batch: 32513/37625 (86.413%), Loss: 0.8688\n",
      "Epoch: 4, Batch: 32769/37625 (87.094%), Loss: 1.2149\n",
      "Epoch: 4, Batch: 33025/37625 (87.774%), Loss: 1.3471\n",
      "Epoch: 4, Batch: 33281/37625 (88.454%), Loss: 0.6865\n",
      "Epoch: 4, Batch: 33537/37625 (89.135%), Loss: 0.7413\n",
      "Epoch: 4, Batch: 33793/37625 (89.815%), Loss: 1.1107\n",
      "Epoch: 4, Batch: 34049/37625 (90.496%), Loss: 0.9598\n",
      "Epoch: 4, Batch: 34305/37625 (91.176%), Loss: 0.9224\n",
      "Epoch: 4, Batch: 34561/37625 (91.856%), Loss: 0.7540\n",
      "Epoch: 4, Batch: 34817/37625 (92.537%), Loss: 0.7372\n",
      "Epoch: 4, Batch: 35073/37625 (93.217%), Loss: 0.7201\n",
      "Epoch: 4, Batch: 35329/37625 (93.898%), Loss: 0.9432\n",
      "Epoch: 4, Batch: 35585/37625 (94.578%), Loss: 5.9270\n",
      "Epoch: 4, Batch: 35841/37625 (95.258%), Loss: 0.7216\n",
      "Epoch: 4, Batch: 36097/37625 (95.939%), Loss: 1.1421\n",
      "Epoch: 4, Batch: 36353/37625 (96.619%), Loss: 1.1483\n",
      "Epoch: 4, Batch: 36609/37625 (97.300%), Loss: 1.1151\n",
      "Epoch: 4, Batch: 36865/37625 (97.980%), Loss: 0.7470\n",
      "Epoch: 4, Batch: 37121/37625 (98.660%), Loss: 0.8829\n",
      "Epoch: 4, Batch: 37377/37625 (99.341%), Loss: 0.8684\n",
      "Epoch: 5, Batch: 1/37625 (0.003%), Loss: 0.8789\n",
      "Epoch: 5, Batch: 257/37625 (0.683%), Loss: 1.2552\n",
      "Epoch: 5, Batch: 513/37625 (1.363%), Loss: 1.1786\n",
      "Epoch: 5, Batch: 769/37625 (2.044%), Loss: 0.8187\n",
      "Epoch: 5, Batch: 1025/37625 (2.724%), Loss: 0.6892\n",
      "Epoch: 5, Batch: 1281/37625 (3.405%), Loss: 0.6471\n",
      "Epoch: 5, Batch: 1537/37625 (4.085%), Loss: 1.2078\n",
      "Epoch: 5, Batch: 1793/37625 (4.765%), Loss: 0.6314\n",
      "Epoch: 5, Batch: 2049/37625 (5.446%), Loss: 0.7087\n",
      "Epoch: 5, Batch: 2305/37625 (6.126%), Loss: 1.2317\n",
      "Epoch: 5, Batch: 2561/37625 (6.807%), Loss: 5.3764\n",
      "Epoch: 5, Batch: 2817/37625 (7.487%), Loss: 1.2979\n",
      "Epoch: 5, Batch: 3073/37625 (8.167%), Loss: 0.8661\n",
      "Epoch: 5, Batch: 3329/37625 (8.848%), Loss: 0.6198\n",
      "Epoch: 5, Batch: 3585/37625 (9.528%), Loss: 0.7190\n",
      "Epoch: 5, Batch: 3841/37625 (10.209%), Loss: 0.7299\n",
      "Epoch: 5, Batch: 4097/37625 (10.889%), Loss: 0.8827\n",
      "Epoch: 5, Batch: 4353/37625 (11.569%), Loss: 0.9711\n",
      "Epoch: 5, Batch: 4609/37625 (12.250%), Loss: 1.7485\n",
      "Epoch: 5, Batch: 4865/37625 (12.930%), Loss: 0.7513\n",
      "Epoch: 5, Batch: 5121/37625 (13.611%), Loss: 1.2614\n",
      "Epoch: 5, Batch: 5377/37625 (14.291%), Loss: 3.1237\n",
      "Epoch: 5, Batch: 5633/37625 (14.971%), Loss: 1.3981\n",
      "Epoch: 5, Batch: 5889/37625 (15.652%), Loss: 0.9559\n",
      "Epoch: 5, Batch: 6145/37625 (16.332%), Loss: 0.8584\n",
      "Epoch: 5, Batch: 6401/37625 (17.013%), Loss: 1.0153\n",
      "Epoch: 5, Batch: 6657/37625 (17.693%), Loss: 0.7088\n",
      "Epoch: 5, Batch: 6913/37625 (18.373%), Loss: 1.7327\n",
      "Epoch: 5, Batch: 7169/37625 (19.054%), Loss: 1.2503\n",
      "Epoch: 5, Batch: 7425/37625 (19.734%), Loss: 0.9927\n",
      "Epoch: 5, Batch: 7681/37625 (20.415%), Loss: 1.0921\n",
      "Epoch: 5, Batch: 7937/37625 (21.095%), Loss: 1.0401\n",
      "Epoch: 5, Batch: 8193/37625 (21.775%), Loss: 0.7721\n",
      "Epoch: 5, Batch: 8449/37625 (22.456%), Loss: 0.9682\n",
      "Epoch: 5, Batch: 8705/37625 (23.136%), Loss: 0.8911\n",
      "Epoch: 5, Batch: 8961/37625 (23.817%), Loss: 1.1883\n",
      "Epoch: 5, Batch: 9217/37625 (24.497%), Loss: 1.1579\n",
      "Epoch: 5, Batch: 9473/37625 (25.177%), Loss: 0.6951\n",
      "Epoch: 5, Batch: 9729/37625 (25.858%), Loss: 1.0016\n",
      "Epoch: 5, Batch: 9985/37625 (26.538%), Loss: 0.8606\n",
      "Epoch: 5, Batch: 10241/37625 (27.219%), Loss: 0.7260\n",
      "Epoch: 5, Batch: 10497/37625 (27.899%), Loss: 0.9007\n",
      "Epoch: 5, Batch: 10753/37625 (28.579%), Loss: 0.7243\n",
      "Epoch: 5, Batch: 11009/37625 (29.260%), Loss: 0.8041\n",
      "Epoch: 5, Batch: 11265/37625 (29.940%), Loss: 0.5794\n",
      "Epoch: 5, Batch: 11521/37625 (30.621%), Loss: 0.9630\n",
      "Epoch: 5, Batch: 11777/37625 (31.301%), Loss: 0.7789\n",
      "Epoch: 5, Batch: 12033/37625 (31.981%), Loss: 0.8209\n",
      "Epoch: 5, Batch: 12289/37625 (32.662%), Loss: 1.0723\n",
      "Epoch: 5, Batch: 12545/37625 (33.342%), Loss: 1.8510\n",
      "Epoch: 5, Batch: 12801/37625 (34.023%), Loss: 0.8683\n",
      "Epoch: 5, Batch: 13057/37625 (34.703%), Loss: 0.8623\n",
      "Epoch: 5, Batch: 13313/37625 (35.383%), Loss: 0.7587\n",
      "Epoch: 5, Batch: 13569/37625 (36.064%), Loss: 2.0911\n",
      "Epoch: 5, Batch: 13825/37625 (36.744%), Loss: 1.2893\n",
      "Epoch: 5, Batch: 14081/37625 (37.425%), Loss: 1.2060\n",
      "Epoch: 5, Batch: 14337/37625 (38.105%), Loss: 1.1146\n",
      "Epoch: 5, Batch: 14593/37625 (38.785%), Loss: 0.6846\n",
      "Epoch: 5, Batch: 14849/37625 (39.466%), Loss: 0.7955\n",
      "Epoch: 5, Batch: 15105/37625 (40.146%), Loss: 0.9533\n",
      "Epoch: 5, Batch: 15361/37625 (40.827%), Loss: 1.0464\n",
      "Epoch: 5, Batch: 15617/37625 (41.507%), Loss: 2.4234\n",
      "Epoch: 5, Batch: 15873/37625 (42.187%), Loss: 1.2666\n",
      "Epoch: 5, Batch: 16129/37625 (42.868%), Loss: 1.5286\n",
      "Epoch: 5, Batch: 16385/37625 (43.548%), Loss: 1.0068\n",
      "Epoch: 5, Batch: 16641/37625 (44.229%), Loss: 0.8632\n",
      "Epoch: 5, Batch: 16897/37625 (44.909%), Loss: 0.9383\n",
      "Epoch: 5, Batch: 17153/37625 (45.589%), Loss: 0.5293\n",
      "Epoch: 5, Batch: 17409/37625 (46.270%), Loss: 0.6610\n",
      "Epoch: 5, Batch: 17665/37625 (46.950%), Loss: 1.4113\n",
      "Epoch: 5, Batch: 17921/37625 (47.631%), Loss: 0.7740\n",
      "Epoch: 5, Batch: 18177/37625 (48.311%), Loss: 0.6545\n",
      "Epoch: 5, Batch: 18433/37625 (48.991%), Loss: 4.2796\n",
      "Epoch: 5, Batch: 18689/37625 (49.672%), Loss: 0.8018\n",
      "Epoch: 5, Batch: 18945/37625 (50.352%), Loss: 1.1094\n",
      "Epoch: 5, Batch: 19201/37625 (51.033%), Loss: 0.8365\n",
      "Epoch: 5, Batch: 19457/37625 (51.713%), Loss: 0.9742\n",
      "Epoch: 5, Batch: 19713/37625 (52.393%), Loss: 1.2449\n",
      "Epoch: 5, Batch: 19969/37625 (53.074%), Loss: 0.7106\n",
      "Epoch: 5, Batch: 20225/37625 (53.754%), Loss: 0.9188\n",
      "Epoch: 5, Batch: 20481/37625 (54.435%), Loss: 0.6959\n",
      "Epoch: 5, Batch: 20737/37625 (55.115%), Loss: 0.7199\n",
      "Epoch: 5, Batch: 20993/37625 (55.795%), Loss: 0.9754\n",
      "Epoch: 5, Batch: 21249/37625 (56.476%), Loss: 0.9103\n",
      "Epoch: 5, Batch: 21505/37625 (57.156%), Loss: 0.7193\n",
      "Epoch: 5, Batch: 21761/37625 (57.837%), Loss: 0.7557\n",
      "Epoch: 5, Batch: 22017/37625 (58.517%), Loss: 0.8253\n",
      "Epoch: 5, Batch: 22273/37625 (59.197%), Loss: 0.5705\n",
      "Epoch: 5, Batch: 22529/37625 (59.878%), Loss: 1.1131\n",
      "Epoch: 5, Batch: 22785/37625 (60.558%), Loss: 1.0078\n",
      "Epoch: 5, Batch: 23041/37625 (61.239%), Loss: 5.4995\n",
      "Epoch: 5, Batch: 23297/37625 (61.919%), Loss: 1.4201\n",
      "Epoch: 5, Batch: 23553/37625 (62.599%), Loss: 0.5482\n",
      "Epoch: 5, Batch: 23809/37625 (63.280%), Loss: 1.0493\n",
      "Epoch: 5, Batch: 24065/37625 (63.960%), Loss: 0.6795\n",
      "Epoch: 5, Batch: 24321/37625 (64.641%), Loss: 0.5131\n",
      "Epoch: 5, Batch: 24577/37625 (65.321%), Loss: 0.5170\n",
      "Epoch: 5, Batch: 24833/37625 (66.001%), Loss: 1.4060\n",
      "Epoch: 5, Batch: 25089/37625 (66.682%), Loss: 0.8083\n",
      "Epoch: 5, Batch: 25345/37625 (67.362%), Loss: 0.7651\n",
      "Epoch: 5, Batch: 25601/37625 (68.043%), Loss: 0.9050\n",
      "Epoch: 5, Batch: 25857/37625 (68.723%), Loss: 0.6252\n",
      "Epoch: 5, Batch: 26113/37625 (69.403%), Loss: 2.7070\n",
      "Epoch: 5, Batch: 26369/37625 (70.084%), Loss: 0.9682\n",
      "Epoch: 5, Batch: 26625/37625 (70.764%), Loss: 1.8492\n",
      "Epoch: 5, Batch: 26881/37625 (71.445%), Loss: 0.4521\n",
      "Epoch: 5, Batch: 27137/37625 (72.125%), Loss: 0.9943\n",
      "Epoch: 5, Batch: 27393/37625 (72.805%), Loss: 1.5454\n",
      "Epoch: 5, Batch: 27649/37625 (73.486%), Loss: 0.7189\n",
      "Epoch: 5, Batch: 27905/37625 (74.166%), Loss: 0.8983\n",
      "Epoch: 5, Batch: 28161/37625 (74.847%), Loss: 0.8237\n",
      "Epoch: 5, Batch: 28417/37625 (75.527%), Loss: 0.9432\n",
      "Epoch: 5, Batch: 28673/37625 (76.207%), Loss: 0.6861\n",
      "Epoch: 5, Batch: 28929/37625 (76.888%), Loss: 1.0854\n",
      "Epoch: 5, Batch: 29185/37625 (77.568%), Loss: 1.1349\n",
      "Epoch: 5, Batch: 29441/37625 (78.249%), Loss: 1.4736\n",
      "Epoch: 5, Batch: 29697/37625 (78.929%), Loss: 1.9732\n",
      "Epoch: 5, Batch: 29953/37625 (79.609%), Loss: 0.6265\n",
      "Epoch: 5, Batch: 30209/37625 (80.290%), Loss: 1.4438\n",
      "Epoch: 5, Batch: 30465/37625 (80.970%), Loss: 1.9683\n",
      "Epoch: 5, Batch: 30721/37625 (81.650%), Loss: 1.3667\n",
      "Epoch: 5, Batch: 30977/37625 (82.331%), Loss: 0.5819\n",
      "Epoch: 5, Batch: 31233/37625 (83.011%), Loss: 0.9837\n",
      "Epoch: 5, Batch: 31489/37625 (83.692%), Loss: 1.0333\n",
      "Epoch: 5, Batch: 31745/37625 (84.372%), Loss: 1.0827\n",
      "Epoch: 5, Batch: 32001/37625 (85.052%), Loss: 0.9125\n",
      "Epoch: 5, Batch: 32257/37625 (85.733%), Loss: 0.6401\n",
      "Epoch: 5, Batch: 32513/37625 (86.413%), Loss: 3.9661\n",
      "Epoch: 5, Batch: 32769/37625 (87.094%), Loss: 1.5708\n",
      "Epoch: 5, Batch: 33025/37625 (87.774%), Loss: 1.2684\n",
      "Epoch: 5, Batch: 33281/37625 (88.454%), Loss: 0.6721\n",
      "Epoch: 5, Batch: 33537/37625 (89.135%), Loss: 0.7103\n",
      "Epoch: 5, Batch: 33793/37625 (89.815%), Loss: 0.7151\n",
      "Epoch: 5, Batch: 34049/37625 (90.496%), Loss: 1.1393\n",
      "Epoch: 5, Batch: 34305/37625 (91.176%), Loss: 1.2592\n",
      "Epoch: 5, Batch: 34561/37625 (91.856%), Loss: 0.8194\n",
      "Epoch: 5, Batch: 34817/37625 (92.537%), Loss: 0.6922\n",
      "Epoch: 5, Batch: 35073/37625 (93.217%), Loss: 0.9357\n",
      "Epoch: 5, Batch: 35329/37625 (93.898%), Loss: 1.5004\n",
      "Epoch: 5, Batch: 35585/37625 (94.578%), Loss: 0.4724\n",
      "Epoch: 5, Batch: 35841/37625 (95.258%), Loss: 0.9670\n",
      "Epoch: 5, Batch: 36097/37625 (95.939%), Loss: 1.3382\n",
      "Epoch: 5, Batch: 36353/37625 (96.619%), Loss: 0.6682\n",
      "Epoch: 5, Batch: 36609/37625 (97.300%), Loss: 0.6201\n",
      "Epoch: 5, Batch: 36865/37625 (97.980%), Loss: 0.8823\n",
      "Epoch: 5, Batch: 37121/37625 (98.660%), Loss: 0.9400\n",
      "Epoch: 5, Batch: 37377/37625 (99.341%), Loss: 0.7063\n",
      "Epoch: 6, Batch: 1/37625 (0.003%), Loss: 0.6978\n",
      "Epoch: 6, Batch: 257/37625 (0.683%), Loss: 0.8339\n",
      "Epoch: 6, Batch: 513/37625 (1.363%), Loss: 0.8480\n",
      "Epoch: 6, Batch: 769/37625 (2.044%), Loss: 1.5152\n",
      "Epoch: 6, Batch: 1025/37625 (2.724%), Loss: 0.9447\n",
      "Epoch: 6, Batch: 1281/37625 (3.405%), Loss: 1.0117\n",
      "Epoch: 6, Batch: 1537/37625 (4.085%), Loss: 0.5365\n",
      "Epoch: 6, Batch: 1793/37625 (4.765%), Loss: 1.4788\n",
      "Epoch: 6, Batch: 2049/37625 (5.446%), Loss: 0.7010\n",
      "Epoch: 6, Batch: 2305/37625 (6.126%), Loss: 1.0069\n",
      "Epoch: 6, Batch: 2561/37625 (6.807%), Loss: 0.5041\n",
      "Epoch: 6, Batch: 2817/37625 (7.487%), Loss: 0.6296\n",
      "Epoch: 6, Batch: 3073/37625 (8.167%), Loss: 0.7750\n",
      "Epoch: 6, Batch: 3329/37625 (8.848%), Loss: 0.7010\n",
      "Epoch: 6, Batch: 3585/37625 (9.528%), Loss: 1.0489\n",
      "Epoch: 6, Batch: 3841/37625 (10.209%), Loss: 0.8389\n",
      "Epoch: 6, Batch: 4097/37625 (10.889%), Loss: 0.9298\n",
      "Epoch: 6, Batch: 4353/37625 (11.569%), Loss: 0.8486\n",
      "Epoch: 6, Batch: 4609/37625 (12.250%), Loss: 0.6499\n",
      "Epoch: 6, Batch: 4865/37625 (12.930%), Loss: 0.8117\n",
      "Epoch: 6, Batch: 5121/37625 (13.611%), Loss: 0.9858\n",
      "Epoch: 6, Batch: 5377/37625 (14.291%), Loss: 1.3316\n",
      "Epoch: 6, Batch: 5633/37625 (14.971%), Loss: 0.9969\n",
      "Epoch: 6, Batch: 5889/37625 (15.652%), Loss: 0.6726\n",
      "Epoch: 6, Batch: 6145/37625 (16.332%), Loss: 2.1610\n",
      "Epoch: 6, Batch: 6401/37625 (17.013%), Loss: 0.8377\n",
      "Epoch: 6, Batch: 6657/37625 (17.693%), Loss: 0.6883\n",
      "Epoch: 6, Batch: 6913/37625 (18.373%), Loss: 0.6707\n",
      "Epoch: 6, Batch: 7169/37625 (19.054%), Loss: 1.4928\n",
      "Epoch: 6, Batch: 7425/37625 (19.734%), Loss: 1.7632\n",
      "Epoch: 6, Batch: 7681/37625 (20.415%), Loss: 1.6891\n",
      "Epoch: 6, Batch: 7937/37625 (21.095%), Loss: 0.8639\n",
      "Epoch: 6, Batch: 8193/37625 (21.775%), Loss: 0.7307\n",
      "Epoch: 6, Batch: 8449/37625 (22.456%), Loss: 0.9361\n",
      "Epoch: 6, Batch: 8705/37625 (23.136%), Loss: 0.9119\n",
      "Epoch: 6, Batch: 8961/37625 (23.817%), Loss: 0.6331\n",
      "Epoch: 6, Batch: 9217/37625 (24.497%), Loss: 0.6766\n",
      "Epoch: 6, Batch: 9473/37625 (25.177%), Loss: 0.6532\n",
      "Epoch: 6, Batch: 9729/37625 (25.858%), Loss: 0.6546\n",
      "Epoch: 6, Batch: 9985/37625 (26.538%), Loss: 1.2029\n",
      "Epoch: 6, Batch: 10241/37625 (27.219%), Loss: 0.6680\n",
      "Epoch: 6, Batch: 10497/37625 (27.899%), Loss: 0.8624\n",
      "Epoch: 6, Batch: 10753/37625 (28.579%), Loss: 3.1735\n",
      "Epoch: 6, Batch: 11009/37625 (29.260%), Loss: 0.9364\n",
      "Epoch: 6, Batch: 11265/37625 (29.940%), Loss: 0.9427\n",
      "Epoch: 6, Batch: 11521/37625 (30.621%), Loss: 1.0509\n",
      "Epoch: 6, Batch: 11777/37625 (31.301%), Loss: 1.1269\n",
      "Epoch: 6, Batch: 12033/37625 (31.981%), Loss: 1.6828\n",
      "Epoch: 6, Batch: 12289/37625 (32.662%), Loss: 1.2478\n",
      "Epoch: 6, Batch: 12545/37625 (33.342%), Loss: 1.6114\n",
      "Epoch: 6, Batch: 12801/37625 (34.023%), Loss: 1.1693\n",
      "Epoch: 6, Batch: 13057/37625 (34.703%), Loss: 0.9368\n",
      "Epoch: 6, Batch: 13313/37625 (35.383%), Loss: 0.6325\n",
      "Epoch: 6, Batch: 13569/37625 (36.064%), Loss: 5.2367\n",
      "Epoch: 6, Batch: 13825/37625 (36.744%), Loss: 1.0940\n",
      "Epoch: 6, Batch: 14081/37625 (37.425%), Loss: 0.6070\n",
      "Epoch: 6, Batch: 14337/37625 (38.105%), Loss: 0.9249\n",
      "Epoch: 6, Batch: 14593/37625 (38.785%), Loss: 0.6246\n",
      "Epoch: 6, Batch: 14849/37625 (39.466%), Loss: 1.0704\n",
      "Epoch: 6, Batch: 15105/37625 (40.146%), Loss: 0.5867\n",
      "Epoch: 6, Batch: 15361/37625 (40.827%), Loss: 0.5362\n",
      "Epoch: 6, Batch: 15617/37625 (41.507%), Loss: 0.9380\n",
      "Epoch: 6, Batch: 15873/37625 (42.187%), Loss: 1.1024\n",
      "Epoch: 6, Batch: 16129/37625 (42.868%), Loss: 1.2185\n",
      "Epoch: 6, Batch: 16385/37625 (43.548%), Loss: 1.4640\n",
      "Epoch: 6, Batch: 16641/37625 (44.229%), Loss: 0.7842\n",
      "Epoch: 6, Batch: 16897/37625 (44.909%), Loss: 0.7834\n",
      "Epoch: 6, Batch: 17153/37625 (45.589%), Loss: 4.8125\n",
      "Epoch: 6, Batch: 17409/37625 (46.270%), Loss: 0.9563\n",
      "Epoch: 6, Batch: 17665/37625 (46.950%), Loss: 2.3521\n",
      "Epoch: 6, Batch: 17921/37625 (47.631%), Loss: 0.8291\n",
      "Epoch: 6, Batch: 18177/37625 (48.311%), Loss: 1.4166\n",
      "Epoch: 6, Batch: 18433/37625 (48.991%), Loss: 0.7781\n",
      "Epoch: 6, Batch: 18689/37625 (49.672%), Loss: 0.6917\n",
      "Epoch: 6, Batch: 18945/37625 (50.352%), Loss: 0.6409\n",
      "Epoch: 6, Batch: 19201/37625 (51.033%), Loss: 0.8756\n",
      "Epoch: 6, Batch: 19457/37625 (51.713%), Loss: 0.7957\n",
      "Epoch: 6, Batch: 19713/37625 (52.393%), Loss: 3.1006\n",
      "Epoch: 6, Batch: 19969/37625 (53.074%), Loss: 1.7995\n",
      "Epoch: 6, Batch: 20225/37625 (53.754%), Loss: 1.0389\n",
      "Epoch: 6, Batch: 20481/37625 (54.435%), Loss: 1.0504\n",
      "Epoch: 6, Batch: 20737/37625 (55.115%), Loss: 1.2194\n",
      "Epoch: 6, Batch: 20993/37625 (55.795%), Loss: 0.7762\n",
      "Epoch: 6, Batch: 21249/37625 (56.476%), Loss: 0.7915\n",
      "Epoch: 6, Batch: 21505/37625 (57.156%), Loss: 0.6817\n",
      "Epoch: 6, Batch: 21761/37625 (57.837%), Loss: 1.0665\n",
      "Epoch: 6, Batch: 22017/37625 (58.517%), Loss: 1.5746\n",
      "Epoch: 6, Batch: 22273/37625 (59.197%), Loss: 2.2661\n",
      "Epoch: 6, Batch: 22529/37625 (59.878%), Loss: 0.7231\n",
      "Epoch: 6, Batch: 22785/37625 (60.558%), Loss: 0.7154\n",
      "Epoch: 6, Batch: 23041/37625 (61.239%), Loss: 0.5753\n",
      "Epoch: 6, Batch: 23297/37625 (61.919%), Loss: 1.6963\n",
      "Epoch: 6, Batch: 23553/37625 (62.599%), Loss: 0.9456\n",
      "Epoch: 6, Batch: 23809/37625 (63.280%), Loss: 0.8796\n",
      "Epoch: 6, Batch: 24065/37625 (63.960%), Loss: 0.8279\n",
      "Epoch: 6, Batch: 24321/37625 (64.641%), Loss: 1.2315\n",
      "Epoch: 6, Batch: 24577/37625 (65.321%), Loss: 1.4533\n",
      "Epoch: 6, Batch: 24833/37625 (66.001%), Loss: 0.7862\n",
      "Epoch: 6, Batch: 25089/37625 (66.682%), Loss: 1.0113\n",
      "Epoch: 6, Batch: 25345/37625 (67.362%), Loss: 1.0092\n",
      "Epoch: 6, Batch: 25601/37625 (68.043%), Loss: 1.2157\n",
      "Epoch: 6, Batch: 25857/37625 (68.723%), Loss: 0.8401\n",
      "Epoch: 6, Batch: 26113/37625 (69.403%), Loss: 1.0379\n",
      "Epoch: 6, Batch: 26369/37625 (70.084%), Loss: 1.5576\n",
      "Epoch: 6, Batch: 26625/37625 (70.764%), Loss: 1.3994\n",
      "Epoch: 6, Batch: 26881/37625 (71.445%), Loss: 0.5142\n",
      "Epoch: 6, Batch: 27137/37625 (72.125%), Loss: 0.6681\n",
      "Epoch: 6, Batch: 27393/37625 (72.805%), Loss: 1.2039\n",
      "Epoch: 6, Batch: 27649/37625 (73.486%), Loss: 0.8449\n",
      "Epoch: 6, Batch: 27905/37625 (74.166%), Loss: 0.8185\n",
      "Epoch: 6, Batch: 28161/37625 (74.847%), Loss: 0.7384\n",
      "Epoch: 6, Batch: 28417/37625 (75.527%), Loss: 1.0562\n",
      "Epoch: 6, Batch: 28673/37625 (76.207%), Loss: 0.6835\n",
      "Epoch: 6, Batch: 28929/37625 (76.888%), Loss: 0.5741\n",
      "Epoch: 6, Batch: 29185/37625 (77.568%), Loss: 1.0727\n",
      "Epoch: 6, Batch: 29441/37625 (78.249%), Loss: 0.5205\n",
      "Epoch: 6, Batch: 29697/37625 (78.929%), Loss: 0.7485\n",
      "Epoch: 6, Batch: 29953/37625 (79.609%), Loss: 0.8692\n",
      "Epoch: 6, Batch: 30209/37625 (80.290%), Loss: 1.0533\n",
      "Epoch: 6, Batch: 30465/37625 (80.970%), Loss: 0.7414\n",
      "Epoch: 6, Batch: 30721/37625 (81.650%), Loss: 1.0902\n",
      "Epoch: 6, Batch: 30977/37625 (82.331%), Loss: 0.9090\n",
      "Epoch: 6, Batch: 31233/37625 (83.011%), Loss: 0.6819\n",
      "Epoch: 6, Batch: 31489/37625 (83.692%), Loss: 0.8684\n",
      "Epoch: 6, Batch: 31745/37625 (84.372%), Loss: 0.8702\n",
      "Epoch: 6, Batch: 32001/37625 (85.052%), Loss: 1.4715\n",
      "Epoch: 6, Batch: 32257/37625 (85.733%), Loss: 1.2176\n",
      "Epoch: 6, Batch: 32513/37625 (86.413%), Loss: 5.0053\n",
      "Epoch: 6, Batch: 32769/37625 (87.094%), Loss: 0.8197\n",
      "Epoch: 6, Batch: 33025/37625 (87.774%), Loss: 0.6852\n",
      "Epoch: 6, Batch: 33281/37625 (88.454%), Loss: 0.8363\n",
      "Epoch: 6, Batch: 33537/37625 (89.135%), Loss: 0.8799\n",
      "Epoch: 6, Batch: 33793/37625 (89.815%), Loss: 0.8372\n",
      "Epoch: 6, Batch: 34049/37625 (90.496%), Loss: 0.7771\n",
      "Epoch: 6, Batch: 34305/37625 (91.176%), Loss: 0.8000\n",
      "Epoch: 6, Batch: 34561/37625 (91.856%), Loss: 0.8012\n",
      "Epoch: 6, Batch: 34817/37625 (92.537%), Loss: 0.8618\n",
      "Epoch: 6, Batch: 35073/37625 (93.217%), Loss: 0.7167\n",
      "Epoch: 6, Batch: 35329/37625 (93.898%), Loss: 1.1767\n",
      "Epoch: 6, Batch: 35585/37625 (94.578%), Loss: 0.9042\n",
      "Epoch: 6, Batch: 35841/37625 (95.258%), Loss: 1.4221\n",
      "Epoch: 6, Batch: 36097/37625 (95.939%), Loss: 1.0182\n",
      "Epoch: 6, Batch: 36353/37625 (96.619%), Loss: 1.6143\n",
      "Epoch: 6, Batch: 36609/37625 (97.300%), Loss: 1.2779\n",
      "Epoch: 6, Batch: 36865/37625 (97.980%), Loss: 0.7842\n",
      "Epoch: 6, Batch: 37121/37625 (98.660%), Loss: 2.4764\n",
      "Epoch: 6, Batch: 37377/37625 (99.341%), Loss: 2.6097\n",
      "Epoch: 7, Batch: 1/37625 (0.003%), Loss: 0.9801\n",
      "Epoch: 7, Batch: 257/37625 (0.683%), Loss: 0.5456\n",
      "Epoch: 7, Batch: 513/37625 (1.363%), Loss: 1.1261\n",
      "Epoch: 7, Batch: 769/37625 (2.044%), Loss: 0.6728\n",
      "Epoch: 7, Batch: 1025/37625 (2.724%), Loss: 0.8227\n",
      "Epoch: 7, Batch: 1281/37625 (3.405%), Loss: 0.6626\n",
      "Epoch: 7, Batch: 1537/37625 (4.085%), Loss: 0.7665\n",
      "Epoch: 7, Batch: 1793/37625 (4.765%), Loss: 0.8238\n",
      "Epoch: 7, Batch: 2049/37625 (5.446%), Loss: 0.6957\n",
      "Epoch: 7, Batch: 2305/37625 (6.126%), Loss: 0.7624\n",
      "Epoch: 7, Batch: 2561/37625 (6.807%), Loss: 1.1913\n",
      "Epoch: 7, Batch: 2817/37625 (7.487%), Loss: 0.6746\n",
      "Epoch: 7, Batch: 3073/37625 (8.167%), Loss: 0.8515\n",
      "Epoch: 7, Batch: 3329/37625 (8.848%), Loss: 0.8943\n",
      "Epoch: 7, Batch: 3585/37625 (9.528%), Loss: 1.3204\n",
      "Epoch: 7, Batch: 3841/37625 (10.209%), Loss: 1.1773\n",
      "Epoch: 7, Batch: 4097/37625 (10.889%), Loss: 0.9580\n",
      "Epoch: 7, Batch: 4353/37625 (11.569%), Loss: 0.8162\n",
      "Epoch: 7, Batch: 4609/37625 (12.250%), Loss: 1.6579\n",
      "Epoch: 7, Batch: 4865/37625 (12.930%), Loss: 1.5122\n",
      "Epoch: 7, Batch: 5121/37625 (13.611%), Loss: 0.8190\n",
      "Epoch: 7, Batch: 5377/37625 (14.291%), Loss: 1.0060\n",
      "Epoch: 7, Batch: 5633/37625 (14.971%), Loss: 0.6823\n",
      "Epoch: 7, Batch: 5889/37625 (15.652%), Loss: 5.0098\n",
      "Epoch: 7, Batch: 6145/37625 (16.332%), Loss: 1.5590\n",
      "Epoch: 7, Batch: 6401/37625 (17.013%), Loss: 1.1107\n",
      "Epoch: 7, Batch: 6657/37625 (17.693%), Loss: 0.7594\n",
      "Epoch: 7, Batch: 6913/37625 (18.373%), Loss: 1.0488\n",
      "Epoch: 7, Batch: 7169/37625 (19.054%), Loss: 1.5343\n",
      "Epoch: 7, Batch: 7425/37625 (19.734%), Loss: 1.3375\n",
      "Epoch: 7, Batch: 7681/37625 (20.415%), Loss: 0.8472\n",
      "Epoch: 7, Batch: 7937/37625 (21.095%), Loss: 1.0660\n",
      "Epoch: 7, Batch: 8193/37625 (21.775%), Loss: 0.8138\n",
      "Epoch: 7, Batch: 8449/37625 (22.456%), Loss: 0.6020\n",
      "Epoch: 7, Batch: 8705/37625 (23.136%), Loss: 0.8222\n",
      "Epoch: 7, Batch: 8961/37625 (23.817%), Loss: 0.6645\n",
      "Epoch: 7, Batch: 9217/37625 (24.497%), Loss: 0.7936\n",
      "Epoch: 7, Batch: 9473/37625 (25.177%), Loss: 0.7701\n",
      "Epoch: 7, Batch: 9729/37625 (25.858%), Loss: 1.5008\n",
      "Epoch: 7, Batch: 9985/37625 (26.538%), Loss: 0.7961\n",
      "Epoch: 7, Batch: 10241/37625 (27.219%), Loss: 0.7491\n",
      "Epoch: 7, Batch: 10497/37625 (27.899%), Loss: 1.6585\n",
      "Epoch: 7, Batch: 10753/37625 (28.579%), Loss: 1.6188\n",
      "Epoch: 7, Batch: 11009/37625 (29.260%), Loss: 3.1466\n",
      "Epoch: 7, Batch: 11265/37625 (29.940%), Loss: 0.6922\n",
      "Epoch: 7, Batch: 11521/37625 (30.621%), Loss: 4.4914\n",
      "Epoch: 7, Batch: 11777/37625 (31.301%), Loss: 0.6419\n",
      "Epoch: 7, Batch: 12033/37625 (31.981%), Loss: 1.1127\n",
      "Epoch: 7, Batch: 12289/37625 (32.662%), Loss: 0.7776\n",
      "Epoch: 7, Batch: 12545/37625 (33.342%), Loss: 3.0781\n",
      "Epoch: 7, Batch: 12801/37625 (34.023%), Loss: 1.1226\n",
      "Epoch: 7, Batch: 13057/37625 (34.703%), Loss: 1.6209\n",
      "Epoch: 7, Batch: 13313/37625 (35.383%), Loss: 3.6093\n",
      "Epoch: 7, Batch: 13569/37625 (36.064%), Loss: 0.7489\n",
      "Epoch: 7, Batch: 13825/37625 (36.744%), Loss: 0.6775\n",
      "Epoch: 7, Batch: 14081/37625 (37.425%), Loss: 1.0315\n",
      "Epoch: 7, Batch: 14337/37625 (38.105%), Loss: 1.1485\n",
      "Epoch: 7, Batch: 14593/37625 (38.785%), Loss: 0.7882\n",
      "Epoch: 7, Batch: 14849/37625 (39.466%), Loss: 0.5838\n",
      "Epoch: 7, Batch: 15105/37625 (40.146%), Loss: 0.8751\n",
      "Epoch: 7, Batch: 15361/37625 (40.827%), Loss: 1.0459\n",
      "Epoch: 7, Batch: 15617/37625 (41.507%), Loss: 1.3080\n",
      "Epoch: 7, Batch: 15873/37625 (42.187%), Loss: 0.9261\n",
      "Epoch: 7, Batch: 16129/37625 (42.868%), Loss: 5.4776\n",
      "Epoch: 7, Batch: 16385/37625 (43.548%), Loss: 1.4398\n",
      "Epoch: 7, Batch: 16641/37625 (44.229%), Loss: 0.8307\n",
      "Epoch: 7, Batch: 16897/37625 (44.909%), Loss: 0.8977\n",
      "Epoch: 7, Batch: 17153/37625 (45.589%), Loss: 0.6538\n",
      "Epoch: 7, Batch: 17409/37625 (46.270%), Loss: 0.5713\n",
      "Epoch: 7, Batch: 17665/37625 (46.950%), Loss: 0.7924\n",
      "Epoch: 7, Batch: 17921/37625 (47.631%), Loss: 0.6277\n",
      "Epoch: 7, Batch: 18177/37625 (48.311%), Loss: 0.9923\n",
      "Epoch: 7, Batch: 18433/37625 (48.991%), Loss: 0.9462\n",
      "Epoch: 7, Batch: 18689/37625 (49.672%), Loss: 0.9931\n",
      "Epoch: 7, Batch: 18945/37625 (50.352%), Loss: 1.1135\n",
      "Epoch: 7, Batch: 19201/37625 (51.033%), Loss: 0.8776\n",
      "Epoch: 7, Batch: 19457/37625 (51.713%), Loss: 0.9291\n",
      "Epoch: 7, Batch: 19713/37625 (52.393%), Loss: 0.8880\n",
      "Epoch: 7, Batch: 19969/37625 (53.074%), Loss: 1.2561\n",
      "Epoch: 7, Batch: 20225/37625 (53.754%), Loss: 0.9436\n",
      "Epoch: 7, Batch: 20481/37625 (54.435%), Loss: 0.7191\n",
      "Epoch: 7, Batch: 20737/37625 (55.115%), Loss: 0.8280\n",
      "Epoch: 7, Batch: 20993/37625 (55.795%), Loss: 0.9880\n",
      "Epoch: 7, Batch: 21249/37625 (56.476%), Loss: 1.1055\n",
      "Epoch: 7, Batch: 21505/37625 (57.156%), Loss: 1.0156\n",
      "Epoch: 7, Batch: 21761/37625 (57.837%), Loss: 0.7715\n",
      "Epoch: 7, Batch: 22017/37625 (58.517%), Loss: 1.3436\n",
      "Epoch: 7, Batch: 22273/37625 (59.197%), Loss: 0.7765\n",
      "Epoch: 7, Batch: 22529/37625 (59.878%), Loss: 0.9075\n",
      "Epoch: 7, Batch: 22785/37625 (60.558%), Loss: 1.0464\n",
      "Epoch: 7, Batch: 23041/37625 (61.239%), Loss: 0.6972\n",
      "Epoch: 7, Batch: 23297/37625 (61.919%), Loss: 1.0271\n",
      "Epoch: 7, Batch: 23553/37625 (62.599%), Loss: 1.1145\n",
      "Epoch: 7, Batch: 23809/37625 (63.280%), Loss: 0.9772\n",
      "Epoch: 7, Batch: 24065/37625 (63.960%), Loss: 0.7036\n",
      "Epoch: 7, Batch: 24321/37625 (64.641%), Loss: 0.7044\n",
      "Epoch: 7, Batch: 24577/37625 (65.321%), Loss: 0.7264\n",
      "Epoch: 7, Batch: 24833/37625 (66.001%), Loss: 1.0699\n",
      "Epoch: 7, Batch: 25089/37625 (66.682%), Loss: 0.5813\n",
      "Epoch: 7, Batch: 25345/37625 (67.362%), Loss: 1.3298\n",
      "Epoch: 7, Batch: 25601/37625 (68.043%), Loss: 1.2486\n",
      "Epoch: 7, Batch: 25857/37625 (68.723%), Loss: 0.9916\n",
      "Epoch: 7, Batch: 26113/37625 (69.403%), Loss: 2.1131\n",
      "Epoch: 7, Batch: 26369/37625 (70.084%), Loss: 0.8203\n",
      "Epoch: 7, Batch: 26625/37625 (70.764%), Loss: 0.7040\n",
      "Epoch: 7, Batch: 26881/37625 (71.445%), Loss: 0.7927\n",
      "Epoch: 7, Batch: 27137/37625 (72.125%), Loss: 1.0497\n",
      "Epoch: 7, Batch: 27393/37625 (72.805%), Loss: 3.2150\n",
      "Epoch: 7, Batch: 27649/37625 (73.486%), Loss: 2.3626\n",
      "Epoch: 7, Batch: 27905/37625 (74.166%), Loss: 0.6599\n",
      "Epoch: 7, Batch: 28161/37625 (74.847%), Loss: 1.2316\n",
      "Epoch: 7, Batch: 28417/37625 (75.527%), Loss: 0.8410\n",
      "Epoch: 7, Batch: 28673/37625 (76.207%), Loss: 0.8550\n",
      "Epoch: 7, Batch: 28929/37625 (76.888%), Loss: 1.1384\n",
      "Epoch: 7, Batch: 29185/37625 (77.568%), Loss: 0.5910\n",
      "Epoch: 7, Batch: 29441/37625 (78.249%), Loss: 0.9873\n",
      "Epoch: 7, Batch: 29697/37625 (78.929%), Loss: 0.8210\n",
      "Epoch: 7, Batch: 29953/37625 (79.609%), Loss: 2.3119\n",
      "Epoch: 7, Batch: 30209/37625 (80.290%), Loss: 0.8713\n",
      "Epoch: 7, Batch: 30465/37625 (80.970%), Loss: 0.8586\n",
      "Epoch: 7, Batch: 30721/37625 (81.650%), Loss: 1.2013\n",
      "Epoch: 7, Batch: 30977/37625 (82.331%), Loss: 0.9712\n",
      "Epoch: 7, Batch: 31233/37625 (83.011%), Loss: 0.7321\n",
      "Epoch: 7, Batch: 31489/37625 (83.692%), Loss: 0.6247\n",
      "Epoch: 7, Batch: 31745/37625 (84.372%), Loss: 1.0367\n",
      "Epoch: 7, Batch: 32001/37625 (85.052%), Loss: 1.6341\n",
      "Epoch: 7, Batch: 32257/37625 (85.733%), Loss: 0.9282\n",
      "Epoch: 7, Batch: 32513/37625 (86.413%), Loss: 0.7564\n",
      "Epoch: 7, Batch: 32769/37625 (87.094%), Loss: 0.7122\n",
      "Epoch: 7, Batch: 33025/37625 (87.774%), Loss: 0.6838\n",
      "Epoch: 7, Batch: 33281/37625 (88.454%), Loss: 0.9850\n",
      "Epoch: 7, Batch: 33537/37625 (89.135%), Loss: 0.6620\n",
      "Epoch: 7, Batch: 33793/37625 (89.815%), Loss: 0.6908\n",
      "Epoch: 7, Batch: 34049/37625 (90.496%), Loss: 0.7478\n",
      "Epoch: 7, Batch: 34305/37625 (91.176%), Loss: 1.1982\n",
      "Epoch: 7, Batch: 34561/37625 (91.856%), Loss: 0.9196\n",
      "Epoch: 7, Batch: 34817/37625 (92.537%), Loss: 0.6969\n",
      "Epoch: 7, Batch: 35073/37625 (93.217%), Loss: 0.8116\n",
      "Epoch: 7, Batch: 35329/37625 (93.898%), Loss: 0.7327\n",
      "Epoch: 7, Batch: 35585/37625 (94.578%), Loss: 1.1043\n",
      "Epoch: 7, Batch: 35841/37625 (95.258%), Loss: 0.7944\n",
      "Epoch: 7, Batch: 36097/37625 (95.939%), Loss: 0.8934\n",
      "Epoch: 7, Batch: 36353/37625 (96.619%), Loss: 0.5811\n",
      "Epoch: 7, Batch: 36609/37625 (97.300%), Loss: 0.8911\n",
      "Epoch: 7, Batch: 36865/37625 (97.980%), Loss: 1.3060\n",
      "Epoch: 7, Batch: 37121/37625 (98.660%), Loss: 1.4806\n",
      "Epoch: 7, Batch: 37377/37625 (99.341%), Loss: 0.9583\n",
      "Epoch: 8, Batch: 1/37625 (0.003%), Loss: 1.4735\n",
      "Epoch: 8, Batch: 257/37625 (0.683%), Loss: 0.7078\n",
      "Epoch: 8, Batch: 513/37625 (1.363%), Loss: 1.0750\n",
      "Epoch: 8, Batch: 769/37625 (2.044%), Loss: 1.2023\n",
      "Epoch: 8, Batch: 1025/37625 (2.724%), Loss: 0.5617\n",
      "Epoch: 8, Batch: 1281/37625 (3.405%), Loss: 0.6886\n",
      "Epoch: 8, Batch: 1537/37625 (4.085%), Loss: 0.4796\n",
      "Epoch: 8, Batch: 1793/37625 (4.765%), Loss: 2.1945\n",
      "Epoch: 8, Batch: 2049/37625 (5.446%), Loss: 1.0985\n",
      "Epoch: 8, Batch: 2305/37625 (6.126%), Loss: 2.4791\n",
      "Epoch: 8, Batch: 2561/37625 (6.807%), Loss: 0.9789\n",
      "Epoch: 8, Batch: 2817/37625 (7.487%), Loss: 1.4798\n",
      "Epoch: 8, Batch: 3073/37625 (8.167%), Loss: 0.7296\n",
      "Epoch: 8, Batch: 3329/37625 (8.848%), Loss: 1.3024\n",
      "Epoch: 8, Batch: 3585/37625 (9.528%), Loss: 0.9914\n",
      "Epoch: 8, Batch: 3841/37625 (10.209%), Loss: 1.0034\n",
      "Epoch: 8, Batch: 4097/37625 (10.889%), Loss: 0.6596\n",
      "Epoch: 8, Batch: 4353/37625 (11.569%), Loss: 2.6167\n",
      "Epoch: 8, Batch: 4609/37625 (12.250%), Loss: 0.6730\n",
      "Epoch: 8, Batch: 4865/37625 (12.930%), Loss: 1.3838\n",
      "Epoch: 8, Batch: 5121/37625 (13.611%), Loss: 0.9080\n",
      "Epoch: 8, Batch: 5377/37625 (14.291%), Loss: 0.9022\n",
      "Epoch: 8, Batch: 5633/37625 (14.971%), Loss: 0.6533\n",
      "Epoch: 8, Batch: 5889/37625 (15.652%), Loss: 1.6838\n",
      "Epoch: 8, Batch: 6145/37625 (16.332%), Loss: 5.4884\n",
      "Epoch: 8, Batch: 6401/37625 (17.013%), Loss: 0.7150\n",
      "Epoch: 8, Batch: 6657/37625 (17.693%), Loss: 1.4103\n",
      "Epoch: 8, Batch: 6913/37625 (18.373%), Loss: 0.7981\n",
      "Epoch: 8, Batch: 7169/37625 (19.054%), Loss: 0.8389\n",
      "Epoch: 8, Batch: 7425/37625 (19.734%), Loss: 0.8660\n",
      "Epoch: 8, Batch: 7681/37625 (20.415%), Loss: 0.9086\n",
      "Epoch: 8, Batch: 7937/37625 (21.095%), Loss: 0.5299\n",
      "Epoch: 8, Batch: 8193/37625 (21.775%), Loss: 2.0371\n",
      "Epoch: 8, Batch: 8449/37625 (22.456%), Loss: 1.6504\n",
      "Epoch: 8, Batch: 8705/37625 (23.136%), Loss: 1.8443\n",
      "Epoch: 8, Batch: 8961/37625 (23.817%), Loss: 1.2258\n",
      "Epoch: 8, Batch: 9217/37625 (24.497%), Loss: 0.8319\n",
      "Epoch: 8, Batch: 9473/37625 (25.177%), Loss: 0.6032\n",
      "Epoch: 8, Batch: 9729/37625 (25.858%), Loss: 0.7838\n",
      "Epoch: 8, Batch: 9985/37625 (26.538%), Loss: 0.7124\n",
      "Epoch: 8, Batch: 10241/37625 (27.219%), Loss: 0.7116\n",
      "Epoch: 8, Batch: 10497/37625 (27.899%), Loss: 0.7029\n",
      "Epoch: 8, Batch: 10753/37625 (28.579%), Loss: 0.7641\n",
      "Epoch: 8, Batch: 11009/37625 (29.260%), Loss: 0.8196\n",
      "Epoch: 8, Batch: 11265/37625 (29.940%), Loss: 0.6870\n",
      "Epoch: 8, Batch: 11521/37625 (30.621%), Loss: 4.7160\n",
      "Epoch: 8, Batch: 11777/37625 (31.301%), Loss: 1.3208\n",
      "Epoch: 8, Batch: 12033/37625 (31.981%), Loss: 0.7238\n",
      "Epoch: 8, Batch: 12289/37625 (32.662%), Loss: 0.6424\n",
      "Epoch: 8, Batch: 12545/37625 (33.342%), Loss: 0.7645\n",
      "Epoch: 8, Batch: 12801/37625 (34.023%), Loss: 1.2343\n",
      "Epoch: 8, Batch: 13057/37625 (34.703%), Loss: 0.6065\n",
      "Epoch: 8, Batch: 13313/37625 (35.383%), Loss: 0.7928\n",
      "Epoch: 8, Batch: 13569/37625 (36.064%), Loss: 0.9560\n",
      "Epoch: 8, Batch: 13825/37625 (36.744%), Loss: 0.9224\n",
      "Epoch: 8, Batch: 14081/37625 (37.425%), Loss: 0.9865\n",
      "Epoch: 8, Batch: 14337/37625 (38.105%), Loss: 1.8290\n",
      "Epoch: 8, Batch: 14593/37625 (38.785%), Loss: 1.1166\n",
      "Epoch: 8, Batch: 14849/37625 (39.466%), Loss: 1.0891\n",
      "Epoch: 8, Batch: 15105/37625 (40.146%), Loss: 3.2806\n",
      "Epoch: 8, Batch: 15361/37625 (40.827%), Loss: 0.6891\n",
      "Epoch: 8, Batch: 15617/37625 (41.507%), Loss: 1.0424\n",
      "Epoch: 8, Batch: 15873/37625 (42.187%), Loss: 0.9084\n",
      "Epoch: 8, Batch: 16129/37625 (42.868%), Loss: 0.7553\n",
      "Epoch: 8, Batch: 16385/37625 (43.548%), Loss: 0.6131\n",
      "Epoch: 8, Batch: 16641/37625 (44.229%), Loss: 0.7030\n",
      "Epoch: 8, Batch: 16897/37625 (44.909%), Loss: 1.3287\n",
      "Epoch: 8, Batch: 17153/37625 (45.589%), Loss: 1.0204\n",
      "Epoch: 8, Batch: 17409/37625 (46.270%), Loss: 1.3623\n",
      "Epoch: 8, Batch: 17665/37625 (46.950%), Loss: 0.6579\n",
      "Epoch: 8, Batch: 17921/37625 (47.631%), Loss: 0.5908\n",
      "Epoch: 8, Batch: 18177/37625 (48.311%), Loss: 0.9771\n",
      "Epoch: 8, Batch: 18433/37625 (48.991%), Loss: 0.6513\n",
      "Epoch: 8, Batch: 18689/37625 (49.672%), Loss: 0.8509\n",
      "Epoch: 8, Batch: 18945/37625 (50.352%), Loss: 0.8713\n",
      "Epoch: 8, Batch: 19201/37625 (51.033%), Loss: 0.6051\n",
      "Epoch: 8, Batch: 19457/37625 (51.713%), Loss: 0.7762\n",
      "Epoch: 8, Batch: 19713/37625 (52.393%), Loss: 0.7963\n",
      "Epoch: 8, Batch: 19969/37625 (53.074%), Loss: 0.6930\n",
      "Epoch: 8, Batch: 20225/37625 (53.754%), Loss: 0.7298\n",
      "Epoch: 8, Batch: 20481/37625 (54.435%), Loss: 0.7783\n",
      "Epoch: 8, Batch: 20737/37625 (55.115%), Loss: 1.4225\n",
      "Epoch: 8, Batch: 20993/37625 (55.795%), Loss: 1.3450\n",
      "Epoch: 8, Batch: 21249/37625 (56.476%), Loss: 2.1856\n",
      "Epoch: 8, Batch: 21505/37625 (57.156%), Loss: 1.1287\n",
      "Epoch: 8, Batch: 21761/37625 (57.837%), Loss: 0.8513\n",
      "Epoch: 8, Batch: 22017/37625 (58.517%), Loss: 1.1988\n",
      "Epoch: 8, Batch: 22273/37625 (59.197%), Loss: 0.9597\n",
      "Epoch: 8, Batch: 22529/37625 (59.878%), Loss: 1.0976\n",
      "Epoch: 8, Batch: 22785/37625 (60.558%), Loss: 0.9653\n",
      "Epoch: 8, Batch: 23041/37625 (61.239%), Loss: 0.6556\n",
      "Epoch: 8, Batch: 23297/37625 (61.919%), Loss: 0.9109\n",
      "Epoch: 8, Batch: 23553/37625 (62.599%), Loss: 1.0198\n",
      "Epoch: 8, Batch: 23809/37625 (63.280%), Loss: 1.2108\n",
      "Epoch: 8, Batch: 24065/37625 (63.960%), Loss: 0.6970\n",
      "Epoch: 8, Batch: 24321/37625 (64.641%), Loss: 1.4085\n",
      "Epoch: 8, Batch: 24577/37625 (65.321%), Loss: 0.8183\n",
      "Epoch: 8, Batch: 24833/37625 (66.001%), Loss: 0.7276\n",
      "Epoch: 8, Batch: 25089/37625 (66.682%), Loss: 1.0984\n",
      "Epoch: 8, Batch: 25345/37625 (67.362%), Loss: 0.8380\n",
      "Epoch: 8, Batch: 25601/37625 (68.043%), Loss: 1.5545\n",
      "Epoch: 8, Batch: 25857/37625 (68.723%), Loss: 0.6556\n",
      "Epoch: 8, Batch: 26113/37625 (69.403%), Loss: 0.8061\n",
      "Epoch: 8, Batch: 26369/37625 (70.084%), Loss: 1.2382\n",
      "Epoch: 8, Batch: 26625/37625 (70.764%), Loss: 1.3658\n",
      "Epoch: 8, Batch: 26881/37625 (71.445%), Loss: 0.7520\n",
      "Epoch: 8, Batch: 27137/37625 (72.125%), Loss: 0.8193\n",
      "Epoch: 8, Batch: 27393/37625 (72.805%), Loss: 0.7645\n",
      "Epoch: 8, Batch: 27649/37625 (73.486%), Loss: 1.1653\n",
      "Epoch: 8, Batch: 27905/37625 (74.166%), Loss: 0.8934\n",
      "Epoch: 8, Batch: 28161/37625 (74.847%), Loss: 1.7327\n",
      "Epoch: 8, Batch: 28417/37625 (75.527%), Loss: 1.2396\n",
      "Epoch: 8, Batch: 28673/37625 (76.207%), Loss: 1.0378\n",
      "Epoch: 8, Batch: 28929/37625 (76.888%), Loss: 0.8760\n",
      "Epoch: 8, Batch: 29185/37625 (77.568%), Loss: 0.7863\n",
      "Epoch: 8, Batch: 29441/37625 (78.249%), Loss: 0.8748\n",
      "Epoch: 8, Batch: 29697/37625 (78.929%), Loss: 0.4940\n",
      "Epoch: 8, Batch: 29953/37625 (79.609%), Loss: 0.6362\n",
      "Epoch: 8, Batch: 30209/37625 (80.290%), Loss: 0.7735\n",
      "Epoch: 8, Batch: 30465/37625 (80.970%), Loss: 0.7705\n",
      "Epoch: 8, Batch: 30721/37625 (81.650%), Loss: 0.6520\n",
      "Epoch: 8, Batch: 30977/37625 (82.331%), Loss: 0.9967\n",
      "Epoch: 8, Batch: 31233/37625 (83.011%), Loss: 0.7620\n",
      "Epoch: 8, Batch: 31489/37625 (83.692%), Loss: 0.9174\n",
      "Epoch: 8, Batch: 31745/37625 (84.372%), Loss: 0.8770\n",
      "Epoch: 8, Batch: 32001/37625 (85.052%), Loss: 5.0287\n",
      "Epoch: 8, Batch: 32257/37625 (85.733%), Loss: 1.1854\n",
      "Epoch: 8, Batch: 32513/37625 (86.413%), Loss: 0.5899\n",
      "Epoch: 8, Batch: 32769/37625 (87.094%), Loss: 0.8145\n",
      "Epoch: 8, Batch: 33025/37625 (87.774%), Loss: 0.8980\n",
      "Epoch: 8, Batch: 33281/37625 (88.454%), Loss: 1.1508\n",
      "Epoch: 8, Batch: 33537/37625 (89.135%), Loss: 0.7677\n",
      "Epoch: 8, Batch: 33793/37625 (89.815%), Loss: 0.7870\n",
      "Epoch: 8, Batch: 34049/37625 (90.496%), Loss: 0.8447\n",
      "Epoch: 8, Batch: 34305/37625 (91.176%), Loss: 0.8651\n",
      "Epoch: 8, Batch: 34561/37625 (91.856%), Loss: 0.6369\n",
      "Epoch: 8, Batch: 34817/37625 (92.537%), Loss: 0.8287\n",
      "Epoch: 8, Batch: 35073/37625 (93.217%), Loss: 1.5269\n",
      "Epoch: 8, Batch: 35329/37625 (93.898%), Loss: 0.8930\n",
      "Epoch: 8, Batch: 35585/37625 (94.578%), Loss: 1.0948\n",
      "Epoch: 8, Batch: 35841/37625 (95.258%), Loss: 1.0174\n",
      "Epoch: 8, Batch: 36097/37625 (95.939%), Loss: 4.0516\n",
      "Epoch: 8, Batch: 36353/37625 (96.619%), Loss: 0.7524\n",
      "Epoch: 8, Batch: 36609/37625 (97.300%), Loss: 0.9438\n",
      "Epoch: 8, Batch: 36865/37625 (97.980%), Loss: 1.2071\n",
      "Epoch: 8, Batch: 37121/37625 (98.660%), Loss: 0.9358\n",
      "Epoch: 8, Batch: 37377/37625 (99.341%), Loss: 1.7542\n",
      "Epoch: 9, Batch: 1/37625 (0.003%), Loss: 0.6348\n",
      "Epoch: 9, Batch: 257/37625 (0.683%), Loss: 1.1938\n",
      "Epoch: 9, Batch: 513/37625 (1.363%), Loss: 0.7960\n",
      "Epoch: 9, Batch: 769/37625 (2.044%), Loss: 0.8848\n",
      "Epoch: 9, Batch: 1025/37625 (2.724%), Loss: 0.7857\n",
      "Epoch: 9, Batch: 1281/37625 (3.405%), Loss: 0.7198\n",
      "Epoch: 9, Batch: 1537/37625 (4.085%), Loss: 1.7246\n",
      "Epoch: 9, Batch: 1793/37625 (4.765%), Loss: 1.2256\n",
      "Epoch: 9, Batch: 2049/37625 (5.446%), Loss: 1.3976\n",
      "Epoch: 9, Batch: 2305/37625 (6.126%), Loss: 1.2077\n",
      "Epoch: 9, Batch: 2561/37625 (6.807%), Loss: 0.6138\n",
      "Epoch: 9, Batch: 2817/37625 (7.487%), Loss: 0.8280\n",
      "Epoch: 9, Batch: 3073/37625 (8.167%), Loss: 0.6776\n",
      "Epoch: 9, Batch: 3329/37625 (8.848%), Loss: 1.4267\n",
      "Epoch: 9, Batch: 3585/37625 (9.528%), Loss: 0.9263\n",
      "Epoch: 9, Batch: 3841/37625 (10.209%), Loss: 0.9031\n",
      "Epoch: 9, Batch: 4097/37625 (10.889%), Loss: 1.1340\n",
      "Epoch: 9, Batch: 4353/37625 (11.569%), Loss: 0.8442\n",
      "Epoch: 9, Batch: 4609/37625 (12.250%), Loss: 0.9512\n",
      "Epoch: 9, Batch: 4865/37625 (12.930%), Loss: 0.7635\n",
      "Epoch: 9, Batch: 5121/37625 (13.611%), Loss: 1.6358\n",
      "Epoch: 9, Batch: 5377/37625 (14.291%), Loss: 1.1927\n",
      "Epoch: 9, Batch: 5633/37625 (14.971%), Loss: 0.7834\n",
      "Epoch: 9, Batch: 5889/37625 (15.652%), Loss: 1.4683\n",
      "Epoch: 9, Batch: 6145/37625 (16.332%), Loss: 1.1491\n",
      "Epoch: 9, Batch: 6401/37625 (17.013%), Loss: 0.6714\n",
      "Epoch: 9, Batch: 6657/37625 (17.693%), Loss: 1.5401\n",
      "Epoch: 9, Batch: 6913/37625 (18.373%), Loss: 0.7847\n",
      "Epoch: 9, Batch: 7169/37625 (19.054%), Loss: 0.6606\n",
      "Epoch: 9, Batch: 7425/37625 (19.734%), Loss: 1.0808\n",
      "Epoch: 9, Batch: 7681/37625 (20.415%), Loss: 0.8574\n",
      "Epoch: 9, Batch: 7937/37625 (21.095%), Loss: 0.8232\n",
      "Epoch: 9, Batch: 8193/37625 (21.775%), Loss: 0.6924\n",
      "Epoch: 9, Batch: 8449/37625 (22.456%), Loss: 1.0333\n",
      "Epoch: 9, Batch: 8705/37625 (23.136%), Loss: 1.0112\n",
      "Epoch: 9, Batch: 8961/37625 (23.817%), Loss: 1.2984\n",
      "Epoch: 9, Batch: 9217/37625 (24.497%), Loss: 1.0294\n",
      "Epoch: 9, Batch: 9473/37625 (25.177%), Loss: 1.1228\n",
      "Epoch: 9, Batch: 9729/37625 (25.858%), Loss: 0.6008\n",
      "Epoch: 9, Batch: 9985/37625 (26.538%), Loss: 0.8081\n",
      "Epoch: 9, Batch: 10241/37625 (27.219%), Loss: 1.1805\n",
      "Epoch: 9, Batch: 10497/37625 (27.899%), Loss: 0.6128\n",
      "Epoch: 9, Batch: 10753/37625 (28.579%), Loss: 1.0233\n",
      "Epoch: 9, Batch: 11009/37625 (29.260%), Loss: 0.7211\n",
      "Epoch: 9, Batch: 11265/37625 (29.940%), Loss: 0.8764\n",
      "Epoch: 9, Batch: 11521/37625 (30.621%), Loss: 5.3119\n",
      "Epoch: 9, Batch: 11777/37625 (31.301%), Loss: 0.7474\n",
      "Epoch: 9, Batch: 12033/37625 (31.981%), Loss: 0.7840\n",
      "Epoch: 9, Batch: 12289/37625 (32.662%), Loss: 0.6828\n",
      "Epoch: 9, Batch: 12545/37625 (33.342%), Loss: 0.9466\n",
      "Epoch: 9, Batch: 12801/37625 (34.023%), Loss: 0.7623\n",
      "Epoch: 9, Batch: 13057/37625 (34.703%), Loss: 0.9909\n",
      "Epoch: 9, Batch: 13313/37625 (35.383%), Loss: 0.6937\n",
      "Epoch: 9, Batch: 13569/37625 (36.064%), Loss: 1.1275\n",
      "Epoch: 9, Batch: 13825/37625 (36.744%), Loss: 1.0043\n",
      "Epoch: 9, Batch: 14081/37625 (37.425%), Loss: 1.5887\n",
      "Epoch: 9, Batch: 14337/37625 (38.105%), Loss: 1.9547\n",
      "Epoch: 9, Batch: 14593/37625 (38.785%), Loss: 0.9415\n",
      "Epoch: 9, Batch: 14849/37625 (39.466%), Loss: 1.0297\n",
      "Epoch: 9, Batch: 15105/37625 (40.146%), Loss: 3.2599\n",
      "Epoch: 9, Batch: 15361/37625 (40.827%), Loss: 0.8079\n",
      "Epoch: 9, Batch: 15617/37625 (41.507%), Loss: 1.5933\n",
      "Epoch: 9, Batch: 15873/37625 (42.187%), Loss: 0.6889\n",
      "Epoch: 9, Batch: 16129/37625 (42.868%), Loss: 0.8398\n",
      "Epoch: 9, Batch: 16385/37625 (43.548%), Loss: 1.7420\n",
      "Epoch: 9, Batch: 16641/37625 (44.229%), Loss: 0.6443\n",
      "Epoch: 9, Batch: 16897/37625 (44.909%), Loss: 1.1814\n",
      "Epoch: 9, Batch: 17153/37625 (45.589%), Loss: 0.9371\n",
      "Epoch: 9, Batch: 17409/37625 (46.270%), Loss: 0.8494\n",
      "Epoch: 9, Batch: 17665/37625 (46.950%), Loss: 0.8251\n",
      "Epoch: 9, Batch: 17921/37625 (47.631%), Loss: 1.0766\n",
      "Epoch: 9, Batch: 18177/37625 (48.311%), Loss: 3.5855\n",
      "Epoch: 9, Batch: 18433/37625 (48.991%), Loss: 0.7179\n",
      "Epoch: 9, Batch: 18689/37625 (49.672%), Loss: 1.5789\n",
      "Epoch: 9, Batch: 18945/37625 (50.352%), Loss: 1.1050\n",
      "Epoch: 9, Batch: 19201/37625 (51.033%), Loss: 0.9671\n",
      "Epoch: 9, Batch: 19457/37625 (51.713%), Loss: 0.7076\n",
      "Epoch: 9, Batch: 19713/37625 (52.393%), Loss: 0.5445\n",
      "Epoch: 9, Batch: 19969/37625 (53.074%), Loss: 1.0567\n",
      "Epoch: 9, Batch: 20225/37625 (53.754%), Loss: 0.8012\n",
      "Epoch: 9, Batch: 20481/37625 (54.435%), Loss: 0.9113\n",
      "Epoch: 9, Batch: 20737/37625 (55.115%), Loss: 0.7170\n",
      "Epoch: 9, Batch: 20993/37625 (55.795%), Loss: 0.5687\n",
      "Epoch: 9, Batch: 21249/37625 (56.476%), Loss: 0.9666\n",
      "Epoch: 9, Batch: 21505/37625 (57.156%), Loss: 0.8133\n",
      "Epoch: 9, Batch: 21761/37625 (57.837%), Loss: 1.0143\n",
      "Epoch: 9, Batch: 22017/37625 (58.517%), Loss: 1.6562\n",
      "Epoch: 9, Batch: 22273/37625 (59.197%), Loss: 1.1148\n",
      "Epoch: 9, Batch: 22529/37625 (59.878%), Loss: 1.0583\n",
      "Epoch: 9, Batch: 22785/37625 (60.558%), Loss: 0.6914\n",
      "Epoch: 9, Batch: 23041/37625 (61.239%), Loss: 3.2480\n",
      "Epoch: 9, Batch: 23297/37625 (61.919%), Loss: 1.5948\n",
      "Epoch: 9, Batch: 23553/37625 (62.599%), Loss: 1.0783\n",
      "Epoch: 9, Batch: 23809/37625 (63.280%), Loss: 1.3295\n",
      "Epoch: 9, Batch: 24065/37625 (63.960%), Loss: 0.8395\n",
      "Epoch: 9, Batch: 24321/37625 (64.641%), Loss: 1.4228\n",
      "Epoch: 9, Batch: 24577/37625 (65.321%), Loss: 0.8769\n",
      "Epoch: 9, Batch: 24833/37625 (66.001%), Loss: 0.5585\n",
      "Epoch: 9, Batch: 25089/37625 (66.682%), Loss: 0.9047\n",
      "Epoch: 9, Batch: 25345/37625 (67.362%), Loss: 0.6582\n",
      "Epoch: 9, Batch: 25601/37625 (68.043%), Loss: 0.9333\n",
      "Epoch: 9, Batch: 25857/37625 (68.723%), Loss: 0.6315\n",
      "Epoch: 9, Batch: 26113/37625 (69.403%), Loss: 0.8315\n",
      "Epoch: 9, Batch: 26369/37625 (70.084%), Loss: 1.4323\n",
      "Epoch: 9, Batch: 26625/37625 (70.764%), Loss: 0.9238\n",
      "Epoch: 9, Batch: 26881/37625 (71.445%), Loss: 0.8822\n",
      "Epoch: 9, Batch: 27137/37625 (72.125%), Loss: 0.4780\n",
      "Epoch: 9, Batch: 27393/37625 (72.805%), Loss: 0.9502\n",
      "Epoch: 9, Batch: 27649/37625 (73.486%), Loss: 0.7159\n",
      "Epoch: 9, Batch: 27905/37625 (74.166%), Loss: 1.1344\n",
      "Epoch: 9, Batch: 28161/37625 (74.847%), Loss: 1.1441\n",
      "Epoch: 9, Batch: 28417/37625 (75.527%), Loss: 0.9152\n",
      "Epoch: 9, Batch: 28673/37625 (76.207%), Loss: 0.9316\n",
      "Epoch: 9, Batch: 28929/37625 (76.888%), Loss: 0.7891\n",
      "Epoch: 9, Batch: 29185/37625 (77.568%), Loss: 0.5873\n",
      "Epoch: 9, Batch: 29441/37625 (78.249%), Loss: 5.3045\n",
      "Epoch: 9, Batch: 29697/37625 (78.929%), Loss: 0.6803\n",
      "Epoch: 9, Batch: 29953/37625 (79.609%), Loss: 0.9939\n",
      "Epoch: 9, Batch: 30209/37625 (80.290%), Loss: 1.4612\n",
      "Epoch: 9, Batch: 30465/37625 (80.970%), Loss: 0.7513\n",
      "Epoch: 9, Batch: 30721/37625 (81.650%), Loss: 0.6801\n",
      "Epoch: 9, Batch: 30977/37625 (82.331%), Loss: 0.9922\n",
      "Epoch: 9, Batch: 31233/37625 (83.011%), Loss: 0.8316\n",
      "Epoch: 9, Batch: 31489/37625 (83.692%), Loss: 0.8604\n",
      "Epoch: 9, Batch: 31745/37625 (84.372%), Loss: 1.5436\n",
      "Epoch: 9, Batch: 32001/37625 (85.052%), Loss: 0.6517\n",
      "Epoch: 9, Batch: 32257/37625 (85.733%), Loss: 4.7671\n",
      "Epoch: 9, Batch: 32513/37625 (86.413%), Loss: 2.8688\n",
      "Epoch: 9, Batch: 32769/37625 (87.094%), Loss: 0.6503\n",
      "Epoch: 9, Batch: 33025/37625 (87.774%), Loss: 0.8883\n",
      "Epoch: 9, Batch: 33281/37625 (88.454%), Loss: 0.6984\n",
      "Epoch: 9, Batch: 33537/37625 (89.135%), Loss: 0.8354\n",
      "Epoch: 9, Batch: 33793/37625 (89.815%), Loss: 1.1466\n",
      "Epoch: 9, Batch: 34049/37625 (90.496%), Loss: 1.4018\n",
      "Epoch: 9, Batch: 34305/37625 (91.176%), Loss: 0.8523\n",
      "Epoch: 9, Batch: 34561/37625 (91.856%), Loss: 0.6788\n",
      "Epoch: 9, Batch: 34817/37625 (92.537%), Loss: 0.7723\n",
      "Epoch: 9, Batch: 35073/37625 (93.217%), Loss: 0.6249\n",
      "Epoch: 9, Batch: 35329/37625 (93.898%), Loss: 0.7925\n",
      "Epoch: 9, Batch: 35585/37625 (94.578%), Loss: 0.6918\n",
      "Epoch: 9, Batch: 35841/37625 (95.258%), Loss: 0.7057\n",
      "Epoch: 9, Batch: 36097/37625 (95.939%), Loss: 2.2306\n",
      "Epoch: 9, Batch: 36353/37625 (96.619%), Loss: 1.1155\n",
      "Epoch: 9, Batch: 36609/37625 (97.300%), Loss: 0.8901\n",
      "Epoch: 9, Batch: 36865/37625 (97.980%), Loss: 0.7136\n",
      "Epoch: 9, Batch: 37121/37625 (98.660%), Loss: 1.0548\n",
      "Epoch: 9, Batch: 37377/37625 (99.341%), Loss: 0.9648\n",
      "Epoch: 10, Batch: 1/37625 (0.003%), Loss: 0.7127\n",
      "Epoch: 10, Batch: 257/37625 (0.683%), Loss: 1.1603\n",
      "Epoch: 10, Batch: 513/37625 (1.363%), Loss: 0.6418\n",
      "Epoch: 10, Batch: 769/37625 (2.044%), Loss: 0.9446\n",
      "Epoch: 10, Batch: 1025/37625 (2.724%), Loss: 1.2443\n",
      "Epoch: 10, Batch: 1281/37625 (3.405%), Loss: 0.8945\n",
      "Epoch: 10, Batch: 1537/37625 (4.085%), Loss: 0.6333\n",
      "Epoch: 10, Batch: 1793/37625 (4.765%), Loss: 1.5547\n",
      "Epoch: 10, Batch: 2049/37625 (5.446%), Loss: 0.7292\n",
      "Epoch: 10, Batch: 2305/37625 (6.126%), Loss: 1.1673\n",
      "Epoch: 10, Batch: 2561/37625 (6.807%), Loss: 0.9123\n",
      "Epoch: 10, Batch: 2817/37625 (7.487%), Loss: 1.1826\n",
      "Epoch: 10, Batch: 3073/37625 (8.167%), Loss: 1.2553\n",
      "Epoch: 10, Batch: 3329/37625 (8.848%), Loss: 0.6796\n",
      "Epoch: 10, Batch: 3585/37625 (9.528%), Loss: 0.6611\n",
      "Epoch: 10, Batch: 3841/37625 (10.209%), Loss: 0.9062\n",
      "Epoch: 10, Batch: 4097/37625 (10.889%), Loss: 1.3432\n",
      "Epoch: 10, Batch: 4353/37625 (11.569%), Loss: 1.1464\n",
      "Epoch: 10, Batch: 4609/37625 (12.250%), Loss: 1.0196\n",
      "Epoch: 10, Batch: 4865/37625 (12.930%), Loss: 0.8187\n",
      "Epoch: 10, Batch: 5121/37625 (13.611%), Loss: 1.1116\n",
      "Epoch: 10, Batch: 5377/37625 (14.291%), Loss: 0.9361\n",
      "Epoch: 10, Batch: 5633/37625 (14.971%), Loss: 1.4276\n",
      "Epoch: 10, Batch: 5889/37625 (15.652%), Loss: 3.1806\n",
      "Epoch: 10, Batch: 6145/37625 (16.332%), Loss: 0.7920\n",
      "Epoch: 10, Batch: 6401/37625 (17.013%), Loss: 1.0021\n",
      "Epoch: 10, Batch: 6657/37625 (17.693%), Loss: 0.6663\n",
      "Epoch: 10, Batch: 6913/37625 (18.373%), Loss: 0.7758\n",
      "Epoch: 10, Batch: 7169/37625 (19.054%), Loss: 1.9265\n",
      "Epoch: 10, Batch: 7425/37625 (19.734%), Loss: 0.7248\n",
      "Epoch: 10, Batch: 7681/37625 (20.415%), Loss: 0.6380\n",
      "Epoch: 10, Batch: 7937/37625 (21.095%), Loss: 1.0088\n",
      "Epoch: 10, Batch: 8193/37625 (21.775%), Loss: 0.7889\n",
      "Epoch: 10, Batch: 8449/37625 (22.456%), Loss: 1.1203\n",
      "Epoch: 10, Batch: 8705/37625 (23.136%), Loss: 1.6610\n",
      "Epoch: 10, Batch: 8961/37625 (23.817%), Loss: 0.7925\n",
      "Epoch: 10, Batch: 9217/37625 (24.497%), Loss: 0.8281\n",
      "Epoch: 10, Batch: 9473/37625 (25.177%), Loss: 0.5561\n",
      "Epoch: 10, Batch: 9729/37625 (25.858%), Loss: 0.8043\n",
      "Epoch: 10, Batch: 9985/37625 (26.538%), Loss: 0.7295\n",
      "Epoch: 10, Batch: 10241/37625 (27.219%), Loss: 1.2293\n",
      "Epoch: 10, Batch: 10497/37625 (27.899%), Loss: 0.7649\n",
      "Epoch: 10, Batch: 10753/37625 (28.579%), Loss: 1.9792\n",
      "Epoch: 10, Batch: 11009/37625 (29.260%), Loss: 1.0015\n",
      "Epoch: 10, Batch: 11265/37625 (29.940%), Loss: 1.3478\n",
      "Epoch: 10, Batch: 11521/37625 (30.621%), Loss: 0.9121\n",
      "Epoch: 10, Batch: 11777/37625 (31.301%), Loss: 0.8291\n",
      "Epoch: 10, Batch: 12033/37625 (31.981%), Loss: 0.8613\n",
      "Epoch: 10, Batch: 12289/37625 (32.662%), Loss: 0.7120\n",
      "Epoch: 10, Batch: 12545/37625 (33.342%), Loss: 1.6260\n",
      "Epoch: 10, Batch: 12801/37625 (34.023%), Loss: 0.6853\n",
      "Epoch: 10, Batch: 13057/37625 (34.703%), Loss: 0.8978\n",
      "Epoch: 10, Batch: 13313/37625 (35.383%), Loss: 0.7206\n",
      "Epoch: 10, Batch: 13569/37625 (36.064%), Loss: 0.7928\n",
      "Epoch: 10, Batch: 13825/37625 (36.744%), Loss: 0.6680\n",
      "Epoch: 10, Batch: 14081/37625 (37.425%), Loss: 1.4473\n",
      "Epoch: 10, Batch: 14337/37625 (38.105%), Loss: 3.2325\n",
      "Epoch: 10, Batch: 14593/37625 (38.785%), Loss: 1.2842\n",
      "Epoch: 10, Batch: 14849/37625 (39.466%), Loss: 1.4223\n",
      "Epoch: 10, Batch: 15105/37625 (40.146%), Loss: 0.6445\n",
      "Epoch: 10, Batch: 15361/37625 (40.827%), Loss: 0.8929\n",
      "Epoch: 10, Batch: 15617/37625 (41.507%), Loss: 1.0813\n",
      "Epoch: 10, Batch: 15873/37625 (42.187%), Loss: 0.5485\n",
      "Epoch: 10, Batch: 16129/37625 (42.868%), Loss: 0.8046\n",
      "Epoch: 10, Batch: 16385/37625 (43.548%), Loss: 1.0234\n",
      "Epoch: 10, Batch: 16641/37625 (44.229%), Loss: 0.7267\n",
      "Epoch: 10, Batch: 16897/37625 (44.909%), Loss: 0.7245\n",
      "Epoch: 10, Batch: 17153/37625 (45.589%), Loss: 0.8077\n",
      "Epoch: 10, Batch: 17409/37625 (46.270%), Loss: 0.9808\n",
      "Epoch: 10, Batch: 17665/37625 (46.950%), Loss: 1.4313\n",
      "Epoch: 10, Batch: 17921/37625 (47.631%), Loss: 1.5086\n",
      "Epoch: 10, Batch: 18177/37625 (48.311%), Loss: 0.5193\n",
      "Epoch: 10, Batch: 18433/37625 (48.991%), Loss: 0.7426\n",
      "Epoch: 10, Batch: 18689/37625 (49.672%), Loss: 2.1887\n",
      "Epoch: 10, Batch: 18945/37625 (50.352%), Loss: 1.0364\n",
      "Epoch: 10, Batch: 19201/37625 (51.033%), Loss: 2.2073\n",
      "Epoch: 10, Batch: 19457/37625 (51.713%), Loss: 0.5701\n",
      "Epoch: 10, Batch: 19713/37625 (52.393%), Loss: 0.5502\n",
      "Epoch: 10, Batch: 19969/37625 (53.074%), Loss: 0.6434\n",
      "Epoch: 10, Batch: 20225/37625 (53.754%), Loss: 1.0093\n",
      "Epoch: 10, Batch: 20481/37625 (54.435%), Loss: 1.0424\n",
      "Epoch: 10, Batch: 20737/37625 (55.115%), Loss: 0.7587\n",
      "Epoch: 10, Batch: 20993/37625 (55.795%), Loss: 1.3383\n",
      "Epoch: 10, Batch: 21249/37625 (56.476%), Loss: 1.6064\n",
      "Epoch: 10, Batch: 21505/37625 (57.156%), Loss: 0.8998\n",
      "Epoch: 10, Batch: 21761/37625 (57.837%), Loss: 1.2676\n",
      "Epoch: 10, Batch: 22017/37625 (58.517%), Loss: 0.5125\n",
      "Epoch: 10, Batch: 22273/37625 (59.197%), Loss: 2.2741\n",
      "Epoch: 10, Batch: 22529/37625 (59.878%), Loss: 6.0178\n",
      "Epoch: 10, Batch: 22785/37625 (60.558%), Loss: 0.7567\n",
      "Epoch: 10, Batch: 23041/37625 (61.239%), Loss: 5.0776\n",
      "Epoch: 10, Batch: 23297/37625 (61.919%), Loss: 0.8301\n",
      "Epoch: 10, Batch: 23553/37625 (62.599%), Loss: 0.8052\n",
      "Epoch: 10, Batch: 23809/37625 (63.280%), Loss: 0.6676\n",
      "Epoch: 10, Batch: 24065/37625 (63.960%), Loss: 0.5681\n",
      "Epoch: 10, Batch: 24321/37625 (64.641%), Loss: 0.9898\n",
      "Epoch: 10, Batch: 24577/37625 (65.321%), Loss: 0.6273\n",
      "Epoch: 10, Batch: 24833/37625 (66.001%), Loss: 2.0881\n",
      "Epoch: 10, Batch: 25089/37625 (66.682%), Loss: 0.7104\n",
      "Epoch: 10, Batch: 25345/37625 (67.362%), Loss: 0.9948\n",
      "Epoch: 10, Batch: 25601/37625 (68.043%), Loss: 0.5858\n",
      "Epoch: 10, Batch: 25857/37625 (68.723%), Loss: 0.9895\n",
      "Epoch: 10, Batch: 26113/37625 (69.403%), Loss: 1.6144\n",
      "Epoch: 10, Batch: 26369/37625 (70.084%), Loss: 0.8664\n",
      "Epoch: 10, Batch: 26625/37625 (70.764%), Loss: 1.3761\n",
      "Epoch: 10, Batch: 26881/37625 (71.445%), Loss: 1.9055\n",
      "Epoch: 10, Batch: 27137/37625 (72.125%), Loss: 0.7904\n",
      "Epoch: 10, Batch: 27393/37625 (72.805%), Loss: 0.6813\n",
      "Epoch: 10, Batch: 27649/37625 (73.486%), Loss: 0.6751\n",
      "Epoch: 10, Batch: 27905/37625 (74.166%), Loss: 0.8594\n",
      "Epoch: 10, Batch: 28161/37625 (74.847%), Loss: 1.1196\n",
      "Epoch: 10, Batch: 28417/37625 (75.527%), Loss: 0.5846\n",
      "Epoch: 10, Batch: 28673/37625 (76.207%), Loss: 0.7014\n",
      "Epoch: 10, Batch: 28929/37625 (76.888%), Loss: 0.7851\n",
      "Epoch: 10, Batch: 29185/37625 (77.568%), Loss: 1.0206\n",
      "Epoch: 10, Batch: 29441/37625 (78.249%), Loss: 1.3987\n",
      "Epoch: 10, Batch: 29697/37625 (78.929%), Loss: 1.0199\n",
      "Epoch: 10, Batch: 29953/37625 (79.609%), Loss: 0.6710\n",
      "Epoch: 10, Batch: 30209/37625 (80.290%), Loss: 1.0150\n",
      "Epoch: 10, Batch: 30465/37625 (80.970%), Loss: 0.8023\n",
      "Epoch: 10, Batch: 30721/37625 (81.650%), Loss: 0.9231\n",
      "Epoch: 10, Batch: 30977/37625 (82.331%), Loss: 1.3650\n",
      "Epoch: 10, Batch: 31233/37625 (83.011%), Loss: 0.7046\n",
      "Epoch: 10, Batch: 31489/37625 (83.692%), Loss: 1.2630\n",
      "Epoch: 10, Batch: 31745/37625 (84.372%), Loss: 0.5908\n",
      "Epoch: 10, Batch: 32001/37625 (85.052%), Loss: 0.6474\n",
      "Epoch: 10, Batch: 32257/37625 (85.733%), Loss: 0.6925\n",
      "Epoch: 10, Batch: 32513/37625 (86.413%), Loss: 1.3464\n",
      "Epoch: 10, Batch: 32769/37625 (87.094%), Loss: 0.9819\n",
      "Epoch: 10, Batch: 33025/37625 (87.774%), Loss: 0.7345\n",
      "Epoch: 10, Batch: 33281/37625 (88.454%), Loss: 0.6180\n",
      "Epoch: 10, Batch: 33537/37625 (89.135%), Loss: 0.5406\n",
      "Epoch: 10, Batch: 33793/37625 (89.815%), Loss: 1.0823\n",
      "Epoch: 10, Batch: 34049/37625 (90.496%), Loss: 0.8733\n",
      "Epoch: 10, Batch: 34305/37625 (91.176%), Loss: 5.9842\n",
      "Epoch: 10, Batch: 34561/37625 (91.856%), Loss: 0.6875\n",
      "Epoch: 10, Batch: 34817/37625 (92.537%), Loss: 0.8984\n",
      "Epoch: 10, Batch: 35073/37625 (93.217%), Loss: 0.6861\n",
      "Epoch: 10, Batch: 35329/37625 (93.898%), Loss: 0.8702\n",
      "Epoch: 10, Batch: 35585/37625 (94.578%), Loss: 0.4854\n",
      "Epoch: 10, Batch: 35841/37625 (95.258%), Loss: 2.6739\n",
      "Epoch: 10, Batch: 36097/37625 (95.939%), Loss: 0.7555\n",
      "Epoch: 10, Batch: 36353/37625 (96.619%), Loss: 0.9197\n",
      "Epoch: 10, Batch: 36609/37625 (97.300%), Loss: 0.9949\n",
      "Epoch: 10, Batch: 36865/37625 (97.980%), Loss: 0.6998\n",
      "Epoch: 10, Batch: 37121/37625 (98.660%), Loss: 0.9662\n",
      "Epoch: 10, Batch: 37377/37625 (99.341%), Loss: 1.3664\n",
      "Epoch: 11, Batch: 1/37625 (0.003%), Loss: 0.9478\n",
      "Epoch: 11, Batch: 257/37625 (0.683%), Loss: 2.0300\n",
      "Epoch: 11, Batch: 513/37625 (1.363%), Loss: 1.2721\n",
      "Epoch: 11, Batch: 769/37625 (2.044%), Loss: 0.6260\n",
      "Epoch: 11, Batch: 1025/37625 (2.724%), Loss: 0.9339\n",
      "Epoch: 11, Batch: 1281/37625 (3.405%), Loss: 0.7528\n",
      "Epoch: 11, Batch: 1537/37625 (4.085%), Loss: 2.1443\n",
      "Epoch: 11, Batch: 1793/37625 (4.765%), Loss: 0.6680\n",
      "Epoch: 11, Batch: 2049/37625 (5.446%), Loss: 1.1465\n",
      "Epoch: 11, Batch: 2305/37625 (6.126%), Loss: 0.8886\n",
      "Epoch: 11, Batch: 2561/37625 (6.807%), Loss: 0.6465\n",
      "Epoch: 11, Batch: 2817/37625 (7.487%), Loss: 0.6925\n",
      "Epoch: 11, Batch: 3073/37625 (8.167%), Loss: 0.7913\n",
      "Epoch: 11, Batch: 3329/37625 (8.848%), Loss: 1.3041\n",
      "Epoch: 11, Batch: 3585/37625 (9.528%), Loss: 1.1564\n",
      "Epoch: 11, Batch: 3841/37625 (10.209%), Loss: 1.6415\n",
      "Epoch: 11, Batch: 4097/37625 (10.889%), Loss: 0.6769\n",
      "Epoch: 11, Batch: 4353/37625 (11.569%), Loss: 0.8828\n",
      "Epoch: 11, Batch: 4609/37625 (12.250%), Loss: 0.8608\n",
      "Epoch: 11, Batch: 4865/37625 (12.930%), Loss: 1.0085\n",
      "Epoch: 11, Batch: 5121/37625 (13.611%), Loss: 0.6005\n",
      "Epoch: 11, Batch: 5377/37625 (14.291%), Loss: 1.0599\n",
      "Epoch: 11, Batch: 5633/37625 (14.971%), Loss: 0.6691\n",
      "Epoch: 11, Batch: 5889/37625 (15.652%), Loss: 1.1956\n",
      "Epoch: 11, Batch: 6145/37625 (16.332%), Loss: 0.9964\n",
      "Epoch: 11, Batch: 6401/37625 (17.013%), Loss: 1.0372\n",
      "Epoch: 11, Batch: 6657/37625 (17.693%), Loss: 0.7938\n",
      "Epoch: 11, Batch: 6913/37625 (18.373%), Loss: 0.9156\n",
      "Epoch: 11, Batch: 7169/37625 (19.054%), Loss: 0.7519\n",
      "Epoch: 11, Batch: 7425/37625 (19.734%), Loss: 0.9598\n",
      "Epoch: 11, Batch: 7681/37625 (20.415%), Loss: 4.8658\n",
      "Epoch: 11, Batch: 7937/37625 (21.095%), Loss: 1.1564\n",
      "Epoch: 11, Batch: 8193/37625 (21.775%), Loss: 1.3254\n",
      "Epoch: 11, Batch: 8449/37625 (22.456%), Loss: 1.1510\n",
      "Epoch: 11, Batch: 8705/37625 (23.136%), Loss: 0.6139\n",
      "Epoch: 11, Batch: 8961/37625 (23.817%), Loss: 0.7623\n",
      "Epoch: 11, Batch: 9217/37625 (24.497%), Loss: 0.6169\n",
      "Epoch: 11, Batch: 9473/37625 (25.177%), Loss: 1.2360\n",
      "Epoch: 11, Batch: 9729/37625 (25.858%), Loss: 1.1904\n",
      "Epoch: 11, Batch: 9985/37625 (26.538%), Loss: 0.6020\n",
      "Epoch: 11, Batch: 10241/37625 (27.219%), Loss: 1.1470\n",
      "Epoch: 11, Batch: 10497/37625 (27.899%), Loss: 0.6462\n",
      "Epoch: 11, Batch: 10753/37625 (28.579%), Loss: 0.6637\n",
      "Epoch: 11, Batch: 11009/37625 (29.260%), Loss: 0.8642\n",
      "Epoch: 11, Batch: 11265/37625 (29.940%), Loss: 0.8618\n",
      "Epoch: 11, Batch: 11521/37625 (30.621%), Loss: 1.0714\n",
      "Epoch: 11, Batch: 11777/37625 (31.301%), Loss: 1.1231\n",
      "Epoch: 11, Batch: 12033/37625 (31.981%), Loss: 0.8104\n",
      "Epoch: 11, Batch: 12289/37625 (32.662%), Loss: 5.4534\n",
      "Epoch: 11, Batch: 12545/37625 (33.342%), Loss: 0.6912\n",
      "Epoch: 11, Batch: 12801/37625 (34.023%), Loss: 0.5828\n",
      "Epoch: 11, Batch: 13057/37625 (34.703%), Loss: 2.3553\n",
      "Epoch: 11, Batch: 13313/37625 (35.383%), Loss: 4.9182\n",
      "Epoch: 11, Batch: 13569/37625 (36.064%), Loss: 0.8350\n",
      "Epoch: 11, Batch: 13825/37625 (36.744%), Loss: 0.7246\n",
      "Epoch: 11, Batch: 14081/37625 (37.425%), Loss: 0.7185\n",
      "Epoch: 11, Batch: 14337/37625 (38.105%), Loss: 0.6386\n",
      "Epoch: 11, Batch: 14593/37625 (38.785%), Loss: 0.9972\n",
      "Epoch: 11, Batch: 14849/37625 (39.466%), Loss: 1.0242\n",
      "Epoch: 11, Batch: 15105/37625 (40.146%), Loss: 0.5254\n",
      "Epoch: 11, Batch: 15361/37625 (40.827%), Loss: 0.8637\n",
      "Epoch: 11, Batch: 15617/37625 (41.507%), Loss: 0.9838\n",
      "Epoch: 11, Batch: 15873/37625 (42.187%), Loss: 1.6509\n",
      "Epoch: 11, Batch: 16129/37625 (42.868%), Loss: 0.9378\n",
      "Epoch: 11, Batch: 16385/37625 (43.548%), Loss: 0.4815\n",
      "Epoch: 11, Batch: 16641/37625 (44.229%), Loss: 1.4767\n",
      "Epoch: 11, Batch: 16897/37625 (44.909%), Loss: 0.8210\n",
      "Epoch: 11, Batch: 17153/37625 (45.589%), Loss: 0.6732\n",
      "Epoch: 11, Batch: 17409/37625 (46.270%), Loss: 0.9782\n",
      "Epoch: 11, Batch: 17665/37625 (46.950%), Loss: 1.6385\n",
      "Epoch: 11, Batch: 17921/37625 (47.631%), Loss: 0.7420\n",
      "Epoch: 11, Batch: 18177/37625 (48.311%), Loss: 0.6155\n",
      "Epoch: 11, Batch: 18433/37625 (48.991%), Loss: 0.8587\n",
      "Epoch: 11, Batch: 18689/37625 (49.672%), Loss: 0.9404\n",
      "Epoch: 11, Batch: 18945/37625 (50.352%), Loss: 0.6636\n",
      "Epoch: 11, Batch: 19201/37625 (51.033%), Loss: 1.0814\n",
      "Epoch: 11, Batch: 19457/37625 (51.713%), Loss: 1.3073\n",
      "Epoch: 11, Batch: 19713/37625 (52.393%), Loss: 0.9693\n",
      "Epoch: 11, Batch: 19969/37625 (53.074%), Loss: 0.9677\n",
      "Epoch: 11, Batch: 20225/37625 (53.754%), Loss: 0.8633\n",
      "Epoch: 11, Batch: 20481/37625 (54.435%), Loss: 0.5598\n",
      "Epoch: 11, Batch: 20737/37625 (55.115%), Loss: 0.7557\n",
      "Epoch: 11, Batch: 20993/37625 (55.795%), Loss: 0.7963\n",
      "Epoch: 11, Batch: 21249/37625 (56.476%), Loss: 1.5130\n",
      "Epoch: 11, Batch: 21505/37625 (57.156%), Loss: 0.7229\n",
      "Epoch: 11, Batch: 21761/37625 (57.837%), Loss: 0.8309\n",
      "Epoch: 11, Batch: 22017/37625 (58.517%), Loss: 0.6519\n",
      "Epoch: 11, Batch: 22273/37625 (59.197%), Loss: 1.6210\n",
      "Epoch: 11, Batch: 22529/37625 (59.878%), Loss: 4.1222\n",
      "Epoch: 11, Batch: 22785/37625 (60.558%), Loss: 0.9925\n",
      "Epoch: 11, Batch: 23041/37625 (61.239%), Loss: 0.9120\n",
      "Epoch: 11, Batch: 23297/37625 (61.919%), Loss: 0.7999\n",
      "Epoch: 11, Batch: 23553/37625 (62.599%), Loss: 0.7614\n",
      "Epoch: 11, Batch: 23809/37625 (63.280%), Loss: 1.0547\n",
      "Epoch: 11, Batch: 24065/37625 (63.960%), Loss: 1.2493\n",
      "Epoch: 11, Batch: 24321/37625 (64.641%), Loss: 0.5898\n",
      "Epoch: 11, Batch: 24577/37625 (65.321%), Loss: 0.6449\n",
      "Epoch: 11, Batch: 24833/37625 (66.001%), Loss: 1.3798\n",
      "Epoch: 11, Batch: 25089/37625 (66.682%), Loss: 0.8589\n",
      "Epoch: 11, Batch: 25345/37625 (67.362%), Loss: 3.2649\n",
      "Epoch: 11, Batch: 25601/37625 (68.043%), Loss: 0.9841\n",
      "Epoch: 11, Batch: 25857/37625 (68.723%), Loss: 0.8602\n",
      "Epoch: 11, Batch: 26113/37625 (69.403%), Loss: 1.1208\n",
      "Epoch: 11, Batch: 26369/37625 (70.084%), Loss: 0.7594\n",
      "Epoch: 11, Batch: 26625/37625 (70.764%), Loss: 0.8224\n",
      "Epoch: 11, Batch: 26881/37625 (71.445%), Loss: 1.6972\n",
      "Epoch: 11, Batch: 27137/37625 (72.125%), Loss: 0.5781\n",
      "Epoch: 11, Batch: 27393/37625 (72.805%), Loss: 0.6969\n",
      "Epoch: 11, Batch: 27649/37625 (73.486%), Loss: 1.8045\n",
      "Epoch: 11, Batch: 27905/37625 (74.166%), Loss: 1.1415\n",
      "Epoch: 11, Batch: 28161/37625 (74.847%), Loss: 0.7959\n",
      "Epoch: 11, Batch: 28417/37625 (75.527%), Loss: 0.8051\n",
      "Epoch: 11, Batch: 28673/37625 (76.207%), Loss: 0.7914\n",
      "Epoch: 11, Batch: 28929/37625 (76.888%), Loss: 1.0955\n",
      "Epoch: 11, Batch: 29185/37625 (77.568%), Loss: 0.5631\n",
      "Epoch: 11, Batch: 29441/37625 (78.249%), Loss: 1.8661\n",
      "Epoch: 11, Batch: 29697/37625 (78.929%), Loss: 0.9265\n",
      "Epoch: 11, Batch: 29953/37625 (79.609%), Loss: 1.0016\n",
      "Epoch: 11, Batch: 30209/37625 (80.290%), Loss: 0.8667\n",
      "Epoch: 11, Batch: 30465/37625 (80.970%), Loss: 1.1361\n",
      "Epoch: 11, Batch: 30721/37625 (81.650%), Loss: 1.1976\n",
      "Epoch: 11, Batch: 30977/37625 (82.331%), Loss: 0.7634\n",
      "Epoch: 11, Batch: 31233/37625 (83.011%), Loss: 1.0212\n",
      "Epoch: 11, Batch: 31489/37625 (83.692%), Loss: 1.1948\n",
      "Epoch: 11, Batch: 31745/37625 (84.372%), Loss: 0.6881\n",
      "Epoch: 11, Batch: 32001/37625 (85.052%), Loss: 0.8327\n",
      "Epoch: 11, Batch: 32257/37625 (85.733%), Loss: 0.8678\n",
      "Epoch: 11, Batch: 32513/37625 (86.413%), Loss: 1.2059\n",
      "Epoch: 11, Batch: 32769/37625 (87.094%), Loss: 0.8383\n",
      "Epoch: 11, Batch: 33025/37625 (87.774%), Loss: 1.0106\n",
      "Epoch: 11, Batch: 33281/37625 (88.454%), Loss: 0.6497\n",
      "Epoch: 11, Batch: 33537/37625 (89.135%), Loss: 2.7243\n",
      "Epoch: 11, Batch: 33793/37625 (89.815%), Loss: 0.7869\n",
      "Epoch: 11, Batch: 34049/37625 (90.496%), Loss: 0.7631\n",
      "Epoch: 11, Batch: 34305/37625 (91.176%), Loss: 1.3498\n",
      "Epoch: 11, Batch: 34561/37625 (91.856%), Loss: 0.6009\n",
      "Epoch: 11, Batch: 34817/37625 (92.537%), Loss: 3.3206\n",
      "Epoch: 11, Batch: 35073/37625 (93.217%), Loss: 1.1387\n",
      "Epoch: 11, Batch: 35329/37625 (93.898%), Loss: 0.9010\n",
      "Epoch: 11, Batch: 35585/37625 (94.578%), Loss: 1.5152\n",
      "Epoch: 11, Batch: 35841/37625 (95.258%), Loss: 1.0731\n",
      "Epoch: 11, Batch: 36097/37625 (95.939%), Loss: 0.7478\n",
      "Epoch: 11, Batch: 36353/37625 (96.619%), Loss: 1.4100\n",
      "Epoch: 11, Batch: 36609/37625 (97.300%), Loss: 0.9775\n",
      "Epoch: 11, Batch: 36865/37625 (97.980%), Loss: 0.6495\n",
      "Epoch: 11, Batch: 37121/37625 (98.660%), Loss: 0.5527\n",
      "Epoch: 11, Batch: 37377/37625 (99.341%), Loss: 0.8540\n",
      "Epoch: 12, Batch: 1/37625 (0.003%), Loss: 0.9265\n",
      "Epoch: 12, Batch: 257/37625 (0.683%), Loss: 0.5935\n",
      "Epoch: 12, Batch: 513/37625 (1.363%), Loss: 0.5847\n",
      "Epoch: 12, Batch: 769/37625 (2.044%), Loss: 0.8739\n",
      "Epoch: 12, Batch: 1025/37625 (2.724%), Loss: 0.8249\n",
      "Epoch: 12, Batch: 1281/37625 (3.405%), Loss: 1.1754\n",
      "Epoch: 12, Batch: 1537/37625 (4.085%), Loss: 0.6761\n",
      "Epoch: 12, Batch: 1793/37625 (4.765%), Loss: 2.4116\n",
      "Epoch: 12, Batch: 2049/37625 (5.446%), Loss: 0.6526\n",
      "Epoch: 12, Batch: 2305/37625 (6.126%), Loss: 0.6597\n",
      "Epoch: 12, Batch: 2561/37625 (6.807%), Loss: 0.7021\n",
      "Epoch: 12, Batch: 2817/37625 (7.487%), Loss: 0.9704\n",
      "Epoch: 12, Batch: 3073/37625 (8.167%), Loss: 1.0158\n",
      "Epoch: 12, Batch: 3329/37625 (8.848%), Loss: 0.9621\n",
      "Epoch: 12, Batch: 3585/37625 (9.528%), Loss: 1.0049\n",
      "Epoch: 12, Batch: 3841/37625 (10.209%), Loss: 1.0665\n",
      "Epoch: 12, Batch: 4097/37625 (10.889%), Loss: 0.8239\n",
      "Epoch: 12, Batch: 4353/37625 (11.569%), Loss: 0.7523\n",
      "Epoch: 12, Batch: 4609/37625 (12.250%), Loss: 0.6904\n",
      "Epoch: 12, Batch: 4865/37625 (12.930%), Loss: 0.7757\n",
      "Epoch: 12, Batch: 5121/37625 (13.611%), Loss: 0.8399\n",
      "Epoch: 12, Batch: 5377/37625 (14.291%), Loss: 0.8123\n",
      "Epoch: 12, Batch: 5633/37625 (14.971%), Loss: 1.1505\n",
      "Epoch: 12, Batch: 5889/37625 (15.652%), Loss: 0.8777\n",
      "Epoch: 12, Batch: 6145/37625 (16.332%), Loss: 0.6317\n",
      "Epoch: 12, Batch: 6401/37625 (17.013%), Loss: 0.7812\n",
      "Epoch: 12, Batch: 6657/37625 (17.693%), Loss: 0.9167\n",
      "Epoch: 12, Batch: 6913/37625 (18.373%), Loss: 1.8698\n",
      "Epoch: 12, Batch: 7169/37625 (19.054%), Loss: 0.8614\n",
      "Epoch: 12, Batch: 7425/37625 (19.734%), Loss: 0.8536\n",
      "Epoch: 12, Batch: 7681/37625 (20.415%), Loss: 0.9898\n",
      "Epoch: 12, Batch: 7937/37625 (21.095%), Loss: 1.5960\n",
      "Epoch: 12, Batch: 8193/37625 (21.775%), Loss: 1.4256\n",
      "Epoch: 12, Batch: 8449/37625 (22.456%), Loss: 1.1253\n",
      "Epoch: 12, Batch: 8705/37625 (23.136%), Loss: 1.0570\n",
      "Epoch: 12, Batch: 8961/37625 (23.817%), Loss: 0.6758\n",
      "Epoch: 12, Batch: 9217/37625 (24.497%), Loss: 1.1431\n",
      "Epoch: 12, Batch: 9473/37625 (25.177%), Loss: 0.7285\n",
      "Epoch: 12, Batch: 9729/37625 (25.858%), Loss: 0.7574\n",
      "Epoch: 12, Batch: 9985/37625 (26.538%), Loss: 0.7477\n",
      "Epoch: 12, Batch: 10241/37625 (27.219%), Loss: 1.3562\n",
      "Epoch: 12, Batch: 10497/37625 (27.899%), Loss: 0.8450\n",
      "Epoch: 12, Batch: 10753/37625 (28.579%), Loss: 0.6820\n",
      "Epoch: 12, Batch: 11009/37625 (29.260%), Loss: 0.9499\n",
      "Epoch: 12, Batch: 11265/37625 (29.940%), Loss: 1.4918\n",
      "Epoch: 12, Batch: 11521/37625 (30.621%), Loss: 1.1393\n",
      "Epoch: 12, Batch: 11777/37625 (31.301%), Loss: 0.6548\n",
      "Epoch: 12, Batch: 12033/37625 (31.981%), Loss: 0.6194\n",
      "Epoch: 12, Batch: 12289/37625 (32.662%), Loss: 1.6657\n",
      "Epoch: 12, Batch: 12545/37625 (33.342%), Loss: 1.2279\n",
      "Epoch: 12, Batch: 12801/37625 (34.023%), Loss: 0.7739\n",
      "Epoch: 12, Batch: 13057/37625 (34.703%), Loss: 0.7956\n",
      "Epoch: 12, Batch: 13313/37625 (35.383%), Loss: 0.6880\n",
      "Epoch: 12, Batch: 13569/37625 (36.064%), Loss: 4.6420\n",
      "Epoch: 12, Batch: 13825/37625 (36.744%), Loss: 1.2926\n",
      "Epoch: 12, Batch: 14081/37625 (37.425%), Loss: 1.1567\n",
      "Epoch: 12, Batch: 14337/37625 (38.105%), Loss: 0.6433\n",
      "Epoch: 12, Batch: 14593/37625 (38.785%), Loss: 0.7975\n",
      "Epoch: 12, Batch: 14849/37625 (39.466%), Loss: 0.9318\n",
      "Epoch: 12, Batch: 15105/37625 (40.146%), Loss: 0.9737\n",
      "Epoch: 12, Batch: 15361/37625 (40.827%), Loss: 1.4032\n",
      "Epoch: 12, Batch: 15617/37625 (41.507%), Loss: 0.7353\n",
      "Epoch: 12, Batch: 15873/37625 (42.187%), Loss: 0.8594\n",
      "Epoch: 12, Batch: 16129/37625 (42.868%), Loss: 1.1249\n",
      "Epoch: 12, Batch: 16385/37625 (43.548%), Loss: 0.8455\n",
      "Epoch: 12, Batch: 16641/37625 (44.229%), Loss: 0.6796\n",
      "Epoch: 12, Batch: 16897/37625 (44.909%), Loss: 5.6546\n",
      "Epoch: 12, Batch: 17153/37625 (45.589%), Loss: 1.4496\n",
      "Epoch: 12, Batch: 17409/37625 (46.270%), Loss: 0.9577\n",
      "Epoch: 12, Batch: 17665/37625 (46.950%), Loss: 1.0893\n",
      "Epoch: 12, Batch: 17921/37625 (47.631%), Loss: 0.7316\n",
      "Epoch: 12, Batch: 18177/37625 (48.311%), Loss: 1.0343\n",
      "Epoch: 12, Batch: 18433/37625 (48.991%), Loss: 0.7244\n",
      "Epoch: 12, Batch: 18689/37625 (49.672%), Loss: 0.8187\n",
      "Epoch: 12, Batch: 18945/37625 (50.352%), Loss: 0.7266\n",
      "Epoch: 12, Batch: 19201/37625 (51.033%), Loss: 2.0213\n",
      "Epoch: 12, Batch: 19457/37625 (51.713%), Loss: 1.0415\n",
      "Epoch: 12, Batch: 19713/37625 (52.393%), Loss: 0.7119\n",
      "Epoch: 12, Batch: 19969/37625 (53.074%), Loss: 0.7509\n",
      "Epoch: 12, Batch: 20225/37625 (53.754%), Loss: 0.9158\n",
      "Epoch: 12, Batch: 20481/37625 (54.435%), Loss: 0.6543\n",
      "Epoch: 12, Batch: 20737/37625 (55.115%), Loss: 0.6635\n",
      "Epoch: 12, Batch: 20993/37625 (55.795%), Loss: 0.7788\n",
      "Epoch: 12, Batch: 21249/37625 (56.476%), Loss: 3.3747\n",
      "Epoch: 12, Batch: 21505/37625 (57.156%), Loss: 0.6130\n",
      "Epoch: 12, Batch: 21761/37625 (57.837%), Loss: 0.5853\n",
      "Epoch: 12, Batch: 22017/37625 (58.517%), Loss: 3.0732\n",
      "Epoch: 12, Batch: 22273/37625 (59.197%), Loss: 2.4750\n",
      "Epoch: 12, Batch: 22529/37625 (59.878%), Loss: 1.2081\n",
      "Epoch: 12, Batch: 22785/37625 (60.558%), Loss: 0.8293\n",
      "Epoch: 12, Batch: 23041/37625 (61.239%), Loss: 0.9282\n",
      "Epoch: 12, Batch: 23297/37625 (61.919%), Loss: 0.7707\n",
      "Epoch: 12, Batch: 23553/37625 (62.599%), Loss: 0.6691\n",
      "Epoch: 12, Batch: 23809/37625 (63.280%), Loss: 0.7526\n",
      "Epoch: 12, Batch: 24065/37625 (63.960%), Loss: 1.0946\n",
      "Epoch: 12, Batch: 24321/37625 (64.641%), Loss: 2.3504\n",
      "Epoch: 12, Batch: 24577/37625 (65.321%), Loss: 0.9813\n",
      "Epoch: 12, Batch: 24833/37625 (66.001%), Loss: 0.6231\n",
      "Epoch: 12, Batch: 25089/37625 (66.682%), Loss: 0.9879\n",
      "Epoch: 12, Batch: 25345/37625 (67.362%), Loss: 0.5586\n",
      "Epoch: 12, Batch: 25601/37625 (68.043%), Loss: 1.4091\n",
      "Epoch: 12, Batch: 25857/37625 (68.723%), Loss: 0.8781\n",
      "Epoch: 12, Batch: 26113/37625 (69.403%), Loss: 1.0432\n",
      "Epoch: 12, Batch: 26369/37625 (70.084%), Loss: 0.8887\n",
      "Epoch: 12, Batch: 26625/37625 (70.764%), Loss: 5.1887\n",
      "Epoch: 12, Batch: 26881/37625 (71.445%), Loss: 0.7365\n",
      "Epoch: 12, Batch: 27137/37625 (72.125%), Loss: 1.1455\n",
      "Epoch: 12, Batch: 27393/37625 (72.805%), Loss: 0.8552\n",
      "Epoch: 12, Batch: 27649/37625 (73.486%), Loss: 0.6705\n",
      "Epoch: 12, Batch: 27905/37625 (74.166%), Loss: 0.9584\n",
      "Epoch: 12, Batch: 28161/37625 (74.847%), Loss: 1.1939\n",
      "Epoch: 12, Batch: 28417/37625 (75.527%), Loss: 1.6873\n",
      "Epoch: 12, Batch: 28673/37625 (76.207%), Loss: 0.8101\n",
      "Epoch: 12, Batch: 28929/37625 (76.888%), Loss: 0.7264\n",
      "Epoch: 12, Batch: 29185/37625 (77.568%), Loss: 0.7112\n",
      "Epoch: 12, Batch: 29441/37625 (78.249%), Loss: 1.0916\n",
      "Epoch: 12, Batch: 29697/37625 (78.929%), Loss: 0.8288\n",
      "Epoch: 12, Batch: 29953/37625 (79.609%), Loss: 1.3917\n",
      "Epoch: 12, Batch: 30209/37625 (80.290%), Loss: 0.6978\n",
      "Epoch: 12, Batch: 30465/37625 (80.970%), Loss: 1.3335\n",
      "Epoch: 12, Batch: 30721/37625 (81.650%), Loss: 0.8012\n",
      "Epoch: 12, Batch: 30977/37625 (82.331%), Loss: 0.8601\n",
      "Epoch: 12, Batch: 31233/37625 (83.011%), Loss: 1.0546\n",
      "Epoch: 12, Batch: 31489/37625 (83.692%), Loss: 1.3779\n",
      "Epoch: 12, Batch: 31745/37625 (84.372%), Loss: 1.3137\n",
      "Epoch: 12, Batch: 32001/37625 (85.052%), Loss: 1.2931\n",
      "Epoch: 12, Batch: 32257/37625 (85.733%), Loss: 0.9980\n",
      "Epoch: 12, Batch: 32513/37625 (86.413%), Loss: 0.6388\n",
      "Epoch: 12, Batch: 32769/37625 (87.094%), Loss: 0.9904\n",
      "Epoch: 12, Batch: 33025/37625 (87.774%), Loss: 0.6491\n",
      "Epoch: 12, Batch: 33281/37625 (88.454%), Loss: 0.7905\n",
      "Epoch: 12, Batch: 33537/37625 (89.135%), Loss: 0.8287\n",
      "Epoch: 12, Batch: 33793/37625 (89.815%), Loss: 1.2904\n",
      "Epoch: 12, Batch: 34049/37625 (90.496%), Loss: 1.0645\n",
      "Epoch: 12, Batch: 34305/37625 (91.176%), Loss: 1.2089\n",
      "Epoch: 12, Batch: 34561/37625 (91.856%), Loss: 1.8362\n",
      "Epoch: 12, Batch: 34817/37625 (92.537%), Loss: 0.7874\n",
      "Epoch: 12, Batch: 35073/37625 (93.217%), Loss: 0.9120\n",
      "Epoch: 12, Batch: 35329/37625 (93.898%), Loss: 1.0742\n",
      "Epoch: 12, Batch: 35585/37625 (94.578%), Loss: 2.0558\n",
      "Epoch: 12, Batch: 35841/37625 (95.258%), Loss: 1.8081\n",
      "Epoch: 12, Batch: 36097/37625 (95.939%), Loss: 0.8396\n",
      "Epoch: 12, Batch: 36353/37625 (96.619%), Loss: 2.0111\n",
      "Epoch: 12, Batch: 36609/37625 (97.300%), Loss: 0.5220\n",
      "Epoch: 12, Batch: 36865/37625 (97.980%), Loss: 0.8704\n",
      "Epoch: 12, Batch: 37121/37625 (98.660%), Loss: 0.5931\n",
      "Epoch: 12, Batch: 37377/37625 (99.341%), Loss: 1.5113\n",
      "Epoch: 13, Batch: 1/37625 (0.003%), Loss: 0.8543\n",
      "Epoch: 13, Batch: 257/37625 (0.683%), Loss: 0.8758\n",
      "Epoch: 13, Batch: 513/37625 (1.363%), Loss: 0.9704\n",
      "Epoch: 13, Batch: 769/37625 (2.044%), Loss: 0.7181\n",
      "Epoch: 13, Batch: 1025/37625 (2.724%), Loss: 0.7546\n",
      "Epoch: 13, Batch: 1281/37625 (3.405%), Loss: 0.9361\n",
      "Epoch: 13, Batch: 1537/37625 (4.085%), Loss: 1.3569\n",
      "Epoch: 13, Batch: 1793/37625 (4.765%), Loss: 0.9531\n",
      "Epoch: 13, Batch: 2049/37625 (5.446%), Loss: 1.7143\n",
      "Epoch: 13, Batch: 2305/37625 (6.126%), Loss: 3.7602\n",
      "Epoch: 13, Batch: 2561/37625 (6.807%), Loss: 0.7245\n",
      "Epoch: 13, Batch: 2817/37625 (7.487%), Loss: 1.0544\n",
      "Epoch: 13, Batch: 3073/37625 (8.167%), Loss: 1.0096\n",
      "Epoch: 13, Batch: 3329/37625 (8.848%), Loss: 0.8331\n",
      "Epoch: 13, Batch: 3585/37625 (9.528%), Loss: 0.8317\n",
      "Epoch: 13, Batch: 3841/37625 (10.209%), Loss: 0.9180\n",
      "Epoch: 13, Batch: 4097/37625 (10.889%), Loss: 1.7714\n",
      "Epoch: 13, Batch: 4353/37625 (11.569%), Loss: 0.6470\n",
      "Epoch: 13, Batch: 4609/37625 (12.250%), Loss: 0.7966\n",
      "Epoch: 13, Batch: 4865/37625 (12.930%), Loss: 1.0286\n",
      "Epoch: 13, Batch: 5121/37625 (13.611%), Loss: 0.8531\n",
      "Epoch: 13, Batch: 5377/37625 (14.291%), Loss: 0.9890\n",
      "Epoch: 13, Batch: 5633/37625 (14.971%), Loss: 1.1021\n",
      "Epoch: 13, Batch: 5889/37625 (15.652%), Loss: 4.8990\n",
      "Epoch: 13, Batch: 6145/37625 (16.332%), Loss: 4.4354\n",
      "Epoch: 13, Batch: 6401/37625 (17.013%), Loss: 0.6996\n",
      "Epoch: 13, Batch: 6657/37625 (17.693%), Loss: 1.2254\n",
      "Epoch: 13, Batch: 6913/37625 (18.373%), Loss: 0.6038\n",
      "Epoch: 13, Batch: 7169/37625 (19.054%), Loss: 1.4113\n",
      "Epoch: 13, Batch: 7425/37625 (19.734%), Loss: 0.8902\n",
      "Epoch: 13, Batch: 7681/37625 (20.415%), Loss: 0.6872\n",
      "Epoch: 13, Batch: 7937/37625 (21.095%), Loss: 1.2727\n",
      "Epoch: 13, Batch: 8193/37625 (21.775%), Loss: 1.0152\n",
      "Epoch: 13, Batch: 8449/37625 (22.456%), Loss: 0.7599\n",
      "Epoch: 13, Batch: 8705/37625 (23.136%), Loss: 0.9728\n",
      "Epoch: 13, Batch: 8961/37625 (23.817%), Loss: 0.6327\n",
      "Epoch: 13, Batch: 9217/37625 (24.497%), Loss: 1.4194\n",
      "Epoch: 13, Batch: 9473/37625 (25.177%), Loss: 0.7018\n",
      "Epoch: 13, Batch: 9729/37625 (25.858%), Loss: 0.9977\n",
      "Epoch: 13, Batch: 9985/37625 (26.538%), Loss: 1.9322\n",
      "Epoch: 13, Batch: 10241/37625 (27.219%), Loss: 1.3580\n",
      "Epoch: 13, Batch: 10497/37625 (27.899%), Loss: 0.6110\n",
      "Epoch: 13, Batch: 10753/37625 (28.579%), Loss: 0.6462\n",
      "Epoch: 13, Batch: 11009/37625 (29.260%), Loss: 0.6354\n",
      "Epoch: 13, Batch: 11265/37625 (29.940%), Loss: 0.9459\n",
      "Epoch: 13, Batch: 11521/37625 (30.621%), Loss: 6.1880\n",
      "Epoch: 13, Batch: 11777/37625 (31.301%), Loss: 0.8516\n",
      "Epoch: 13, Batch: 12033/37625 (31.981%), Loss: 0.6018\n",
      "Epoch: 13, Batch: 12289/37625 (32.662%), Loss: 1.0340\n",
      "Epoch: 13, Batch: 12545/37625 (33.342%), Loss: 0.8936\n",
      "Epoch: 13, Batch: 12801/37625 (34.023%), Loss: 0.9688\n",
      "Epoch: 13, Batch: 13057/37625 (34.703%), Loss: 0.9425\n",
      "Epoch: 13, Batch: 13313/37625 (35.383%), Loss: 0.7627\n",
      "Epoch: 13, Batch: 13569/37625 (36.064%), Loss: 0.9516\n",
      "Epoch: 13, Batch: 13825/37625 (36.744%), Loss: 0.8331\n",
      "Epoch: 13, Batch: 14081/37625 (37.425%), Loss: 0.9096\n",
      "Epoch: 13, Batch: 14337/37625 (38.105%), Loss: 0.7933\n",
      "Epoch: 13, Batch: 14593/37625 (38.785%), Loss: 1.4720\n",
      "Epoch: 13, Batch: 14849/37625 (39.466%), Loss: 1.0173\n",
      "Epoch: 13, Batch: 15105/37625 (40.146%), Loss: 0.6471\n",
      "Epoch: 13, Batch: 15361/37625 (40.827%), Loss: 0.5717\n",
      "Epoch: 13, Batch: 15617/37625 (41.507%), Loss: 1.8341\n",
      "Epoch: 13, Batch: 15873/37625 (42.187%), Loss: 0.9816\n",
      "Epoch: 13, Batch: 16129/37625 (42.868%), Loss: 0.9583\n",
      "Epoch: 13, Batch: 16385/37625 (43.548%), Loss: 0.5974\n",
      "Epoch: 13, Batch: 16641/37625 (44.229%), Loss: 1.4104\n",
      "Epoch: 13, Batch: 16897/37625 (44.909%), Loss: 1.0738\n",
      "Epoch: 13, Batch: 17153/37625 (45.589%), Loss: 1.1527\n",
      "Epoch: 13, Batch: 17409/37625 (46.270%), Loss: 1.6558\n",
      "Epoch: 13, Batch: 17665/37625 (46.950%), Loss: 1.1223\n",
      "Epoch: 13, Batch: 17921/37625 (47.631%), Loss: 1.2706\n",
      "Epoch: 13, Batch: 18177/37625 (48.311%), Loss: 0.9542\n",
      "Epoch: 13, Batch: 18433/37625 (48.991%), Loss: 0.5960\n",
      "Epoch: 13, Batch: 18689/37625 (49.672%), Loss: 0.7668\n",
      "Epoch: 13, Batch: 18945/37625 (50.352%), Loss: 0.6760\n",
      "Epoch: 13, Batch: 19201/37625 (51.033%), Loss: 0.6355\n",
      "Epoch: 13, Batch: 19457/37625 (51.713%), Loss: 0.6531\n",
      "Epoch: 13, Batch: 19713/37625 (52.393%), Loss: 1.4800\n",
      "Epoch: 13, Batch: 19969/37625 (53.074%), Loss: 0.9204\n",
      "Epoch: 13, Batch: 20225/37625 (53.754%), Loss: 0.7763\n",
      "Epoch: 13, Batch: 20481/37625 (54.435%), Loss: 0.7481\n",
      "Epoch: 13, Batch: 20737/37625 (55.115%), Loss: 0.6915\n",
      "Epoch: 13, Batch: 20993/37625 (55.795%), Loss: 1.4216\n",
      "Epoch: 13, Batch: 21249/37625 (56.476%), Loss: 1.1707\n",
      "Epoch: 13, Batch: 21505/37625 (57.156%), Loss: 1.0556\n",
      "Epoch: 13, Batch: 21761/37625 (57.837%), Loss: 0.8965\n",
      "Epoch: 13, Batch: 22017/37625 (58.517%), Loss: 1.4237\n",
      "Epoch: 13, Batch: 22273/37625 (59.197%), Loss: 0.7382\n",
      "Epoch: 13, Batch: 22529/37625 (59.878%), Loss: 0.7240\n",
      "Epoch: 13, Batch: 22785/37625 (60.558%), Loss: 1.0706\n",
      "Epoch: 13, Batch: 23041/37625 (61.239%), Loss: 1.1457\n",
      "Epoch: 13, Batch: 23297/37625 (61.919%), Loss: 1.1213\n",
      "Epoch: 13, Batch: 23553/37625 (62.599%), Loss: 0.7203\n",
      "Epoch: 13, Batch: 23809/37625 (63.280%), Loss: 0.9763\n",
      "Epoch: 13, Batch: 24065/37625 (63.960%), Loss: 3.3572\n",
      "Epoch: 13, Batch: 24321/37625 (64.641%), Loss: 1.0424\n",
      "Epoch: 13, Batch: 24577/37625 (65.321%), Loss: 1.1574\n",
      "Epoch: 13, Batch: 24833/37625 (66.001%), Loss: 0.7156\n",
      "Epoch: 13, Batch: 25089/37625 (66.682%), Loss: 0.8047\n",
      "Epoch: 13, Batch: 25345/37625 (67.362%), Loss: 1.0126\n",
      "Epoch: 13, Batch: 25601/37625 (68.043%), Loss: 1.2625\n",
      "Epoch: 13, Batch: 25857/37625 (68.723%), Loss: 0.8977\n",
      "Epoch: 13, Batch: 26113/37625 (69.403%), Loss: 0.6175\n",
      "Epoch: 13, Batch: 26369/37625 (70.084%), Loss: 0.6444\n",
      "Epoch: 13, Batch: 26625/37625 (70.764%), Loss: 0.7877\n",
      "Epoch: 13, Batch: 26881/37625 (71.445%), Loss: 0.9695\n",
      "Epoch: 13, Batch: 27137/37625 (72.125%), Loss: 0.8986\n",
      "Epoch: 13, Batch: 27393/37625 (72.805%), Loss: 0.6209\n",
      "Epoch: 13, Batch: 27649/37625 (73.486%), Loss: 1.4934\n",
      "Epoch: 13, Batch: 27905/37625 (74.166%), Loss: 0.7751\n",
      "Epoch: 13, Batch: 28161/37625 (74.847%), Loss: 0.7233\n",
      "Epoch: 13, Batch: 28417/37625 (75.527%), Loss: 0.6310\n",
      "Epoch: 13, Batch: 28673/37625 (76.207%), Loss: 0.9575\n",
      "Epoch: 13, Batch: 28929/37625 (76.888%), Loss: 1.9946\n",
      "Epoch: 13, Batch: 29185/37625 (77.568%), Loss: 1.2228\n",
      "Epoch: 13, Batch: 29441/37625 (78.249%), Loss: 0.7484\n",
      "Epoch: 13, Batch: 29697/37625 (78.929%), Loss: 1.0708\n",
      "Epoch: 13, Batch: 29953/37625 (79.609%), Loss: 0.5863\n",
      "Epoch: 13, Batch: 30209/37625 (80.290%), Loss: 0.7312\n",
      "Epoch: 13, Batch: 30465/37625 (80.970%), Loss: 0.9558\n",
      "Epoch: 13, Batch: 30721/37625 (81.650%), Loss: 0.8279\n",
      "Epoch: 13, Batch: 30977/37625 (82.331%), Loss: 0.8207\n",
      "Epoch: 13, Batch: 31233/37625 (83.011%), Loss: 0.9325\n",
      "Epoch: 13, Batch: 31489/37625 (83.692%), Loss: 0.6757\n",
      "Epoch: 13, Batch: 31745/37625 (84.372%), Loss: 0.5922\n",
      "Epoch: 13, Batch: 32001/37625 (85.052%), Loss: 1.8545\n",
      "Epoch: 13, Batch: 32257/37625 (85.733%), Loss: 0.7764\n",
      "Epoch: 13, Batch: 32513/37625 (86.413%), Loss: 0.8963\n",
      "Epoch: 13, Batch: 32769/37625 (87.094%), Loss: 2.1503\n",
      "Epoch: 13, Batch: 33025/37625 (87.774%), Loss: 1.0982\n",
      "Epoch: 13, Batch: 33281/37625 (88.454%), Loss: 0.9506\n",
      "Epoch: 13, Batch: 33537/37625 (89.135%), Loss: 0.6898\n",
      "Epoch: 13, Batch: 33793/37625 (89.815%), Loss: 1.0807\n",
      "Epoch: 13, Batch: 34049/37625 (90.496%), Loss: 0.7182\n",
      "Epoch: 13, Batch: 34305/37625 (91.176%), Loss: 0.9403\n",
      "Epoch: 13, Batch: 34561/37625 (91.856%), Loss: 1.0098\n",
      "Epoch: 13, Batch: 34817/37625 (92.537%), Loss: 2.1309\n",
      "Epoch: 13, Batch: 35073/37625 (93.217%), Loss: 1.2638\n",
      "Epoch: 13, Batch: 35329/37625 (93.898%), Loss: 0.8617\n",
      "Epoch: 13, Batch: 35585/37625 (94.578%), Loss: 1.4673\n",
      "Epoch: 13, Batch: 35841/37625 (95.258%), Loss: 3.4785\n",
      "Epoch: 13, Batch: 36097/37625 (95.939%), Loss: 0.7086\n",
      "Epoch: 13, Batch: 36353/37625 (96.619%), Loss: 0.8110\n",
      "Epoch: 13, Batch: 36609/37625 (97.300%), Loss: 0.5926\n",
      "Epoch: 13, Batch: 36865/37625 (97.980%), Loss: 0.9328\n",
      "Epoch: 13, Batch: 37121/37625 (98.660%), Loss: 0.8386\n",
      "Epoch: 13, Batch: 37377/37625 (99.341%), Loss: 0.9275\n",
      "Epoch: 14, Batch: 1/37625 (0.003%), Loss: 1.1001\n",
      "Epoch: 14, Batch: 257/37625 (0.683%), Loss: 1.0624\n",
      "Epoch: 14, Batch: 513/37625 (1.363%), Loss: 1.1401\n",
      "Epoch: 14, Batch: 769/37625 (2.044%), Loss: 0.8662\n",
      "Epoch: 14, Batch: 1025/37625 (2.724%), Loss: 0.7990\n",
      "Epoch: 14, Batch: 1281/37625 (3.405%), Loss: 0.7741\n",
      "Epoch: 14, Batch: 1537/37625 (4.085%), Loss: 0.6179\n",
      "Epoch: 14, Batch: 1793/37625 (4.765%), Loss: 0.6897\n",
      "Epoch: 14, Batch: 2049/37625 (5.446%), Loss: 1.1902\n",
      "Epoch: 14, Batch: 2305/37625 (6.126%), Loss: 1.0665\n",
      "Epoch: 14, Batch: 2561/37625 (6.807%), Loss: 1.4825\n",
      "Epoch: 14, Batch: 2817/37625 (7.487%), Loss: 0.8888\n",
      "Epoch: 14, Batch: 3073/37625 (8.167%), Loss: 0.7209\n",
      "Epoch: 14, Batch: 3329/37625 (8.848%), Loss: 1.0595\n",
      "Epoch: 14, Batch: 3585/37625 (9.528%), Loss: 1.0550\n",
      "Epoch: 14, Batch: 3841/37625 (10.209%), Loss: 0.7579\n",
      "Epoch: 14, Batch: 4097/37625 (10.889%), Loss: 1.3440\n",
      "Epoch: 14, Batch: 4353/37625 (11.569%), Loss: 0.9671\n",
      "Epoch: 14, Batch: 4609/37625 (12.250%), Loss: 0.7152\n",
      "Epoch: 14, Batch: 4865/37625 (12.930%), Loss: 0.7360\n",
      "Epoch: 14, Batch: 5121/37625 (13.611%), Loss: 0.7048\n",
      "Epoch: 14, Batch: 5377/37625 (14.291%), Loss: 0.7606\n",
      "Epoch: 14, Batch: 5633/37625 (14.971%), Loss: 1.1713\n",
      "Epoch: 14, Batch: 5889/37625 (15.652%), Loss: 0.8716\n",
      "Epoch: 14, Batch: 6145/37625 (16.332%), Loss: 0.7539\n",
      "Epoch: 14, Batch: 6401/37625 (17.013%), Loss: 1.1146\n",
      "Epoch: 14, Batch: 6657/37625 (17.693%), Loss: 0.7400\n",
      "Epoch: 14, Batch: 6913/37625 (18.373%), Loss: 0.7655\n",
      "Epoch: 14, Batch: 7169/37625 (19.054%), Loss: 0.8335\n",
      "Epoch: 14, Batch: 7425/37625 (19.734%), Loss: 0.7295\n",
      "Epoch: 14, Batch: 7681/37625 (20.415%), Loss: 1.4411\n",
      "Epoch: 14, Batch: 7937/37625 (21.095%), Loss: 0.6077\n",
      "Epoch: 14, Batch: 8193/37625 (21.775%), Loss: 0.8014\n",
      "Epoch: 14, Batch: 8449/37625 (22.456%), Loss: 0.9309\n",
      "Epoch: 14, Batch: 8705/37625 (23.136%), Loss: 0.5977\n",
      "Epoch: 14, Batch: 8961/37625 (23.817%), Loss: 0.8152\n",
      "Epoch: 14, Batch: 9217/37625 (24.497%), Loss: 0.7879\n",
      "Epoch: 14, Batch: 9473/37625 (25.177%), Loss: 0.7397\n",
      "Epoch: 14, Batch: 9729/37625 (25.858%), Loss: 0.8816\n",
      "Epoch: 14, Batch: 9985/37625 (26.538%), Loss: 0.6523\n",
      "Epoch: 14, Batch: 10241/37625 (27.219%), Loss: 1.2332\n",
      "Epoch: 14, Batch: 10497/37625 (27.899%), Loss: 0.7573\n",
      "Epoch: 14, Batch: 10753/37625 (28.579%), Loss: 0.7700\n",
      "Epoch: 14, Batch: 11009/37625 (29.260%), Loss: 1.2282\n",
      "Epoch: 14, Batch: 11265/37625 (29.940%), Loss: 0.9009\n",
      "Epoch: 14, Batch: 11521/37625 (30.621%), Loss: 1.9613\n",
      "Epoch: 14, Batch: 11777/37625 (31.301%), Loss: 0.7935\n",
      "Epoch: 14, Batch: 12033/37625 (31.981%), Loss: 0.6581\n",
      "Epoch: 14, Batch: 12289/37625 (32.662%), Loss: 1.0047\n",
      "Epoch: 14, Batch: 12545/37625 (33.342%), Loss: 0.7440\n",
      "Epoch: 14, Batch: 12801/37625 (34.023%), Loss: 0.6675\n",
      "Epoch: 14, Batch: 13057/37625 (34.703%), Loss: 2.0988\n",
      "Epoch: 14, Batch: 13313/37625 (35.383%), Loss: 0.9407\n",
      "Epoch: 14, Batch: 13569/37625 (36.064%), Loss: 0.9413\n",
      "Epoch: 14, Batch: 13825/37625 (36.744%), Loss: 0.5469\n",
      "Epoch: 14, Batch: 14081/37625 (37.425%), Loss: 0.5562\n",
      "Epoch: 14, Batch: 14337/37625 (38.105%), Loss: 0.7476\n",
      "Epoch: 14, Batch: 14593/37625 (38.785%), Loss: 1.2354\n",
      "Epoch: 14, Batch: 14849/37625 (39.466%), Loss: 4.9621\n",
      "Epoch: 14, Batch: 15105/37625 (40.146%), Loss: 1.2250\n",
      "Epoch: 14, Batch: 15361/37625 (40.827%), Loss: 0.9813\n",
      "Epoch: 14, Batch: 15617/37625 (41.507%), Loss: 0.7772\n",
      "Epoch: 14, Batch: 15873/37625 (42.187%), Loss: 0.9487\n",
      "Epoch: 14, Batch: 16129/37625 (42.868%), Loss: 0.4923\n",
      "Epoch: 14, Batch: 16385/37625 (43.548%), Loss: 1.2770\n",
      "Epoch: 14, Batch: 16641/37625 (44.229%), Loss: 0.6552\n",
      "Epoch: 14, Batch: 16897/37625 (44.909%), Loss: 1.8161\n",
      "Epoch: 14, Batch: 17153/37625 (45.589%), Loss: 0.8904\n",
      "Epoch: 14, Batch: 17409/37625 (46.270%), Loss: 0.6779\n",
      "Epoch: 14, Batch: 17665/37625 (46.950%), Loss: 0.6275\n",
      "Epoch: 14, Batch: 17921/37625 (47.631%), Loss: 0.8823\n",
      "Epoch: 14, Batch: 18177/37625 (48.311%), Loss: 0.6973\n",
      "Epoch: 14, Batch: 18433/37625 (48.991%), Loss: 0.8915\n",
      "Epoch: 14, Batch: 18689/37625 (49.672%), Loss: 0.6353\n",
      "Epoch: 14, Batch: 18945/37625 (50.352%), Loss: 0.6535\n",
      "Epoch: 14, Batch: 19201/37625 (51.033%), Loss: 0.9290\n",
      "Epoch: 14, Batch: 19457/37625 (51.713%), Loss: 0.9049\n",
      "Epoch: 14, Batch: 19713/37625 (52.393%), Loss: 3.4514\n",
      "Epoch: 14, Batch: 19969/37625 (53.074%), Loss: 2.5718\n",
      "Epoch: 14, Batch: 20225/37625 (53.754%), Loss: 0.9428\n",
      "Epoch: 14, Batch: 20481/37625 (54.435%), Loss: 0.6204\n",
      "Epoch: 14, Batch: 20737/37625 (55.115%), Loss: 1.1644\n",
      "Epoch: 14, Batch: 20993/37625 (55.795%), Loss: 1.2420\n",
      "Epoch: 14, Batch: 21249/37625 (56.476%), Loss: 0.6742\n",
      "Epoch: 14, Batch: 21505/37625 (57.156%), Loss: 0.9088\n",
      "Epoch: 14, Batch: 21761/37625 (57.837%), Loss: 2.9335\n",
      "Epoch: 14, Batch: 22017/37625 (58.517%), Loss: 0.8264\n",
      "Epoch: 14, Batch: 22273/37625 (59.197%), Loss: 1.2186\n",
      "Epoch: 14, Batch: 22529/37625 (59.878%), Loss: 0.9185\n",
      "Epoch: 14, Batch: 22785/37625 (60.558%), Loss: 0.7834\n",
      "Epoch: 14, Batch: 23041/37625 (61.239%), Loss: 0.7506\n",
      "Epoch: 14, Batch: 23297/37625 (61.919%), Loss: 1.2872\n",
      "Epoch: 14, Batch: 23553/37625 (62.599%), Loss: 0.8657\n",
      "Epoch: 14, Batch: 23809/37625 (63.280%), Loss: 1.4207\n",
      "Epoch: 14, Batch: 24065/37625 (63.960%), Loss: 1.5401\n",
      "Epoch: 14, Batch: 24321/37625 (64.641%), Loss: 0.6881\n",
      "Epoch: 14, Batch: 24577/37625 (65.321%), Loss: 1.1978\n",
      "Epoch: 14, Batch: 24833/37625 (66.001%), Loss: 0.8260\n",
      "Epoch: 14, Batch: 25089/37625 (66.682%), Loss: 0.6482\n",
      "Epoch: 14, Batch: 25345/37625 (67.362%), Loss: 1.0010\n",
      "Epoch: 14, Batch: 25601/37625 (68.043%), Loss: 1.4914\n",
      "Epoch: 14, Batch: 25857/37625 (68.723%), Loss: 0.7102\n",
      "Epoch: 14, Batch: 26113/37625 (69.403%), Loss: 0.8247\n",
      "Epoch: 14, Batch: 26369/37625 (70.084%), Loss: 0.8173\n",
      "Epoch: 14, Batch: 26625/37625 (70.764%), Loss: 0.6687\n",
      "Epoch: 14, Batch: 26881/37625 (71.445%), Loss: 0.8946\n",
      "Epoch: 14, Batch: 27137/37625 (72.125%), Loss: 4.5795\n",
      "Epoch: 14, Batch: 27393/37625 (72.805%), Loss: 1.5505\n",
      "Epoch: 14, Batch: 27649/37625 (73.486%), Loss: 0.5880\n",
      "Epoch: 14, Batch: 27905/37625 (74.166%), Loss: 0.8988\n",
      "Epoch: 14, Batch: 28161/37625 (74.847%), Loss: 0.8545\n",
      "Epoch: 14, Batch: 28417/37625 (75.527%), Loss: 0.8985\n",
      "Epoch: 14, Batch: 28673/37625 (76.207%), Loss: 1.1021\n",
      "Epoch: 14, Batch: 28929/37625 (76.888%), Loss: 1.0777\n",
      "Epoch: 14, Batch: 29185/37625 (77.568%), Loss: 1.6128\n",
      "Epoch: 14, Batch: 29441/37625 (78.249%), Loss: 1.4859\n",
      "Epoch: 14, Batch: 29697/37625 (78.929%), Loss: 0.6830\n",
      "Epoch: 14, Batch: 29953/37625 (79.609%), Loss: 1.0515\n",
      "Epoch: 14, Batch: 30209/37625 (80.290%), Loss: 1.5067\n",
      "Epoch: 14, Batch: 30465/37625 (80.970%), Loss: 0.8889\n",
      "Epoch: 14, Batch: 30721/37625 (81.650%), Loss: 1.2696\n",
      "Epoch: 14, Batch: 30977/37625 (82.331%), Loss: 1.0149\n",
      "Epoch: 14, Batch: 31233/37625 (83.011%), Loss: 1.2795\n",
      "Epoch: 14, Batch: 31489/37625 (83.692%), Loss: 0.7400\n",
      "Epoch: 14, Batch: 31745/37625 (84.372%), Loss: 0.7757\n",
      "Epoch: 14, Batch: 32001/37625 (85.052%), Loss: 3.4040\n",
      "Epoch: 14, Batch: 32257/37625 (85.733%), Loss: 1.0163\n",
      "Epoch: 14, Batch: 32513/37625 (86.413%), Loss: 1.4347\n",
      "Epoch: 14, Batch: 32769/37625 (87.094%), Loss: 0.9620\n",
      "Epoch: 14, Batch: 33025/37625 (87.774%), Loss: 0.6311\n",
      "Epoch: 14, Batch: 33281/37625 (88.454%), Loss: 0.8450\n",
      "Epoch: 14, Batch: 33537/37625 (89.135%), Loss: 1.2078\n",
      "Epoch: 14, Batch: 33793/37625 (89.815%), Loss: 1.3335\n",
      "Epoch: 14, Batch: 34049/37625 (90.496%), Loss: 1.7020\n",
      "Epoch: 14, Batch: 34305/37625 (91.176%), Loss: 0.8106\n",
      "Epoch: 14, Batch: 34561/37625 (91.856%), Loss: 0.8113\n",
      "Epoch: 14, Batch: 34817/37625 (92.537%), Loss: 6.4842\n",
      "Epoch: 14, Batch: 35073/37625 (93.217%), Loss: 1.3433\n",
      "Epoch: 14, Batch: 35329/37625 (93.898%), Loss: 1.5772\n",
      "Epoch: 14, Batch: 35585/37625 (94.578%), Loss: 0.7365\n",
      "Epoch: 14, Batch: 35841/37625 (95.258%), Loss: 0.8164\n",
      "Epoch: 14, Batch: 36097/37625 (95.939%), Loss: 0.9886\n",
      "Epoch: 14, Batch: 36353/37625 (96.619%), Loss: 0.7070\n",
      "Epoch: 14, Batch: 36609/37625 (97.300%), Loss: 1.3476\n",
      "Epoch: 14, Batch: 36865/37625 (97.980%), Loss: 1.6345\n",
      "Epoch: 14, Batch: 37121/37625 (98.660%), Loss: 0.8512\n",
      "Epoch: 14, Batch: 37377/37625 (99.341%), Loss: 0.9346\n",
      "Epoch: 15, Batch: 1/37625 (0.003%), Loss: 0.8389\n",
      "Epoch: 15, Batch: 257/37625 (0.683%), Loss: 0.9247\n",
      "Epoch: 15, Batch: 513/37625 (1.363%), Loss: 0.9287\n",
      "Epoch: 15, Batch: 769/37625 (2.044%), Loss: 0.6839\n",
      "Epoch: 15, Batch: 1025/37625 (2.724%), Loss: 1.9811\n",
      "Epoch: 15, Batch: 1281/37625 (3.405%), Loss: 0.8986\n",
      "Epoch: 15, Batch: 1537/37625 (4.085%), Loss: 0.6304\n",
      "Epoch: 15, Batch: 1793/37625 (4.765%), Loss: 0.7550\n",
      "Epoch: 15, Batch: 2049/37625 (5.446%), Loss: 0.8956\n",
      "Epoch: 15, Batch: 2305/37625 (6.126%), Loss: 0.9078\n",
      "Epoch: 15, Batch: 2561/37625 (6.807%), Loss: 0.8295\n",
      "Epoch: 15, Batch: 2817/37625 (7.487%), Loss: 0.9477\n",
      "Epoch: 15, Batch: 3073/37625 (8.167%), Loss: 0.6760\n",
      "Epoch: 15, Batch: 3329/37625 (8.848%), Loss: 0.7091\n",
      "Epoch: 15, Batch: 3585/37625 (9.528%), Loss: 0.9661\n",
      "Epoch: 15, Batch: 3841/37625 (10.209%), Loss: 1.4241\n",
      "Epoch: 15, Batch: 4097/37625 (10.889%), Loss: 0.7357\n",
      "Epoch: 15, Batch: 4353/37625 (11.569%), Loss: 0.6508\n",
      "Epoch: 15, Batch: 4609/37625 (12.250%), Loss: 1.1146\n",
      "Epoch: 15, Batch: 4865/37625 (12.930%), Loss: 1.0793\n",
      "Epoch: 15, Batch: 5121/37625 (13.611%), Loss: 0.7209\n",
      "Epoch: 15, Batch: 5377/37625 (14.291%), Loss: 5.8222\n",
      "Epoch: 15, Batch: 5633/37625 (14.971%), Loss: 1.0248\n",
      "Epoch: 15, Batch: 5889/37625 (15.652%), Loss: 1.3667\n",
      "Epoch: 15, Batch: 6145/37625 (16.332%), Loss: 1.2460\n",
      "Epoch: 15, Batch: 6401/37625 (17.013%), Loss: 1.5678\n",
      "Epoch: 15, Batch: 6657/37625 (17.693%), Loss: 0.6265\n",
      "Epoch: 15, Batch: 6913/37625 (18.373%), Loss: 0.6960\n",
      "Epoch: 15, Batch: 7169/37625 (19.054%), Loss: 0.9738\n",
      "Epoch: 15, Batch: 7425/37625 (19.734%), Loss: 0.5865\n",
      "Epoch: 15, Batch: 7681/37625 (20.415%), Loss: 1.5127\n",
      "Epoch: 15, Batch: 7937/37625 (21.095%), Loss: 0.9805\n",
      "Epoch: 15, Batch: 8193/37625 (21.775%), Loss: 0.7274\n",
      "Epoch: 15, Batch: 8449/37625 (22.456%), Loss: 0.7133\n",
      "Epoch: 15, Batch: 8705/37625 (23.136%), Loss: 1.2740\n",
      "Epoch: 15, Batch: 8961/37625 (23.817%), Loss: 1.1268\n",
      "Epoch: 15, Batch: 9217/37625 (24.497%), Loss: 0.8378\n",
      "Epoch: 15, Batch: 9473/37625 (25.177%), Loss: 0.7393\n",
      "Epoch: 15, Batch: 9729/37625 (25.858%), Loss: 0.8008\n",
      "Epoch: 15, Batch: 9985/37625 (26.538%), Loss: 1.3743\n",
      "Epoch: 15, Batch: 10241/37625 (27.219%), Loss: 1.3833\n",
      "Epoch: 15, Batch: 10497/37625 (27.899%), Loss: 0.8872\n",
      "Epoch: 15, Batch: 10753/37625 (28.579%), Loss: 1.0340\n",
      "Epoch: 15, Batch: 11009/37625 (29.260%), Loss: 0.6941\n",
      "Epoch: 15, Batch: 11265/37625 (29.940%), Loss: 1.2051\n",
      "Epoch: 15, Batch: 11521/37625 (30.621%), Loss: 0.7862\n",
      "Epoch: 15, Batch: 11777/37625 (31.301%), Loss: 0.7660\n",
      "Epoch: 15, Batch: 12033/37625 (31.981%), Loss: 1.1665\n",
      "Epoch: 15, Batch: 12289/37625 (32.662%), Loss: 0.9585\n",
      "Epoch: 15, Batch: 12545/37625 (33.342%), Loss: 0.9197\n",
      "Epoch: 15, Batch: 12801/37625 (34.023%), Loss: 0.9550\n",
      "Epoch: 15, Batch: 13057/37625 (34.703%), Loss: 2.3064\n",
      "Epoch: 15, Batch: 13313/37625 (35.383%), Loss: 1.0852\n",
      "Epoch: 15, Batch: 13569/37625 (36.064%), Loss: 1.0727\n",
      "Epoch: 15, Batch: 13825/37625 (36.744%), Loss: 0.7654\n",
      "Epoch: 15, Batch: 14081/37625 (37.425%), Loss: 0.6368\n",
      "Epoch: 15, Batch: 14337/37625 (38.105%), Loss: 1.1095\n",
      "Epoch: 15, Batch: 14593/37625 (38.785%), Loss: 1.0264\n",
      "Epoch: 15, Batch: 14849/37625 (39.466%), Loss: 0.6911\n",
      "Epoch: 15, Batch: 15105/37625 (40.146%), Loss: 0.7815\n",
      "Epoch: 15, Batch: 15361/37625 (40.827%), Loss: 0.9636\n",
      "Epoch: 15, Batch: 15617/37625 (41.507%), Loss: 0.6711\n",
      "Epoch: 15, Batch: 15873/37625 (42.187%), Loss: 6.0457\n",
      "Epoch: 15, Batch: 16129/37625 (42.868%), Loss: 1.1987\n",
      "Epoch: 15, Batch: 16385/37625 (43.548%), Loss: 0.6262\n",
      "Epoch: 15, Batch: 16641/37625 (44.229%), Loss: 0.7210\n",
      "Epoch: 15, Batch: 16897/37625 (44.909%), Loss: 0.6993\n",
      "Epoch: 15, Batch: 17153/37625 (45.589%), Loss: 0.8504\n",
      "Epoch: 15, Batch: 17409/37625 (46.270%), Loss: 1.1205\n",
      "Epoch: 15, Batch: 17665/37625 (46.950%), Loss: 0.8445\n",
      "Epoch: 15, Batch: 17921/37625 (47.631%), Loss: 1.2919\n",
      "Epoch: 15, Batch: 18177/37625 (48.311%), Loss: 1.0772\n",
      "Epoch: 15, Batch: 18433/37625 (48.991%), Loss: 0.9106\n",
      "Epoch: 15, Batch: 18689/37625 (49.672%), Loss: 1.0807\n",
      "Epoch: 15, Batch: 18945/37625 (50.352%), Loss: 0.7385\n",
      "Epoch: 15, Batch: 19201/37625 (51.033%), Loss: 1.0231\n",
      "Epoch: 15, Batch: 19457/37625 (51.713%), Loss: 0.8849\n",
      "Epoch: 15, Batch: 19713/37625 (52.393%), Loss: 0.8609\n",
      "Epoch: 15, Batch: 19969/37625 (53.074%), Loss: 0.8119\n",
      "Epoch: 15, Batch: 20225/37625 (53.754%), Loss: 0.5505\n",
      "Epoch: 15, Batch: 20481/37625 (54.435%), Loss: 1.2423\n",
      "Epoch: 15, Batch: 20737/37625 (55.115%), Loss: 1.0956\n",
      "Epoch: 15, Batch: 20993/37625 (55.795%), Loss: 0.7567\n",
      "Epoch: 15, Batch: 21249/37625 (56.476%), Loss: 0.8357\n",
      "Epoch: 15, Batch: 21505/37625 (57.156%), Loss: 0.8005\n",
      "Epoch: 15, Batch: 21761/37625 (57.837%), Loss: 0.9582\n",
      "Epoch: 15, Batch: 22017/37625 (58.517%), Loss: 0.7486\n",
      "Epoch: 15, Batch: 22273/37625 (59.197%), Loss: 0.9963\n",
      "Epoch: 15, Batch: 22529/37625 (59.878%), Loss: 1.0721\n",
      "Epoch: 15, Batch: 22785/37625 (60.558%), Loss: 1.0117\n",
      "Epoch: 15, Batch: 23041/37625 (61.239%), Loss: 0.9729\n",
      "Epoch: 15, Batch: 23297/37625 (61.919%), Loss: 0.7641\n",
      "Epoch: 15, Batch: 23553/37625 (62.599%), Loss: 0.9818\n",
      "Epoch: 15, Batch: 23809/37625 (63.280%), Loss: 0.7238\n",
      "Epoch: 15, Batch: 24065/37625 (63.960%), Loss: 0.8807\n",
      "Epoch: 15, Batch: 24321/37625 (64.641%), Loss: 0.6881\n",
      "Epoch: 15, Batch: 24577/37625 (65.321%), Loss: 0.6229\n",
      "Epoch: 15, Batch: 24833/37625 (66.001%), Loss: 0.6723\n",
      "Epoch: 15, Batch: 25089/37625 (66.682%), Loss: 0.8214\n",
      "Epoch: 15, Batch: 25345/37625 (67.362%), Loss: 1.1036\n",
      "Epoch: 15, Batch: 25601/37625 (68.043%), Loss: 0.9149\n",
      "Epoch: 15, Batch: 25857/37625 (68.723%), Loss: 0.6827\n",
      "Epoch: 15, Batch: 26113/37625 (69.403%), Loss: 1.2665\n",
      "Epoch: 15, Batch: 26369/37625 (70.084%), Loss: 0.6927\n",
      "Epoch: 15, Batch: 26625/37625 (70.764%), Loss: 0.9197\n",
      "Epoch: 15, Batch: 26881/37625 (71.445%), Loss: 1.0961\n",
      "Epoch: 15, Batch: 27137/37625 (72.125%), Loss: 4.6350\n",
      "Epoch: 15, Batch: 27393/37625 (72.805%), Loss: 1.9805\n",
      "Epoch: 15, Batch: 27649/37625 (73.486%), Loss: 2.1101\n",
      "Epoch: 15, Batch: 27905/37625 (74.166%), Loss: 1.5248\n",
      "Epoch: 15, Batch: 28161/37625 (74.847%), Loss: 0.9197\n",
      "Epoch: 15, Batch: 28417/37625 (75.527%), Loss: 0.7987\n",
      "Epoch: 15, Batch: 28673/37625 (76.207%), Loss: 0.8897\n",
      "Epoch: 15, Batch: 28929/37625 (76.888%), Loss: 0.9372\n",
      "Epoch: 15, Batch: 29185/37625 (77.568%), Loss: 1.2496\n",
      "Epoch: 15, Batch: 29441/37625 (78.249%), Loss: 0.5404\n",
      "Epoch: 15, Batch: 29697/37625 (78.929%), Loss: 0.9096\n",
      "Epoch: 15, Batch: 29953/37625 (79.609%), Loss: 0.7995\n",
      "Epoch: 15, Batch: 30209/37625 (80.290%), Loss: 0.6328\n",
      "Epoch: 15, Batch: 30465/37625 (80.970%), Loss: 1.4547\n",
      "Epoch: 15, Batch: 30721/37625 (81.650%), Loss: 1.2878\n",
      "Epoch: 15, Batch: 30977/37625 (82.331%), Loss: 0.7137\n",
      "Epoch: 15, Batch: 31233/37625 (83.011%), Loss: 2.5216\n",
      "Epoch: 15, Batch: 31489/37625 (83.692%), Loss: 0.8205\n",
      "Epoch: 15, Batch: 31745/37625 (84.372%), Loss: 1.2137\n",
      "Epoch: 15, Batch: 32001/37625 (85.052%), Loss: 0.8623\n",
      "Epoch: 15, Batch: 32257/37625 (85.733%), Loss: 0.5854\n",
      "Epoch: 15, Batch: 32513/37625 (86.413%), Loss: 0.6009\n",
      "Epoch: 15, Batch: 32769/37625 (87.094%), Loss: 0.8050\n",
      "Epoch: 15, Batch: 33025/37625 (87.774%), Loss: 1.0091\n",
      "Epoch: 15, Batch: 33281/37625 (88.454%), Loss: 0.9307\n",
      "Epoch: 15, Batch: 33537/37625 (89.135%), Loss: 2.7198\n",
      "Epoch: 15, Batch: 33793/37625 (89.815%), Loss: 0.7692\n",
      "Epoch: 15, Batch: 34049/37625 (90.496%), Loss: 2.4838\n",
      "Epoch: 15, Batch: 34305/37625 (91.176%), Loss: 0.6166\n",
      "Epoch: 15, Batch: 34561/37625 (91.856%), Loss: 0.8544\n",
      "Epoch: 15, Batch: 34817/37625 (92.537%), Loss: 0.7114\n",
      "Epoch: 15, Batch: 35073/37625 (93.217%), Loss: 0.7285\n",
      "Epoch: 15, Batch: 35329/37625 (93.898%), Loss: 0.8289\n",
      "Epoch: 15, Batch: 35585/37625 (94.578%), Loss: 0.9191\n",
      "Epoch: 15, Batch: 35841/37625 (95.258%), Loss: 0.8840\n",
      "Epoch: 15, Batch: 36097/37625 (95.939%), Loss: 3.8110\n",
      "Epoch: 15, Batch: 36353/37625 (96.619%), Loss: 3.3631\n",
      "Epoch: 15, Batch: 36609/37625 (97.300%), Loss: 0.6422\n",
      "Epoch: 15, Batch: 36865/37625 (97.980%), Loss: 0.8003\n",
      "Epoch: 15, Batch: 37121/37625 (98.660%), Loss: 1.0960\n",
      "Epoch: 15, Batch: 37377/37625 (99.341%), Loss: 2.0191\n",
      "Epoch: 16, Batch: 1/37625 (0.003%), Loss: 0.9344\n",
      "Epoch: 16, Batch: 257/37625 (0.683%), Loss: 0.9339\n",
      "Epoch: 16, Batch: 513/37625 (1.363%), Loss: 1.4592\n",
      "Epoch: 16, Batch: 769/37625 (2.044%), Loss: 1.0974\n",
      "Epoch: 16, Batch: 1025/37625 (2.724%), Loss: 0.6072\n",
      "Epoch: 16, Batch: 1281/37625 (3.405%), Loss: 1.4904\n",
      "Epoch: 16, Batch: 1537/37625 (4.085%), Loss: 0.7638\n",
      "Epoch: 16, Batch: 1793/37625 (4.765%), Loss: 0.5859\n",
      "Epoch: 16, Batch: 2049/37625 (5.446%), Loss: 0.7402\n",
      "Epoch: 16, Batch: 2305/37625 (6.126%), Loss: 0.6379\n",
      "Epoch: 16, Batch: 2561/37625 (6.807%), Loss: 1.4850\n",
      "Epoch: 16, Batch: 2817/37625 (7.487%), Loss: 0.8791\n",
      "Epoch: 16, Batch: 3073/37625 (8.167%), Loss: 0.8754\n",
      "Epoch: 16, Batch: 3329/37625 (8.848%), Loss: 0.7612\n",
      "Epoch: 16, Batch: 3585/37625 (9.528%), Loss: 2.4965\n",
      "Epoch: 16, Batch: 3841/37625 (10.209%), Loss: 0.9776\n",
      "Epoch: 16, Batch: 4097/37625 (10.889%), Loss: 2.2051\n",
      "Epoch: 16, Batch: 4353/37625 (11.569%), Loss: 1.3366\n",
      "Epoch: 16, Batch: 4609/37625 (12.250%), Loss: 0.8640\n",
      "Epoch: 16, Batch: 4865/37625 (12.930%), Loss: 1.3056\n",
      "Epoch: 16, Batch: 5121/37625 (13.611%), Loss: 1.1486\n",
      "Epoch: 16, Batch: 5377/37625 (14.291%), Loss: 1.3197\n",
      "Epoch: 16, Batch: 5633/37625 (14.971%), Loss: 0.9242\n",
      "Epoch: 16, Batch: 5889/37625 (15.652%), Loss: 1.0283\n",
      "Epoch: 16, Batch: 6145/37625 (16.332%), Loss: 0.7492\n",
      "Epoch: 16, Batch: 6401/37625 (17.013%), Loss: 1.2239\n",
      "Epoch: 16, Batch: 6657/37625 (17.693%), Loss: 4.1917\n",
      "Epoch: 16, Batch: 6913/37625 (18.373%), Loss: 0.6963\n",
      "Epoch: 16, Batch: 7169/37625 (19.054%), Loss: 0.7115\n",
      "Epoch: 16, Batch: 7425/37625 (19.734%), Loss: 0.7210\n",
      "Epoch: 16, Batch: 7681/37625 (20.415%), Loss: 1.0035\n",
      "Epoch: 16, Batch: 7937/37625 (21.095%), Loss: 0.7986\n",
      "Epoch: 16, Batch: 8193/37625 (21.775%), Loss: 1.5273\n",
      "Epoch: 16, Batch: 8449/37625 (22.456%), Loss: 1.3126\n",
      "Epoch: 16, Batch: 8705/37625 (23.136%), Loss: 1.0178\n",
      "Epoch: 16, Batch: 8961/37625 (23.817%), Loss: 0.9183\n",
      "Epoch: 16, Batch: 9217/37625 (24.497%), Loss: 0.6695\n",
      "Epoch: 16, Batch: 9473/37625 (25.177%), Loss: 1.0255\n",
      "Epoch: 16, Batch: 9729/37625 (25.858%), Loss: 0.7336\n",
      "Epoch: 16, Batch: 9985/37625 (26.538%), Loss: 1.1713\n",
      "Epoch: 16, Batch: 10241/37625 (27.219%), Loss: 0.8761\n",
      "Epoch: 16, Batch: 10497/37625 (27.899%), Loss: 1.0157\n",
      "Epoch: 16, Batch: 10753/37625 (28.579%), Loss: 1.6185\n",
      "Epoch: 16, Batch: 11009/37625 (29.260%), Loss: 1.0238\n",
      "Epoch: 16, Batch: 11265/37625 (29.940%), Loss: 0.8761\n",
      "Epoch: 16, Batch: 11521/37625 (30.621%), Loss: 0.9087\n",
      "Epoch: 16, Batch: 11777/37625 (31.301%), Loss: 0.6726\n",
      "Epoch: 16, Batch: 12033/37625 (31.981%), Loss: 1.6196\n",
      "Epoch: 16, Batch: 12289/37625 (32.662%), Loss: 0.5395\n",
      "Epoch: 16, Batch: 12545/37625 (33.342%), Loss: 0.9545\n",
      "Epoch: 16, Batch: 12801/37625 (34.023%), Loss: 1.0685\n",
      "Epoch: 16, Batch: 13057/37625 (34.703%), Loss: 0.8100\n",
      "Epoch: 16, Batch: 13313/37625 (35.383%), Loss: 0.6435\n",
      "Epoch: 16, Batch: 13569/37625 (36.064%), Loss: 0.6669\n",
      "Epoch: 16, Batch: 13825/37625 (36.744%), Loss: 1.5416\n",
      "Epoch: 16, Batch: 14081/37625 (37.425%), Loss: 0.5403\n",
      "Epoch: 16, Batch: 14337/37625 (38.105%), Loss: 0.9779\n",
      "Epoch: 16, Batch: 14593/37625 (38.785%), Loss: 4.9018\n",
      "Epoch: 16, Batch: 14849/37625 (39.466%), Loss: 0.7319\n",
      "Epoch: 16, Batch: 15105/37625 (40.146%), Loss: 0.9402\n",
      "Epoch: 16, Batch: 15361/37625 (40.827%), Loss: 0.7586\n",
      "Epoch: 16, Batch: 15617/37625 (41.507%), Loss: 0.9220\n",
      "Epoch: 16, Batch: 15873/37625 (42.187%), Loss: 1.6361\n",
      "Epoch: 16, Batch: 16129/37625 (42.868%), Loss: 1.0543\n",
      "Epoch: 16, Batch: 16385/37625 (43.548%), Loss: 0.6985\n",
      "Epoch: 16, Batch: 16641/37625 (44.229%), Loss: 1.1251\n",
      "Epoch: 16, Batch: 16897/37625 (44.909%), Loss: 1.2152\n",
      "Epoch: 16, Batch: 17153/37625 (45.589%), Loss: 1.5006\n",
      "Epoch: 16, Batch: 17409/37625 (46.270%), Loss: 0.9142\n",
      "Epoch: 16, Batch: 17665/37625 (46.950%), Loss: 0.9913\n",
      "Epoch: 16, Batch: 17921/37625 (47.631%), Loss: 0.6645\n",
      "Epoch: 16, Batch: 18177/37625 (48.311%), Loss: 0.6306\n",
      "Epoch: 16, Batch: 18433/37625 (48.991%), Loss: 1.4771\n",
      "Epoch: 16, Batch: 18689/37625 (49.672%), Loss: 0.8860\n",
      "Epoch: 16, Batch: 18945/37625 (50.352%), Loss: 0.6033\n",
      "Epoch: 16, Batch: 19201/37625 (51.033%), Loss: 0.6451\n",
      "Epoch: 16, Batch: 19457/37625 (51.713%), Loss: 0.8832\n",
      "Epoch: 16, Batch: 19713/37625 (52.393%), Loss: 3.2472\n",
      "Epoch: 16, Batch: 19969/37625 (53.074%), Loss: 0.6948\n",
      "Epoch: 16, Batch: 20225/37625 (53.754%), Loss: 0.8769\n",
      "Epoch: 16, Batch: 20481/37625 (54.435%), Loss: 0.8774\n",
      "Epoch: 16, Batch: 20737/37625 (55.115%), Loss: 1.0497\n",
      "Epoch: 16, Batch: 20993/37625 (55.795%), Loss: 0.6287\n",
      "Epoch: 16, Batch: 21249/37625 (56.476%), Loss: 0.6054\n",
      "Epoch: 16, Batch: 21505/37625 (57.156%), Loss: 1.1421\n",
      "Epoch: 16, Batch: 21761/37625 (57.837%), Loss: 0.6943\n",
      "Epoch: 16, Batch: 22017/37625 (58.517%), Loss: 1.5212\n",
      "Epoch: 16, Batch: 22273/37625 (59.197%), Loss: 1.0185\n",
      "Epoch: 16, Batch: 22529/37625 (59.878%), Loss: 0.8066\n",
      "Epoch: 16, Batch: 22785/37625 (60.558%), Loss: 0.8358\n",
      "Epoch: 16, Batch: 23041/37625 (61.239%), Loss: 2.0207\n",
      "Epoch: 16, Batch: 23297/37625 (61.919%), Loss: 0.7703\n",
      "Epoch: 16, Batch: 23553/37625 (62.599%), Loss: 1.1230\n",
      "Epoch: 16, Batch: 23809/37625 (63.280%), Loss: 1.5602\n",
      "Epoch: 16, Batch: 24065/37625 (63.960%), Loss: 1.3210\n",
      "Epoch: 16, Batch: 24321/37625 (64.641%), Loss: 0.8035\n",
      "Epoch: 16, Batch: 24577/37625 (65.321%), Loss: 1.9146\n",
      "Epoch: 16, Batch: 24833/37625 (66.001%), Loss: 0.7845\n",
      "Epoch: 16, Batch: 25089/37625 (66.682%), Loss: 8.2493\n",
      "Epoch: 16, Batch: 25345/37625 (67.362%), Loss: 0.6356\n",
      "Epoch: 16, Batch: 25601/37625 (68.043%), Loss: 0.9578\n",
      "Epoch: 16, Batch: 25857/37625 (68.723%), Loss: 0.6168\n",
      "Epoch: 16, Batch: 26113/37625 (69.403%), Loss: 1.8747\n",
      "Epoch: 16, Batch: 26369/37625 (70.084%), Loss: 0.6274\n",
      "Epoch: 16, Batch: 26625/37625 (70.764%), Loss: 0.7867\n",
      "Epoch: 16, Batch: 26881/37625 (71.445%), Loss: 0.6338\n",
      "Epoch: 16, Batch: 27137/37625 (72.125%), Loss: 0.6490\n",
      "Epoch: 16, Batch: 27393/37625 (72.805%), Loss: 0.9740\n",
      "Epoch: 16, Batch: 27649/37625 (73.486%), Loss: 1.2492\n",
      "Epoch: 16, Batch: 27905/37625 (74.166%), Loss: 1.3261\n",
      "Epoch: 16, Batch: 28161/37625 (74.847%), Loss: 0.7814\n",
      "Epoch: 16, Batch: 28417/37625 (75.527%), Loss: 0.9826\n",
      "Epoch: 16, Batch: 28673/37625 (76.207%), Loss: 1.1133\n",
      "Epoch: 16, Batch: 28929/37625 (76.888%), Loss: 0.8263\n",
      "Epoch: 16, Batch: 29185/37625 (77.568%), Loss: 1.6447\n",
      "Epoch: 16, Batch: 29441/37625 (78.249%), Loss: 1.0444\n",
      "Epoch: 16, Batch: 29697/37625 (78.929%), Loss: 0.7086\n",
      "Epoch: 16, Batch: 29953/37625 (79.609%), Loss: 1.4160\n",
      "Epoch: 16, Batch: 30209/37625 (80.290%), Loss: 0.9581\n",
      "Epoch: 16, Batch: 30465/37625 (80.970%), Loss: 0.5747\n",
      "Epoch: 16, Batch: 30721/37625 (81.650%), Loss: 0.8263\n",
      "Epoch: 16, Batch: 30977/37625 (82.331%), Loss: 0.6680\n",
      "Epoch: 16, Batch: 31233/37625 (83.011%), Loss: 1.0733\n",
      "Epoch: 16, Batch: 31489/37625 (83.692%), Loss: 0.8409\n",
      "Epoch: 16, Batch: 31745/37625 (84.372%), Loss: 0.9030\n",
      "Epoch: 16, Batch: 32001/37625 (85.052%), Loss: 0.6062\n",
      "Epoch: 16, Batch: 32257/37625 (85.733%), Loss: 1.4507\n",
      "Epoch: 16, Batch: 32513/37625 (86.413%), Loss: 0.6850\n",
      "Epoch: 16, Batch: 32769/37625 (87.094%), Loss: 1.2261\n",
      "Epoch: 16, Batch: 33025/37625 (87.774%), Loss: 1.1115\n",
      "Epoch: 16, Batch: 33281/37625 (88.454%), Loss: 1.0067\n",
      "Epoch: 16, Batch: 33537/37625 (89.135%), Loss: 1.0704\n",
      "Epoch: 16, Batch: 33793/37625 (89.815%), Loss: 0.7151\n",
      "Epoch: 16, Batch: 34049/37625 (90.496%), Loss: 1.0818\n",
      "Epoch: 16, Batch: 34305/37625 (91.176%), Loss: 1.4278\n",
      "Epoch: 16, Batch: 34561/37625 (91.856%), Loss: 1.3477\n",
      "Epoch: 16, Batch: 34817/37625 (92.537%), Loss: 0.6660\n",
      "Epoch: 16, Batch: 35073/37625 (93.217%), Loss: 1.0638\n",
      "Epoch: 16, Batch: 35329/37625 (93.898%), Loss: 1.2005\n",
      "Epoch: 16, Batch: 35585/37625 (94.578%), Loss: 0.9676\n",
      "Epoch: 16, Batch: 35841/37625 (95.258%), Loss: 1.1292\n",
      "Epoch: 16, Batch: 36097/37625 (95.939%), Loss: 0.9025\n",
      "Epoch: 16, Batch: 36353/37625 (96.619%), Loss: 0.6688\n",
      "Epoch: 16, Batch: 36609/37625 (97.300%), Loss: 0.6475\n",
      "Epoch: 16, Batch: 36865/37625 (97.980%), Loss: 0.6441\n",
      "Epoch: 16, Batch: 37121/37625 (98.660%), Loss: 1.1391\n",
      "Epoch: 16, Batch: 37377/37625 (99.341%), Loss: 0.9112\n",
      "Epoch: 17, Batch: 1/37625 (0.003%), Loss: 0.7640\n",
      "Epoch: 17, Batch: 257/37625 (0.683%), Loss: 1.5818\n",
      "Epoch: 17, Batch: 513/37625 (1.363%), Loss: 1.0469\n",
      "Epoch: 17, Batch: 769/37625 (2.044%), Loss: 1.3312\n",
      "Epoch: 17, Batch: 1025/37625 (2.724%), Loss: 0.8930\n",
      "Epoch: 17, Batch: 1281/37625 (3.405%), Loss: 0.8067\n",
      "Epoch: 17, Batch: 1537/37625 (4.085%), Loss: 0.6051\n",
      "Epoch: 17, Batch: 1793/37625 (4.765%), Loss: 0.8111\n",
      "Epoch: 17, Batch: 2049/37625 (5.446%), Loss: 0.6630\n",
      "Epoch: 17, Batch: 2305/37625 (6.126%), Loss: 2.2176\n",
      "Epoch: 17, Batch: 2561/37625 (6.807%), Loss: 0.9181\n",
      "Epoch: 17, Batch: 2817/37625 (7.487%), Loss: 1.0051\n",
      "Epoch: 17, Batch: 3073/37625 (8.167%), Loss: 1.2159\n",
      "Epoch: 17, Batch: 3329/37625 (8.848%), Loss: 1.2761\n",
      "Epoch: 17, Batch: 3585/37625 (9.528%), Loss: 1.1082\n",
      "Epoch: 17, Batch: 3841/37625 (10.209%), Loss: 1.1685\n",
      "Epoch: 17, Batch: 4097/37625 (10.889%), Loss: 2.2811\n",
      "Epoch: 17, Batch: 4353/37625 (11.569%), Loss: 0.7762\n",
      "Epoch: 17, Batch: 4609/37625 (12.250%), Loss: 0.7308\n",
      "Epoch: 17, Batch: 4865/37625 (12.930%), Loss: 1.7917\n",
      "Epoch: 17, Batch: 5121/37625 (13.611%), Loss: 0.6743\n",
      "Epoch: 17, Batch: 5377/37625 (14.291%), Loss: 0.7783\n",
      "Epoch: 17, Batch: 5633/37625 (14.971%), Loss: 1.3920\n",
      "Epoch: 17, Batch: 5889/37625 (15.652%), Loss: 0.7598\n",
      "Epoch: 17, Batch: 6145/37625 (16.332%), Loss: 1.1616\n",
      "Epoch: 17, Batch: 6401/37625 (17.013%), Loss: 0.9722\n",
      "Epoch: 17, Batch: 6657/37625 (17.693%), Loss: 0.5834\n",
      "Epoch: 17, Batch: 6913/37625 (18.373%), Loss: 0.9534\n",
      "Epoch: 17, Batch: 7169/37625 (19.054%), Loss: 1.6234\n",
      "Epoch: 17, Batch: 7425/37625 (19.734%), Loss: 0.6170\n",
      "Epoch: 17, Batch: 7681/37625 (20.415%), Loss: 1.6347\n",
      "Epoch: 17, Batch: 7937/37625 (21.095%), Loss: 0.9983\n",
      "Epoch: 17, Batch: 8193/37625 (21.775%), Loss: 0.8835\n",
      "Epoch: 17, Batch: 8449/37625 (22.456%), Loss: 1.2079\n",
      "Epoch: 17, Batch: 8705/37625 (23.136%), Loss: 0.7739\n",
      "Epoch: 17, Batch: 8961/37625 (23.817%), Loss: 0.8328\n",
      "Epoch: 17, Batch: 9217/37625 (24.497%), Loss: 0.7576\n",
      "Epoch: 17, Batch: 9473/37625 (25.177%), Loss: 0.9086\n",
      "Epoch: 17, Batch: 9729/37625 (25.858%), Loss: 0.8351\n",
      "Epoch: 17, Batch: 9985/37625 (26.538%), Loss: 0.9780\n",
      "Epoch: 17, Batch: 10241/37625 (27.219%), Loss: 0.8760\n",
      "Epoch: 17, Batch: 10497/37625 (27.899%), Loss: 0.8466\n",
      "Epoch: 17, Batch: 10753/37625 (28.579%), Loss: 0.6598\n",
      "Epoch: 17, Batch: 11009/37625 (29.260%), Loss: 0.9213\n",
      "Epoch: 17, Batch: 11265/37625 (29.940%), Loss: 0.7796\n",
      "Epoch: 17, Batch: 11521/37625 (30.621%), Loss: 0.9007\n",
      "Epoch: 17, Batch: 11777/37625 (31.301%), Loss: 1.0368\n",
      "Epoch: 17, Batch: 12033/37625 (31.981%), Loss: 1.3728\n",
      "Epoch: 17, Batch: 12289/37625 (32.662%), Loss: 1.1360\n",
      "Epoch: 17, Batch: 12545/37625 (33.342%), Loss: 0.7585\n",
      "Epoch: 17, Batch: 12801/37625 (34.023%), Loss: 1.1834\n",
      "Epoch: 17, Batch: 13057/37625 (34.703%), Loss: 1.0009\n",
      "Epoch: 17, Batch: 13313/37625 (35.383%), Loss: 0.8561\n",
      "Epoch: 17, Batch: 13569/37625 (36.064%), Loss: 0.8300\n",
      "Epoch: 17, Batch: 13825/37625 (36.744%), Loss: 0.9691\n",
      "Epoch: 17, Batch: 14081/37625 (37.425%), Loss: 0.5974\n",
      "Epoch: 17, Batch: 14337/37625 (38.105%), Loss: 3.0716\n",
      "Epoch: 17, Batch: 14593/37625 (38.785%), Loss: 1.8034\n",
      "Epoch: 17, Batch: 14849/37625 (39.466%), Loss: 0.7908\n",
      "Epoch: 17, Batch: 15105/37625 (40.146%), Loss: 1.1705\n",
      "Epoch: 17, Batch: 15361/37625 (40.827%), Loss: 0.5609\n",
      "Epoch: 17, Batch: 15617/37625 (41.507%), Loss: 0.8226\n",
      "Epoch: 17, Batch: 15873/37625 (42.187%), Loss: 1.1528\n",
      "Epoch: 17, Batch: 16129/37625 (42.868%), Loss: 0.6091\n",
      "Epoch: 17, Batch: 16385/37625 (43.548%), Loss: 0.6705\n",
      "Epoch: 17, Batch: 16641/37625 (44.229%), Loss: 0.9778\n",
      "Epoch: 17, Batch: 16897/37625 (44.909%), Loss: 0.8328\n",
      "Epoch: 17, Batch: 17153/37625 (45.589%), Loss: 0.8241\n",
      "Epoch: 17, Batch: 17409/37625 (46.270%), Loss: 0.8650\n",
      "Epoch: 17, Batch: 17665/37625 (46.950%), Loss: 0.8218\n",
      "Epoch: 17, Batch: 17921/37625 (47.631%), Loss: 0.7784\n",
      "Epoch: 17, Batch: 18177/37625 (48.311%), Loss: 0.6454\n",
      "Epoch: 17, Batch: 18433/37625 (48.991%), Loss: 1.2645\n",
      "Epoch: 17, Batch: 18689/37625 (49.672%), Loss: 0.6203\n",
      "Epoch: 17, Batch: 18945/37625 (50.352%), Loss: 0.9265\n",
      "Epoch: 17, Batch: 19201/37625 (51.033%), Loss: 0.7399\n",
      "Epoch: 17, Batch: 19457/37625 (51.713%), Loss: 2.5248\n",
      "Epoch: 17, Batch: 19713/37625 (52.393%), Loss: 0.9112\n",
      "Epoch: 17, Batch: 19969/37625 (53.074%), Loss: 1.0701\n",
      "Epoch: 17, Batch: 20225/37625 (53.754%), Loss: 1.5145\n",
      "Epoch: 17, Batch: 20481/37625 (54.435%), Loss: 0.9460\n",
      "Epoch: 17, Batch: 20737/37625 (55.115%), Loss: 2.1781\n",
      "Epoch: 17, Batch: 20993/37625 (55.795%), Loss: 1.0925\n",
      "Epoch: 17, Batch: 21249/37625 (56.476%), Loss: 1.0621\n",
      "Epoch: 17, Batch: 21505/37625 (57.156%), Loss: 0.7741\n",
      "Epoch: 17, Batch: 21761/37625 (57.837%), Loss: 0.9227\n",
      "Epoch: 17, Batch: 22017/37625 (58.517%), Loss: 0.7325\n",
      "Epoch: 17, Batch: 22273/37625 (59.197%), Loss: 0.6720\n",
      "Epoch: 17, Batch: 22529/37625 (59.878%), Loss: 1.1313\n",
      "Epoch: 17, Batch: 22785/37625 (60.558%), Loss: 0.5891\n",
      "Epoch: 17, Batch: 23041/37625 (61.239%), Loss: 0.8708\n",
      "Epoch: 17, Batch: 23297/37625 (61.919%), Loss: 0.8651\n",
      "Epoch: 17, Batch: 23553/37625 (62.599%), Loss: 0.8008\n",
      "Epoch: 17, Batch: 23809/37625 (63.280%), Loss: 1.2927\n",
      "Epoch: 17, Batch: 24065/37625 (63.960%), Loss: 1.0988\n",
      "Epoch: 17, Batch: 24321/37625 (64.641%), Loss: 0.9739\n",
      "Epoch: 17, Batch: 24577/37625 (65.321%), Loss: 0.7870\n",
      "Epoch: 17, Batch: 24833/37625 (66.001%), Loss: 0.7079\n",
      "Epoch: 17, Batch: 25089/37625 (66.682%), Loss: 0.9074\n",
      "Epoch: 17, Batch: 25345/37625 (67.362%), Loss: 1.7585\n",
      "Epoch: 17, Batch: 25601/37625 (68.043%), Loss: 0.8193\n",
      "Epoch: 17, Batch: 25857/37625 (68.723%), Loss: 1.2545\n",
      "Epoch: 17, Batch: 26113/37625 (69.403%), Loss: 1.0567\n",
      "Epoch: 17, Batch: 26369/37625 (70.084%), Loss: 1.3915\n",
      "Epoch: 17, Batch: 26625/37625 (70.764%), Loss: 0.7728\n",
      "Epoch: 17, Batch: 26881/37625 (71.445%), Loss: 1.0961\n",
      "Epoch: 17, Batch: 27137/37625 (72.125%), Loss: 1.0983\n",
      "Epoch: 17, Batch: 27393/37625 (72.805%), Loss: 0.9492\n",
      "Epoch: 17, Batch: 27649/37625 (73.486%), Loss: 0.9905\n",
      "Epoch: 17, Batch: 27905/37625 (74.166%), Loss: 0.7776\n",
      "Epoch: 17, Batch: 28161/37625 (74.847%), Loss: 0.8362\n",
      "Epoch: 17, Batch: 28417/37625 (75.527%), Loss: 0.5493\n",
      "Epoch: 17, Batch: 28673/37625 (76.207%), Loss: 0.7700\n",
      "Epoch: 17, Batch: 28929/37625 (76.888%), Loss: 0.6088\n",
      "Epoch: 17, Batch: 29185/37625 (77.568%), Loss: 0.8348\n",
      "Epoch: 17, Batch: 29441/37625 (78.249%), Loss: 1.1220\n",
      "Epoch: 17, Batch: 29697/37625 (78.929%), Loss: 0.8484\n",
      "Epoch: 17, Batch: 29953/37625 (79.609%), Loss: 0.8004\n",
      "Epoch: 17, Batch: 30209/37625 (80.290%), Loss: 0.7963\n",
      "Epoch: 17, Batch: 30465/37625 (80.970%), Loss: 3.1383\n",
      "Epoch: 17, Batch: 30721/37625 (81.650%), Loss: 0.8621\n",
      "Epoch: 17, Batch: 30977/37625 (82.331%), Loss: 0.7797\n",
      "Epoch: 17, Batch: 31233/37625 (83.011%), Loss: 1.4829\n",
      "Epoch: 17, Batch: 31489/37625 (83.692%), Loss: 4.6762\n",
      "Epoch: 17, Batch: 31745/37625 (84.372%), Loss: 0.7806\n",
      "Epoch: 17, Batch: 32001/37625 (85.052%), Loss: 1.1556\n",
      "Epoch: 17, Batch: 32257/37625 (85.733%), Loss: 0.8168\n",
      "Epoch: 17, Batch: 32513/37625 (86.413%), Loss: 0.9313\n",
      "Epoch: 17, Batch: 32769/37625 (87.094%), Loss: 5.2377\n",
      "Epoch: 17, Batch: 33025/37625 (87.774%), Loss: 5.3789\n",
      "Epoch: 17, Batch: 33281/37625 (88.454%), Loss: 1.9216\n",
      "Epoch: 17, Batch: 33537/37625 (89.135%), Loss: 0.7956\n",
      "Epoch: 17, Batch: 33793/37625 (89.815%), Loss: 0.9249\n",
      "Epoch: 17, Batch: 34049/37625 (90.496%), Loss: 1.2198\n",
      "Epoch: 17, Batch: 34305/37625 (91.176%), Loss: 1.2219\n",
      "Epoch: 17, Batch: 34561/37625 (91.856%), Loss: 1.3043\n",
      "Epoch: 17, Batch: 34817/37625 (92.537%), Loss: 0.6447\n",
      "Epoch: 17, Batch: 35073/37625 (93.217%), Loss: 0.6167\n",
      "Epoch: 17, Batch: 35329/37625 (93.898%), Loss: 0.6562\n",
      "Epoch: 17, Batch: 35585/37625 (94.578%), Loss: 0.8661\n",
      "Epoch: 17, Batch: 35841/37625 (95.258%), Loss: 0.6524\n",
      "Epoch: 17, Batch: 36097/37625 (95.939%), Loss: 0.8744\n",
      "Epoch: 17, Batch: 36353/37625 (96.619%), Loss: 0.8084\n",
      "Epoch: 17, Batch: 36609/37625 (97.300%), Loss: 0.9708\n",
      "Epoch: 17, Batch: 36865/37625 (97.980%), Loss: 1.2005\n",
      "Epoch: 17, Batch: 37121/37625 (98.660%), Loss: 2.7308\n",
      "Epoch: 17, Batch: 37377/37625 (99.341%), Loss: 0.5626\n",
      "Epoch: 18, Batch: 1/37625 (0.003%), Loss: 0.7032\n",
      "Epoch: 18, Batch: 257/37625 (0.683%), Loss: 1.0449\n",
      "Epoch: 18, Batch: 513/37625 (1.363%), Loss: 1.1075\n",
      "Epoch: 18, Batch: 769/37625 (2.044%), Loss: 1.7085\n",
      "Epoch: 18, Batch: 1025/37625 (2.724%), Loss: 0.5736\n",
      "Epoch: 18, Batch: 1281/37625 (3.405%), Loss: 0.6205\n",
      "Epoch: 18, Batch: 1537/37625 (4.085%), Loss: 0.8108\n",
      "Epoch: 18, Batch: 1793/37625 (4.765%), Loss: 1.0129\n",
      "Epoch: 18, Batch: 2049/37625 (5.446%), Loss: 1.4099\n",
      "Epoch: 18, Batch: 2305/37625 (6.126%), Loss: 0.7763\n",
      "Epoch: 18, Batch: 2561/37625 (6.807%), Loss: 0.9178\n",
      "Epoch: 18, Batch: 2817/37625 (7.487%), Loss: 0.6443\n",
      "Epoch: 18, Batch: 3073/37625 (8.167%), Loss: 0.9334\n",
      "Epoch: 18, Batch: 3329/37625 (8.848%), Loss: 2.3330\n",
      "Epoch: 18, Batch: 3585/37625 (9.528%), Loss: 1.1705\n",
      "Epoch: 18, Batch: 3841/37625 (10.209%), Loss: 1.2045\n",
      "Epoch: 18, Batch: 4097/37625 (10.889%), Loss: 0.8043\n",
      "Epoch: 18, Batch: 4353/37625 (11.569%), Loss: 2.2895\n",
      "Epoch: 18, Batch: 4609/37625 (12.250%), Loss: 0.9915\n",
      "Epoch: 18, Batch: 4865/37625 (12.930%), Loss: 0.9882\n",
      "Epoch: 18, Batch: 5121/37625 (13.611%), Loss: 1.1032\n",
      "Epoch: 18, Batch: 5377/37625 (14.291%), Loss: 0.7407\n",
      "Epoch: 18, Batch: 5633/37625 (14.971%), Loss: 6.1745\n",
      "Epoch: 18, Batch: 5889/37625 (15.652%), Loss: 0.5966\n",
      "Epoch: 18, Batch: 6145/37625 (16.332%), Loss: 4.2817\n",
      "Epoch: 18, Batch: 6401/37625 (17.013%), Loss: 0.7891\n",
      "Epoch: 18, Batch: 6657/37625 (17.693%), Loss: 0.5655\n",
      "Epoch: 18, Batch: 6913/37625 (18.373%), Loss: 1.0231\n",
      "Epoch: 18, Batch: 7169/37625 (19.054%), Loss: 1.0716\n",
      "Epoch: 18, Batch: 7425/37625 (19.734%), Loss: 0.9934\n",
      "Epoch: 18, Batch: 7681/37625 (20.415%), Loss: 2.5747\n",
      "Epoch: 18, Batch: 7937/37625 (21.095%), Loss: 0.7088\n",
      "Epoch: 18, Batch: 8193/37625 (21.775%), Loss: 1.2039\n",
      "Epoch: 18, Batch: 8449/37625 (22.456%), Loss: 0.7560\n",
      "Epoch: 18, Batch: 8705/37625 (23.136%), Loss: 0.9809\n",
      "Epoch: 18, Batch: 8961/37625 (23.817%), Loss: 5.3441\n",
      "Epoch: 18, Batch: 9217/37625 (24.497%), Loss: 0.8439\n",
      "Epoch: 18, Batch: 9473/37625 (25.177%), Loss: 0.9363\n",
      "Epoch: 18, Batch: 9729/37625 (25.858%), Loss: 1.9691\n",
      "Epoch: 18, Batch: 9985/37625 (26.538%), Loss: 0.6816\n",
      "Epoch: 18, Batch: 10241/37625 (27.219%), Loss: 1.3180\n",
      "Epoch: 18, Batch: 10497/37625 (27.899%), Loss: 0.9273\n",
      "Epoch: 18, Batch: 10753/37625 (28.579%), Loss: 0.9887\n",
      "Epoch: 18, Batch: 11009/37625 (29.260%), Loss: 0.6692\n",
      "Epoch: 18, Batch: 11265/37625 (29.940%), Loss: 0.7962\n",
      "Epoch: 18, Batch: 11521/37625 (30.621%), Loss: 0.7312\n",
      "Epoch: 18, Batch: 11777/37625 (31.301%), Loss: 1.3214\n",
      "Epoch: 18, Batch: 12033/37625 (31.981%), Loss: 0.7593\n",
      "Epoch: 18, Batch: 12289/37625 (32.662%), Loss: 1.0244\n",
      "Epoch: 18, Batch: 12545/37625 (33.342%), Loss: 1.0699\n",
      "Epoch: 18, Batch: 12801/37625 (34.023%), Loss: 0.6624\n",
      "Epoch: 18, Batch: 13057/37625 (34.703%), Loss: 1.1847\n",
      "Epoch: 18, Batch: 13313/37625 (35.383%), Loss: 1.0217\n",
      "Epoch: 18, Batch: 13569/37625 (36.064%), Loss: 0.8262\n",
      "Epoch: 18, Batch: 13825/37625 (36.744%), Loss: 1.0561\n",
      "Epoch: 18, Batch: 14081/37625 (37.425%), Loss: 1.4794\n",
      "Epoch: 18, Batch: 14337/37625 (38.105%), Loss: 0.8881\n",
      "Epoch: 18, Batch: 14593/37625 (38.785%), Loss: 2.1427\n",
      "Epoch: 18, Batch: 14849/37625 (39.466%), Loss: 1.7239\n",
      "Epoch: 18, Batch: 15105/37625 (40.146%), Loss: 0.9270\n",
      "Epoch: 18, Batch: 15361/37625 (40.827%), Loss: 1.3834\n",
      "Epoch: 18, Batch: 15617/37625 (41.507%), Loss: 0.8289\n",
      "Epoch: 18, Batch: 15873/37625 (42.187%), Loss: 0.5452\n",
      "Epoch: 18, Batch: 16129/37625 (42.868%), Loss: 1.2493\n",
      "Epoch: 18, Batch: 16385/37625 (43.548%), Loss: 0.9965\n",
      "Epoch: 18, Batch: 16641/37625 (44.229%), Loss: 0.8750\n",
      "Epoch: 18, Batch: 16897/37625 (44.909%), Loss: 0.8061\n",
      "Epoch: 18, Batch: 17153/37625 (45.589%), Loss: 1.0421\n",
      "Epoch: 18, Batch: 17409/37625 (46.270%), Loss: 0.6435\n",
      "Epoch: 18, Batch: 17665/37625 (46.950%), Loss: 3.4977\n",
      "Epoch: 18, Batch: 17921/37625 (47.631%), Loss: 0.9235\n",
      "Epoch: 18, Batch: 18177/37625 (48.311%), Loss: 0.9363\n",
      "Epoch: 18, Batch: 18433/37625 (48.991%), Loss: 2.1133\n",
      "Epoch: 18, Batch: 18689/37625 (49.672%), Loss: 0.8114\n",
      "Epoch: 18, Batch: 18945/37625 (50.352%), Loss: 0.9530\n",
      "Epoch: 18, Batch: 19201/37625 (51.033%), Loss: 0.7476\n",
      "Epoch: 18, Batch: 19457/37625 (51.713%), Loss: 0.7728\n",
      "Epoch: 18, Batch: 19713/37625 (52.393%), Loss: 1.3729\n",
      "Epoch: 18, Batch: 19969/37625 (53.074%), Loss: 0.8056\n",
      "Epoch: 18, Batch: 20225/37625 (53.754%), Loss: 1.2310\n",
      "Epoch: 18, Batch: 20481/37625 (54.435%), Loss: 0.6797\n",
      "Epoch: 18, Batch: 20737/37625 (55.115%), Loss: 0.7021\n",
      "Epoch: 18, Batch: 20993/37625 (55.795%), Loss: 0.7083\n",
      "Epoch: 18, Batch: 21249/37625 (56.476%), Loss: 0.7491\n",
      "Epoch: 18, Batch: 21505/37625 (57.156%), Loss: 0.9408\n",
      "Epoch: 18, Batch: 21761/37625 (57.837%), Loss: 1.3699\n",
      "Epoch: 18, Batch: 22017/37625 (58.517%), Loss: 1.2546\n",
      "Epoch: 18, Batch: 22273/37625 (59.197%), Loss: 1.0343\n",
      "Epoch: 18, Batch: 22529/37625 (59.878%), Loss: 0.9806\n",
      "Epoch: 18, Batch: 22785/37625 (60.558%), Loss: 0.9010\n",
      "Epoch: 18, Batch: 23041/37625 (61.239%), Loss: 0.8780\n",
      "Epoch: 18, Batch: 23297/37625 (61.919%), Loss: 1.1531\n",
      "Epoch: 18, Batch: 23553/37625 (62.599%), Loss: 0.7770\n",
      "Epoch: 18, Batch: 23809/37625 (63.280%), Loss: 0.8859\n",
      "Epoch: 18, Batch: 24065/37625 (63.960%), Loss: 0.8479\n",
      "Epoch: 18, Batch: 24321/37625 (64.641%), Loss: 0.9634\n",
      "Epoch: 18, Batch: 24577/37625 (65.321%), Loss: 0.8849\n",
      "Epoch: 18, Batch: 24833/37625 (66.001%), Loss: 0.8105\n",
      "Epoch: 18, Batch: 25089/37625 (66.682%), Loss: 0.6653\n",
      "Epoch: 18, Batch: 25345/37625 (67.362%), Loss: 0.8972\n",
      "Epoch: 18, Batch: 25601/37625 (68.043%), Loss: 0.8163\n",
      "Epoch: 18, Batch: 25857/37625 (68.723%), Loss: 0.5876\n",
      "Epoch: 18, Batch: 26113/37625 (69.403%), Loss: 0.8133\n",
      "Epoch: 18, Batch: 26369/37625 (70.084%), Loss: 0.7547\n",
      "Epoch: 18, Batch: 26625/37625 (70.764%), Loss: 0.6080\n",
      "Epoch: 18, Batch: 26881/37625 (71.445%), Loss: 1.3075\n",
      "Epoch: 18, Batch: 27137/37625 (72.125%), Loss: 0.7290\n",
      "Epoch: 18, Batch: 27393/37625 (72.805%), Loss: 0.9537\n",
      "Epoch: 18, Batch: 27649/37625 (73.486%), Loss: 0.7814\n",
      "Epoch: 18, Batch: 27905/37625 (74.166%), Loss: 0.8747\n",
      "Epoch: 18, Batch: 28161/37625 (74.847%), Loss: 0.7928\n",
      "Epoch: 18, Batch: 28417/37625 (75.527%), Loss: 1.2280\n",
      "Epoch: 18, Batch: 28673/37625 (76.207%), Loss: 0.6700\n",
      "Epoch: 18, Batch: 28929/37625 (76.888%), Loss: 1.0541\n",
      "Epoch: 18, Batch: 29185/37625 (77.568%), Loss: 0.7663\n",
      "Epoch: 18, Batch: 29441/37625 (78.249%), Loss: 0.9761\n",
      "Epoch: 18, Batch: 29697/37625 (78.929%), Loss: 0.8933\n",
      "Epoch: 18, Batch: 29953/37625 (79.609%), Loss: 1.0983\n",
      "Epoch: 18, Batch: 30209/37625 (80.290%), Loss: 1.6849\n",
      "Epoch: 18, Batch: 30465/37625 (80.970%), Loss: 1.1006\n",
      "Epoch: 18, Batch: 30721/37625 (81.650%), Loss: 0.5390\n",
      "Epoch: 18, Batch: 30977/37625 (82.331%), Loss: 0.7850\n",
      "Epoch: 18, Batch: 31233/37625 (83.011%), Loss: 1.3075\n",
      "Epoch: 18, Batch: 31489/37625 (83.692%), Loss: 0.9600\n",
      "Epoch: 18, Batch: 31745/37625 (84.372%), Loss: 0.6738\n",
      "Epoch: 18, Batch: 32001/37625 (85.052%), Loss: 0.9849\n",
      "Epoch: 18, Batch: 32257/37625 (85.733%), Loss: 0.9227\n",
      "Epoch: 18, Batch: 32513/37625 (86.413%), Loss: 3.2485\n",
      "Epoch: 18, Batch: 32769/37625 (87.094%), Loss: 0.9461\n",
      "Epoch: 18, Batch: 33025/37625 (87.774%), Loss: 0.7288\n",
      "Epoch: 18, Batch: 33281/37625 (88.454%), Loss: 0.9442\n",
      "Epoch: 18, Batch: 33537/37625 (89.135%), Loss: 0.7630\n",
      "Epoch: 18, Batch: 33793/37625 (89.815%), Loss: 0.9182\n",
      "Epoch: 18, Batch: 34049/37625 (90.496%), Loss: 0.7024\n",
      "Epoch: 18, Batch: 34305/37625 (91.176%), Loss: 0.8019\n",
      "Epoch: 18, Batch: 34561/37625 (91.856%), Loss: 0.8629\n",
      "Epoch: 18, Batch: 34817/37625 (92.537%), Loss: 1.5063\n",
      "Epoch: 18, Batch: 35073/37625 (93.217%), Loss: 0.8883\n",
      "Epoch: 18, Batch: 35329/37625 (93.898%), Loss: 0.8213\n",
      "Epoch: 18, Batch: 35585/37625 (94.578%), Loss: 0.9432\n",
      "Epoch: 18, Batch: 35841/37625 (95.258%), Loss: 1.3848\n",
      "Epoch: 18, Batch: 36097/37625 (95.939%), Loss: 1.2567\n",
      "Epoch: 18, Batch: 36353/37625 (96.619%), Loss: 0.8174\n",
      "Epoch: 18, Batch: 36609/37625 (97.300%), Loss: 0.7599\n",
      "Epoch: 18, Batch: 36865/37625 (97.980%), Loss: 0.7773\n",
      "Epoch: 18, Batch: 37121/37625 (98.660%), Loss: 0.9204\n",
      "Epoch: 18, Batch: 37377/37625 (99.341%), Loss: 1.6129\n",
      "Epoch: 19, Batch: 1/37625 (0.003%), Loss: 0.8817\n",
      "Epoch: 19, Batch: 257/37625 (0.683%), Loss: 0.6793\n",
      "Epoch: 19, Batch: 513/37625 (1.363%), Loss: 1.1199\n",
      "Epoch: 19, Batch: 769/37625 (2.044%), Loss: 1.1203\n",
      "Epoch: 19, Batch: 1025/37625 (2.724%), Loss: 2.4354\n",
      "Epoch: 19, Batch: 1281/37625 (3.405%), Loss: 1.0440\n",
      "Epoch: 19, Batch: 1537/37625 (4.085%), Loss: 0.7991\n",
      "Epoch: 19, Batch: 1793/37625 (4.765%), Loss: 0.9992\n",
      "Epoch: 19, Batch: 2049/37625 (5.446%), Loss: 5.2452\n",
      "Epoch: 19, Batch: 2305/37625 (6.126%), Loss: 0.7797\n",
      "Epoch: 19, Batch: 2561/37625 (6.807%), Loss: 0.9712\n",
      "Epoch: 19, Batch: 2817/37625 (7.487%), Loss: 1.2496\n",
      "Epoch: 19, Batch: 3073/37625 (8.167%), Loss: 1.3790\n",
      "Epoch: 19, Batch: 3329/37625 (8.848%), Loss: 4.7489\n",
      "Epoch: 19, Batch: 3585/37625 (9.528%), Loss: 0.6477\n",
      "Epoch: 19, Batch: 3841/37625 (10.209%), Loss: 0.8033\n",
      "Epoch: 19, Batch: 4097/37625 (10.889%), Loss: 1.5944\n",
      "Epoch: 19, Batch: 4353/37625 (11.569%), Loss: 2.3475\n",
      "Epoch: 19, Batch: 4609/37625 (12.250%), Loss: 0.8124\n",
      "Epoch: 19, Batch: 4865/37625 (12.930%), Loss: 0.9616\n",
      "Epoch: 19, Batch: 5121/37625 (13.611%), Loss: 0.6768\n",
      "Epoch: 19, Batch: 5377/37625 (14.291%), Loss: 0.8709\n",
      "Epoch: 19, Batch: 5633/37625 (14.971%), Loss: 1.0555\n",
      "Epoch: 19, Batch: 5889/37625 (15.652%), Loss: 0.8780\n",
      "Epoch: 19, Batch: 6145/37625 (16.332%), Loss: 0.9155\n",
      "Epoch: 19, Batch: 6401/37625 (17.013%), Loss: 0.8317\n",
      "Epoch: 19, Batch: 6657/37625 (17.693%), Loss: 0.7783\n",
      "Epoch: 19, Batch: 6913/37625 (18.373%), Loss: 1.0253\n",
      "Epoch: 19, Batch: 7169/37625 (19.054%), Loss: 0.6663\n",
      "Epoch: 19, Batch: 7425/37625 (19.734%), Loss: 0.8067\n",
      "Epoch: 19, Batch: 7681/37625 (20.415%), Loss: 0.7450\n",
      "Epoch: 19, Batch: 7937/37625 (21.095%), Loss: 0.6108\n",
      "Epoch: 19, Batch: 8193/37625 (21.775%), Loss: 0.7822\n",
      "Epoch: 19, Batch: 8449/37625 (22.456%), Loss: 1.2420\n",
      "Epoch: 19, Batch: 8705/37625 (23.136%), Loss: 0.8425\n",
      "Epoch: 19, Batch: 8961/37625 (23.817%), Loss: 1.6895\n",
      "Epoch: 19, Batch: 9217/37625 (24.497%), Loss: 1.1098\n",
      "Epoch: 19, Batch: 9473/37625 (25.177%), Loss: 0.8261\n",
      "Epoch: 19, Batch: 9729/37625 (25.858%), Loss: 0.8515\n",
      "Epoch: 19, Batch: 9985/37625 (26.538%), Loss: 0.8777\n",
      "Epoch: 19, Batch: 10241/37625 (27.219%), Loss: 0.8433\n",
      "Epoch: 19, Batch: 10497/37625 (27.899%), Loss: 0.8905\n",
      "Epoch: 19, Batch: 10753/37625 (28.579%), Loss: 1.6235\n",
      "Epoch: 19, Batch: 11009/37625 (29.260%), Loss: 1.0995\n",
      "Epoch: 19, Batch: 11265/37625 (29.940%), Loss: 0.9148\n",
      "Epoch: 19, Batch: 11521/37625 (30.621%), Loss: 0.8283\n",
      "Epoch: 19, Batch: 11777/37625 (31.301%), Loss: 0.5397\n",
      "Epoch: 19, Batch: 12033/37625 (31.981%), Loss: 0.5936\n",
      "Epoch: 19, Batch: 12289/37625 (32.662%), Loss: 0.8941\n",
      "Epoch: 19, Batch: 12545/37625 (33.342%), Loss: 0.6810\n",
      "Epoch: 19, Batch: 12801/37625 (34.023%), Loss: 1.6002\n",
      "Epoch: 19, Batch: 13057/37625 (34.703%), Loss: 0.6989\n",
      "Epoch: 19, Batch: 13313/37625 (35.383%), Loss: 0.8908\n",
      "Epoch: 19, Batch: 13569/37625 (36.064%), Loss: 0.8676\n",
      "Epoch: 19, Batch: 13825/37625 (36.744%), Loss: 1.6388\n",
      "Epoch: 19, Batch: 14081/37625 (37.425%), Loss: 0.9401\n",
      "Epoch: 19, Batch: 14337/37625 (38.105%), Loss: 0.7504\n",
      "Epoch: 19, Batch: 14593/37625 (38.785%), Loss: 0.9167\n",
      "Epoch: 19, Batch: 14849/37625 (39.466%), Loss: 0.9143\n",
      "Epoch: 19, Batch: 15105/37625 (40.146%), Loss: 0.6519\n",
      "Epoch: 19, Batch: 15361/37625 (40.827%), Loss: 0.8738\n",
      "Epoch: 19, Batch: 15617/37625 (41.507%), Loss: 1.5568\n",
      "Epoch: 19, Batch: 15873/37625 (42.187%), Loss: 0.6752\n",
      "Epoch: 19, Batch: 16129/37625 (42.868%), Loss: 0.6761\n",
      "Epoch: 19, Batch: 16385/37625 (43.548%), Loss: 0.8956\n",
      "Epoch: 19, Batch: 16641/37625 (44.229%), Loss: 1.5093\n",
      "Epoch: 19, Batch: 16897/37625 (44.909%), Loss: 0.9200\n",
      "Epoch: 19, Batch: 17153/37625 (45.589%), Loss: 0.9506\n",
      "Epoch: 19, Batch: 17409/37625 (46.270%), Loss: 0.9821\n",
      "Epoch: 19, Batch: 17665/37625 (46.950%), Loss: 1.2568\n",
      "Epoch: 19, Batch: 17921/37625 (47.631%), Loss: 0.8984\n",
      "Epoch: 19, Batch: 18177/37625 (48.311%), Loss: 3.2556\n",
      "Epoch: 19, Batch: 18433/37625 (48.991%), Loss: 0.9313\n",
      "Epoch: 19, Batch: 18689/37625 (49.672%), Loss: 0.6144\n",
      "Epoch: 19, Batch: 18945/37625 (50.352%), Loss: 0.7280\n",
      "Epoch: 19, Batch: 19201/37625 (51.033%), Loss: 1.0081\n",
      "Epoch: 19, Batch: 19457/37625 (51.713%), Loss: 0.8285\n",
      "Epoch: 19, Batch: 19713/37625 (52.393%), Loss: 0.8256\n",
      "Epoch: 19, Batch: 19969/37625 (53.074%), Loss: 0.4913\n",
      "Epoch: 19, Batch: 20225/37625 (53.754%), Loss: 0.9029\n",
      "Epoch: 19, Batch: 20481/37625 (54.435%), Loss: 1.7850\n",
      "Epoch: 19, Batch: 20737/37625 (55.115%), Loss: 0.7129\n",
      "Epoch: 19, Batch: 20993/37625 (55.795%), Loss: 0.8408\n",
      "Epoch: 19, Batch: 21249/37625 (56.476%), Loss: 1.0640\n",
      "Epoch: 19, Batch: 21505/37625 (57.156%), Loss: 1.1543\n",
      "Epoch: 19, Batch: 21761/37625 (57.837%), Loss: 1.4768\n",
      "Epoch: 19, Batch: 22017/37625 (58.517%), Loss: 0.9346\n",
      "Epoch: 19, Batch: 22273/37625 (59.197%), Loss: 1.4796\n",
      "Epoch: 19, Batch: 22529/37625 (59.878%), Loss: 0.6747\n",
      "Epoch: 19, Batch: 22785/37625 (60.558%), Loss: 0.9577\n",
      "Epoch: 19, Batch: 23041/37625 (61.239%), Loss: 0.7936\n",
      "Epoch: 19, Batch: 23297/37625 (61.919%), Loss: 0.7307\n",
      "Epoch: 19, Batch: 23553/37625 (62.599%), Loss: 1.0375\n",
      "Epoch: 19, Batch: 23809/37625 (63.280%), Loss: 0.7499\n",
      "Epoch: 19, Batch: 24065/37625 (63.960%), Loss: 0.5407\n",
      "Epoch: 19, Batch: 24321/37625 (64.641%), Loss: 2.5915\n",
      "Epoch: 19, Batch: 24577/37625 (65.321%), Loss: 0.7153\n",
      "Epoch: 19, Batch: 24833/37625 (66.001%), Loss: 0.6761\n",
      "Epoch: 19, Batch: 25089/37625 (66.682%), Loss: 0.9649\n",
      "Epoch: 19, Batch: 25345/37625 (67.362%), Loss: 0.7626\n",
      "Epoch: 19, Batch: 25601/37625 (68.043%), Loss: 1.0154\n",
      "Epoch: 19, Batch: 25857/37625 (68.723%), Loss: 0.7423\n",
      "Epoch: 19, Batch: 26113/37625 (69.403%), Loss: 0.6341\n",
      "Epoch: 19, Batch: 26369/37625 (70.084%), Loss: 1.4822\n",
      "Epoch: 19, Batch: 26625/37625 (70.764%), Loss: 0.8210\n",
      "Epoch: 19, Batch: 26881/37625 (71.445%), Loss: 0.7627\n",
      "Epoch: 19, Batch: 27137/37625 (72.125%), Loss: 0.8518\n",
      "Epoch: 19, Batch: 27393/37625 (72.805%), Loss: 0.7363\n",
      "Epoch: 19, Batch: 27649/37625 (73.486%), Loss: 0.6547\n",
      "Epoch: 19, Batch: 27905/37625 (74.166%), Loss: 0.5755\n",
      "Epoch: 19, Batch: 28161/37625 (74.847%), Loss: 0.6376\n",
      "Epoch: 19, Batch: 28417/37625 (75.527%), Loss: 0.7583\n",
      "Epoch: 19, Batch: 28673/37625 (76.207%), Loss: 2.3901\n",
      "Epoch: 19, Batch: 28929/37625 (76.888%), Loss: 0.7797\n",
      "Epoch: 19, Batch: 29185/37625 (77.568%), Loss: 0.7228\n",
      "Epoch: 19, Batch: 29441/37625 (78.249%), Loss: 0.6673\n",
      "Epoch: 19, Batch: 29697/37625 (78.929%), Loss: 1.4183\n",
      "Epoch: 19, Batch: 29953/37625 (79.609%), Loss: 0.7052\n",
      "Epoch: 19, Batch: 30209/37625 (80.290%), Loss: 0.5783\n",
      "Epoch: 19, Batch: 30465/37625 (80.970%), Loss: 0.9224\n",
      "Epoch: 19, Batch: 30721/37625 (81.650%), Loss: 5.9115\n",
      "Epoch: 19, Batch: 30977/37625 (82.331%), Loss: 0.8549\n",
      "Epoch: 19, Batch: 31233/37625 (83.011%), Loss: 0.7722\n",
      "Epoch: 19, Batch: 31489/37625 (83.692%), Loss: 1.1259\n",
      "Epoch: 19, Batch: 31745/37625 (84.372%), Loss: 0.7561\n",
      "Epoch: 19, Batch: 32001/37625 (85.052%), Loss: 2.5214\n",
      "Epoch: 19, Batch: 32257/37625 (85.733%), Loss: 0.9067\n",
      "Epoch: 19, Batch: 32513/37625 (86.413%), Loss: 0.7560\n",
      "Epoch: 19, Batch: 32769/37625 (87.094%), Loss: 0.8614\n",
      "Epoch: 19, Batch: 33025/37625 (87.774%), Loss: 0.5795\n",
      "Epoch: 19, Batch: 33281/37625 (88.454%), Loss: 1.0029\n",
      "Epoch: 19, Batch: 33537/37625 (89.135%), Loss: 0.7728\n",
      "Epoch: 19, Batch: 33793/37625 (89.815%), Loss: 1.6019\n",
      "Epoch: 19, Batch: 34049/37625 (90.496%), Loss: 0.6437\n",
      "Epoch: 19, Batch: 34305/37625 (91.176%), Loss: 0.7487\n",
      "Epoch: 19, Batch: 34561/37625 (91.856%), Loss: 0.9727\n",
      "Epoch: 19, Batch: 34817/37625 (92.537%), Loss: 2.5045\n",
      "Epoch: 19, Batch: 35073/37625 (93.217%), Loss: 0.9110\n",
      "Epoch: 19, Batch: 35329/37625 (93.898%), Loss: 1.2998\n",
      "Epoch: 19, Batch: 35585/37625 (94.578%), Loss: 0.6246\n",
      "Epoch: 19, Batch: 35841/37625 (95.258%), Loss: 3.4705\n",
      "Epoch: 19, Batch: 36097/37625 (95.939%), Loss: 0.8695\n",
      "Epoch: 19, Batch: 36353/37625 (96.619%), Loss: 0.8126\n",
      "Epoch: 19, Batch: 36609/37625 (97.300%), Loss: 1.2638\n",
      "Epoch: 19, Batch: 36865/37625 (97.980%), Loss: 2.8099\n",
      "Epoch: 19, Batch: 37121/37625 (98.660%), Loss: 0.6820\n",
      "Epoch: 19, Batch: 37377/37625 (99.341%), Loss: 0.9753\n",
      "Epoch: 20, Batch: 1/37625 (0.003%), Loss: 0.8133\n",
      "Epoch: 20, Batch: 257/37625 (0.683%), Loss: 0.6636\n",
      "Epoch: 20, Batch: 513/37625 (1.363%), Loss: 0.7096\n",
      "Epoch: 20, Batch: 769/37625 (2.044%), Loss: 1.0510\n",
      "Epoch: 20, Batch: 1025/37625 (2.724%), Loss: 0.6781\n",
      "Epoch: 20, Batch: 1281/37625 (3.405%), Loss: 1.0183\n",
      "Epoch: 20, Batch: 1537/37625 (4.085%), Loss: 1.0816\n",
      "Epoch: 20, Batch: 1793/37625 (4.765%), Loss: 0.5378\n",
      "Epoch: 20, Batch: 2049/37625 (5.446%), Loss: 0.6275\n",
      "Epoch: 20, Batch: 2305/37625 (6.126%), Loss: 0.7855\n",
      "Epoch: 20, Batch: 2561/37625 (6.807%), Loss: 1.0025\n",
      "Epoch: 20, Batch: 2817/37625 (7.487%), Loss: 2.5346\n",
      "Epoch: 20, Batch: 3073/37625 (8.167%), Loss: 1.3657\n",
      "Epoch: 20, Batch: 3329/37625 (8.848%), Loss: 0.5732\n",
      "Epoch: 20, Batch: 3585/37625 (9.528%), Loss: 4.4356\n",
      "Epoch: 20, Batch: 3841/37625 (10.209%), Loss: 5.4644\n",
      "Epoch: 20, Batch: 4097/37625 (10.889%), Loss: 1.1727\n",
      "Epoch: 20, Batch: 4353/37625 (11.569%), Loss: 0.8151\n",
      "Epoch: 20, Batch: 4609/37625 (12.250%), Loss: 0.5704\n",
      "Epoch: 20, Batch: 4865/37625 (12.930%), Loss: 0.7861\n",
      "Epoch: 20, Batch: 5121/37625 (13.611%), Loss: 0.7968\n",
      "Epoch: 20, Batch: 5377/37625 (14.291%), Loss: 1.0878\n",
      "Epoch: 20, Batch: 5633/37625 (14.971%), Loss: 1.0643\n",
      "Epoch: 20, Batch: 5889/37625 (15.652%), Loss: 0.8448\n",
      "Epoch: 20, Batch: 6145/37625 (16.332%), Loss: 0.8249\n",
      "Epoch: 20, Batch: 6401/37625 (17.013%), Loss: 0.6392\n",
      "Epoch: 20, Batch: 6657/37625 (17.693%), Loss: 2.4595\n",
      "Epoch: 20, Batch: 6913/37625 (18.373%), Loss: 1.6743\n",
      "Epoch: 20, Batch: 7169/37625 (19.054%), Loss: 0.8540\n",
      "Epoch: 20, Batch: 7425/37625 (19.734%), Loss: 0.8420\n",
      "Epoch: 20, Batch: 7681/37625 (20.415%), Loss: 0.6268\n",
      "Epoch: 20, Batch: 7937/37625 (21.095%), Loss: 0.9696\n",
      "Epoch: 20, Batch: 8193/37625 (21.775%), Loss: 0.8563\n",
      "Epoch: 20, Batch: 8449/37625 (22.456%), Loss: 0.8687\n",
      "Epoch: 20, Batch: 8705/37625 (23.136%), Loss: 2.9841\n",
      "Epoch: 20, Batch: 8961/37625 (23.817%), Loss: 0.8382\n",
      "Epoch: 20, Batch: 9217/37625 (24.497%), Loss: 0.6721\n",
      "Epoch: 20, Batch: 9473/37625 (25.177%), Loss: 0.7536\n",
      "Epoch: 20, Batch: 9729/37625 (25.858%), Loss: 1.6530\n",
      "Epoch: 20, Batch: 9985/37625 (26.538%), Loss: 1.1271\n",
      "Epoch: 20, Batch: 10241/37625 (27.219%), Loss: 1.2129\n",
      "Epoch: 20, Batch: 10497/37625 (27.899%), Loss: 0.9799\n",
      "Epoch: 20, Batch: 10753/37625 (28.579%), Loss: 1.2551\n",
      "Epoch: 20, Batch: 11009/37625 (29.260%), Loss: 1.0012\n",
      "Epoch: 20, Batch: 11265/37625 (29.940%), Loss: 0.8852\n",
      "Epoch: 20, Batch: 11521/37625 (30.621%), Loss: 1.0821\n",
      "Epoch: 20, Batch: 11777/37625 (31.301%), Loss: 0.9323\n",
      "Epoch: 20, Batch: 12033/37625 (31.981%), Loss: 1.2969\n",
      "Epoch: 20, Batch: 12289/37625 (32.662%), Loss: 1.5148\n",
      "Epoch: 20, Batch: 12545/37625 (33.342%), Loss: 0.7799\n",
      "Epoch: 20, Batch: 12801/37625 (34.023%), Loss: 0.8687\n",
      "Epoch: 20, Batch: 13057/37625 (34.703%), Loss: 1.0875\n",
      "Epoch: 20, Batch: 13313/37625 (35.383%), Loss: 0.7658\n",
      "Epoch: 20, Batch: 13569/37625 (36.064%), Loss: 1.1031\n",
      "Epoch: 20, Batch: 13825/37625 (36.744%), Loss: 0.7847\n",
      "Epoch: 20, Batch: 14081/37625 (37.425%), Loss: 1.1615\n",
      "Epoch: 20, Batch: 14337/37625 (38.105%), Loss: 1.0543\n",
      "Epoch: 20, Batch: 14593/37625 (38.785%), Loss: 0.7080\n",
      "Epoch: 20, Batch: 14849/37625 (39.466%), Loss: 0.6271\n",
      "Epoch: 20, Batch: 15105/37625 (40.146%), Loss: 0.9504\n",
      "Epoch: 20, Batch: 15361/37625 (40.827%), Loss: 0.4862\n",
      "Epoch: 20, Batch: 15617/37625 (41.507%), Loss: 0.8202\n",
      "Epoch: 20, Batch: 15873/37625 (42.187%), Loss: 0.6507\n",
      "Epoch: 20, Batch: 16129/37625 (42.868%), Loss: 0.6307\n",
      "Epoch: 20, Batch: 16385/37625 (43.548%), Loss: 1.0112\n",
      "Epoch: 20, Batch: 16641/37625 (44.229%), Loss: 0.6560\n",
      "Epoch: 20, Batch: 16897/37625 (44.909%), Loss: 0.9551\n",
      "Epoch: 20, Batch: 17153/37625 (45.589%), Loss: 0.9148\n",
      "Epoch: 20, Batch: 17409/37625 (46.270%), Loss: 0.8141\n",
      "Epoch: 20, Batch: 17665/37625 (46.950%), Loss: 0.6299\n",
      "Epoch: 20, Batch: 17921/37625 (47.631%), Loss: 0.7824\n",
      "Epoch: 20, Batch: 18177/37625 (48.311%), Loss: 1.0166\n",
      "Epoch: 20, Batch: 18433/37625 (48.991%), Loss: 0.7452\n",
      "Epoch: 20, Batch: 18689/37625 (49.672%), Loss: 0.7294\n",
      "Epoch: 20, Batch: 18945/37625 (50.352%), Loss: 2.9305\n",
      "Epoch: 20, Batch: 19201/37625 (51.033%), Loss: 1.2539\n",
      "Epoch: 20, Batch: 19457/37625 (51.713%), Loss: 0.7702\n",
      "Epoch: 20, Batch: 19713/37625 (52.393%), Loss: 0.8329\n",
      "Epoch: 20, Batch: 19969/37625 (53.074%), Loss: 1.1108\n",
      "Epoch: 20, Batch: 20225/37625 (53.754%), Loss: 0.6845\n",
      "Epoch: 20, Batch: 20481/37625 (54.435%), Loss: 1.3566\n",
      "Epoch: 20, Batch: 20737/37625 (55.115%), Loss: 0.8830\n",
      "Epoch: 20, Batch: 20993/37625 (55.795%), Loss: 1.3111\n",
      "Epoch: 20, Batch: 21249/37625 (56.476%), Loss: 0.7285\n",
      "Epoch: 20, Batch: 21505/37625 (57.156%), Loss: 0.9985\n",
      "Epoch: 20, Batch: 21761/37625 (57.837%), Loss: 0.5584\n",
      "Epoch: 20, Batch: 22017/37625 (58.517%), Loss: 1.6548\n",
      "Epoch: 20, Batch: 22273/37625 (59.197%), Loss: 1.1003\n",
      "Epoch: 20, Batch: 22529/37625 (59.878%), Loss: 0.9360\n",
      "Epoch: 20, Batch: 22785/37625 (60.558%), Loss: 0.7913\n",
      "Epoch: 20, Batch: 23041/37625 (61.239%), Loss: 4.9473\n",
      "Epoch: 20, Batch: 23297/37625 (61.919%), Loss: 0.7094\n",
      "Epoch: 20, Batch: 23553/37625 (62.599%), Loss: 1.3237\n",
      "Epoch: 20, Batch: 23809/37625 (63.280%), Loss: 0.9537\n",
      "Epoch: 20, Batch: 24065/37625 (63.960%), Loss: 1.3731\n",
      "Epoch: 20, Batch: 24321/37625 (64.641%), Loss: 0.6571\n",
      "Epoch: 20, Batch: 24577/37625 (65.321%), Loss: 0.7553\n",
      "Epoch: 20, Batch: 24833/37625 (66.001%), Loss: 0.8551\n",
      "Epoch: 20, Batch: 25089/37625 (66.682%), Loss: 0.7201\n",
      "Epoch: 20, Batch: 25345/37625 (67.362%), Loss: 1.9997\n",
      "Epoch: 20, Batch: 25601/37625 (68.043%), Loss: 0.8538\n",
      "Epoch: 20, Batch: 25857/37625 (68.723%), Loss: 0.7841\n",
      "Epoch: 20, Batch: 26113/37625 (69.403%), Loss: 1.1663\n",
      "Epoch: 20, Batch: 26369/37625 (70.084%), Loss: 1.2956\n",
      "Epoch: 20, Batch: 26625/37625 (70.764%), Loss: 0.7406\n",
      "Epoch: 20, Batch: 26881/37625 (71.445%), Loss: 2.2858\n",
      "Epoch: 20, Batch: 27137/37625 (72.125%), Loss: 0.6694\n",
      "Epoch: 20, Batch: 27393/37625 (72.805%), Loss: 0.8660\n",
      "Epoch: 20, Batch: 27649/37625 (73.486%), Loss: 1.5071\n",
      "Epoch: 20, Batch: 27905/37625 (74.166%), Loss: 0.6806\n",
      "Epoch: 20, Batch: 28161/37625 (74.847%), Loss: 0.8926\n",
      "Epoch: 20, Batch: 28417/37625 (75.527%), Loss: 1.2859\n",
      "Epoch: 20, Batch: 28673/37625 (76.207%), Loss: 3.4028\n",
      "Epoch: 20, Batch: 28929/37625 (76.888%), Loss: 0.8704\n",
      "Epoch: 20, Batch: 29185/37625 (77.568%), Loss: 0.7409\n",
      "Epoch: 20, Batch: 29441/37625 (78.249%), Loss: 0.9359\n",
      "Epoch: 20, Batch: 29697/37625 (78.929%), Loss: 1.2127\n",
      "Epoch: 20, Batch: 29953/37625 (79.609%), Loss: 1.1322\n",
      "Epoch: 20, Batch: 30209/37625 (80.290%), Loss: 1.2435\n",
      "Epoch: 20, Batch: 30465/37625 (80.970%), Loss: 0.7648\n",
      "Epoch: 20, Batch: 30721/37625 (81.650%), Loss: 0.7835\n",
      "Epoch: 20, Batch: 30977/37625 (82.331%), Loss: 2.2834\n",
      "Epoch: 20, Batch: 31233/37625 (83.011%), Loss: 1.3242\n",
      "Epoch: 20, Batch: 31489/37625 (83.692%), Loss: 1.0695\n",
      "Epoch: 20, Batch: 31745/37625 (84.372%), Loss: 1.1327\n",
      "Epoch: 20, Batch: 32001/37625 (85.052%), Loss: 0.8393\n",
      "Epoch: 20, Batch: 32257/37625 (85.733%), Loss: 0.9376\n",
      "Epoch: 20, Batch: 32513/37625 (86.413%), Loss: 0.6226\n",
      "Epoch: 20, Batch: 32769/37625 (87.094%), Loss: 1.4748\n",
      "Epoch: 20, Batch: 33025/37625 (87.774%), Loss: 0.8619\n",
      "Epoch: 20, Batch: 33281/37625 (88.454%), Loss: 0.5883\n",
      "Epoch: 20, Batch: 33537/37625 (89.135%), Loss: 0.6086\n",
      "Epoch: 20, Batch: 33793/37625 (89.815%), Loss: 2.1742\n",
      "Epoch: 20, Batch: 34049/37625 (90.496%), Loss: 1.1420\n",
      "Epoch: 20, Batch: 34305/37625 (91.176%), Loss: 0.8397\n",
      "Epoch: 20, Batch: 34561/37625 (91.856%), Loss: 1.0467\n",
      "Epoch: 20, Batch: 34817/37625 (92.537%), Loss: 1.1248\n",
      "Epoch: 20, Batch: 35073/37625 (93.217%), Loss: 1.2150\n",
      "Epoch: 20, Batch: 35329/37625 (93.898%), Loss: 0.7175\n",
      "Epoch: 20, Batch: 35585/37625 (94.578%), Loss: 1.3358\n",
      "Epoch: 20, Batch: 35841/37625 (95.258%), Loss: 1.1707\n",
      "Epoch: 20, Batch: 36097/37625 (95.939%), Loss: 0.6051\n",
      "Epoch: 20, Batch: 36353/37625 (96.619%), Loss: 0.9553\n",
      "Epoch: 20, Batch: 36609/37625 (97.300%), Loss: 0.7745\n",
      "Epoch: 20, Batch: 36865/37625 (97.980%), Loss: 0.8429\n",
      "Epoch: 20, Batch: 37121/37625 (98.660%), Loss: 0.8649\n",
      "Epoch: 20, Batch: 37377/37625 (99.341%), Loss: 0.8886\n",
      "Epoch: 21, Batch: 1/37625 (0.003%), Loss: 0.7126\n",
      "Epoch: 21, Batch: 257/37625 (0.683%), Loss: 1.0197\n",
      "Epoch: 21, Batch: 513/37625 (1.363%), Loss: 0.8876\n",
      "Epoch: 21, Batch: 769/37625 (2.044%), Loss: 0.7737\n",
      "Epoch: 21, Batch: 1025/37625 (2.724%), Loss: 0.9825\n",
      "Epoch: 21, Batch: 1281/37625 (3.405%), Loss: 0.6379\n",
      "Epoch: 21, Batch: 1537/37625 (4.085%), Loss: 0.5708\n",
      "Epoch: 21, Batch: 1793/37625 (4.765%), Loss: 2.2183\n",
      "Epoch: 21, Batch: 2049/37625 (5.446%), Loss: 0.9647\n",
      "Epoch: 21, Batch: 2305/37625 (6.126%), Loss: 1.0619\n",
      "Epoch: 21, Batch: 2561/37625 (6.807%), Loss: 1.1423\n",
      "Epoch: 21, Batch: 2817/37625 (7.487%), Loss: 0.7121\n",
      "Epoch: 21, Batch: 3073/37625 (8.167%), Loss: 0.8014\n",
      "Epoch: 21, Batch: 3329/37625 (8.848%), Loss: 0.7101\n",
      "Epoch: 21, Batch: 3585/37625 (9.528%), Loss: 0.8971\n",
      "Epoch: 21, Batch: 3841/37625 (10.209%), Loss: 2.2286\n",
      "Epoch: 21, Batch: 4097/37625 (10.889%), Loss: 0.6535\n",
      "Epoch: 21, Batch: 4353/37625 (11.569%), Loss: 1.9073\n",
      "Epoch: 21, Batch: 4609/37625 (12.250%), Loss: 5.5949\n",
      "Epoch: 21, Batch: 4865/37625 (12.930%), Loss: 0.7385\n",
      "Epoch: 21, Batch: 5121/37625 (13.611%), Loss: 0.9597\n",
      "Epoch: 21, Batch: 5377/37625 (14.291%), Loss: 1.6629\n",
      "Epoch: 21, Batch: 5633/37625 (14.971%), Loss: 1.0952\n",
      "Epoch: 21, Batch: 5889/37625 (15.652%), Loss: 0.5112\n",
      "Epoch: 21, Batch: 6145/37625 (16.332%), Loss: 0.5701\n",
      "Epoch: 21, Batch: 6401/37625 (17.013%), Loss: 2.3076\n",
      "Epoch: 21, Batch: 6657/37625 (17.693%), Loss: 4.5461\n",
      "Epoch: 21, Batch: 6913/37625 (18.373%), Loss: 0.9460\n",
      "Epoch: 21, Batch: 7169/37625 (19.054%), Loss: 0.6018\n",
      "Epoch: 21, Batch: 7425/37625 (19.734%), Loss: 1.6388\n",
      "Epoch: 21, Batch: 7681/37625 (20.415%), Loss: 0.6731\n",
      "Epoch: 21, Batch: 7937/37625 (21.095%), Loss: 0.7622\n",
      "Epoch: 21, Batch: 8193/37625 (21.775%), Loss: 0.9010\n",
      "Epoch: 21, Batch: 8449/37625 (22.456%), Loss: 0.8730\n",
      "Epoch: 21, Batch: 8705/37625 (23.136%), Loss: 1.0498\n",
      "Epoch: 21, Batch: 8961/37625 (23.817%), Loss: 0.6463\n",
      "Epoch: 21, Batch: 9217/37625 (24.497%), Loss: 0.6802\n",
      "Epoch: 21, Batch: 9473/37625 (25.177%), Loss: 0.5918\n",
      "Epoch: 21, Batch: 9729/37625 (25.858%), Loss: 0.8647\n",
      "Epoch: 21, Batch: 9985/37625 (26.538%), Loss: 1.5984\n",
      "Epoch: 21, Batch: 10241/37625 (27.219%), Loss: 2.9069\n",
      "Epoch: 21, Batch: 10497/37625 (27.899%), Loss: 0.9488\n",
      "Epoch: 21, Batch: 10753/37625 (28.579%), Loss: 0.8335\n",
      "Epoch: 21, Batch: 11009/37625 (29.260%), Loss: 0.7047\n",
      "Epoch: 21, Batch: 11265/37625 (29.940%), Loss: 0.7431\n",
      "Epoch: 21, Batch: 11521/37625 (30.621%), Loss: 0.9951\n",
      "Epoch: 21, Batch: 11777/37625 (31.301%), Loss: 1.1958\n",
      "Epoch: 21, Batch: 12033/37625 (31.981%), Loss: 0.7987\n",
      "Epoch: 21, Batch: 12289/37625 (32.662%), Loss: 0.8098\n",
      "Epoch: 21, Batch: 12545/37625 (33.342%), Loss: 1.0321\n",
      "Epoch: 21, Batch: 12801/37625 (34.023%), Loss: 0.7829\n",
      "Epoch: 21, Batch: 13057/37625 (34.703%), Loss: 0.9789\n",
      "Epoch: 21, Batch: 13313/37625 (35.383%), Loss: 0.6167\n",
      "Epoch: 21, Batch: 13569/37625 (36.064%), Loss: 1.6884\n",
      "Epoch: 21, Batch: 13825/37625 (36.744%), Loss: 0.9266\n",
      "Epoch: 21, Batch: 14081/37625 (37.425%), Loss: 0.9171\n",
      "Epoch: 21, Batch: 14337/37625 (38.105%), Loss: 1.0643\n",
      "Epoch: 21, Batch: 14593/37625 (38.785%), Loss: 1.0963\n",
      "Epoch: 21, Batch: 14849/37625 (39.466%), Loss: 1.9891\n",
      "Epoch: 21, Batch: 15105/37625 (40.146%), Loss: 0.4699\n",
      "Epoch: 21, Batch: 15361/37625 (40.827%), Loss: 0.8138\n",
      "Epoch: 21, Batch: 15617/37625 (41.507%), Loss: 0.8326\n",
      "Epoch: 21, Batch: 15873/37625 (42.187%), Loss: 1.0173\n",
      "Epoch: 21, Batch: 16129/37625 (42.868%), Loss: 0.7699\n",
      "Epoch: 21, Batch: 16385/37625 (43.548%), Loss: 0.7637\n",
      "Epoch: 21, Batch: 16641/37625 (44.229%), Loss: 0.9338\n",
      "Epoch: 21, Batch: 16897/37625 (44.909%), Loss: 1.1040\n",
      "Epoch: 21, Batch: 17153/37625 (45.589%), Loss: 0.7565\n",
      "Epoch: 21, Batch: 17409/37625 (46.270%), Loss: 0.5425\n",
      "Epoch: 21, Batch: 17665/37625 (46.950%), Loss: 5.4239\n",
      "Epoch: 21, Batch: 17921/37625 (47.631%), Loss: 1.2291\n",
      "Epoch: 21, Batch: 18177/37625 (48.311%), Loss: 0.7068\n",
      "Epoch: 21, Batch: 18433/37625 (48.991%), Loss: 0.7360\n",
      "Epoch: 21, Batch: 18689/37625 (49.672%), Loss: 0.8441\n",
      "Epoch: 21, Batch: 18945/37625 (50.352%), Loss: 1.0172\n",
      "Epoch: 21, Batch: 19201/37625 (51.033%), Loss: 1.1380\n",
      "Epoch: 21, Batch: 19457/37625 (51.713%), Loss: 0.9230\n",
      "Epoch: 21, Batch: 19713/37625 (52.393%), Loss: 0.9329\n",
      "Epoch: 21, Batch: 19969/37625 (53.074%), Loss: 0.7937\n",
      "Epoch: 21, Batch: 20225/37625 (53.754%), Loss: 0.8339\n",
      "Epoch: 21, Batch: 20481/37625 (54.435%), Loss: 0.5605\n",
      "Epoch: 21, Batch: 20737/37625 (55.115%), Loss: 0.8715\n",
      "Epoch: 21, Batch: 20993/37625 (55.795%), Loss: 0.7782\n",
      "Epoch: 21, Batch: 21249/37625 (56.476%), Loss: 0.6531\n",
      "Epoch: 21, Batch: 21505/37625 (57.156%), Loss: 1.2813\n",
      "Epoch: 21, Batch: 21761/37625 (57.837%), Loss: 0.6922\n",
      "Epoch: 21, Batch: 22017/37625 (58.517%), Loss: 0.8926\n",
      "Epoch: 21, Batch: 22273/37625 (59.197%), Loss: 0.6780\n",
      "Epoch: 21, Batch: 22529/37625 (59.878%), Loss: 1.0665\n",
      "Epoch: 21, Batch: 22785/37625 (60.558%), Loss: 1.6969\n",
      "Epoch: 21, Batch: 23041/37625 (61.239%), Loss: 1.4781\n",
      "Epoch: 21, Batch: 23297/37625 (61.919%), Loss: 0.7038\n",
      "Epoch: 21, Batch: 23553/37625 (62.599%), Loss: 0.5337\n",
      "Epoch: 21, Batch: 23809/37625 (63.280%), Loss: 1.0158\n",
      "Epoch: 21, Batch: 24065/37625 (63.960%), Loss: 1.2430\n",
      "Epoch: 21, Batch: 24321/37625 (64.641%), Loss: 0.6964\n",
      "Epoch: 21, Batch: 24577/37625 (65.321%), Loss: 0.9907\n",
      "Epoch: 21, Batch: 24833/37625 (66.001%), Loss: 0.8319\n",
      "Epoch: 21, Batch: 25089/37625 (66.682%), Loss: 1.0112\n",
      "Epoch: 21, Batch: 25345/37625 (67.362%), Loss: 0.7728\n",
      "Epoch: 21, Batch: 25601/37625 (68.043%), Loss: 0.7564\n",
      "Epoch: 21, Batch: 25857/37625 (68.723%), Loss: 1.0815\n",
      "Epoch: 21, Batch: 26113/37625 (69.403%), Loss: 0.8630\n",
      "Epoch: 21, Batch: 26369/37625 (70.084%), Loss: 0.9068\n",
      "Epoch: 21, Batch: 26625/37625 (70.764%), Loss: 1.2385\n",
      "Epoch: 21, Batch: 26881/37625 (71.445%), Loss: 0.9616\n",
      "Epoch: 21, Batch: 27137/37625 (72.125%), Loss: 0.6132\n",
      "Epoch: 21, Batch: 27393/37625 (72.805%), Loss: 0.8991\n",
      "Epoch: 21, Batch: 27649/37625 (73.486%), Loss: 1.0481\n",
      "Epoch: 21, Batch: 27905/37625 (74.166%), Loss: 1.5429\n",
      "Epoch: 21, Batch: 28161/37625 (74.847%), Loss: 3.1338\n",
      "Epoch: 21, Batch: 28417/37625 (75.527%), Loss: 1.1767\n",
      "Epoch: 21, Batch: 28673/37625 (76.207%), Loss: 0.8926\n",
      "Epoch: 21, Batch: 28929/37625 (76.888%), Loss: 1.0887\n",
      "Epoch: 21, Batch: 29185/37625 (77.568%), Loss: 0.8266\n",
      "Epoch: 21, Batch: 29441/37625 (78.249%), Loss: 0.7497\n",
      "Epoch: 21, Batch: 29697/37625 (78.929%), Loss: 0.5902\n",
      "Epoch: 21, Batch: 29953/37625 (79.609%), Loss: 0.8982\n",
      "Epoch: 21, Batch: 30209/37625 (80.290%), Loss: 0.8101\n",
      "Epoch: 21, Batch: 30465/37625 (80.970%), Loss: 0.9835\n",
      "Epoch: 21, Batch: 30721/37625 (81.650%), Loss: 0.9283\n",
      "Epoch: 21, Batch: 30977/37625 (82.331%), Loss: 0.5974\n",
      "Epoch: 21, Batch: 31233/37625 (83.011%), Loss: 2.2277\n",
      "Epoch: 21, Batch: 31489/37625 (83.692%), Loss: 0.9089\n",
      "Epoch: 21, Batch: 31745/37625 (84.372%), Loss: 1.2390\n",
      "Epoch: 21, Batch: 32001/37625 (85.052%), Loss: 0.7273\n",
      "Epoch: 21, Batch: 32257/37625 (85.733%), Loss: 1.4587\n",
      "Epoch: 21, Batch: 32513/37625 (86.413%), Loss: 0.8998\n",
      "Epoch: 21, Batch: 32769/37625 (87.094%), Loss: 1.0080\n",
      "Epoch: 21, Batch: 33025/37625 (87.774%), Loss: 1.4173\n",
      "Epoch: 21, Batch: 33281/37625 (88.454%), Loss: 1.3528\n",
      "Epoch: 21, Batch: 33537/37625 (89.135%), Loss: 0.9506\n",
      "Epoch: 21, Batch: 33793/37625 (89.815%), Loss: 0.9292\n",
      "Epoch: 21, Batch: 34049/37625 (90.496%), Loss: 0.6795\n",
      "Epoch: 21, Batch: 34305/37625 (91.176%), Loss: 1.0702\n",
      "Epoch: 21, Batch: 34561/37625 (91.856%), Loss: 1.0321\n",
      "Epoch: 21, Batch: 34817/37625 (92.537%), Loss: 1.4334\n",
      "Epoch: 21, Batch: 35073/37625 (93.217%), Loss: 0.6750\n",
      "Epoch: 21, Batch: 35329/37625 (93.898%), Loss: 0.8378\n",
      "Epoch: 21, Batch: 35585/37625 (94.578%), Loss: 1.3151\n",
      "Epoch: 21, Batch: 35841/37625 (95.258%), Loss: 5.2140\n",
      "Epoch: 21, Batch: 36097/37625 (95.939%), Loss: 0.9551\n",
      "Epoch: 21, Batch: 36353/37625 (96.619%), Loss: 0.7454\n",
      "Epoch: 21, Batch: 36609/37625 (97.300%), Loss: 0.8555\n",
      "Epoch: 21, Batch: 36865/37625 (97.980%), Loss: 0.9321\n",
      "Epoch: 21, Batch: 37121/37625 (98.660%), Loss: 1.0194\n",
      "Epoch: 21, Batch: 37377/37625 (99.341%), Loss: 0.5326\n",
      "Epoch: 22, Batch: 1/37625 (0.003%), Loss: 1.2485\n",
      "Epoch: 22, Batch: 257/37625 (0.683%), Loss: 1.1237\n",
      "Epoch: 22, Batch: 513/37625 (1.363%), Loss: 0.7567\n",
      "Epoch: 22, Batch: 769/37625 (2.044%), Loss: 0.6955\n",
      "Epoch: 22, Batch: 1025/37625 (2.724%), Loss: 0.8983\n",
      "Epoch: 22, Batch: 1281/37625 (3.405%), Loss: 1.1101\n",
      "Epoch: 22, Batch: 1537/37625 (4.085%), Loss: 0.8802\n",
      "Epoch: 22, Batch: 1793/37625 (4.765%), Loss: 0.6927\n",
      "Epoch: 22, Batch: 2049/37625 (5.446%), Loss: 2.4907\n",
      "Epoch: 22, Batch: 2305/37625 (6.126%), Loss: 2.3959\n",
      "Epoch: 22, Batch: 2561/37625 (6.807%), Loss: 1.7319\n",
      "Epoch: 22, Batch: 2817/37625 (7.487%), Loss: 0.7307\n",
      "Epoch: 22, Batch: 3073/37625 (8.167%), Loss: 0.6114\n",
      "Epoch: 22, Batch: 3329/37625 (8.848%), Loss: 0.8985\n",
      "Epoch: 22, Batch: 3585/37625 (9.528%), Loss: 0.8216\n",
      "Epoch: 22, Batch: 3841/37625 (10.209%), Loss: 1.3014\n",
      "Epoch: 22, Batch: 4097/37625 (10.889%), Loss: 0.9824\n",
      "Epoch: 22, Batch: 4353/37625 (11.569%), Loss: 1.0775\n",
      "Epoch: 22, Batch: 4609/37625 (12.250%), Loss: 0.8586\n",
      "Epoch: 22, Batch: 4865/37625 (12.930%), Loss: 1.3193\n",
      "Epoch: 22, Batch: 5121/37625 (13.611%), Loss: 1.0624\n",
      "Epoch: 22, Batch: 5377/37625 (14.291%), Loss: 0.8524\n",
      "Epoch: 22, Batch: 5633/37625 (14.971%), Loss: 0.8621\n",
      "Epoch: 22, Batch: 5889/37625 (15.652%), Loss: 0.7680\n",
      "Epoch: 22, Batch: 6145/37625 (16.332%), Loss: 0.8074\n",
      "Epoch: 22, Batch: 6401/37625 (17.013%), Loss: 0.8556\n",
      "Epoch: 22, Batch: 6657/37625 (17.693%), Loss: 0.5653\n",
      "Epoch: 22, Batch: 6913/37625 (18.373%), Loss: 1.5065\n",
      "Epoch: 22, Batch: 7169/37625 (19.054%), Loss: 0.8683\n",
      "Epoch: 22, Batch: 7425/37625 (19.734%), Loss: 0.8898\n",
      "Epoch: 22, Batch: 7681/37625 (20.415%), Loss: 0.7435\n",
      "Epoch: 22, Batch: 7937/37625 (21.095%), Loss: 1.0592\n",
      "Epoch: 22, Batch: 8193/37625 (21.775%), Loss: 0.8711\n",
      "Epoch: 22, Batch: 8449/37625 (22.456%), Loss: 1.3201\n",
      "Epoch: 22, Batch: 8705/37625 (23.136%), Loss: 3.1740\n",
      "Epoch: 22, Batch: 8961/37625 (23.817%), Loss: 0.8094\n",
      "Epoch: 22, Batch: 9217/37625 (24.497%), Loss: 1.1255\n",
      "Epoch: 22, Batch: 9473/37625 (25.177%), Loss: 0.6581\n",
      "Epoch: 22, Batch: 9729/37625 (25.858%), Loss: 1.2029\n",
      "Epoch: 22, Batch: 9985/37625 (26.538%), Loss: 1.0680\n",
      "Epoch: 22, Batch: 10241/37625 (27.219%), Loss: 0.9795\n",
      "Epoch: 22, Batch: 10497/37625 (27.899%), Loss: 0.7946\n",
      "Epoch: 22, Batch: 10753/37625 (28.579%), Loss: 0.9339\n",
      "Epoch: 22, Batch: 11009/37625 (29.260%), Loss: 1.1338\n",
      "Epoch: 22, Batch: 11265/37625 (29.940%), Loss: 0.8390\n",
      "Epoch: 22, Batch: 11521/37625 (30.621%), Loss: 1.2100\n",
      "Epoch: 22, Batch: 11777/37625 (31.301%), Loss: 0.6550\n",
      "Epoch: 22, Batch: 12033/37625 (31.981%), Loss: 0.6398\n",
      "Epoch: 22, Batch: 12289/37625 (32.662%), Loss: 1.4245\n",
      "Epoch: 22, Batch: 12545/37625 (33.342%), Loss: 0.5861\n",
      "Epoch: 22, Batch: 12801/37625 (34.023%), Loss: 0.8055\n",
      "Epoch: 22, Batch: 13057/37625 (34.703%), Loss: 0.5965\n",
      "Epoch: 22, Batch: 13313/37625 (35.383%), Loss: 1.4590\n",
      "Epoch: 22, Batch: 13569/37625 (36.064%), Loss: 0.8463\n",
      "Epoch: 22, Batch: 13825/37625 (36.744%), Loss: 0.9394\n",
      "Epoch: 22, Batch: 14081/37625 (37.425%), Loss: 0.7687\n",
      "Epoch: 22, Batch: 14337/37625 (38.105%), Loss: 0.8820\n",
      "Epoch: 22, Batch: 14593/37625 (38.785%), Loss: 1.9073\n",
      "Epoch: 22, Batch: 14849/37625 (39.466%), Loss: 1.3334\n",
      "Epoch: 22, Batch: 15105/37625 (40.146%), Loss: 0.9086\n",
      "Epoch: 22, Batch: 15361/37625 (40.827%), Loss: 1.0882\n",
      "Epoch: 22, Batch: 15617/37625 (41.507%), Loss: 0.6825\n",
      "Epoch: 22, Batch: 15873/37625 (42.187%), Loss: 0.9537\n",
      "Epoch: 22, Batch: 16129/37625 (42.868%), Loss: 0.9081\n",
      "Epoch: 22, Batch: 16385/37625 (43.548%), Loss: 1.4359\n",
      "Epoch: 22, Batch: 16641/37625 (44.229%), Loss: 1.0153\n",
      "Epoch: 22, Batch: 16897/37625 (44.909%), Loss: 0.8232\n",
      "Epoch: 22, Batch: 17153/37625 (45.589%), Loss: 0.6255\n",
      "Epoch: 22, Batch: 17409/37625 (46.270%), Loss: 1.3991\n",
      "Epoch: 22, Batch: 17665/37625 (46.950%), Loss: 1.0873\n",
      "Epoch: 22, Batch: 17921/37625 (47.631%), Loss: 0.6793\n",
      "Epoch: 22, Batch: 18177/37625 (48.311%), Loss: 0.6580\n",
      "Epoch: 22, Batch: 18433/37625 (48.991%), Loss: 1.0959\n",
      "Epoch: 22, Batch: 18689/37625 (49.672%), Loss: 0.8457\n",
      "Epoch: 22, Batch: 18945/37625 (50.352%), Loss: 0.9255\n",
      "Epoch: 22, Batch: 19201/37625 (51.033%), Loss: 0.8934\n",
      "Epoch: 22, Batch: 19457/37625 (51.713%), Loss: 0.9555\n",
      "Epoch: 22, Batch: 19713/37625 (52.393%), Loss: 0.5994\n",
      "Epoch: 22, Batch: 19969/37625 (53.074%), Loss: 0.9003\n",
      "Epoch: 22, Batch: 20225/37625 (53.754%), Loss: 0.6746\n",
      "Epoch: 22, Batch: 20481/37625 (54.435%), Loss: 0.6953\n",
      "Epoch: 22, Batch: 20737/37625 (55.115%), Loss: 1.7156\n",
      "Epoch: 22, Batch: 20993/37625 (55.795%), Loss: 0.8728\n",
      "Epoch: 22, Batch: 21249/37625 (56.476%), Loss: 0.7735\n",
      "Epoch: 22, Batch: 21505/37625 (57.156%), Loss: 4.3845\n",
      "Epoch: 22, Batch: 21761/37625 (57.837%), Loss: 3.8810\n",
      "Epoch: 22, Batch: 22017/37625 (58.517%), Loss: 5.2602\n",
      "Epoch: 22, Batch: 22273/37625 (59.197%), Loss: 0.7182\n",
      "Epoch: 22, Batch: 22529/37625 (59.878%), Loss: 0.8893\n",
      "Epoch: 22, Batch: 22785/37625 (60.558%), Loss: 0.7233\n",
      "Epoch: 22, Batch: 23041/37625 (61.239%), Loss: 0.6937\n",
      "Epoch: 22, Batch: 23297/37625 (61.919%), Loss: 0.5952\n",
      "Epoch: 22, Batch: 23553/37625 (62.599%), Loss: 0.8149\n",
      "Epoch: 22, Batch: 23809/37625 (63.280%), Loss: 1.2483\n",
      "Epoch: 22, Batch: 24065/37625 (63.960%), Loss: 0.7075\n",
      "Epoch: 22, Batch: 24321/37625 (64.641%), Loss: 1.0456\n",
      "Epoch: 22, Batch: 24577/37625 (65.321%), Loss: 1.0826\n",
      "Epoch: 22, Batch: 24833/37625 (66.001%), Loss: 0.9453\n",
      "Epoch: 22, Batch: 25089/37625 (66.682%), Loss: 1.6803\n",
      "Epoch: 22, Batch: 25345/37625 (67.362%), Loss: 1.6856\n",
      "Epoch: 22, Batch: 25601/37625 (68.043%), Loss: 0.6054\n",
      "Epoch: 22, Batch: 25857/37625 (68.723%), Loss: 0.7622\n",
      "Epoch: 22, Batch: 26113/37625 (69.403%), Loss: 0.6140\n",
      "Epoch: 22, Batch: 26369/37625 (70.084%), Loss: 1.6991\n",
      "Epoch: 22, Batch: 26625/37625 (70.764%), Loss: 5.6408\n",
      "Epoch: 22, Batch: 26881/37625 (71.445%), Loss: 0.7587\n",
      "Epoch: 22, Batch: 27137/37625 (72.125%), Loss: 1.0160\n",
      "Epoch: 22, Batch: 27393/37625 (72.805%), Loss: 1.2118\n",
      "Epoch: 22, Batch: 27649/37625 (73.486%), Loss: 0.8126\n",
      "Epoch: 22, Batch: 27905/37625 (74.166%), Loss: 1.5954\n",
      "Epoch: 22, Batch: 28161/37625 (74.847%), Loss: 0.7483\n",
      "Epoch: 22, Batch: 28417/37625 (75.527%), Loss: 0.7808\n",
      "Epoch: 22, Batch: 28673/37625 (76.207%), Loss: 0.9853\n",
      "Epoch: 22, Batch: 28929/37625 (76.888%), Loss: 0.7611\n",
      "Epoch: 22, Batch: 29185/37625 (77.568%), Loss: 0.9565\n",
      "Epoch: 22, Batch: 29441/37625 (78.249%), Loss: 1.8906\n",
      "Epoch: 22, Batch: 29697/37625 (78.929%), Loss: 0.6837\n",
      "Epoch: 22, Batch: 29953/37625 (79.609%), Loss: 1.0172\n",
      "Epoch: 22, Batch: 30209/37625 (80.290%), Loss: 1.4882\n",
      "Epoch: 22, Batch: 30465/37625 (80.970%), Loss: 0.7085\n",
      "Epoch: 22, Batch: 30721/37625 (81.650%), Loss: 0.7543\n",
      "Epoch: 22, Batch: 30977/37625 (82.331%), Loss: 0.9119\n",
      "Epoch: 22, Batch: 31233/37625 (83.011%), Loss: 0.8506\n",
      "Epoch: 22, Batch: 31489/37625 (83.692%), Loss: 0.9738\n",
      "Epoch: 22, Batch: 31745/37625 (84.372%), Loss: 0.7628\n",
      "Epoch: 22, Batch: 32001/37625 (85.052%), Loss: 0.6619\n",
      "Epoch: 22, Batch: 32257/37625 (85.733%), Loss: 0.8587\n",
      "Epoch: 22, Batch: 32513/37625 (86.413%), Loss: 0.5455\n",
      "Epoch: 22, Batch: 32769/37625 (87.094%), Loss: 0.8756\n",
      "Epoch: 22, Batch: 33025/37625 (87.774%), Loss: 1.5138\n",
      "Epoch: 22, Batch: 33281/37625 (88.454%), Loss: 0.9175\n",
      "Epoch: 22, Batch: 33537/37625 (89.135%), Loss: 1.6683\n",
      "Epoch: 22, Batch: 33793/37625 (89.815%), Loss: 1.6721\n",
      "Epoch: 22, Batch: 34049/37625 (90.496%), Loss: 0.8324\n",
      "Epoch: 22, Batch: 34305/37625 (91.176%), Loss: 0.8585\n",
      "Epoch: 22, Batch: 34561/37625 (91.856%), Loss: 2.1421\n",
      "Epoch: 22, Batch: 34817/37625 (92.537%), Loss: 0.8667\n",
      "Epoch: 22, Batch: 35073/37625 (93.217%), Loss: 1.3623\n",
      "Epoch: 22, Batch: 35329/37625 (93.898%), Loss: 0.7869\n",
      "Epoch: 22, Batch: 35585/37625 (94.578%), Loss: 1.0955\n",
      "Epoch: 22, Batch: 35841/37625 (95.258%), Loss: 0.9891\n",
      "Epoch: 22, Batch: 36097/37625 (95.939%), Loss: 1.0481\n",
      "Epoch: 22, Batch: 36353/37625 (96.619%), Loss: 0.5861\n",
      "Epoch: 22, Batch: 36609/37625 (97.300%), Loss: 0.6648\n",
      "Epoch: 22, Batch: 36865/37625 (97.980%), Loss: 0.9574\n",
      "Epoch: 22, Batch: 37121/37625 (98.660%), Loss: 1.1645\n",
      "Epoch: 22, Batch: 37377/37625 (99.341%), Loss: 0.7083\n",
      "Epoch: 23, Batch: 1/37625 (0.003%), Loss: 0.6186\n",
      "Epoch: 23, Batch: 257/37625 (0.683%), Loss: 0.6557\n",
      "Epoch: 23, Batch: 513/37625 (1.363%), Loss: 1.3146\n",
      "Epoch: 23, Batch: 769/37625 (2.044%), Loss: 0.7309\n",
      "Epoch: 23, Batch: 1025/37625 (2.724%), Loss: 1.8011\n",
      "Epoch: 23, Batch: 1281/37625 (3.405%), Loss: 0.6960\n",
      "Epoch: 23, Batch: 1537/37625 (4.085%), Loss: 4.3947\n",
      "Epoch: 23, Batch: 1793/37625 (4.765%), Loss: 1.0624\n",
      "Epoch: 23, Batch: 2049/37625 (5.446%), Loss: 1.3016\n",
      "Epoch: 23, Batch: 2305/37625 (6.126%), Loss: 1.2242\n",
      "Epoch: 23, Batch: 2561/37625 (6.807%), Loss: 0.9924\n",
      "Epoch: 23, Batch: 2817/37625 (7.487%), Loss: 1.1005\n",
      "Epoch: 23, Batch: 3073/37625 (8.167%), Loss: 1.0161\n",
      "Epoch: 23, Batch: 3329/37625 (8.848%), Loss: 0.8982\n",
      "Epoch: 23, Batch: 3585/37625 (9.528%), Loss: 1.2774\n",
      "Epoch: 23, Batch: 3841/37625 (10.209%), Loss: 1.3842\n",
      "Epoch: 23, Batch: 4097/37625 (10.889%), Loss: 0.9537\n",
      "Epoch: 23, Batch: 4353/37625 (11.569%), Loss: 0.7770\n",
      "Epoch: 23, Batch: 4609/37625 (12.250%), Loss: 0.6411\n",
      "Epoch: 23, Batch: 4865/37625 (12.930%), Loss: 0.8771\n",
      "Epoch: 23, Batch: 5121/37625 (13.611%), Loss: 0.7936\n",
      "Epoch: 23, Batch: 5377/37625 (14.291%), Loss: 2.1393\n",
      "Epoch: 23, Batch: 5633/37625 (14.971%), Loss: 1.2542\n",
      "Epoch: 23, Batch: 5889/37625 (15.652%), Loss: 1.1909\n",
      "Epoch: 23, Batch: 6145/37625 (16.332%), Loss: 1.5102\n",
      "Epoch: 23, Batch: 6401/37625 (17.013%), Loss: 1.0095\n",
      "Epoch: 23, Batch: 6657/37625 (17.693%), Loss: 0.5945\n",
      "Epoch: 23, Batch: 6913/37625 (18.373%), Loss: 0.8251\n",
      "Epoch: 23, Batch: 7169/37625 (19.054%), Loss: 5.8154\n",
      "Epoch: 23, Batch: 7425/37625 (19.734%), Loss: 2.7741\n",
      "Epoch: 23, Batch: 7681/37625 (20.415%), Loss: 1.5876\n",
      "Epoch: 23, Batch: 7937/37625 (21.095%), Loss: 1.4306\n",
      "Epoch: 23, Batch: 8193/37625 (21.775%), Loss: 1.2270\n",
      "Epoch: 23, Batch: 8449/37625 (22.456%), Loss: 0.7332\n",
      "Epoch: 23, Batch: 8705/37625 (23.136%), Loss: 0.9046\n",
      "Epoch: 23, Batch: 8961/37625 (23.817%), Loss: 1.1597\n",
      "Epoch: 23, Batch: 9217/37625 (24.497%), Loss: 1.0029\n",
      "Epoch: 23, Batch: 9473/37625 (25.177%), Loss: 0.8690\n",
      "Epoch: 23, Batch: 9729/37625 (25.858%), Loss: 0.8131\n",
      "Epoch: 23, Batch: 9985/37625 (26.538%), Loss: 0.9919\n",
      "Epoch: 23, Batch: 10241/37625 (27.219%), Loss: 1.2195\n",
      "Epoch: 23, Batch: 10497/37625 (27.899%), Loss: 0.6241\n",
      "Epoch: 23, Batch: 10753/37625 (28.579%), Loss: 1.0756\n",
      "Epoch: 23, Batch: 11009/37625 (29.260%), Loss: 1.0108\n",
      "Epoch: 23, Batch: 11265/37625 (29.940%), Loss: 1.0308\n",
      "Epoch: 23, Batch: 11521/37625 (30.621%), Loss: 0.6403\n",
      "Epoch: 23, Batch: 11777/37625 (31.301%), Loss: 0.8224\n",
      "Epoch: 23, Batch: 12033/37625 (31.981%), Loss: 0.8639\n",
      "Epoch: 23, Batch: 12289/37625 (32.662%), Loss: 0.6165\n",
      "Epoch: 23, Batch: 12545/37625 (33.342%), Loss: 0.9029\n",
      "Epoch: 23, Batch: 12801/37625 (34.023%), Loss: 1.0926\n",
      "Epoch: 23, Batch: 13057/37625 (34.703%), Loss: 0.4775\n",
      "Epoch: 23, Batch: 13313/37625 (35.383%), Loss: 0.9449\n",
      "Epoch: 23, Batch: 13569/37625 (36.064%), Loss: 1.2057\n",
      "Epoch: 23, Batch: 13825/37625 (36.744%), Loss: 1.0409\n",
      "Epoch: 23, Batch: 14081/37625 (37.425%), Loss: 0.7811\n",
      "Epoch: 23, Batch: 14337/37625 (38.105%), Loss: 5.1769\n",
      "Epoch: 23, Batch: 14593/37625 (38.785%), Loss: 0.9915\n",
      "Epoch: 23, Batch: 14849/37625 (39.466%), Loss: 0.7925\n",
      "Epoch: 23, Batch: 15105/37625 (40.146%), Loss: 1.3056\n",
      "Epoch: 23, Batch: 15361/37625 (40.827%), Loss: 1.1585\n",
      "Epoch: 23, Batch: 15617/37625 (41.507%), Loss: 0.7471\n",
      "Epoch: 23, Batch: 15873/37625 (42.187%), Loss: 1.2678\n",
      "Epoch: 23, Batch: 16129/37625 (42.868%), Loss: 3.5014\n",
      "Epoch: 23, Batch: 16385/37625 (43.548%), Loss: 0.7527\n",
      "Epoch: 23, Batch: 16641/37625 (44.229%), Loss: 0.6441\n",
      "Epoch: 23, Batch: 16897/37625 (44.909%), Loss: 0.8886\n",
      "Epoch: 23, Batch: 17153/37625 (45.589%), Loss: 0.8219\n",
      "Epoch: 23, Batch: 17409/37625 (46.270%), Loss: 0.8065\n",
      "Epoch: 23, Batch: 17665/37625 (46.950%), Loss: 0.6749\n",
      "Epoch: 23, Batch: 17921/37625 (47.631%), Loss: 1.3570\n",
      "Epoch: 23, Batch: 18177/37625 (48.311%), Loss: 1.2433\n",
      "Epoch: 23, Batch: 18433/37625 (48.991%), Loss: 0.9976\n",
      "Epoch: 23, Batch: 18689/37625 (49.672%), Loss: 0.6883\n",
      "Epoch: 23, Batch: 18945/37625 (50.352%), Loss: 0.9816\n",
      "Epoch: 23, Batch: 19201/37625 (51.033%), Loss: 0.6219\n",
      "Epoch: 23, Batch: 19457/37625 (51.713%), Loss: 0.6638\n",
      "Epoch: 23, Batch: 19713/37625 (52.393%), Loss: 0.5861\n",
      "Epoch: 23, Batch: 19969/37625 (53.074%), Loss: 0.8001\n",
      "Epoch: 23, Batch: 20225/37625 (53.754%), Loss: 1.0283\n",
      "Epoch: 23, Batch: 20481/37625 (54.435%), Loss: 0.8941\n",
      "Epoch: 23, Batch: 20737/37625 (55.115%), Loss: 1.3132\n",
      "Epoch: 23, Batch: 20993/37625 (55.795%), Loss: 2.2961\n",
      "Epoch: 23, Batch: 21249/37625 (56.476%), Loss: 0.9019\n",
      "Epoch: 23, Batch: 21505/37625 (57.156%), Loss: 1.1130\n",
      "Epoch: 23, Batch: 21761/37625 (57.837%), Loss: 1.9342\n",
      "Epoch: 23, Batch: 22017/37625 (58.517%), Loss: 0.8937\n",
      "Epoch: 23, Batch: 22273/37625 (59.197%), Loss: 0.9298\n",
      "Epoch: 23, Batch: 22529/37625 (59.878%), Loss: 0.9373\n",
      "Epoch: 23, Batch: 22785/37625 (60.558%), Loss: 0.7129\n",
      "Epoch: 23, Batch: 23041/37625 (61.239%), Loss: 2.0378\n",
      "Epoch: 23, Batch: 23297/37625 (61.919%), Loss: 0.7045\n",
      "Epoch: 23, Batch: 23553/37625 (62.599%), Loss: 0.6323\n",
      "Epoch: 23, Batch: 23809/37625 (63.280%), Loss: 1.0990\n",
      "Epoch: 23, Batch: 24065/37625 (63.960%), Loss: 0.9403\n",
      "Epoch: 23, Batch: 24321/37625 (64.641%), Loss: 0.5981\n",
      "Epoch: 23, Batch: 24577/37625 (65.321%), Loss: 0.8367\n",
      "Epoch: 23, Batch: 24833/37625 (66.001%), Loss: 2.1673\n",
      "Epoch: 23, Batch: 25089/37625 (66.682%), Loss: 1.0359\n",
      "Epoch: 23, Batch: 25345/37625 (67.362%), Loss: 0.7923\n",
      "Epoch: 23, Batch: 25601/37625 (68.043%), Loss: 1.4450\n",
      "Epoch: 23, Batch: 25857/37625 (68.723%), Loss: 0.9400\n",
      "Epoch: 23, Batch: 26113/37625 (69.403%), Loss: 0.8538\n",
      "Epoch: 23, Batch: 26369/37625 (70.084%), Loss: 0.8424\n",
      "Epoch: 23, Batch: 26625/37625 (70.764%), Loss: 0.6211\n",
      "Epoch: 23, Batch: 26881/37625 (71.445%), Loss: 0.9851\n",
      "Epoch: 23, Batch: 27137/37625 (72.125%), Loss: 0.7545\n",
      "Epoch: 23, Batch: 27393/37625 (72.805%), Loss: 1.0139\n",
      "Epoch: 23, Batch: 27649/37625 (73.486%), Loss: 3.1656\n",
      "Epoch: 23, Batch: 27905/37625 (74.166%), Loss: 1.0313\n",
      "Epoch: 23, Batch: 28161/37625 (74.847%), Loss: 0.9015\n",
      "Epoch: 23, Batch: 28417/37625 (75.527%), Loss: 1.4223\n",
      "Epoch: 23, Batch: 28673/37625 (76.207%), Loss: 0.7634\n",
      "Epoch: 23, Batch: 28929/37625 (76.888%), Loss: 0.6295\n",
      "Epoch: 23, Batch: 29185/37625 (77.568%), Loss: 2.0890\n",
      "Epoch: 23, Batch: 29441/37625 (78.249%), Loss: 0.8734\n",
      "Epoch: 23, Batch: 29697/37625 (78.929%), Loss: 1.7257\n",
      "Epoch: 23, Batch: 29953/37625 (79.609%), Loss: 0.7014\n",
      "Epoch: 23, Batch: 30209/37625 (80.290%), Loss: 0.7206\n",
      "Epoch: 23, Batch: 30465/37625 (80.970%), Loss: 0.9842\n",
      "Epoch: 23, Batch: 30721/37625 (81.650%), Loss: 1.0219\n",
      "Epoch: 23, Batch: 30977/37625 (82.331%), Loss: 0.6626\n",
      "Epoch: 23, Batch: 31233/37625 (83.011%), Loss: 0.7586\n",
      "Epoch: 23, Batch: 31489/37625 (83.692%), Loss: 0.7658\n",
      "Epoch: 23, Batch: 31745/37625 (84.372%), Loss: 1.0281\n",
      "Epoch: 23, Batch: 32001/37625 (85.052%), Loss: 1.6119\n",
      "Epoch: 23, Batch: 32257/37625 (85.733%), Loss: 0.8319\n",
      "Epoch: 23, Batch: 32513/37625 (86.413%), Loss: 1.0271\n",
      "Epoch: 23, Batch: 32769/37625 (87.094%), Loss: 0.8597\n",
      "Epoch: 23, Batch: 33025/37625 (87.774%), Loss: 0.7781\n",
      "Epoch: 23, Batch: 33281/37625 (88.454%), Loss: 0.6708\n",
      "Epoch: 23, Batch: 33537/37625 (89.135%), Loss: 0.7172\n",
      "Epoch: 23, Batch: 33793/37625 (89.815%), Loss: 0.9086\n",
      "Epoch: 23, Batch: 34049/37625 (90.496%), Loss: 1.0263\n",
      "Epoch: 23, Batch: 34305/37625 (91.176%), Loss: 0.8158\n",
      "Epoch: 23, Batch: 34561/37625 (91.856%), Loss: 0.9159\n",
      "Epoch: 23, Batch: 34817/37625 (92.537%), Loss: 0.7257\n",
      "Epoch: 23, Batch: 35073/37625 (93.217%), Loss: 0.9517\n",
      "Epoch: 23, Batch: 35329/37625 (93.898%), Loss: 0.8639\n",
      "Epoch: 23, Batch: 35585/37625 (94.578%), Loss: 0.8294\n",
      "Epoch: 23, Batch: 35841/37625 (95.258%), Loss: 1.1961\n",
      "Epoch: 23, Batch: 36097/37625 (95.939%), Loss: 0.6111\n",
      "Epoch: 23, Batch: 36353/37625 (96.619%), Loss: 0.6262\n",
      "Epoch: 23, Batch: 36609/37625 (97.300%), Loss: 0.8925\n",
      "Epoch: 23, Batch: 36865/37625 (97.980%), Loss: 1.1222\n",
      "Epoch: 23, Batch: 37121/37625 (98.660%), Loss: 0.5216\n",
      "Epoch: 23, Batch: 37377/37625 (99.341%), Loss: 0.5936\n",
      "Epoch: 24, Batch: 1/37625 (0.003%), Loss: 1.1558\n",
      "Epoch: 24, Batch: 257/37625 (0.683%), Loss: 0.5106\n",
      "Epoch: 24, Batch: 513/37625 (1.363%), Loss: 1.2081\n",
      "Epoch: 24, Batch: 769/37625 (2.044%), Loss: 0.8883\n",
      "Epoch: 24, Batch: 1025/37625 (2.724%), Loss: 1.0019\n",
      "Epoch: 24, Batch: 1281/37625 (3.405%), Loss: 1.0485\n",
      "Epoch: 24, Batch: 1537/37625 (4.085%), Loss: 0.9442\n",
      "Epoch: 24, Batch: 1793/37625 (4.765%), Loss: 0.7184\n",
      "Epoch: 24, Batch: 2049/37625 (5.446%), Loss: 0.6037\n",
      "Epoch: 24, Batch: 2305/37625 (6.126%), Loss: 0.7649\n",
      "Epoch: 24, Batch: 2561/37625 (6.807%), Loss: 1.0912\n",
      "Epoch: 24, Batch: 2817/37625 (7.487%), Loss: 0.9213\n",
      "Epoch: 24, Batch: 3073/37625 (8.167%), Loss: 0.6616\n",
      "Epoch: 24, Batch: 3329/37625 (8.848%), Loss: 1.4304\n",
      "Epoch: 24, Batch: 3585/37625 (9.528%), Loss: 0.7139\n",
      "Epoch: 24, Batch: 3841/37625 (10.209%), Loss: 0.9977\n",
      "Epoch: 24, Batch: 4097/37625 (10.889%), Loss: 1.0300\n",
      "Epoch: 24, Batch: 4353/37625 (11.569%), Loss: 1.0219\n",
      "Epoch: 24, Batch: 4609/37625 (12.250%), Loss: 0.9638\n",
      "Epoch: 24, Batch: 4865/37625 (12.930%), Loss: 0.7786\n",
      "Epoch: 24, Batch: 5121/37625 (13.611%), Loss: 1.5088\n",
      "Epoch: 24, Batch: 5377/37625 (14.291%), Loss: 1.5134\n",
      "Epoch: 24, Batch: 5633/37625 (14.971%), Loss: 1.2704\n",
      "Epoch: 24, Batch: 5889/37625 (15.652%), Loss: 2.0106\n",
      "Epoch: 24, Batch: 6145/37625 (16.332%), Loss: 0.9339\n",
      "Epoch: 24, Batch: 6401/37625 (17.013%), Loss: 3.4439\n",
      "Epoch: 24, Batch: 6657/37625 (17.693%), Loss: 0.6525\n",
      "Epoch: 24, Batch: 6913/37625 (18.373%), Loss: 0.7789\n",
      "Epoch: 24, Batch: 7169/37625 (19.054%), Loss: 0.5967\n",
      "Epoch: 24, Batch: 7425/37625 (19.734%), Loss: 1.5913\n",
      "Epoch: 24, Batch: 7681/37625 (20.415%), Loss: 0.4829\n",
      "Epoch: 24, Batch: 7937/37625 (21.095%), Loss: 0.8674\n",
      "Epoch: 24, Batch: 8193/37625 (21.775%), Loss: 1.0428\n",
      "Epoch: 24, Batch: 8449/37625 (22.456%), Loss: 1.0766\n",
      "Epoch: 24, Batch: 8705/37625 (23.136%), Loss: 0.6970\n",
      "Epoch: 24, Batch: 8961/37625 (23.817%), Loss: 1.3124\n",
      "Epoch: 24, Batch: 9217/37625 (24.497%), Loss: 0.7261\n",
      "Epoch: 24, Batch: 9473/37625 (25.177%), Loss: 1.2357\n",
      "Epoch: 24, Batch: 9729/37625 (25.858%), Loss: 1.5416\n",
      "Epoch: 24, Batch: 9985/37625 (26.538%), Loss: 1.4218\n",
      "Epoch: 24, Batch: 10241/37625 (27.219%), Loss: 0.5692\n",
      "Epoch: 24, Batch: 10497/37625 (27.899%), Loss: 0.5987\n",
      "Epoch: 24, Batch: 10753/37625 (28.579%), Loss: 0.7476\n",
      "Epoch: 24, Batch: 11009/37625 (29.260%), Loss: 0.6444\n",
      "Epoch: 24, Batch: 11265/37625 (29.940%), Loss: 0.7825\n",
      "Epoch: 24, Batch: 11521/37625 (30.621%), Loss: 1.2104\n",
      "Epoch: 24, Batch: 11777/37625 (31.301%), Loss: 1.7080\n",
      "Epoch: 24, Batch: 12033/37625 (31.981%), Loss: 1.4273\n",
      "Epoch: 24, Batch: 12289/37625 (32.662%), Loss: 0.9041\n",
      "Epoch: 24, Batch: 12545/37625 (33.342%), Loss: 0.6765\n",
      "Epoch: 24, Batch: 12801/37625 (34.023%), Loss: 0.6177\n",
      "Epoch: 24, Batch: 13057/37625 (34.703%), Loss: 1.6312\n",
      "Epoch: 24, Batch: 13313/37625 (35.383%), Loss: 0.8793\n",
      "Epoch: 24, Batch: 13569/37625 (36.064%), Loss: 0.8833\n",
      "Epoch: 24, Batch: 13825/37625 (36.744%), Loss: 0.9161\n",
      "Epoch: 24, Batch: 14081/37625 (37.425%), Loss: 0.8857\n",
      "Epoch: 24, Batch: 14337/37625 (38.105%), Loss: 0.7200\n",
      "Epoch: 24, Batch: 14593/37625 (38.785%), Loss: 0.8012\n",
      "Epoch: 24, Batch: 14849/37625 (39.466%), Loss: 0.8908\n",
      "Epoch: 24, Batch: 15105/37625 (40.146%), Loss: 1.5491\n",
      "Epoch: 24, Batch: 15361/37625 (40.827%), Loss: 5.7346\n",
      "Epoch: 24, Batch: 15617/37625 (41.507%), Loss: 1.3089\n",
      "Epoch: 24, Batch: 15873/37625 (42.187%), Loss: 0.8618\n",
      "Epoch: 24, Batch: 16129/37625 (42.868%), Loss: 1.2215\n",
      "Epoch: 24, Batch: 16385/37625 (43.548%), Loss: 1.1275\n",
      "Epoch: 24, Batch: 16641/37625 (44.229%), Loss: 1.0065\n",
      "Epoch: 24, Batch: 16897/37625 (44.909%), Loss: 0.5379\n",
      "Epoch: 24, Batch: 17153/37625 (45.589%), Loss: 0.7949\n",
      "Epoch: 24, Batch: 17409/37625 (46.270%), Loss: 1.0031\n",
      "Epoch: 24, Batch: 17665/37625 (46.950%), Loss: 0.8282\n",
      "Epoch: 24, Batch: 17921/37625 (47.631%), Loss: 0.7160\n",
      "Epoch: 24, Batch: 18177/37625 (48.311%), Loss: 0.7815\n",
      "Epoch: 24, Batch: 18433/37625 (48.991%), Loss: 0.8405\n",
      "Epoch: 24, Batch: 18689/37625 (49.672%), Loss: 0.9977\n",
      "Epoch: 24, Batch: 18945/37625 (50.352%), Loss: 1.4442\n",
      "Epoch: 24, Batch: 19201/37625 (51.033%), Loss: 1.2525\n",
      "Epoch: 24, Batch: 19457/37625 (51.713%), Loss: 0.9275\n",
      "Epoch: 24, Batch: 19713/37625 (52.393%), Loss: 0.5688\n",
      "Epoch: 24, Batch: 19969/37625 (53.074%), Loss: 0.5222\n",
      "Epoch: 24, Batch: 20225/37625 (53.754%), Loss: 0.7580\n",
      "Epoch: 24, Batch: 20481/37625 (54.435%), Loss: 0.9530\n",
      "Epoch: 24, Batch: 20737/37625 (55.115%), Loss: 0.9806\n",
      "Epoch: 24, Batch: 20993/37625 (55.795%), Loss: 0.6385\n",
      "Epoch: 24, Batch: 21249/37625 (56.476%), Loss: 0.7354\n",
      "Epoch: 24, Batch: 21505/37625 (57.156%), Loss: 0.9789\n",
      "Epoch: 24, Batch: 21761/37625 (57.837%), Loss: 0.7564\n",
      "Epoch: 24, Batch: 22017/37625 (58.517%), Loss: 4.8121\n",
      "Epoch: 24, Batch: 22273/37625 (59.197%), Loss: 0.8496\n",
      "Epoch: 24, Batch: 22529/37625 (59.878%), Loss: 1.0942\n",
      "Epoch: 24, Batch: 22785/37625 (60.558%), Loss: 0.6795\n",
      "Epoch: 24, Batch: 23041/37625 (61.239%), Loss: 1.1732\n",
      "Epoch: 24, Batch: 23297/37625 (61.919%), Loss: 1.0490\n",
      "Epoch: 24, Batch: 23553/37625 (62.599%), Loss: 0.9360\n",
      "Epoch: 24, Batch: 23809/37625 (63.280%), Loss: 0.5724\n",
      "Epoch: 24, Batch: 24065/37625 (63.960%), Loss: 0.5969\n",
      "Epoch: 24, Batch: 24321/37625 (64.641%), Loss: 1.8399\n",
      "Epoch: 24, Batch: 24577/37625 (65.321%), Loss: 1.0873\n",
      "Epoch: 24, Batch: 24833/37625 (66.001%), Loss: 2.0008\n",
      "Epoch: 24, Batch: 25089/37625 (66.682%), Loss: 0.9441\n",
      "Epoch: 24, Batch: 25345/37625 (67.362%), Loss: 5.5879\n",
      "Epoch: 24, Batch: 25601/37625 (68.043%), Loss: 2.4939\n",
      "Epoch: 24, Batch: 25857/37625 (68.723%), Loss: 0.7317\n",
      "Epoch: 24, Batch: 26113/37625 (69.403%), Loss: 0.5820\n",
      "Epoch: 24, Batch: 26369/37625 (70.084%), Loss: 2.5209\n",
      "Epoch: 24, Batch: 26625/37625 (70.764%), Loss: 1.2581\n",
      "Epoch: 24, Batch: 26881/37625 (71.445%), Loss: 0.5009\n",
      "Epoch: 24, Batch: 27137/37625 (72.125%), Loss: 0.7842\n",
      "Epoch: 24, Batch: 27393/37625 (72.805%), Loss: 1.3552\n",
      "Epoch: 24, Batch: 27649/37625 (73.486%), Loss: 0.6890\n",
      "Epoch: 24, Batch: 27905/37625 (74.166%), Loss: 0.7675\n",
      "Epoch: 24, Batch: 28161/37625 (74.847%), Loss: 1.0671\n",
      "Epoch: 24, Batch: 28417/37625 (75.527%), Loss: 0.9906\n",
      "Epoch: 24, Batch: 28673/37625 (76.207%), Loss: 3.3214\n",
      "Epoch: 24, Batch: 28929/37625 (76.888%), Loss: 0.9769\n",
      "Epoch: 24, Batch: 29185/37625 (77.568%), Loss: 0.9056\n",
      "Epoch: 24, Batch: 29441/37625 (78.249%), Loss: 0.8674\n",
      "Epoch: 24, Batch: 29697/37625 (78.929%), Loss: 0.6944\n",
      "Epoch: 24, Batch: 29953/37625 (79.609%), Loss: 1.6599\n",
      "Epoch: 24, Batch: 30209/37625 (80.290%), Loss: 0.8629\n",
      "Epoch: 24, Batch: 30465/37625 (80.970%), Loss: 1.6733\n",
      "Epoch: 24, Batch: 30721/37625 (81.650%), Loss: 0.7170\n",
      "Epoch: 24, Batch: 30977/37625 (82.331%), Loss: 0.9392\n",
      "Epoch: 24, Batch: 31233/37625 (83.011%), Loss: 0.7576\n",
      "Epoch: 24, Batch: 31489/37625 (83.692%), Loss: 0.7971\n",
      "Epoch: 24, Batch: 31745/37625 (84.372%), Loss: 1.1129\n",
      "Epoch: 24, Batch: 32001/37625 (85.052%), Loss: 0.6184\n",
      "Epoch: 24, Batch: 32257/37625 (85.733%), Loss: 1.6332\n",
      "Epoch: 24, Batch: 32513/37625 (86.413%), Loss: 1.7466\n",
      "Epoch: 24, Batch: 32769/37625 (87.094%), Loss: 1.0282\n",
      "Epoch: 24, Batch: 33025/37625 (87.774%), Loss: 0.9028\n",
      "Epoch: 24, Batch: 33281/37625 (88.454%), Loss: 0.8997\n",
      "Epoch: 24, Batch: 33537/37625 (89.135%), Loss: 0.8627\n",
      "Epoch: 24, Batch: 33793/37625 (89.815%), Loss: 0.9636\n",
      "Epoch: 24, Batch: 34049/37625 (90.496%), Loss: 0.7569\n",
      "Epoch: 24, Batch: 34305/37625 (91.176%), Loss: 0.9523\n",
      "Epoch: 24, Batch: 34561/37625 (91.856%), Loss: 0.8867\n",
      "Epoch: 24, Batch: 34817/37625 (92.537%), Loss: 1.2013\n",
      "Epoch: 24, Batch: 35073/37625 (93.217%), Loss: 0.5227\n",
      "Epoch: 24, Batch: 35329/37625 (93.898%), Loss: 0.6459\n",
      "Epoch: 24, Batch: 35585/37625 (94.578%), Loss: 0.6891\n",
      "Epoch: 24, Batch: 35841/37625 (95.258%), Loss: 0.7176\n",
      "Epoch: 24, Batch: 36097/37625 (95.939%), Loss: 0.9272\n",
      "Epoch: 24, Batch: 36353/37625 (96.619%), Loss: 0.8504\n",
      "Epoch: 24, Batch: 36609/37625 (97.300%), Loss: 1.7258\n",
      "Epoch: 24, Batch: 36865/37625 (97.980%), Loss: 0.6657\n",
      "Epoch: 24, Batch: 37121/37625 (98.660%), Loss: 1.0263\n",
      "Epoch: 24, Batch: 37377/37625 (99.341%), Loss: 0.8145\n",
      "Epoch: 25, Batch: 1/37625 (0.003%), Loss: 0.7576\n",
      "Epoch: 25, Batch: 257/37625 (0.683%), Loss: 1.1136\n",
      "Epoch: 25, Batch: 513/37625 (1.363%), Loss: 1.6824\n",
      "Epoch: 25, Batch: 769/37625 (2.044%), Loss: 0.8525\n",
      "Epoch: 25, Batch: 1025/37625 (2.724%), Loss: 1.1287\n",
      "Epoch: 25, Batch: 1281/37625 (3.405%), Loss: 1.1038\n",
      "Epoch: 25, Batch: 1537/37625 (4.085%), Loss: 1.3581\n",
      "Epoch: 25, Batch: 1793/37625 (4.765%), Loss: 0.9386\n",
      "Epoch: 25, Batch: 2049/37625 (5.446%), Loss: 0.8175\n",
      "Epoch: 25, Batch: 2305/37625 (6.126%), Loss: 0.7166\n",
      "Epoch: 25, Batch: 2561/37625 (6.807%), Loss: 2.5614\n",
      "Epoch: 25, Batch: 2817/37625 (7.487%), Loss: 0.6754\n",
      "Epoch: 25, Batch: 3073/37625 (8.167%), Loss: 1.1443\n",
      "Epoch: 25, Batch: 3329/37625 (8.848%), Loss: 0.7062\n",
      "Epoch: 25, Batch: 3585/37625 (9.528%), Loss: 1.2086\n",
      "Epoch: 25, Batch: 3841/37625 (10.209%), Loss: 0.8644\n",
      "Epoch: 25, Batch: 4097/37625 (10.889%), Loss: 0.9000\n",
      "Epoch: 25, Batch: 4353/37625 (11.569%), Loss: 1.2067\n",
      "Epoch: 25, Batch: 4609/37625 (12.250%), Loss: 1.0517\n",
      "Epoch: 25, Batch: 4865/37625 (12.930%), Loss: 0.7861\n",
      "Epoch: 25, Batch: 5121/37625 (13.611%), Loss: 0.8090\n",
      "Epoch: 25, Batch: 5377/37625 (14.291%), Loss: 1.0091\n",
      "Epoch: 25, Batch: 5633/37625 (14.971%), Loss: 0.7980\n",
      "Epoch: 25, Batch: 5889/37625 (15.652%), Loss: 4.7636\n",
      "Epoch: 25, Batch: 6145/37625 (16.332%), Loss: 0.7631\n",
      "Epoch: 25, Batch: 6401/37625 (17.013%), Loss: 0.8519\n",
      "Epoch: 25, Batch: 6657/37625 (17.693%), Loss: 0.6686\n",
      "Epoch: 25, Batch: 6913/37625 (18.373%), Loss: 0.7783\n",
      "Epoch: 25, Batch: 7169/37625 (19.054%), Loss: 1.0009\n",
      "Epoch: 25, Batch: 7425/37625 (19.734%), Loss: 1.1640\n",
      "Epoch: 25, Batch: 7681/37625 (20.415%), Loss: 1.7856\n",
      "Epoch: 25, Batch: 7937/37625 (21.095%), Loss: 1.1776\n",
      "Epoch: 25, Batch: 8193/37625 (21.775%), Loss: 1.6600\n",
      "Epoch: 25, Batch: 8449/37625 (22.456%), Loss: 1.8576\n",
      "Epoch: 25, Batch: 8705/37625 (23.136%), Loss: 0.5460\n",
      "Epoch: 25, Batch: 8961/37625 (23.817%), Loss: 0.5753\n",
      "Epoch: 25, Batch: 9217/37625 (24.497%), Loss: 0.8863\n",
      "Epoch: 25, Batch: 9473/37625 (25.177%), Loss: 0.9413\n",
      "Epoch: 25, Batch: 9729/37625 (25.858%), Loss: 0.6371\n",
      "Epoch: 25, Batch: 9985/37625 (26.538%), Loss: 0.9596\n",
      "Epoch: 25, Batch: 10241/37625 (27.219%), Loss: 1.8389\n",
      "Epoch: 25, Batch: 10497/37625 (27.899%), Loss: 1.3008\n",
      "Epoch: 25, Batch: 10753/37625 (28.579%), Loss: 1.3292\n",
      "Epoch: 25, Batch: 11009/37625 (29.260%), Loss: 0.6249\n",
      "Epoch: 25, Batch: 11265/37625 (29.940%), Loss: 0.9524\n",
      "Epoch: 25, Batch: 11521/37625 (30.621%), Loss: 1.1598\n",
      "Epoch: 25, Batch: 11777/37625 (31.301%), Loss: 1.3827\n",
      "Epoch: 25, Batch: 12033/37625 (31.981%), Loss: 0.7887\n",
      "Epoch: 25, Batch: 12289/37625 (32.662%), Loss: 0.8261\n",
      "Epoch: 25, Batch: 12545/37625 (33.342%), Loss: 0.9921\n",
      "Epoch: 25, Batch: 12801/37625 (34.023%), Loss: 3.7854\n",
      "Epoch: 25, Batch: 13057/37625 (34.703%), Loss: 0.9970\n",
      "Epoch: 25, Batch: 13313/37625 (35.383%), Loss: 0.6839\n",
      "Epoch: 25, Batch: 13569/37625 (36.064%), Loss: 1.0335\n",
      "Epoch: 25, Batch: 13825/37625 (36.744%), Loss: 0.9400\n",
      "Epoch: 25, Batch: 14081/37625 (37.425%), Loss: 1.0801\n",
      "Epoch: 25, Batch: 14337/37625 (38.105%), Loss: 1.0237\n",
      "Epoch: 25, Batch: 14593/37625 (38.785%), Loss: 0.8031\n",
      "Epoch: 25, Batch: 14849/37625 (39.466%), Loss: 0.7216\n",
      "Epoch: 25, Batch: 15105/37625 (40.146%), Loss: 0.7112\n",
      "Epoch: 25, Batch: 15361/37625 (40.827%), Loss: 1.4371\n",
      "Epoch: 25, Batch: 15617/37625 (41.507%), Loss: 1.1914\n",
      "Epoch: 25, Batch: 15873/37625 (42.187%), Loss: 1.0283\n",
      "Epoch: 25, Batch: 16129/37625 (42.868%), Loss: 0.9181\n",
      "Epoch: 25, Batch: 16385/37625 (43.548%), Loss: 0.7345\n",
      "Epoch: 25, Batch: 16641/37625 (44.229%), Loss: 0.8622\n",
      "Epoch: 25, Batch: 16897/37625 (44.909%), Loss: 0.5836\n",
      "Epoch: 25, Batch: 17153/37625 (45.589%), Loss: 0.8829\n",
      "Epoch: 25, Batch: 17409/37625 (46.270%), Loss: 1.2242\n",
      "Epoch: 25, Batch: 17665/37625 (46.950%), Loss: 0.5288\n",
      "Epoch: 25, Batch: 17921/37625 (47.631%), Loss: 0.6379\n",
      "Epoch: 25, Batch: 18177/37625 (48.311%), Loss: 1.0305\n",
      "Epoch: 25, Batch: 18433/37625 (48.991%), Loss: 0.7565\n",
      "Epoch: 25, Batch: 18689/37625 (49.672%), Loss: 0.6902\n",
      "Epoch: 25, Batch: 18945/37625 (50.352%), Loss: 0.5478\n",
      "Epoch: 25, Batch: 19201/37625 (51.033%), Loss: 0.8453\n",
      "Epoch: 25, Batch: 19457/37625 (51.713%), Loss: 5.9484\n",
      "Epoch: 25, Batch: 19713/37625 (52.393%), Loss: 0.6788\n",
      "Epoch: 25, Batch: 19969/37625 (53.074%), Loss: 1.2260\n",
      "Epoch: 25, Batch: 20225/37625 (53.754%), Loss: 0.7364\n",
      "Epoch: 25, Batch: 20481/37625 (54.435%), Loss: 1.9485\n",
      "Epoch: 25, Batch: 20737/37625 (55.115%), Loss: 1.3002\n",
      "Epoch: 25, Batch: 20993/37625 (55.795%), Loss: 0.6501\n",
      "Epoch: 25, Batch: 21249/37625 (56.476%), Loss: 0.7865\n",
      "Epoch: 25, Batch: 21505/37625 (57.156%), Loss: 0.9643\n",
      "Epoch: 25, Batch: 21761/37625 (57.837%), Loss: 0.8716\n",
      "Epoch: 25, Batch: 22017/37625 (58.517%), Loss: 5.1819\n",
      "Epoch: 25, Batch: 22273/37625 (59.197%), Loss: 1.5362\n",
      "Epoch: 25, Batch: 22529/37625 (59.878%), Loss: 0.6427\n",
      "Epoch: 25, Batch: 22785/37625 (60.558%), Loss: 5.5625\n",
      "Epoch: 25, Batch: 23041/37625 (61.239%), Loss: 0.8137\n",
      "Epoch: 25, Batch: 23297/37625 (61.919%), Loss: 1.4092\n",
      "Epoch: 25, Batch: 23553/37625 (62.599%), Loss: 0.9982\n",
      "Epoch: 25, Batch: 23809/37625 (63.280%), Loss: 1.0007\n",
      "Epoch: 25, Batch: 24065/37625 (63.960%), Loss: 0.5106\n",
      "Epoch: 25, Batch: 24321/37625 (64.641%), Loss: 0.5695\n",
      "Epoch: 25, Batch: 24577/37625 (65.321%), Loss: 0.6330\n",
      "Epoch: 25, Batch: 24833/37625 (66.001%), Loss: 1.0456\n",
      "Epoch: 25, Batch: 25089/37625 (66.682%), Loss: 0.7939\n",
      "Epoch: 25, Batch: 25345/37625 (67.362%), Loss: 1.3065\n",
      "Epoch: 25, Batch: 25601/37625 (68.043%), Loss: 0.6561\n",
      "Epoch: 25, Batch: 25857/37625 (68.723%), Loss: 1.3397\n",
      "Epoch: 25, Batch: 26113/37625 (69.403%), Loss: 0.7488\n",
      "Epoch: 25, Batch: 26369/37625 (70.084%), Loss: 0.7512\n",
      "Epoch: 25, Batch: 26625/37625 (70.764%), Loss: 0.6665\n",
      "Epoch: 25, Batch: 26881/37625 (71.445%), Loss: 1.0268\n",
      "Epoch: 25, Batch: 27137/37625 (72.125%), Loss: 0.6960\n",
      "Epoch: 25, Batch: 27393/37625 (72.805%), Loss: 1.2363\n",
      "Epoch: 25, Batch: 27649/37625 (73.486%), Loss: 0.4894\n",
      "Epoch: 25, Batch: 27905/37625 (74.166%), Loss: 0.8919\n",
      "Epoch: 25, Batch: 28161/37625 (74.847%), Loss: 0.9537\n",
      "Epoch: 25, Batch: 28417/37625 (75.527%), Loss: 0.8117\n",
      "Epoch: 25, Batch: 28673/37625 (76.207%), Loss: 0.8809\n",
      "Epoch: 25, Batch: 28929/37625 (76.888%), Loss: 0.7067\n",
      "Epoch: 25, Batch: 29185/37625 (77.568%), Loss: 0.7770\n",
      "Epoch: 25, Batch: 29441/37625 (78.249%), Loss: 0.7706\n",
      "Epoch: 25, Batch: 29697/37625 (78.929%), Loss: 0.9698\n",
      "Epoch: 25, Batch: 29953/37625 (79.609%), Loss: 1.9172\n",
      "Epoch: 25, Batch: 30209/37625 (80.290%), Loss: 1.1009\n",
      "Epoch: 25, Batch: 30465/37625 (80.970%), Loss: 0.8156\n",
      "Epoch: 25, Batch: 30721/37625 (81.650%), Loss: 1.0424\n",
      "Epoch: 25, Batch: 30977/37625 (82.331%), Loss: 0.7173\n",
      "Epoch: 25, Batch: 31233/37625 (83.011%), Loss: 0.8327\n",
      "Epoch: 25, Batch: 31489/37625 (83.692%), Loss: 0.5608\n",
      "Epoch: 25, Batch: 31745/37625 (84.372%), Loss: 1.6742\n",
      "Epoch: 25, Batch: 32001/37625 (85.052%), Loss: 1.1494\n",
      "Epoch: 25, Batch: 32257/37625 (85.733%), Loss: 0.7785\n",
      "Epoch: 25, Batch: 32513/37625 (86.413%), Loss: 0.6730\n",
      "Epoch: 25, Batch: 32769/37625 (87.094%), Loss: 0.8170\n",
      "Epoch: 25, Batch: 33025/37625 (87.774%), Loss: 0.7984\n",
      "Epoch: 25, Batch: 33281/37625 (88.454%), Loss: 2.3132\n",
      "Epoch: 25, Batch: 33537/37625 (89.135%), Loss: 1.1042\n",
      "Epoch: 25, Batch: 33793/37625 (89.815%), Loss: 0.9524\n",
      "Epoch: 25, Batch: 34049/37625 (90.496%), Loss: 0.9268\n",
      "Epoch: 25, Batch: 34305/37625 (91.176%), Loss: 1.0973\n",
      "Epoch: 25, Batch: 34561/37625 (91.856%), Loss: 0.7337\n",
      "Epoch: 25, Batch: 34817/37625 (92.537%), Loss: 1.0676\n",
      "Epoch: 25, Batch: 35073/37625 (93.217%), Loss: 0.6460\n",
      "Epoch: 25, Batch: 35329/37625 (93.898%), Loss: 0.8852\n",
      "Epoch: 25, Batch: 35585/37625 (94.578%), Loss: 1.1223\n",
      "Epoch: 25, Batch: 35841/37625 (95.258%), Loss: 0.5790\n",
      "Epoch: 25, Batch: 36097/37625 (95.939%), Loss: 0.8446\n",
      "Epoch: 25, Batch: 36353/37625 (96.619%), Loss: 1.2497\n",
      "Epoch: 25, Batch: 36609/37625 (97.300%), Loss: 1.0280\n",
      "Epoch: 25, Batch: 36865/37625 (97.980%), Loss: 0.7817\n",
      "Epoch: 25, Batch: 37121/37625 (98.660%), Loss: 1.1720\n",
      "Epoch: 25, Batch: 37377/37625 (99.341%), Loss: 0.8152\n",
      "Epoch: 26, Batch: 1/37625 (0.003%), Loss: 1.2107\n",
      "Epoch: 26, Batch: 257/37625 (0.683%), Loss: 0.6530\n",
      "Epoch: 26, Batch: 513/37625 (1.363%), Loss: 5.2738\n",
      "Epoch: 26, Batch: 769/37625 (2.044%), Loss: 0.9167\n",
      "Epoch: 26, Batch: 1025/37625 (2.724%), Loss: 1.3800\n",
      "Epoch: 26, Batch: 1281/37625 (3.405%), Loss: 2.3801\n",
      "Epoch: 26, Batch: 1537/37625 (4.085%), Loss: 0.9049\n",
      "Epoch: 26, Batch: 1793/37625 (4.765%), Loss: 0.7329\n",
      "Epoch: 26, Batch: 2049/37625 (5.446%), Loss: 1.1318\n",
      "Epoch: 26, Batch: 2305/37625 (6.126%), Loss: 0.9050\n",
      "Epoch: 26, Batch: 2561/37625 (6.807%), Loss: 1.1737\n",
      "Epoch: 26, Batch: 2817/37625 (7.487%), Loss: 0.7514\n",
      "Epoch: 26, Batch: 3073/37625 (8.167%), Loss: 0.6563\n",
      "Epoch: 26, Batch: 3329/37625 (8.848%), Loss: 0.9428\n",
      "Epoch: 26, Batch: 3585/37625 (9.528%), Loss: 1.0507\n",
      "Epoch: 26, Batch: 3841/37625 (10.209%), Loss: 0.7289\n",
      "Epoch: 26, Batch: 4097/37625 (10.889%), Loss: 1.5347\n",
      "Epoch: 26, Batch: 4353/37625 (11.569%), Loss: 0.9296\n",
      "Epoch: 26, Batch: 4609/37625 (12.250%), Loss: 0.5675\n",
      "Epoch: 26, Batch: 4865/37625 (12.930%), Loss: 1.1387\n",
      "Epoch: 26, Batch: 5121/37625 (13.611%), Loss: 0.8651\n",
      "Epoch: 26, Batch: 5377/37625 (14.291%), Loss: 0.8127\n",
      "Epoch: 26, Batch: 5633/37625 (14.971%), Loss: 1.2196\n",
      "Epoch: 26, Batch: 5889/37625 (15.652%), Loss: 0.9411\n",
      "Epoch: 26, Batch: 6145/37625 (16.332%), Loss: 1.1254\n",
      "Epoch: 26, Batch: 6401/37625 (17.013%), Loss: 0.8179\n",
      "Epoch: 26, Batch: 6657/37625 (17.693%), Loss: 0.5383\n",
      "Epoch: 26, Batch: 6913/37625 (18.373%), Loss: 0.7825\n",
      "Epoch: 26, Batch: 7169/37625 (19.054%), Loss: 2.2672\n",
      "Epoch: 26, Batch: 7425/37625 (19.734%), Loss: 0.8399\n",
      "Epoch: 26, Batch: 7681/37625 (20.415%), Loss: 0.7978\n",
      "Epoch: 26, Batch: 7937/37625 (21.095%), Loss: 1.2749\n",
      "Epoch: 26, Batch: 8193/37625 (21.775%), Loss: 0.6599\n",
      "Epoch: 26, Batch: 8449/37625 (22.456%), Loss: 0.7986\n",
      "Epoch: 26, Batch: 8705/37625 (23.136%), Loss: 0.7243\n",
      "Epoch: 26, Batch: 8961/37625 (23.817%), Loss: 0.5012\n",
      "Epoch: 26, Batch: 9217/37625 (24.497%), Loss: 1.1799\n",
      "Epoch: 26, Batch: 9473/37625 (25.177%), Loss: 0.5631\n",
      "Epoch: 26, Batch: 9729/37625 (25.858%), Loss: 0.8235\n",
      "Epoch: 26, Batch: 9985/37625 (26.538%), Loss: 1.0978\n",
      "Epoch: 26, Batch: 10241/37625 (27.219%), Loss: 0.6663\n",
      "Epoch: 26, Batch: 10497/37625 (27.899%), Loss: 0.8758\n",
      "Epoch: 26, Batch: 10753/37625 (28.579%), Loss: 0.9211\n",
      "Epoch: 26, Batch: 11009/37625 (29.260%), Loss: 1.0958\n",
      "Epoch: 26, Batch: 11265/37625 (29.940%), Loss: 0.7591\n",
      "Epoch: 26, Batch: 11521/37625 (30.621%), Loss: 0.9572\n",
      "Epoch: 26, Batch: 11777/37625 (31.301%), Loss: 1.0345\n",
      "Epoch: 26, Batch: 12033/37625 (31.981%), Loss: 0.6489\n",
      "Epoch: 26, Batch: 12289/37625 (32.662%), Loss: 0.9944\n",
      "Epoch: 26, Batch: 12545/37625 (33.342%), Loss: 1.0700\n",
      "Epoch: 26, Batch: 12801/37625 (34.023%), Loss: 1.0083\n",
      "Epoch: 26, Batch: 13057/37625 (34.703%), Loss: 1.0763\n",
      "Epoch: 26, Batch: 13313/37625 (35.383%), Loss: 0.6847\n",
      "Epoch: 26, Batch: 13569/37625 (36.064%), Loss: 1.5375\n",
      "Epoch: 26, Batch: 13825/37625 (36.744%), Loss: 1.0477\n",
      "Epoch: 26, Batch: 14081/37625 (37.425%), Loss: 0.9710\n",
      "Epoch: 26, Batch: 14337/37625 (38.105%), Loss: 1.9172\n",
      "Epoch: 26, Batch: 14593/37625 (38.785%), Loss: 1.2875\n",
      "Epoch: 26, Batch: 14849/37625 (39.466%), Loss: 0.8805\n",
      "Epoch: 26, Batch: 15105/37625 (40.146%), Loss: 0.6774\n",
      "Epoch: 26, Batch: 15361/37625 (40.827%), Loss: 0.8183\n",
      "Epoch: 26, Batch: 15617/37625 (41.507%), Loss: 0.8059\n",
      "Epoch: 26, Batch: 15873/37625 (42.187%), Loss: 0.7122\n",
      "Epoch: 26, Batch: 16129/37625 (42.868%), Loss: 1.9598\n",
      "Epoch: 26, Batch: 16385/37625 (43.548%), Loss: 0.8988\n",
      "Epoch: 26, Batch: 16641/37625 (44.229%), Loss: 0.6162\n",
      "Epoch: 26, Batch: 16897/37625 (44.909%), Loss: 1.3532\n",
      "Epoch: 26, Batch: 17153/37625 (45.589%), Loss: 0.6075\n",
      "Epoch: 26, Batch: 17409/37625 (46.270%), Loss: 1.7349\n",
      "Epoch: 26, Batch: 17665/37625 (46.950%), Loss: 1.0202\n",
      "Epoch: 26, Batch: 17921/37625 (47.631%), Loss: 1.3211\n",
      "Epoch: 26, Batch: 18177/37625 (48.311%), Loss: 1.1006\n",
      "Epoch: 26, Batch: 18433/37625 (48.991%), Loss: 1.0146\n",
      "Epoch: 26, Batch: 18689/37625 (49.672%), Loss: 0.8825\n",
      "Epoch: 26, Batch: 18945/37625 (50.352%), Loss: 1.0136\n",
      "Epoch: 26, Batch: 19201/37625 (51.033%), Loss: 1.3549\n",
      "Epoch: 26, Batch: 19457/37625 (51.713%), Loss: 1.1399\n",
      "Epoch: 26, Batch: 19713/37625 (52.393%), Loss: 0.8877\n",
      "Epoch: 26, Batch: 19969/37625 (53.074%), Loss: 0.8520\n",
      "Epoch: 26, Batch: 20225/37625 (53.754%), Loss: 0.9696\n",
      "Epoch: 26, Batch: 20481/37625 (54.435%), Loss: 0.7622\n",
      "Epoch: 26, Batch: 20737/37625 (55.115%), Loss: 1.1438\n",
      "Epoch: 26, Batch: 20993/37625 (55.795%), Loss: 1.0662\n",
      "Epoch: 26, Batch: 21249/37625 (56.476%), Loss: 5.4225\n",
      "Epoch: 26, Batch: 21505/37625 (57.156%), Loss: 0.7984\n",
      "Epoch: 26, Batch: 21761/37625 (57.837%), Loss: 0.5433\n",
      "Epoch: 26, Batch: 22017/37625 (58.517%), Loss: 2.2393\n",
      "Epoch: 26, Batch: 22273/37625 (59.197%), Loss: 0.6104\n",
      "Epoch: 26, Batch: 22529/37625 (59.878%), Loss: 0.7252\n",
      "Epoch: 26, Batch: 22785/37625 (60.558%), Loss: 0.6636\n",
      "Epoch: 26, Batch: 23041/37625 (61.239%), Loss: 4.6257\n",
      "Epoch: 26, Batch: 23297/37625 (61.919%), Loss: 3.9867\n",
      "Epoch: 26, Batch: 23553/37625 (62.599%), Loss: 0.7471\n",
      "Epoch: 26, Batch: 23809/37625 (63.280%), Loss: 1.6387\n",
      "Epoch: 26, Batch: 24065/37625 (63.960%), Loss: 1.4700\n",
      "Epoch: 26, Batch: 24321/37625 (64.641%), Loss: 0.6396\n",
      "Epoch: 26, Batch: 24577/37625 (65.321%), Loss: 0.9080\n",
      "Epoch: 26, Batch: 24833/37625 (66.001%), Loss: 0.8816\n",
      "Epoch: 26, Batch: 25089/37625 (66.682%), Loss: 0.7601\n",
      "Epoch: 26, Batch: 25345/37625 (67.362%), Loss: 0.6264\n",
      "Epoch: 26, Batch: 25601/37625 (68.043%), Loss: 1.1615\n",
      "Epoch: 26, Batch: 25857/37625 (68.723%), Loss: 1.6384\n",
      "Epoch: 26, Batch: 26113/37625 (69.403%), Loss: 0.9291\n",
      "Epoch: 26, Batch: 26369/37625 (70.084%), Loss: 0.9082\n",
      "Epoch: 26, Batch: 26625/37625 (70.764%), Loss: 0.7263\n",
      "Epoch: 26, Batch: 26881/37625 (71.445%), Loss: 1.1019\n",
      "Epoch: 26, Batch: 27137/37625 (72.125%), Loss: 1.3201\n",
      "Epoch: 26, Batch: 27393/37625 (72.805%), Loss: 1.1491\n",
      "Epoch: 26, Batch: 27649/37625 (73.486%), Loss: 1.0702\n",
      "Epoch: 26, Batch: 27905/37625 (74.166%), Loss: 0.5916\n",
      "Epoch: 26, Batch: 28161/37625 (74.847%), Loss: 2.0433\n",
      "Epoch: 26, Batch: 28417/37625 (75.527%), Loss: 0.6604\n",
      "Epoch: 26, Batch: 28673/37625 (76.207%), Loss: 1.2725\n",
      "Epoch: 26, Batch: 28929/37625 (76.888%), Loss: 1.5312\n",
      "Epoch: 26, Batch: 29185/37625 (77.568%), Loss: 0.6760\n",
      "Epoch: 26, Batch: 29441/37625 (78.249%), Loss: 0.8543\n",
      "Epoch: 26, Batch: 29697/37625 (78.929%), Loss: 1.0818\n",
      "Epoch: 26, Batch: 29953/37625 (79.609%), Loss: 0.7594\n",
      "Epoch: 26, Batch: 30209/37625 (80.290%), Loss: 1.1063\n",
      "Epoch: 26, Batch: 30465/37625 (80.970%), Loss: 0.7181\n",
      "Epoch: 26, Batch: 30721/37625 (81.650%), Loss: 0.9958\n",
      "Epoch: 26, Batch: 30977/37625 (82.331%), Loss: 0.8302\n",
      "Epoch: 26, Batch: 31233/37625 (83.011%), Loss: 0.5746\n",
      "Epoch: 26, Batch: 31489/37625 (83.692%), Loss: 0.6917\n",
      "Epoch: 26, Batch: 31745/37625 (84.372%), Loss: 0.5681\n",
      "Epoch: 26, Batch: 32001/37625 (85.052%), Loss: 1.5584\n",
      "Epoch: 26, Batch: 32257/37625 (85.733%), Loss: 0.7669\n",
      "Epoch: 26, Batch: 32513/37625 (86.413%), Loss: 0.9965\n",
      "Epoch: 26, Batch: 32769/37625 (87.094%), Loss: 3.3847\n",
      "Epoch: 26, Batch: 33025/37625 (87.774%), Loss: 0.7338\n",
      "Epoch: 26, Batch: 33281/37625 (88.454%), Loss: 0.8901\n",
      "Epoch: 26, Batch: 33537/37625 (89.135%), Loss: 0.7887\n",
      "Epoch: 26, Batch: 33793/37625 (89.815%), Loss: 0.7035\n",
      "Epoch: 26, Batch: 34049/37625 (90.496%), Loss: 0.7215\n",
      "Epoch: 26, Batch: 34305/37625 (91.176%), Loss: 0.9335\n",
      "Epoch: 26, Batch: 34561/37625 (91.856%), Loss: 0.6408\n",
      "Epoch: 26, Batch: 34817/37625 (92.537%), Loss: 1.7491\n",
      "Epoch: 26, Batch: 35073/37625 (93.217%), Loss: 1.3791\n",
      "Epoch: 26, Batch: 35329/37625 (93.898%), Loss: 0.6991\n",
      "Epoch: 26, Batch: 35585/37625 (94.578%), Loss: 2.3437\n",
      "Epoch: 26, Batch: 35841/37625 (95.258%), Loss: 0.7275\n",
      "Epoch: 26, Batch: 36097/37625 (95.939%), Loss: 0.5386\n",
      "Epoch: 26, Batch: 36353/37625 (96.619%), Loss: 0.6834\n",
      "Epoch: 26, Batch: 36609/37625 (97.300%), Loss: 0.5779\n",
      "Epoch: 26, Batch: 36865/37625 (97.980%), Loss: 1.6363\n",
      "Epoch: 26, Batch: 37121/37625 (98.660%), Loss: 0.4954\n",
      "Epoch: 26, Batch: 37377/37625 (99.341%), Loss: 0.8304\n",
      "Epoch: 27, Batch: 1/37625 (0.003%), Loss: 0.6580\n",
      "Epoch: 27, Batch: 257/37625 (0.683%), Loss: 1.0567\n",
      "Epoch: 27, Batch: 513/37625 (1.363%), Loss: 0.9864\n",
      "Epoch: 27, Batch: 769/37625 (2.044%), Loss: 1.0977\n",
      "Epoch: 27, Batch: 1025/37625 (2.724%), Loss: 1.0846\n",
      "Epoch: 27, Batch: 1281/37625 (3.405%), Loss: 0.6150\n",
      "Epoch: 27, Batch: 1537/37625 (4.085%), Loss: 0.8275\n",
      "Epoch: 27, Batch: 1793/37625 (4.765%), Loss: 1.7364\n",
      "Epoch: 27, Batch: 2049/37625 (5.446%), Loss: 0.8686\n",
      "Epoch: 27, Batch: 2305/37625 (6.126%), Loss: 4.9387\n",
      "Epoch: 27, Batch: 2561/37625 (6.807%), Loss: 1.4777\n",
      "Epoch: 27, Batch: 2817/37625 (7.487%), Loss: 0.6547\n",
      "Epoch: 27, Batch: 3073/37625 (8.167%), Loss: 1.1933\n",
      "Epoch: 27, Batch: 3329/37625 (8.848%), Loss: 0.6838\n",
      "Epoch: 27, Batch: 3585/37625 (9.528%), Loss: 0.6708\n",
      "Epoch: 27, Batch: 3841/37625 (10.209%), Loss: 1.4705\n",
      "Epoch: 27, Batch: 4097/37625 (10.889%), Loss: 0.7080\n",
      "Epoch: 27, Batch: 4353/37625 (11.569%), Loss: 0.8491\n",
      "Epoch: 27, Batch: 4609/37625 (12.250%), Loss: 0.5997\n",
      "Epoch: 27, Batch: 4865/37625 (12.930%), Loss: 1.0738\n",
      "Epoch: 27, Batch: 5121/37625 (13.611%), Loss: 0.9725\n",
      "Epoch: 27, Batch: 5377/37625 (14.291%), Loss: 0.8119\n",
      "Epoch: 27, Batch: 5633/37625 (14.971%), Loss: 0.7382\n",
      "Epoch: 27, Batch: 5889/37625 (15.652%), Loss: 1.1784\n",
      "Epoch: 27, Batch: 6145/37625 (16.332%), Loss: 0.9343\n",
      "Epoch: 27, Batch: 6401/37625 (17.013%), Loss: 0.7219\n",
      "Epoch: 27, Batch: 6657/37625 (17.693%), Loss: 0.8352\n",
      "Epoch: 27, Batch: 6913/37625 (18.373%), Loss: 0.8726\n",
      "Epoch: 27, Batch: 7169/37625 (19.054%), Loss: 0.9057\n",
      "Epoch: 27, Batch: 7425/37625 (19.734%), Loss: 1.0080\n",
      "Epoch: 27, Batch: 7681/37625 (20.415%), Loss: 1.2319\n",
      "Epoch: 27, Batch: 7937/37625 (21.095%), Loss: 1.2505\n",
      "Epoch: 27, Batch: 8193/37625 (21.775%), Loss: 0.7615\n",
      "Epoch: 27, Batch: 8449/37625 (22.456%), Loss: 0.6680\n",
      "Epoch: 27, Batch: 8705/37625 (23.136%), Loss: 0.9701\n",
      "Epoch: 27, Batch: 8961/37625 (23.817%), Loss: 0.8713\n",
      "Epoch: 27, Batch: 9217/37625 (24.497%), Loss: 1.0604\n",
      "Epoch: 27, Batch: 9473/37625 (25.177%), Loss: 1.2370\n",
      "Epoch: 27, Batch: 9729/37625 (25.858%), Loss: 0.5845\n",
      "Epoch: 27, Batch: 9985/37625 (26.538%), Loss: 0.4657\n",
      "Epoch: 27, Batch: 10241/37625 (27.219%), Loss: 0.6590\n",
      "Epoch: 27, Batch: 10497/37625 (27.899%), Loss: 0.7490\n",
      "Epoch: 27, Batch: 10753/37625 (28.579%), Loss: 1.0642\n",
      "Epoch: 27, Batch: 11009/37625 (29.260%), Loss: 0.7181\n",
      "Epoch: 27, Batch: 11265/37625 (29.940%), Loss: 1.5963\n",
      "Epoch: 27, Batch: 11521/37625 (30.621%), Loss: 1.4193\n",
      "Epoch: 27, Batch: 11777/37625 (31.301%), Loss: 0.6373\n",
      "Epoch: 27, Batch: 12033/37625 (31.981%), Loss: 0.7438\n",
      "Epoch: 27, Batch: 12289/37625 (32.662%), Loss: 4.5838\n",
      "Epoch: 27, Batch: 12545/37625 (33.342%), Loss: 3.6161\n",
      "Epoch: 27, Batch: 12801/37625 (34.023%), Loss: 0.7818\n",
      "Epoch: 27, Batch: 13057/37625 (34.703%), Loss: 1.2827\n",
      "Epoch: 27, Batch: 13313/37625 (35.383%), Loss: 0.7160\n",
      "Epoch: 27, Batch: 13569/37625 (36.064%), Loss: 1.2793\n",
      "Epoch: 27, Batch: 13825/37625 (36.744%), Loss: 1.1842\n",
      "Epoch: 27, Batch: 14081/37625 (37.425%), Loss: 2.4499\n",
      "Epoch: 27, Batch: 14337/37625 (38.105%), Loss: 0.6323\n",
      "Epoch: 27, Batch: 14593/37625 (38.785%), Loss: 1.1207\n",
      "Epoch: 27, Batch: 14849/37625 (39.466%), Loss: 0.7510\n",
      "Epoch: 27, Batch: 15105/37625 (40.146%), Loss: 1.9478\n",
      "Epoch: 27, Batch: 15361/37625 (40.827%), Loss: 0.8080\n",
      "Epoch: 27, Batch: 15617/37625 (41.507%), Loss: 1.4588\n",
      "Epoch: 27, Batch: 15873/37625 (42.187%), Loss: 0.6948\n",
      "Epoch: 27, Batch: 16129/37625 (42.868%), Loss: 0.6712\n",
      "Epoch: 27, Batch: 16385/37625 (43.548%), Loss: 1.6333\n",
      "Epoch: 27, Batch: 16641/37625 (44.229%), Loss: 0.8329\n",
      "Epoch: 27, Batch: 16897/37625 (44.909%), Loss: 0.8275\n",
      "Epoch: 27, Batch: 17153/37625 (45.589%), Loss: 0.9251\n",
      "Epoch: 27, Batch: 17409/37625 (46.270%), Loss: 1.1877\n",
      "Epoch: 27, Batch: 17665/37625 (46.950%), Loss: 0.6685\n",
      "Epoch: 27, Batch: 17921/37625 (47.631%), Loss: 0.8586\n",
      "Epoch: 27, Batch: 18177/37625 (48.311%), Loss: 0.7832\n",
      "Epoch: 27, Batch: 18433/37625 (48.991%), Loss: 1.2472\n",
      "Epoch: 27, Batch: 18689/37625 (49.672%), Loss: 1.0061\n",
      "Epoch: 27, Batch: 18945/37625 (50.352%), Loss: 0.6881\n",
      "Epoch: 27, Batch: 19201/37625 (51.033%), Loss: 1.1449\n",
      "Epoch: 27, Batch: 19457/37625 (51.713%), Loss: 0.8568\n",
      "Epoch: 27, Batch: 19713/37625 (52.393%), Loss: 1.6050\n",
      "Epoch: 27, Batch: 19969/37625 (53.074%), Loss: 1.2715\n",
      "Epoch: 27, Batch: 20225/37625 (53.754%), Loss: 1.1687\n",
      "Epoch: 27, Batch: 20481/37625 (54.435%), Loss: 0.5733\n",
      "Epoch: 27, Batch: 20737/37625 (55.115%), Loss: 1.2589\n",
      "Epoch: 27, Batch: 20993/37625 (55.795%), Loss: 1.0170\n",
      "Epoch: 27, Batch: 21249/37625 (56.476%), Loss: 0.5947\n",
      "Epoch: 27, Batch: 21505/37625 (57.156%), Loss: 1.8193\n",
      "Epoch: 27, Batch: 21761/37625 (57.837%), Loss: 0.7887\n",
      "Epoch: 27, Batch: 22017/37625 (58.517%), Loss: 0.5418\n",
      "Epoch: 27, Batch: 22273/37625 (59.197%), Loss: 0.8153\n",
      "Epoch: 27, Batch: 22529/37625 (59.878%), Loss: 1.4679\n",
      "Epoch: 27, Batch: 22785/37625 (60.558%), Loss: 1.7654\n",
      "Epoch: 27, Batch: 23041/37625 (61.239%), Loss: 1.1208\n",
      "Epoch: 27, Batch: 23297/37625 (61.919%), Loss: 0.6831\n",
      "Epoch: 27, Batch: 23553/37625 (62.599%), Loss: 1.0866\n",
      "Epoch: 27, Batch: 23809/37625 (63.280%), Loss: 6.0404\n",
      "Epoch: 27, Batch: 24065/37625 (63.960%), Loss: 0.8845\n",
      "Epoch: 27, Batch: 24321/37625 (64.641%), Loss: 1.1893\n",
      "Epoch: 27, Batch: 24577/37625 (65.321%), Loss: 0.7834\n",
      "Epoch: 27, Batch: 24833/37625 (66.001%), Loss: 0.8370\n",
      "Epoch: 27, Batch: 25089/37625 (66.682%), Loss: 1.1070\n",
      "Epoch: 27, Batch: 25345/37625 (67.362%), Loss: 0.8049\n",
      "Epoch: 27, Batch: 25601/37625 (68.043%), Loss: 1.1555\n",
      "Epoch: 27, Batch: 25857/37625 (68.723%), Loss: 1.5941\n",
      "Epoch: 27, Batch: 26113/37625 (69.403%), Loss: 0.7177\n",
      "Epoch: 27, Batch: 26369/37625 (70.084%), Loss: 1.2211\n",
      "Epoch: 27, Batch: 26625/37625 (70.764%), Loss: 0.7914\n",
      "Epoch: 27, Batch: 26881/37625 (71.445%), Loss: 0.5509\n",
      "Epoch: 27, Batch: 27137/37625 (72.125%), Loss: 1.2929\n",
      "Epoch: 27, Batch: 27393/37625 (72.805%), Loss: 0.6048\n",
      "Epoch: 27, Batch: 27649/37625 (73.486%), Loss: 0.7922\n",
      "Epoch: 27, Batch: 27905/37625 (74.166%), Loss: 3.1762\n",
      "Epoch: 27, Batch: 28161/37625 (74.847%), Loss: 0.7820\n",
      "Epoch: 27, Batch: 28417/37625 (75.527%), Loss: 0.9123\n",
      "Epoch: 27, Batch: 28673/37625 (76.207%), Loss: 2.4611\n",
      "Epoch: 27, Batch: 28929/37625 (76.888%), Loss: 0.7119\n",
      "Epoch: 27, Batch: 29185/37625 (77.568%), Loss: 0.5830\n",
      "Epoch: 27, Batch: 29441/37625 (78.249%), Loss: 1.2875\n",
      "Epoch: 27, Batch: 29697/37625 (78.929%), Loss: 1.1090\n",
      "Epoch: 27, Batch: 29953/37625 (79.609%), Loss: 1.1578\n",
      "Epoch: 27, Batch: 30209/37625 (80.290%), Loss: 0.8556\n",
      "Epoch: 27, Batch: 30465/37625 (80.970%), Loss: 0.5773\n",
      "Epoch: 27, Batch: 30721/37625 (81.650%), Loss: 0.8334\n",
      "Epoch: 27, Batch: 30977/37625 (82.331%), Loss: 1.5991\n",
      "Epoch: 27, Batch: 31233/37625 (83.011%), Loss: 0.9528\n",
      "Epoch: 27, Batch: 31489/37625 (83.692%), Loss: 0.9262\n",
      "Epoch: 27, Batch: 31745/37625 (84.372%), Loss: 2.3941\n",
      "Epoch: 27, Batch: 32001/37625 (85.052%), Loss: 0.9669\n",
      "Epoch: 27, Batch: 32257/37625 (85.733%), Loss: 1.0009\n",
      "Epoch: 27, Batch: 32513/37625 (86.413%), Loss: 0.6559\n",
      "Epoch: 27, Batch: 32769/37625 (87.094%), Loss: 0.9906\n",
      "Epoch: 27, Batch: 33025/37625 (87.774%), Loss: 0.9537\n",
      "Epoch: 27, Batch: 33281/37625 (88.454%), Loss: 1.0651\n",
      "Epoch: 27, Batch: 33537/37625 (89.135%), Loss: 1.0501\n",
      "Epoch: 27, Batch: 33793/37625 (89.815%), Loss: 0.5592\n",
      "Epoch: 27, Batch: 34049/37625 (90.496%), Loss: 0.9301\n",
      "Epoch: 27, Batch: 34305/37625 (91.176%), Loss: 1.0082\n",
      "Epoch: 27, Batch: 34561/37625 (91.856%), Loss: 0.7681\n",
      "Epoch: 27, Batch: 34817/37625 (92.537%), Loss: 1.1466\n",
      "Epoch: 27, Batch: 35073/37625 (93.217%), Loss: 0.8760\n",
      "Epoch: 27, Batch: 35329/37625 (93.898%), Loss: 1.1200\n",
      "Epoch: 27, Batch: 35585/37625 (94.578%), Loss: 0.7756\n",
      "Epoch: 27, Batch: 35841/37625 (95.258%), Loss: 1.1746\n",
      "Epoch: 27, Batch: 36097/37625 (95.939%), Loss: 0.7656\n",
      "Epoch: 27, Batch: 36353/37625 (96.619%), Loss: 0.7665\n",
      "Epoch: 27, Batch: 36609/37625 (97.300%), Loss: 0.8266\n",
      "Epoch: 27, Batch: 36865/37625 (97.980%), Loss: 1.0535\n",
      "Epoch: 27, Batch: 37121/37625 (98.660%), Loss: 0.7608\n",
      "Epoch: 27, Batch: 37377/37625 (99.341%), Loss: 0.7291\n",
      "Epoch: 28, Batch: 1/37625 (0.003%), Loss: 0.7123\n",
      "Epoch: 28, Batch: 257/37625 (0.683%), Loss: 0.8309\n",
      "Epoch: 28, Batch: 513/37625 (1.363%), Loss: 1.1448\n",
      "Epoch: 28, Batch: 769/37625 (2.044%), Loss: 0.8282\n",
      "Epoch: 28, Batch: 1025/37625 (2.724%), Loss: 0.9824\n",
      "Epoch: 28, Batch: 1281/37625 (3.405%), Loss: 0.9834\n",
      "Epoch: 28, Batch: 1537/37625 (4.085%), Loss: 1.0299\n",
      "Epoch: 28, Batch: 1793/37625 (4.765%), Loss: 0.5924\n",
      "Epoch: 28, Batch: 2049/37625 (5.446%), Loss: 0.7064\n",
      "Epoch: 28, Batch: 2305/37625 (6.126%), Loss: 1.4572\n",
      "Epoch: 28, Batch: 2561/37625 (6.807%), Loss: 0.8671\n",
      "Epoch: 28, Batch: 2817/37625 (7.487%), Loss: 0.5285\n",
      "Epoch: 28, Batch: 3073/37625 (8.167%), Loss: 3.1069\n",
      "Epoch: 28, Batch: 3329/37625 (8.848%), Loss: 0.8577\n",
      "Epoch: 28, Batch: 3585/37625 (9.528%), Loss: 1.0641\n",
      "Epoch: 28, Batch: 3841/37625 (10.209%), Loss: 1.1594\n",
      "Epoch: 28, Batch: 4097/37625 (10.889%), Loss: 1.0514\n",
      "Epoch: 28, Batch: 4353/37625 (11.569%), Loss: 0.7226\n",
      "Epoch: 28, Batch: 4609/37625 (12.250%), Loss: 0.9074\n",
      "Epoch: 28, Batch: 4865/37625 (12.930%), Loss: 0.9885\n",
      "Epoch: 28, Batch: 5121/37625 (13.611%), Loss: 5.1927\n",
      "Epoch: 28, Batch: 5377/37625 (14.291%), Loss: 1.0875\n",
      "Epoch: 28, Batch: 5633/37625 (14.971%), Loss: 0.6404\n",
      "Epoch: 28, Batch: 5889/37625 (15.652%), Loss: 1.2504\n",
      "Epoch: 28, Batch: 6145/37625 (16.332%), Loss: 0.5556\n",
      "Epoch: 28, Batch: 6401/37625 (17.013%), Loss: 1.0677\n",
      "Epoch: 28, Batch: 6657/37625 (17.693%), Loss: 0.9944\n",
      "Epoch: 28, Batch: 6913/37625 (18.373%), Loss: 0.9375\n",
      "Epoch: 28, Batch: 7169/37625 (19.054%), Loss: 0.7627\n",
      "Epoch: 28, Batch: 7425/37625 (19.734%), Loss: 1.1020\n",
      "Epoch: 28, Batch: 7681/37625 (20.415%), Loss: 1.4884\n",
      "Epoch: 28, Batch: 7937/37625 (21.095%), Loss: 1.1721\n",
      "Epoch: 28, Batch: 8193/37625 (21.775%), Loss: 1.0991\n",
      "Epoch: 28, Batch: 8449/37625 (22.456%), Loss: 0.7288\n",
      "Epoch: 28, Batch: 8705/37625 (23.136%), Loss: 0.9890\n",
      "Epoch: 28, Batch: 8961/37625 (23.817%), Loss: 0.9330\n",
      "Epoch: 28, Batch: 9217/37625 (24.497%), Loss: 1.3633\n",
      "Epoch: 28, Batch: 9473/37625 (25.177%), Loss: 1.0876\n",
      "Epoch: 28, Batch: 9729/37625 (25.858%), Loss: 0.7201\n",
      "Epoch: 28, Batch: 9985/37625 (26.538%), Loss: 3.1228\n",
      "Epoch: 28, Batch: 10241/37625 (27.219%), Loss: 2.7723\n",
      "Epoch: 28, Batch: 10497/37625 (27.899%), Loss: 1.3067\n",
      "Epoch: 28, Batch: 10753/37625 (28.579%), Loss: 0.6003\n",
      "Epoch: 28, Batch: 11009/37625 (29.260%), Loss: 0.7421\n",
      "Epoch: 28, Batch: 11265/37625 (29.940%), Loss: 2.3086\n",
      "Epoch: 28, Batch: 11521/37625 (30.621%), Loss: 0.6883\n",
      "Epoch: 28, Batch: 11777/37625 (31.301%), Loss: 0.7023\n",
      "Epoch: 28, Batch: 12033/37625 (31.981%), Loss: 0.7541\n",
      "Epoch: 28, Batch: 12289/37625 (32.662%), Loss: 0.8701\n",
      "Epoch: 28, Batch: 12545/37625 (33.342%), Loss: 1.5374\n",
      "Epoch: 28, Batch: 12801/37625 (34.023%), Loss: 0.9658\n",
      "Epoch: 28, Batch: 13057/37625 (34.703%), Loss: 0.7498\n",
      "Epoch: 28, Batch: 13313/37625 (35.383%), Loss: 0.9013\n",
      "Epoch: 28, Batch: 13569/37625 (36.064%), Loss: 0.9552\n",
      "Epoch: 28, Batch: 13825/37625 (36.744%), Loss: 0.9926\n",
      "Epoch: 28, Batch: 14081/37625 (37.425%), Loss: 1.0138\n",
      "Epoch: 28, Batch: 14337/37625 (38.105%), Loss: 0.8881\n",
      "Epoch: 28, Batch: 14593/37625 (38.785%), Loss: 0.9287\n",
      "Epoch: 28, Batch: 14849/37625 (39.466%), Loss: 1.2715\n",
      "Epoch: 28, Batch: 15105/37625 (40.146%), Loss: 1.5182\n",
      "Epoch: 28, Batch: 15361/37625 (40.827%), Loss: 0.7554\n",
      "Epoch: 28, Batch: 15617/37625 (41.507%), Loss: 1.1352\n",
      "Epoch: 28, Batch: 15873/37625 (42.187%), Loss: 1.9965\n",
      "Epoch: 28, Batch: 16129/37625 (42.868%), Loss: 1.1963\n",
      "Epoch: 28, Batch: 16385/37625 (43.548%), Loss: 0.6675\n",
      "Epoch: 28, Batch: 16641/37625 (44.229%), Loss: 0.5219\n",
      "Epoch: 28, Batch: 16897/37625 (44.909%), Loss: 0.6563\n",
      "Epoch: 28, Batch: 17153/37625 (45.589%), Loss: 1.3165\n",
      "Epoch: 28, Batch: 17409/37625 (46.270%), Loss: 0.7620\n",
      "Epoch: 28, Batch: 17665/37625 (46.950%), Loss: 2.2890\n",
      "Epoch: 28, Batch: 17921/37625 (47.631%), Loss: 1.0625\n",
      "Epoch: 28, Batch: 18177/37625 (48.311%), Loss: 1.0334\n",
      "Epoch: 28, Batch: 18433/37625 (48.991%), Loss: 0.7006\n",
      "Epoch: 28, Batch: 18689/37625 (49.672%), Loss: 0.6778\n",
      "Epoch: 28, Batch: 18945/37625 (50.352%), Loss: 0.7767\n",
      "Epoch: 28, Batch: 19201/37625 (51.033%), Loss: 0.6312\n",
      "Epoch: 28, Batch: 19457/37625 (51.713%), Loss: 0.9149\n",
      "Epoch: 28, Batch: 19713/37625 (52.393%), Loss: 0.7458\n",
      "Epoch: 28, Batch: 19969/37625 (53.074%), Loss: 0.8082\n",
      "Epoch: 28, Batch: 20225/37625 (53.754%), Loss: 1.0499\n",
      "Epoch: 28, Batch: 20481/37625 (54.435%), Loss: 0.7458\n",
      "Epoch: 28, Batch: 20737/37625 (55.115%), Loss: 0.7056\n",
      "Epoch: 28, Batch: 20993/37625 (55.795%), Loss: 0.7195\n",
      "Epoch: 28, Batch: 21249/37625 (56.476%), Loss: 1.3015\n",
      "Epoch: 28, Batch: 21505/37625 (57.156%), Loss: 0.6999\n",
      "Epoch: 28, Batch: 21761/37625 (57.837%), Loss: 6.2285\n",
      "Epoch: 28, Batch: 22017/37625 (58.517%), Loss: 1.1320\n",
      "Epoch: 28, Batch: 22273/37625 (59.197%), Loss: 0.8756\n",
      "Epoch: 28, Batch: 22529/37625 (59.878%), Loss: 2.1976\n",
      "Epoch: 28, Batch: 22785/37625 (60.558%), Loss: 0.8780\n",
      "Epoch: 28, Batch: 23041/37625 (61.239%), Loss: 1.0559\n",
      "Epoch: 28, Batch: 23297/37625 (61.919%), Loss: 0.8920\n",
      "Epoch: 28, Batch: 23553/37625 (62.599%), Loss: 0.8937\n",
      "Epoch: 28, Batch: 23809/37625 (63.280%), Loss: 0.5416\n",
      "Epoch: 28, Batch: 24065/37625 (63.960%), Loss: 0.8530\n",
      "Epoch: 28, Batch: 24321/37625 (64.641%), Loss: 0.6452\n",
      "Epoch: 28, Batch: 24577/37625 (65.321%), Loss: 1.6065\n",
      "Epoch: 28, Batch: 24833/37625 (66.001%), Loss: 1.9641\n",
      "Epoch: 28, Batch: 25089/37625 (66.682%), Loss: 0.9776\n",
      "Epoch: 28, Batch: 25345/37625 (67.362%), Loss: 0.7208\n",
      "Epoch: 28, Batch: 25601/37625 (68.043%), Loss: 0.8360\n",
      "Epoch: 28, Batch: 25857/37625 (68.723%), Loss: 0.8403\n",
      "Epoch: 28, Batch: 26113/37625 (69.403%), Loss: 0.6010\n",
      "Epoch: 28, Batch: 26369/37625 (70.084%), Loss: 0.9936\n",
      "Epoch: 28, Batch: 26625/37625 (70.764%), Loss: 1.9069\n",
      "Epoch: 28, Batch: 26881/37625 (71.445%), Loss: 0.7402\n",
      "Epoch: 28, Batch: 27137/37625 (72.125%), Loss: 0.9428\n",
      "Epoch: 28, Batch: 27393/37625 (72.805%), Loss: 0.7427\n",
      "Epoch: 28, Batch: 27649/37625 (73.486%), Loss: 0.5430\n",
      "Epoch: 28, Batch: 27905/37625 (74.166%), Loss: 0.9025\n",
      "Epoch: 28, Batch: 28161/37625 (74.847%), Loss: 0.9142\n",
      "Epoch: 28, Batch: 28417/37625 (75.527%), Loss: 0.7646\n",
      "Epoch: 28, Batch: 28673/37625 (76.207%), Loss: 0.7961\n",
      "Epoch: 28, Batch: 28929/37625 (76.888%), Loss: 0.8117\n",
      "Epoch: 28, Batch: 29185/37625 (77.568%), Loss: 0.7698\n",
      "Epoch: 28, Batch: 29441/37625 (78.249%), Loss: 0.8537\n",
      "Epoch: 28, Batch: 29697/37625 (78.929%), Loss: 0.7509\n",
      "Epoch: 28, Batch: 29953/37625 (79.609%), Loss: 0.9434\n",
      "Epoch: 28, Batch: 30209/37625 (80.290%), Loss: 1.2127\n",
      "Epoch: 28, Batch: 30465/37625 (80.970%), Loss: 0.8161\n",
      "Epoch: 28, Batch: 30721/37625 (81.650%), Loss: 1.0790\n",
      "Epoch: 28, Batch: 30977/37625 (82.331%), Loss: 1.8153\n",
      "Epoch: 28, Batch: 31233/37625 (83.011%), Loss: 0.7921\n",
      "Epoch: 28, Batch: 31489/37625 (83.692%), Loss: 0.7545\n",
      "Epoch: 28, Batch: 31745/37625 (84.372%), Loss: 1.0608\n",
      "Epoch: 28, Batch: 32001/37625 (85.052%), Loss: 1.1196\n",
      "Epoch: 28, Batch: 32257/37625 (85.733%), Loss: 0.8798\n",
      "Epoch: 28, Batch: 32513/37625 (86.413%), Loss: 0.8290\n",
      "Epoch: 28, Batch: 32769/37625 (87.094%), Loss: 4.8056\n",
      "Epoch: 28, Batch: 33025/37625 (87.774%), Loss: 0.8221\n",
      "Epoch: 28, Batch: 33281/37625 (88.454%), Loss: 1.2357\n",
      "Epoch: 28, Batch: 33537/37625 (89.135%), Loss: 0.9290\n",
      "Epoch: 28, Batch: 33793/37625 (89.815%), Loss: 0.9075\n",
      "Epoch: 28, Batch: 34049/37625 (90.496%), Loss: 0.8228\n",
      "Epoch: 28, Batch: 34305/37625 (91.176%), Loss: 2.4697\n",
      "Epoch: 28, Batch: 34561/37625 (91.856%), Loss: 1.3562\n",
      "Epoch: 28, Batch: 34817/37625 (92.537%), Loss: 1.0373\n",
      "Epoch: 28, Batch: 35073/37625 (93.217%), Loss: 0.7097\n",
      "Epoch: 28, Batch: 35329/37625 (93.898%), Loss: 0.7168\n",
      "Epoch: 28, Batch: 35585/37625 (94.578%), Loss: 0.8017\n",
      "Epoch: 28, Batch: 35841/37625 (95.258%), Loss: 0.9221\n",
      "Epoch: 28, Batch: 36097/37625 (95.939%), Loss: 1.1863\n",
      "Epoch: 28, Batch: 36353/37625 (96.619%), Loss: 0.5747\n",
      "Epoch: 28, Batch: 36609/37625 (97.300%), Loss: 0.6966\n",
      "Epoch: 28, Batch: 36865/37625 (97.980%), Loss: 0.9676\n",
      "Epoch: 28, Batch: 37121/37625 (98.660%), Loss: 0.9702\n",
      "Epoch: 28, Batch: 37377/37625 (99.341%), Loss: 1.2174\n",
      "Epoch: 29, Batch: 1/37625 (0.003%), Loss: 0.7874\n",
      "Epoch: 29, Batch: 257/37625 (0.683%), Loss: 0.6811\n",
      "Epoch: 29, Batch: 513/37625 (1.363%), Loss: 0.7196\n",
      "Epoch: 29, Batch: 769/37625 (2.044%), Loss: 1.3161\n",
      "Epoch: 29, Batch: 1025/37625 (2.724%), Loss: 1.0564\n",
      "Epoch: 29, Batch: 1281/37625 (3.405%), Loss: 0.9456\n",
      "Epoch: 29, Batch: 1537/37625 (4.085%), Loss: 1.9389\n",
      "Epoch: 29, Batch: 1793/37625 (4.765%), Loss: 1.4096\n",
      "Epoch: 29, Batch: 2049/37625 (5.446%), Loss: 0.7578\n",
      "Epoch: 29, Batch: 2305/37625 (6.126%), Loss: 3.1996\n",
      "Epoch: 29, Batch: 2561/37625 (6.807%), Loss: 1.0713\n",
      "Epoch: 29, Batch: 2817/37625 (7.487%), Loss: 0.9727\n",
      "Epoch: 29, Batch: 3073/37625 (8.167%), Loss: 0.6290\n",
      "Epoch: 29, Batch: 3329/37625 (8.848%), Loss: 1.7381\n",
      "Epoch: 29, Batch: 3585/37625 (9.528%), Loss: 0.6213\n",
      "Epoch: 29, Batch: 3841/37625 (10.209%), Loss: 1.3418\n",
      "Epoch: 29, Batch: 4097/37625 (10.889%), Loss: 1.0309\n",
      "Epoch: 29, Batch: 4353/37625 (11.569%), Loss: 0.6844\n",
      "Epoch: 29, Batch: 4609/37625 (12.250%), Loss: 0.7688\n",
      "Epoch: 29, Batch: 4865/37625 (12.930%), Loss: 0.9638\n",
      "Epoch: 29, Batch: 5121/37625 (13.611%), Loss: 0.6715\n",
      "Epoch: 29, Batch: 5377/37625 (14.291%), Loss: 0.9523\n",
      "Epoch: 29, Batch: 5633/37625 (14.971%), Loss: 1.0999\n",
      "Epoch: 29, Batch: 5889/37625 (15.652%), Loss: 1.0244\n",
      "Epoch: 29, Batch: 6145/37625 (16.332%), Loss: 0.7076\n",
      "Epoch: 29, Batch: 6401/37625 (17.013%), Loss: 0.8126\n",
      "Epoch: 29, Batch: 6657/37625 (17.693%), Loss: 0.9063\n",
      "Epoch: 29, Batch: 6913/37625 (18.373%), Loss: 2.5236\n",
      "Epoch: 29, Batch: 7169/37625 (19.054%), Loss: 0.6761\n",
      "Epoch: 29, Batch: 7425/37625 (19.734%), Loss: 1.2646\n",
      "Epoch: 29, Batch: 7681/37625 (20.415%), Loss: 1.3148\n",
      "Epoch: 29, Batch: 7937/37625 (21.095%), Loss: 0.7034\n",
      "Epoch: 29, Batch: 8193/37625 (21.775%), Loss: 0.8144\n",
      "Epoch: 29, Batch: 8449/37625 (22.456%), Loss: 1.2872\n",
      "Epoch: 29, Batch: 8705/37625 (23.136%), Loss: 0.8767\n",
      "Epoch: 29, Batch: 8961/37625 (23.817%), Loss: 0.8227\n",
      "Epoch: 29, Batch: 9217/37625 (24.497%), Loss: 0.6113\n",
      "Epoch: 29, Batch: 9473/37625 (25.177%), Loss: 0.6613\n",
      "Epoch: 29, Batch: 9729/37625 (25.858%), Loss: 1.0269\n",
      "Epoch: 29, Batch: 9985/37625 (26.538%), Loss: 0.7198\n",
      "Epoch: 29, Batch: 10241/37625 (27.219%), Loss: 0.6442\n",
      "Epoch: 29, Batch: 10497/37625 (27.899%), Loss: 0.7430\n",
      "Epoch: 29, Batch: 10753/37625 (28.579%), Loss: 0.7530\n",
      "Epoch: 29, Batch: 11009/37625 (29.260%), Loss: 3.2434\n",
      "Epoch: 29, Batch: 11265/37625 (29.940%), Loss: 0.7749\n",
      "Epoch: 29, Batch: 11521/37625 (30.621%), Loss: 1.1224\n",
      "Epoch: 29, Batch: 11777/37625 (31.301%), Loss: 0.6594\n",
      "Epoch: 29, Batch: 12033/37625 (31.981%), Loss: 0.9141\n",
      "Epoch: 29, Batch: 12289/37625 (32.662%), Loss: 0.7787\n",
      "Epoch: 29, Batch: 12545/37625 (33.342%), Loss: 0.6942\n",
      "Epoch: 29, Batch: 12801/37625 (34.023%), Loss: 0.5362\n",
      "Epoch: 29, Batch: 13057/37625 (34.703%), Loss: 0.8026\n",
      "Epoch: 29, Batch: 13313/37625 (35.383%), Loss: 0.9840\n",
      "Epoch: 29, Batch: 13569/37625 (36.064%), Loss: 0.9413\n",
      "Epoch: 29, Batch: 13825/37625 (36.744%), Loss: 0.8366\n",
      "Epoch: 29, Batch: 14081/37625 (37.425%), Loss: 0.9495\n",
      "Epoch: 29, Batch: 14337/37625 (38.105%), Loss: 0.6422\n",
      "Epoch: 29, Batch: 14593/37625 (38.785%), Loss: 0.7892\n",
      "Epoch: 29, Batch: 14849/37625 (39.466%), Loss: 0.7191\n",
      "Epoch: 29, Batch: 15105/37625 (40.146%), Loss: 0.9568\n",
      "Epoch: 29, Batch: 15361/37625 (40.827%), Loss: 0.9422\n",
      "Epoch: 29, Batch: 15617/37625 (41.507%), Loss: 0.9642\n",
      "Epoch: 29, Batch: 15873/37625 (42.187%), Loss: 0.9608\n",
      "Epoch: 29, Batch: 16129/37625 (42.868%), Loss: 0.7203\n",
      "Epoch: 29, Batch: 16385/37625 (43.548%), Loss: 1.4037\n",
      "Epoch: 29, Batch: 16641/37625 (44.229%), Loss: 1.4534\n",
      "Epoch: 29, Batch: 16897/37625 (44.909%), Loss: 2.9514\n",
      "Epoch: 29, Batch: 17153/37625 (45.589%), Loss: 0.6481\n",
      "Epoch: 29, Batch: 17409/37625 (46.270%), Loss: 1.0982\n",
      "Epoch: 29, Batch: 17665/37625 (46.950%), Loss: 0.6967\n",
      "Epoch: 29, Batch: 17921/37625 (47.631%), Loss: 1.0399\n",
      "Epoch: 29, Batch: 18177/37625 (48.311%), Loss: 1.5746\n",
      "Epoch: 29, Batch: 18433/37625 (48.991%), Loss: 1.2856\n",
      "Epoch: 29, Batch: 18689/37625 (49.672%), Loss: 1.0779\n",
      "Epoch: 29, Batch: 18945/37625 (50.352%), Loss: 0.9470\n",
      "Epoch: 29, Batch: 19201/37625 (51.033%), Loss: 1.0339\n",
      "Epoch: 29, Batch: 19457/37625 (51.713%), Loss: 0.7368\n",
      "Epoch: 29, Batch: 19713/37625 (52.393%), Loss: 0.7696\n",
      "Epoch: 29, Batch: 19969/37625 (53.074%), Loss: 0.6944\n",
      "Epoch: 29, Batch: 20225/37625 (53.754%), Loss: 1.0199\n",
      "Epoch: 29, Batch: 20481/37625 (54.435%), Loss: 0.9946\n",
      "Epoch: 29, Batch: 20737/37625 (55.115%), Loss: 0.8737\n",
      "Epoch: 29, Batch: 20993/37625 (55.795%), Loss: 0.7475\n",
      "Epoch: 29, Batch: 21249/37625 (56.476%), Loss: 1.4772\n",
      "Epoch: 29, Batch: 21505/37625 (57.156%), Loss: 5.8125\n",
      "Epoch: 29, Batch: 21761/37625 (57.837%), Loss: 1.4800\n",
      "Epoch: 29, Batch: 22017/37625 (58.517%), Loss: 0.6240\n",
      "Epoch: 29, Batch: 22273/37625 (59.197%), Loss: 2.0873\n",
      "Epoch: 29, Batch: 22529/37625 (59.878%), Loss: 5.2842\n",
      "Epoch: 29, Batch: 22785/37625 (60.558%), Loss: 0.8829\n",
      "Epoch: 29, Batch: 23041/37625 (61.239%), Loss: 0.9779\n",
      "Epoch: 29, Batch: 23297/37625 (61.919%), Loss: 1.1302\n",
      "Epoch: 29, Batch: 23553/37625 (62.599%), Loss: 1.2402\n",
      "Epoch: 29, Batch: 23809/37625 (63.280%), Loss: 1.0801\n",
      "Epoch: 29, Batch: 24065/37625 (63.960%), Loss: 3.1036\n",
      "Epoch: 29, Batch: 24321/37625 (64.641%), Loss: 0.7980\n",
      "Epoch: 29, Batch: 24577/37625 (65.321%), Loss: 1.4799\n",
      "Epoch: 29, Batch: 24833/37625 (66.001%), Loss: 1.0388\n",
      "Epoch: 29, Batch: 25089/37625 (66.682%), Loss: 0.5140\n",
      "Epoch: 29, Batch: 25345/37625 (67.362%), Loss: 0.7944\n",
      "Epoch: 29, Batch: 25601/37625 (68.043%), Loss: 1.0369\n",
      "Epoch: 29, Batch: 25857/37625 (68.723%), Loss: 0.7426\n",
      "Epoch: 29, Batch: 26113/37625 (69.403%), Loss: 0.7648\n",
      "Epoch: 29, Batch: 26369/37625 (70.084%), Loss: 1.0415\n",
      "Epoch: 29, Batch: 26625/37625 (70.764%), Loss: 1.0834\n",
      "Epoch: 29, Batch: 26881/37625 (71.445%), Loss: 0.8045\n",
      "Epoch: 29, Batch: 27137/37625 (72.125%), Loss: 1.0238\n",
      "Epoch: 29, Batch: 27393/37625 (72.805%), Loss: 0.6305\n",
      "Epoch: 29, Batch: 27649/37625 (73.486%), Loss: 0.6414\n",
      "Epoch: 29, Batch: 27905/37625 (74.166%), Loss: 0.8757\n",
      "Epoch: 29, Batch: 28161/37625 (74.847%), Loss: 0.7325\n",
      "Epoch: 29, Batch: 28417/37625 (75.527%), Loss: 0.8400\n",
      "Epoch: 29, Batch: 28673/37625 (76.207%), Loss: 1.3601\n",
      "Epoch: 29, Batch: 28929/37625 (76.888%), Loss: 0.9759\n",
      "Epoch: 29, Batch: 29185/37625 (77.568%), Loss: 0.9832\n",
      "Epoch: 29, Batch: 29441/37625 (78.249%), Loss: 0.6417\n",
      "Epoch: 29, Batch: 29697/37625 (78.929%), Loss: 0.9325\n",
      "Epoch: 29, Batch: 29953/37625 (79.609%), Loss: 0.7653\n",
      "Epoch: 29, Batch: 30209/37625 (80.290%), Loss: 0.6811\n",
      "Epoch: 29, Batch: 30465/37625 (80.970%), Loss: 0.9765\n",
      "Epoch: 29, Batch: 30721/37625 (81.650%), Loss: 1.0485\n",
      "Epoch: 29, Batch: 30977/37625 (82.331%), Loss: 0.8386\n",
      "Epoch: 29, Batch: 31233/37625 (83.011%), Loss: 4.3968\n",
      "Epoch: 29, Batch: 31489/37625 (83.692%), Loss: 1.5038\n",
      "Epoch: 29, Batch: 31745/37625 (84.372%), Loss: 0.6284\n",
      "Epoch: 29, Batch: 32001/37625 (85.052%), Loss: 1.2598\n",
      "Epoch: 29, Batch: 32257/37625 (85.733%), Loss: 0.7507\n",
      "Epoch: 29, Batch: 32513/37625 (86.413%), Loss: 1.1253\n",
      "Epoch: 29, Batch: 32769/37625 (87.094%), Loss: 1.0091\n",
      "Epoch: 29, Batch: 33025/37625 (87.774%), Loss: 1.1030\n",
      "Epoch: 29, Batch: 33281/37625 (88.454%), Loss: 0.9765\n",
      "Epoch: 29, Batch: 33537/37625 (89.135%), Loss: 1.1996\n",
      "Epoch: 29, Batch: 33793/37625 (89.815%), Loss: 0.7603\n",
      "Epoch: 29, Batch: 34049/37625 (90.496%), Loss: 1.3523\n",
      "Epoch: 29, Batch: 34305/37625 (91.176%), Loss: 1.1570\n",
      "Epoch: 29, Batch: 34561/37625 (91.856%), Loss: 0.7559\n",
      "Epoch: 29, Batch: 34817/37625 (92.537%), Loss: 2.2054\n",
      "Epoch: 29, Batch: 35073/37625 (93.217%), Loss: 0.8560\n",
      "Epoch: 29, Batch: 35329/37625 (93.898%), Loss: 0.7585\n",
      "Epoch: 29, Batch: 35585/37625 (94.578%), Loss: 0.8102\n",
      "Epoch: 29, Batch: 35841/37625 (95.258%), Loss: 0.5808\n",
      "Epoch: 29, Batch: 36097/37625 (95.939%), Loss: 1.0743\n",
      "Epoch: 29, Batch: 36353/37625 (96.619%), Loss: 1.0596\n",
      "Epoch: 29, Batch: 36609/37625 (97.300%), Loss: 0.8238\n",
      "Epoch: 29, Batch: 36865/37625 (97.980%), Loss: 1.4056\n",
      "Epoch: 29, Batch: 37121/37625 (98.660%), Loss: 0.8066\n",
      "Epoch: 29, Batch: 37377/37625 (99.341%), Loss: 0.9535\n",
      "Epoch: 30, Batch: 1/37625 (0.003%), Loss: 1.1887\n",
      "Epoch: 30, Batch: 257/37625 (0.683%), Loss: 0.6933\n",
      "Epoch: 30, Batch: 513/37625 (1.363%), Loss: 1.1639\n",
      "Epoch: 30, Batch: 769/37625 (2.044%), Loss: 0.6489\n",
      "Epoch: 30, Batch: 1025/37625 (2.724%), Loss: 0.9374\n",
      "Epoch: 30, Batch: 1281/37625 (3.405%), Loss: 0.7263\n",
      "Epoch: 30, Batch: 1537/37625 (4.085%), Loss: 0.6054\n",
      "Epoch: 30, Batch: 1793/37625 (4.765%), Loss: 1.1669\n",
      "Epoch: 30, Batch: 2049/37625 (5.446%), Loss: 0.6558\n",
      "Epoch: 30, Batch: 2305/37625 (6.126%), Loss: 0.8173\n",
      "Epoch: 30, Batch: 2561/37625 (6.807%), Loss: 1.0023\n",
      "Epoch: 30, Batch: 2817/37625 (7.487%), Loss: 0.5958\n",
      "Epoch: 30, Batch: 3073/37625 (8.167%), Loss: 1.3380\n",
      "Epoch: 30, Batch: 3329/37625 (8.848%), Loss: 0.8724\n",
      "Epoch: 30, Batch: 3585/37625 (9.528%), Loss: 1.6412\n",
      "Epoch: 30, Batch: 3841/37625 (10.209%), Loss: 0.9121\n",
      "Epoch: 30, Batch: 4097/37625 (10.889%), Loss: 1.0979\n",
      "Epoch: 30, Batch: 4353/37625 (11.569%), Loss: 0.8999\n",
      "Epoch: 30, Batch: 4609/37625 (12.250%), Loss: 0.9401\n",
      "Epoch: 30, Batch: 4865/37625 (12.930%), Loss: 1.1685\n",
      "Epoch: 30, Batch: 5121/37625 (13.611%), Loss: 1.4198\n",
      "Epoch: 30, Batch: 5377/37625 (14.291%), Loss: 1.2742\n",
      "Epoch: 30, Batch: 5633/37625 (14.971%), Loss: 1.0123\n",
      "Epoch: 30, Batch: 5889/37625 (15.652%), Loss: 0.7669\n",
      "Epoch: 30, Batch: 6145/37625 (16.332%), Loss: 0.6305\n",
      "Epoch: 30, Batch: 6401/37625 (17.013%), Loss: 0.5891\n",
      "Epoch: 30, Batch: 6657/37625 (17.693%), Loss: 0.7231\n",
      "Epoch: 30, Batch: 6913/37625 (18.373%), Loss: 0.8403\n",
      "Epoch: 30, Batch: 7169/37625 (19.054%), Loss: 0.9215\n",
      "Epoch: 30, Batch: 7425/37625 (19.734%), Loss: 1.1055\n",
      "Epoch: 30, Batch: 7681/37625 (20.415%), Loss: 3.2030\n",
      "Epoch: 30, Batch: 7937/37625 (21.095%), Loss: 0.8178\n",
      "Epoch: 30, Batch: 8193/37625 (21.775%), Loss: 1.0346\n",
      "Epoch: 30, Batch: 8449/37625 (22.456%), Loss: 1.0252\n",
      "Epoch: 30, Batch: 8705/37625 (23.136%), Loss: 0.5528\n",
      "Epoch: 30, Batch: 8961/37625 (23.817%), Loss: 0.6597\n",
      "Epoch: 30, Batch: 9217/37625 (24.497%), Loss: 0.8977\n",
      "Epoch: 30, Batch: 9473/37625 (25.177%), Loss: 0.9692\n",
      "Epoch: 30, Batch: 9729/37625 (25.858%), Loss: 0.8885\n",
      "Epoch: 30, Batch: 9985/37625 (26.538%), Loss: 0.7454\n",
      "Epoch: 30, Batch: 10241/37625 (27.219%), Loss: 0.7775\n",
      "Epoch: 30, Batch: 10497/37625 (27.899%), Loss: 0.8801\n",
      "Epoch: 30, Batch: 10753/37625 (28.579%), Loss: 1.2291\n",
      "Epoch: 30, Batch: 11009/37625 (29.260%), Loss: 1.0084\n",
      "Epoch: 30, Batch: 11265/37625 (29.940%), Loss: 1.2537\n",
      "Epoch: 30, Batch: 11521/37625 (30.621%), Loss: 0.6285\n",
      "Epoch: 30, Batch: 11777/37625 (31.301%), Loss: 1.2454\n",
      "Epoch: 30, Batch: 12033/37625 (31.981%), Loss: 0.9587\n",
      "Epoch: 30, Batch: 12289/37625 (32.662%), Loss: 0.6117\n",
      "Epoch: 30, Batch: 12545/37625 (33.342%), Loss: 0.7344\n",
      "Epoch: 30, Batch: 12801/37625 (34.023%), Loss: 1.2602\n",
      "Epoch: 30, Batch: 13057/37625 (34.703%), Loss: 0.5749\n",
      "Epoch: 30, Batch: 13313/37625 (35.383%), Loss: 1.0099\n",
      "Epoch: 30, Batch: 13569/37625 (36.064%), Loss: 1.1288\n",
      "Epoch: 30, Batch: 13825/37625 (36.744%), Loss: 1.6651\n",
      "Epoch: 30, Batch: 14081/37625 (37.425%), Loss: 1.3571\n",
      "Epoch: 30, Batch: 14337/37625 (38.105%), Loss: 0.9029\n",
      "Epoch: 30, Batch: 14593/37625 (38.785%), Loss: 0.7736\n",
      "Epoch: 30, Batch: 14849/37625 (39.466%), Loss: 1.0538\n",
      "Epoch: 30, Batch: 15105/37625 (40.146%), Loss: 0.7595\n",
      "Epoch: 30, Batch: 15361/37625 (40.827%), Loss: 1.3023\n",
      "Epoch: 30, Batch: 15617/37625 (41.507%), Loss: 0.9348\n",
      "Epoch: 30, Batch: 15873/37625 (42.187%), Loss: 2.7344\n",
      "Epoch: 30, Batch: 16129/37625 (42.868%), Loss: 1.0295\n",
      "Epoch: 30, Batch: 16385/37625 (43.548%), Loss: 1.6877\n",
      "Epoch: 30, Batch: 16641/37625 (44.229%), Loss: 0.9145\n",
      "Epoch: 30, Batch: 16897/37625 (44.909%), Loss: 1.2084\n",
      "Epoch: 30, Batch: 17153/37625 (45.589%), Loss: 1.0591\n",
      "Epoch: 30, Batch: 17409/37625 (46.270%), Loss: 1.3014\n",
      "Epoch: 30, Batch: 17665/37625 (46.950%), Loss: 0.7182\n",
      "Epoch: 30, Batch: 17921/37625 (47.631%), Loss: 2.3134\n",
      "Epoch: 30, Batch: 18177/37625 (48.311%), Loss: 0.6460\n",
      "Epoch: 30, Batch: 18433/37625 (48.991%), Loss: 0.9346\n",
      "Epoch: 30, Batch: 18689/37625 (49.672%), Loss: 0.9839\n",
      "Epoch: 30, Batch: 18945/37625 (50.352%), Loss: 1.4690\n",
      "Epoch: 30, Batch: 19201/37625 (51.033%), Loss: 1.1012\n",
      "Epoch: 30, Batch: 19457/37625 (51.713%), Loss: 1.0313\n",
      "Epoch: 30, Batch: 19713/37625 (52.393%), Loss: 0.9293\n",
      "Epoch: 30, Batch: 19969/37625 (53.074%), Loss: 1.0851\n",
      "Epoch: 30, Batch: 20225/37625 (53.754%), Loss: 0.8370\n",
      "Epoch: 30, Batch: 20481/37625 (54.435%), Loss: 0.6670\n",
      "Epoch: 30, Batch: 20737/37625 (55.115%), Loss: 1.0753\n",
      "Epoch: 30, Batch: 20993/37625 (55.795%), Loss: 0.7291\n",
      "Epoch: 30, Batch: 21249/37625 (56.476%), Loss: 0.7272\n",
      "Epoch: 30, Batch: 21505/37625 (57.156%), Loss: 0.9004\n",
      "Epoch: 30, Batch: 21761/37625 (57.837%), Loss: 0.7039\n",
      "Epoch: 30, Batch: 22017/37625 (58.517%), Loss: 3.6317\n",
      "Epoch: 30, Batch: 22273/37625 (59.197%), Loss: 1.4292\n",
      "Epoch: 30, Batch: 22529/37625 (59.878%), Loss: 0.6627\n",
      "Epoch: 30, Batch: 22785/37625 (60.558%), Loss: 1.1784\n",
      "Epoch: 30, Batch: 23041/37625 (61.239%), Loss: 0.5978\n",
      "Epoch: 30, Batch: 23297/37625 (61.919%), Loss: 1.4102\n",
      "Epoch: 30, Batch: 23553/37625 (62.599%), Loss: 0.9208\n",
      "Epoch: 30, Batch: 23809/37625 (63.280%), Loss: 0.8565\n",
      "Epoch: 30, Batch: 24065/37625 (63.960%), Loss: 0.7381\n",
      "Epoch: 30, Batch: 24321/37625 (64.641%), Loss: 1.3698\n",
      "Epoch: 30, Batch: 24577/37625 (65.321%), Loss: 1.1254\n",
      "Epoch: 30, Batch: 24833/37625 (66.001%), Loss: 0.8511\n",
      "Epoch: 30, Batch: 25089/37625 (66.682%), Loss: 1.2347\n",
      "Epoch: 30, Batch: 25345/37625 (67.362%), Loss: 1.5164\n",
      "Epoch: 30, Batch: 25601/37625 (68.043%), Loss: 0.9536\n",
      "Epoch: 30, Batch: 25857/37625 (68.723%), Loss: 0.6742\n",
      "Epoch: 30, Batch: 26113/37625 (69.403%), Loss: 0.6711\n",
      "Epoch: 30, Batch: 26369/37625 (70.084%), Loss: 0.8447\n",
      "Epoch: 30, Batch: 26625/37625 (70.764%), Loss: 0.8369\n",
      "Epoch: 30, Batch: 26881/37625 (71.445%), Loss: 0.9261\n",
      "Epoch: 30, Batch: 27137/37625 (72.125%), Loss: 0.8841\n",
      "Epoch: 30, Batch: 27393/37625 (72.805%), Loss: 0.7660\n",
      "Epoch: 30, Batch: 27649/37625 (73.486%), Loss: 0.9173\n",
      "Epoch: 30, Batch: 27905/37625 (74.166%), Loss: 2.1102\n",
      "Epoch: 30, Batch: 28161/37625 (74.847%), Loss: 0.7287\n",
      "Epoch: 30, Batch: 28417/37625 (75.527%), Loss: 1.3141\n",
      "Epoch: 30, Batch: 28673/37625 (76.207%), Loss: 0.9719\n",
      "Epoch: 30, Batch: 28929/37625 (76.888%), Loss: 1.0408\n",
      "Epoch: 30, Batch: 29185/37625 (77.568%), Loss: 1.7083\n",
      "Epoch: 30, Batch: 29441/37625 (78.249%), Loss: 0.8650\n",
      "Epoch: 30, Batch: 29697/37625 (78.929%), Loss: 0.7225\n",
      "Epoch: 30, Batch: 29953/37625 (79.609%), Loss: 0.9642\n",
      "Epoch: 30, Batch: 30209/37625 (80.290%), Loss: 0.6744\n",
      "Epoch: 30, Batch: 30465/37625 (80.970%), Loss: 1.1857\n",
      "Epoch: 30, Batch: 30721/37625 (81.650%), Loss: 1.1159\n",
      "Epoch: 30, Batch: 30977/37625 (82.331%), Loss: 0.6529\n",
      "Epoch: 30, Batch: 31233/37625 (83.011%), Loss: 1.1845\n",
      "Epoch: 30, Batch: 31489/37625 (83.692%), Loss: 0.9910\n",
      "Epoch: 30, Batch: 31745/37625 (84.372%), Loss: 0.6257\n",
      "Epoch: 30, Batch: 32001/37625 (85.052%), Loss: 0.8268\n",
      "Epoch: 30, Batch: 32257/37625 (85.733%), Loss: 0.8017\n",
      "Epoch: 30, Batch: 32513/37625 (86.413%), Loss: 0.5763\n",
      "Epoch: 30, Batch: 32769/37625 (87.094%), Loss: 0.8043\n",
      "Epoch: 30, Batch: 33025/37625 (87.774%), Loss: 0.9233\n",
      "Epoch: 30, Batch: 33281/37625 (88.454%), Loss: 0.6704\n",
      "Epoch: 30, Batch: 33537/37625 (89.135%), Loss: 4.3549\n",
      "Epoch: 30, Batch: 33793/37625 (89.815%), Loss: 0.7860\n",
      "Epoch: 30, Batch: 34049/37625 (90.496%), Loss: 0.7624\n",
      "Epoch: 30, Batch: 34305/37625 (91.176%), Loss: 1.0349\n",
      "Epoch: 30, Batch: 34561/37625 (91.856%), Loss: 1.4696\n",
      "Epoch: 30, Batch: 34817/37625 (92.537%), Loss: 0.8571\n",
      "Epoch: 30, Batch: 35073/37625 (93.217%), Loss: 0.9313\n",
      "Epoch: 30, Batch: 35329/37625 (93.898%), Loss: 1.6871\n",
      "Epoch: 30, Batch: 35585/37625 (94.578%), Loss: 0.7735\n",
      "Epoch: 30, Batch: 35841/37625 (95.258%), Loss: 1.6117\n",
      "Epoch: 30, Batch: 36097/37625 (95.939%), Loss: 0.7620\n",
      "Epoch: 30, Batch: 36353/37625 (96.619%), Loss: 0.6981\n",
      "Epoch: 30, Batch: 36609/37625 (97.300%), Loss: 0.8566\n",
      "Epoch: 30, Batch: 36865/37625 (97.980%), Loss: 6.7644\n",
      "Epoch: 30, Batch: 37121/37625 (98.660%), Loss: 5.3705\n",
      "Epoch: 30, Batch: 37377/37625 (99.341%), Loss: 0.5985\n",
      "Epoch: 31, Batch: 1/37625 (0.003%), Loss: 0.7201\n",
      "Epoch: 31, Batch: 257/37625 (0.683%), Loss: 1.0610\n",
      "Epoch: 31, Batch: 513/37625 (1.363%), Loss: 0.6368\n",
      "Epoch: 31, Batch: 769/37625 (2.044%), Loss: 0.9635\n",
      "Epoch: 31, Batch: 1025/37625 (2.724%), Loss: 0.7498\n",
      "Epoch: 31, Batch: 1281/37625 (3.405%), Loss: 0.8861\n",
      "Epoch: 31, Batch: 1537/37625 (4.085%), Loss: 0.9201\n",
      "Epoch: 31, Batch: 1793/37625 (4.765%), Loss: 1.0209\n",
      "Epoch: 31, Batch: 2049/37625 (5.446%), Loss: 0.9336\n",
      "Epoch: 31, Batch: 2305/37625 (6.126%), Loss: 0.9233\n",
      "Epoch: 31, Batch: 2561/37625 (6.807%), Loss: 0.8333\n",
      "Epoch: 31, Batch: 2817/37625 (7.487%), Loss: 1.6101\n",
      "Epoch: 31, Batch: 3073/37625 (8.167%), Loss: 1.3086\n",
      "Epoch: 31, Batch: 3329/37625 (8.848%), Loss: 0.8779\n",
      "Epoch: 31, Batch: 3585/37625 (9.528%), Loss: 1.3962\n",
      "Epoch: 31, Batch: 3841/37625 (10.209%), Loss: 1.2543\n",
      "Epoch: 31, Batch: 4097/37625 (10.889%), Loss: 2.3166\n",
      "Epoch: 31, Batch: 4353/37625 (11.569%), Loss: 1.0234\n",
      "Epoch: 31, Batch: 4609/37625 (12.250%), Loss: 0.8052\n",
      "Epoch: 31, Batch: 4865/37625 (12.930%), Loss: 1.3231\n",
      "Epoch: 31, Batch: 5121/37625 (13.611%), Loss: 0.6534\n",
      "Epoch: 31, Batch: 5377/37625 (14.291%), Loss: 0.7843\n",
      "Epoch: 31, Batch: 5633/37625 (14.971%), Loss: 4.5637\n",
      "Epoch: 31, Batch: 5889/37625 (15.652%), Loss: 0.8109\n",
      "Epoch: 31, Batch: 6145/37625 (16.332%), Loss: 0.5743\n",
      "Epoch: 31, Batch: 6401/37625 (17.013%), Loss: 1.0672\n",
      "Epoch: 31, Batch: 6657/37625 (17.693%), Loss: 3.1981\n",
      "Epoch: 31, Batch: 6913/37625 (18.373%), Loss: 1.2931\n",
      "Epoch: 31, Batch: 7169/37625 (19.054%), Loss: 0.9021\n",
      "Epoch: 31, Batch: 7425/37625 (19.734%), Loss: 0.7353\n",
      "Epoch: 31, Batch: 7681/37625 (20.415%), Loss: 1.3402\n",
      "Epoch: 31, Batch: 7937/37625 (21.095%), Loss: 1.2433\n",
      "Epoch: 31, Batch: 8193/37625 (21.775%), Loss: 0.8128\n",
      "Epoch: 31, Batch: 8449/37625 (22.456%), Loss: 0.8355\n",
      "Epoch: 31, Batch: 8705/37625 (23.136%), Loss: 0.7388\n",
      "Epoch: 31, Batch: 8961/37625 (23.817%), Loss: 1.0261\n",
      "Epoch: 31, Batch: 9217/37625 (24.497%), Loss: 0.6840\n",
      "Epoch: 31, Batch: 9473/37625 (25.177%), Loss: 0.8597\n",
      "Epoch: 31, Batch: 9729/37625 (25.858%), Loss: 0.8521\n",
      "Epoch: 31, Batch: 9985/37625 (26.538%), Loss: 1.0002\n",
      "Epoch: 31, Batch: 10241/37625 (27.219%), Loss: 0.6512\n",
      "Epoch: 31, Batch: 10497/37625 (27.899%), Loss: 0.8979\n",
      "Epoch: 31, Batch: 10753/37625 (28.579%), Loss: 0.8959\n",
      "Epoch: 31, Batch: 11009/37625 (29.260%), Loss: 0.5949\n",
      "Epoch: 31, Batch: 11265/37625 (29.940%), Loss: 0.7413\n",
      "Epoch: 31, Batch: 11521/37625 (30.621%), Loss: 0.5682\n",
      "Epoch: 31, Batch: 11777/37625 (31.301%), Loss: 1.4512\n",
      "Epoch: 31, Batch: 12033/37625 (31.981%), Loss: 1.7625\n",
      "Epoch: 31, Batch: 12289/37625 (32.662%), Loss: 1.1464\n",
      "Epoch: 31, Batch: 12545/37625 (33.342%), Loss: 1.2106\n",
      "Epoch: 31, Batch: 12801/37625 (34.023%), Loss: 1.0339\n",
      "Epoch: 31, Batch: 13057/37625 (34.703%), Loss: 0.8121\n",
      "Epoch: 31, Batch: 13313/37625 (35.383%), Loss: 1.5157\n",
      "Epoch: 31, Batch: 13569/37625 (36.064%), Loss: 2.8431\n",
      "Epoch: 31, Batch: 13825/37625 (36.744%), Loss: 1.1523\n",
      "Epoch: 31, Batch: 14081/37625 (37.425%), Loss: 1.0524\n",
      "Epoch: 31, Batch: 14337/37625 (38.105%), Loss: 0.7397\n",
      "Epoch: 31, Batch: 14593/37625 (38.785%), Loss: 3.8835\n",
      "Epoch: 31, Batch: 14849/37625 (39.466%), Loss: 0.6832\n",
      "Epoch: 31, Batch: 15105/37625 (40.146%), Loss: 0.6160\n",
      "Epoch: 31, Batch: 15361/37625 (40.827%), Loss: 0.8806\n",
      "Epoch: 31, Batch: 15617/37625 (41.507%), Loss: 0.8254\n",
      "Epoch: 31, Batch: 15873/37625 (42.187%), Loss: 0.7828\n",
      "Epoch: 31, Batch: 16129/37625 (42.868%), Loss: 1.6500\n",
      "Epoch: 31, Batch: 16385/37625 (43.548%), Loss: 0.5997\n",
      "Epoch: 31, Batch: 16641/37625 (44.229%), Loss: 0.8210\n",
      "Epoch: 31, Batch: 16897/37625 (44.909%), Loss: 0.8601\n",
      "Epoch: 31, Batch: 17153/37625 (45.589%), Loss: 0.8717\n",
      "Epoch: 31, Batch: 17409/37625 (46.270%), Loss: 0.9470\n",
      "Epoch: 31, Batch: 17665/37625 (46.950%), Loss: 0.9715\n",
      "Epoch: 31, Batch: 17921/37625 (47.631%), Loss: 0.4756\n",
      "Epoch: 31, Batch: 18177/37625 (48.311%), Loss: 1.1240\n",
      "Epoch: 31, Batch: 18433/37625 (48.991%), Loss: 0.6422\n",
      "Epoch: 31, Batch: 18689/37625 (49.672%), Loss: 0.6819\n",
      "Epoch: 31, Batch: 18945/37625 (50.352%), Loss: 1.1351\n",
      "Epoch: 31, Batch: 19201/37625 (51.033%), Loss: 1.0426\n",
      "Epoch: 31, Batch: 19457/37625 (51.713%), Loss: 0.8199\n",
      "Epoch: 31, Batch: 19713/37625 (52.393%), Loss: 0.8821\n",
      "Epoch: 31, Batch: 19969/37625 (53.074%), Loss: 0.7587\n",
      "Epoch: 31, Batch: 20225/37625 (53.754%), Loss: 1.1124\n",
      "Epoch: 31, Batch: 20481/37625 (54.435%), Loss: 1.1614\n",
      "Epoch: 31, Batch: 20737/37625 (55.115%), Loss: 1.0330\n",
      "Epoch: 31, Batch: 20993/37625 (55.795%), Loss: 0.6793\n",
      "Epoch: 31, Batch: 21249/37625 (56.476%), Loss: 0.8613\n",
      "Epoch: 31, Batch: 21505/37625 (57.156%), Loss: 2.4968\n",
      "Epoch: 31, Batch: 21761/37625 (57.837%), Loss: 4.9296\n",
      "Epoch: 31, Batch: 22017/37625 (58.517%), Loss: 1.1506\n",
      "Epoch: 31, Batch: 22273/37625 (59.197%), Loss: 0.6930\n",
      "Epoch: 31, Batch: 22529/37625 (59.878%), Loss: 0.7124\n",
      "Epoch: 31, Batch: 22785/37625 (60.558%), Loss: 1.1892\n",
      "Epoch: 31, Batch: 23041/37625 (61.239%), Loss: 0.8339\n",
      "Epoch: 31, Batch: 23297/37625 (61.919%), Loss: 1.0407\n",
      "Epoch: 31, Batch: 23553/37625 (62.599%), Loss: 1.0352\n",
      "Epoch: 31, Batch: 23809/37625 (63.280%), Loss: 0.7979\n",
      "Epoch: 31, Batch: 24065/37625 (63.960%), Loss: 0.7673\n",
      "Epoch: 31, Batch: 24321/37625 (64.641%), Loss: 0.5676\n",
      "Epoch: 31, Batch: 24577/37625 (65.321%), Loss: 1.3525\n",
      "Epoch: 31, Batch: 24833/37625 (66.001%), Loss: 0.8074\n",
      "Epoch: 31, Batch: 25089/37625 (66.682%), Loss: 0.8494\n",
      "Epoch: 31, Batch: 25345/37625 (67.362%), Loss: 0.7832\n",
      "Epoch: 31, Batch: 25601/37625 (68.043%), Loss: 2.7292\n",
      "Epoch: 31, Batch: 25857/37625 (68.723%), Loss: 0.7955\n",
      "Epoch: 31, Batch: 26113/37625 (69.403%), Loss: 1.2761\n",
      "Epoch: 31, Batch: 26369/37625 (70.084%), Loss: 0.6525\n",
      "Epoch: 31, Batch: 26625/37625 (70.764%), Loss: 1.1062\n",
      "Epoch: 31, Batch: 26881/37625 (71.445%), Loss: 0.7474\n",
      "Epoch: 31, Batch: 27137/37625 (72.125%), Loss: 1.0892\n",
      "Epoch: 31, Batch: 27393/37625 (72.805%), Loss: 0.9424\n",
      "Epoch: 31, Batch: 27649/37625 (73.486%), Loss: 1.5241\n",
      "Epoch: 31, Batch: 27905/37625 (74.166%), Loss: 0.8239\n",
      "Epoch: 31, Batch: 28161/37625 (74.847%), Loss: 0.9753\n",
      "Epoch: 31, Batch: 28417/37625 (75.527%), Loss: 1.1672\n",
      "Epoch: 31, Batch: 28673/37625 (76.207%), Loss: 1.1461\n",
      "Epoch: 31, Batch: 28929/37625 (76.888%), Loss: 0.8197\n",
      "Epoch: 31, Batch: 29185/37625 (77.568%), Loss: 0.6692\n",
      "Epoch: 31, Batch: 29441/37625 (78.249%), Loss: 1.5469\n",
      "Epoch: 31, Batch: 29697/37625 (78.929%), Loss: 1.8435\n",
      "Epoch: 31, Batch: 29953/37625 (79.609%), Loss: 1.0143\n",
      "Epoch: 31, Batch: 30209/37625 (80.290%), Loss: 0.9170\n",
      "Epoch: 31, Batch: 30465/37625 (80.970%), Loss: 0.7921\n",
      "Epoch: 31, Batch: 30721/37625 (81.650%), Loss: 0.6454\n",
      "Epoch: 31, Batch: 30977/37625 (82.331%), Loss: 0.9637\n",
      "Epoch: 31, Batch: 31233/37625 (83.011%), Loss: 1.0475\n",
      "Epoch: 31, Batch: 31489/37625 (83.692%), Loss: 0.7692\n",
      "Epoch: 31, Batch: 31745/37625 (84.372%), Loss: 1.5523\n",
      "Epoch: 31, Batch: 32001/37625 (85.052%), Loss: 5.3226\n",
      "Epoch: 31, Batch: 32257/37625 (85.733%), Loss: 0.9435\n",
      "Epoch: 31, Batch: 32513/37625 (86.413%), Loss: 0.7806\n",
      "Epoch: 31, Batch: 32769/37625 (87.094%), Loss: 0.6841\n",
      "Epoch: 31, Batch: 33025/37625 (87.774%), Loss: 0.5921\n",
      "Epoch: 31, Batch: 33281/37625 (88.454%), Loss: 0.7077\n",
      "Epoch: 31, Batch: 33537/37625 (89.135%), Loss: 0.8823\n",
      "Epoch: 31, Batch: 33793/37625 (89.815%), Loss: 1.4340\n",
      "Epoch: 31, Batch: 34049/37625 (90.496%), Loss: 0.7037\n",
      "Epoch: 31, Batch: 34305/37625 (91.176%), Loss: 1.2834\n",
      "Epoch: 31, Batch: 34561/37625 (91.856%), Loss: 0.5611\n",
      "Epoch: 31, Batch: 34817/37625 (92.537%), Loss: 1.2880\n",
      "Epoch: 31, Batch: 35073/37625 (93.217%), Loss: 0.7813\n",
      "Epoch: 31, Batch: 35329/37625 (93.898%), Loss: 0.6660\n",
      "Epoch: 31, Batch: 35585/37625 (94.578%), Loss: 1.8205\n",
      "Epoch: 31, Batch: 35841/37625 (95.258%), Loss: 0.7028\n",
      "Epoch: 31, Batch: 36097/37625 (95.939%), Loss: 0.6742\n",
      "Epoch: 31, Batch: 36353/37625 (96.619%), Loss: 0.6412\n",
      "Epoch: 31, Batch: 36609/37625 (97.300%), Loss: 0.7487\n",
      "Epoch: 31, Batch: 36865/37625 (97.980%), Loss: 1.0837\n",
      "Epoch: 31, Batch: 37121/37625 (98.660%), Loss: 1.5741\n",
      "Epoch: 31, Batch: 37377/37625 (99.341%), Loss: 0.9196\n",
      "Epoch: 32, Batch: 1/37625 (0.003%), Loss: 0.9090\n",
      "Epoch: 32, Batch: 257/37625 (0.683%), Loss: 0.8269\n",
      "Epoch: 32, Batch: 513/37625 (1.363%), Loss: 0.9833\n",
      "Epoch: 32, Batch: 769/37625 (2.044%), Loss: 0.8045\n",
      "Epoch: 32, Batch: 1025/37625 (2.724%), Loss: 0.7299\n",
      "Epoch: 32, Batch: 1281/37625 (3.405%), Loss: 1.6882\n",
      "Epoch: 32, Batch: 1537/37625 (4.085%), Loss: 0.9597\n",
      "Epoch: 32, Batch: 1793/37625 (4.765%), Loss: 1.1143\n",
      "Epoch: 32, Batch: 2049/37625 (5.446%), Loss: 0.6513\n",
      "Epoch: 32, Batch: 2305/37625 (6.126%), Loss: 0.7314\n",
      "Epoch: 32, Batch: 2561/37625 (6.807%), Loss: 0.5409\n",
      "Epoch: 32, Batch: 2817/37625 (7.487%), Loss: 0.9335\n",
      "Epoch: 32, Batch: 3073/37625 (8.167%), Loss: 0.7390\n",
      "Epoch: 32, Batch: 3329/37625 (8.848%), Loss: 1.4559\n",
      "Epoch: 32, Batch: 3585/37625 (9.528%), Loss: 0.9089\n",
      "Epoch: 32, Batch: 3841/37625 (10.209%), Loss: 1.2026\n",
      "Epoch: 32, Batch: 4097/37625 (10.889%), Loss: 0.6548\n",
      "Epoch: 32, Batch: 4353/37625 (11.569%), Loss: 0.8602\n",
      "Epoch: 32, Batch: 4609/37625 (12.250%), Loss: 1.4864\n",
      "Epoch: 32, Batch: 4865/37625 (12.930%), Loss: 1.0110\n",
      "Epoch: 32, Batch: 5121/37625 (13.611%), Loss: 0.9923\n",
      "Epoch: 32, Batch: 5377/37625 (14.291%), Loss: 0.8636\n",
      "Epoch: 32, Batch: 5633/37625 (14.971%), Loss: 0.6996\n",
      "Epoch: 32, Batch: 5889/37625 (15.652%), Loss: 1.4089\n",
      "Epoch: 32, Batch: 6145/37625 (16.332%), Loss: 1.3506\n",
      "Epoch: 32, Batch: 6401/37625 (17.013%), Loss: 0.5298\n",
      "Epoch: 32, Batch: 6657/37625 (17.693%), Loss: 0.8021\n",
      "Epoch: 32, Batch: 6913/37625 (18.373%), Loss: 0.7604\n",
      "Epoch: 32, Batch: 7169/37625 (19.054%), Loss: 1.0622\n",
      "Epoch: 32, Batch: 7425/37625 (19.734%), Loss: 0.6949\n",
      "Epoch: 32, Batch: 7681/37625 (20.415%), Loss: 0.7942\n",
      "Epoch: 32, Batch: 7937/37625 (21.095%), Loss: 0.5661\n",
      "Epoch: 32, Batch: 8193/37625 (21.775%), Loss: 0.8518\n",
      "Epoch: 32, Batch: 8449/37625 (22.456%), Loss: 0.7075\n",
      "Epoch: 32, Batch: 8705/37625 (23.136%), Loss: 1.1526\n",
      "Epoch: 32, Batch: 8961/37625 (23.817%), Loss: 0.6530\n",
      "Epoch: 32, Batch: 9217/37625 (24.497%), Loss: 0.8327\n",
      "Epoch: 32, Batch: 9473/37625 (25.177%), Loss: 1.0605\n",
      "Epoch: 32, Batch: 9729/37625 (25.858%), Loss: 0.8588\n",
      "Epoch: 32, Batch: 9985/37625 (26.538%), Loss: 0.7460\n",
      "Epoch: 32, Batch: 10241/37625 (27.219%), Loss: 0.6391\n",
      "Epoch: 32, Batch: 10497/37625 (27.899%), Loss: 0.8163\n",
      "Epoch: 32, Batch: 10753/37625 (28.579%), Loss: 0.9146\n",
      "Epoch: 32, Batch: 11009/37625 (29.260%), Loss: 0.8226\n",
      "Epoch: 32, Batch: 11265/37625 (29.940%), Loss: 1.0400\n",
      "Epoch: 32, Batch: 11521/37625 (30.621%), Loss: 0.8748\n",
      "Epoch: 32, Batch: 11777/37625 (31.301%), Loss: 1.0153\n",
      "Epoch: 32, Batch: 12033/37625 (31.981%), Loss: 0.8908\n",
      "Epoch: 32, Batch: 12289/37625 (32.662%), Loss: 1.4318\n",
      "Epoch: 32, Batch: 12545/37625 (33.342%), Loss: 1.6488\n",
      "Epoch: 32, Batch: 12801/37625 (34.023%), Loss: 0.7210\n",
      "Epoch: 32, Batch: 13057/37625 (34.703%), Loss: 1.0334\n",
      "Epoch: 32, Batch: 13313/37625 (35.383%), Loss: 0.7020\n",
      "Epoch: 32, Batch: 13569/37625 (36.064%), Loss: 0.8027\n",
      "Epoch: 32, Batch: 13825/37625 (36.744%), Loss: 0.4907\n",
      "Epoch: 32, Batch: 14081/37625 (37.425%), Loss: 1.3476\n",
      "Epoch: 32, Batch: 14337/37625 (38.105%), Loss: 0.6841\n",
      "Epoch: 32, Batch: 14593/37625 (38.785%), Loss: 1.1858\n",
      "Epoch: 32, Batch: 14849/37625 (39.466%), Loss: 0.9761\n",
      "Epoch: 32, Batch: 15105/37625 (40.146%), Loss: 0.7851\n",
      "Epoch: 32, Batch: 15361/37625 (40.827%), Loss: 0.6580\n",
      "Epoch: 32, Batch: 15617/37625 (41.507%), Loss: 0.7903\n",
      "Epoch: 32, Batch: 15873/37625 (42.187%), Loss: 0.7394\n",
      "Epoch: 32, Batch: 16129/37625 (42.868%), Loss: 0.5813\n",
      "Epoch: 32, Batch: 16385/37625 (43.548%), Loss: 1.1632\n",
      "Epoch: 32, Batch: 16641/37625 (44.229%), Loss: 1.3261\n",
      "Epoch: 32, Batch: 16897/37625 (44.909%), Loss: 1.1560\n",
      "Epoch: 32, Batch: 17153/37625 (45.589%), Loss: 0.8171\n",
      "Epoch: 32, Batch: 17409/37625 (46.270%), Loss: 0.7126\n",
      "Epoch: 32, Batch: 17665/37625 (46.950%), Loss: 1.1235\n",
      "Epoch: 32, Batch: 17921/37625 (47.631%), Loss: 1.8060\n",
      "Epoch: 32, Batch: 18177/37625 (48.311%), Loss: 0.8247\n",
      "Epoch: 32, Batch: 18433/37625 (48.991%), Loss: 0.8442\n",
      "Epoch: 32, Batch: 18689/37625 (49.672%), Loss: 1.0444\n",
      "Epoch: 32, Batch: 18945/37625 (50.352%), Loss: 0.8019\n",
      "Epoch: 32, Batch: 19201/37625 (51.033%), Loss: 0.7671\n",
      "Epoch: 32, Batch: 19457/37625 (51.713%), Loss: 1.3092\n",
      "Epoch: 32, Batch: 19713/37625 (52.393%), Loss: 1.0462\n",
      "Epoch: 32, Batch: 19969/37625 (53.074%), Loss: 0.9338\n",
      "Epoch: 32, Batch: 20225/37625 (53.754%), Loss: 1.0264\n",
      "Epoch: 32, Batch: 20481/37625 (54.435%), Loss: 0.7060\n",
      "Epoch: 32, Batch: 20737/37625 (55.115%), Loss: 0.8273\n",
      "Epoch: 32, Batch: 20993/37625 (55.795%), Loss: 0.7722\n",
      "Epoch: 32, Batch: 21249/37625 (56.476%), Loss: 1.0947\n",
      "Epoch: 32, Batch: 21505/37625 (57.156%), Loss: 0.6988\n",
      "Epoch: 32, Batch: 21761/37625 (57.837%), Loss: 1.0208\n",
      "Epoch: 32, Batch: 22017/37625 (58.517%), Loss: 0.8432\n",
      "Epoch: 32, Batch: 22273/37625 (59.197%), Loss: 1.1472\n",
      "Epoch: 32, Batch: 22529/37625 (59.878%), Loss: 0.9460\n",
      "Epoch: 32, Batch: 22785/37625 (60.558%), Loss: 1.3701\n",
      "Epoch: 32, Batch: 23041/37625 (61.239%), Loss: 1.1596\n",
      "Epoch: 32, Batch: 23297/37625 (61.919%), Loss: 1.3164\n",
      "Epoch: 32, Batch: 23553/37625 (62.599%), Loss: 0.7824\n",
      "Epoch: 32, Batch: 23809/37625 (63.280%), Loss: 0.9999\n",
      "Epoch: 32, Batch: 24065/37625 (63.960%), Loss: 0.9449\n",
      "Epoch: 32, Batch: 24321/37625 (64.641%), Loss: 0.8015\n",
      "Epoch: 32, Batch: 24577/37625 (65.321%), Loss: 0.7261\n",
      "Epoch: 32, Batch: 24833/37625 (66.001%), Loss: 1.4261\n",
      "Epoch: 32, Batch: 25089/37625 (66.682%), Loss: 0.6208\n",
      "Epoch: 32, Batch: 25345/37625 (67.362%), Loss: 1.4925\n",
      "Epoch: 32, Batch: 25601/37625 (68.043%), Loss: 1.0540\n",
      "Epoch: 32, Batch: 25857/37625 (68.723%), Loss: 0.7528\n",
      "Epoch: 32, Batch: 26113/37625 (69.403%), Loss: 1.5896\n",
      "Epoch: 32, Batch: 26369/37625 (70.084%), Loss: 0.8339\n",
      "Epoch: 32, Batch: 26625/37625 (70.764%), Loss: 7.0181\n",
      "Epoch: 32, Batch: 26881/37625 (71.445%), Loss: 0.7862\n",
      "Epoch: 32, Batch: 27137/37625 (72.125%), Loss: 0.5337\n",
      "Epoch: 32, Batch: 27393/37625 (72.805%), Loss: 0.5791\n",
      "Epoch: 32, Batch: 27649/37625 (73.486%), Loss: 0.6439\n",
      "Epoch: 32, Batch: 27905/37625 (74.166%), Loss: 1.1547\n",
      "Epoch: 32, Batch: 28161/37625 (74.847%), Loss: 0.6679\n",
      "Epoch: 32, Batch: 28417/37625 (75.527%), Loss: 0.5274\n",
      "Epoch: 32, Batch: 28673/37625 (76.207%), Loss: 3.9767\n",
      "Epoch: 32, Batch: 28929/37625 (76.888%), Loss: 4.8063\n",
      "Epoch: 32, Batch: 29185/37625 (77.568%), Loss: 2.3085\n",
      "Epoch: 32, Batch: 29441/37625 (78.249%), Loss: 0.6499\n",
      "Epoch: 32, Batch: 29697/37625 (78.929%), Loss: 1.1947\n",
      "Epoch: 32, Batch: 29953/37625 (79.609%), Loss: 0.6255\n",
      "Epoch: 32, Batch: 30209/37625 (80.290%), Loss: 1.0616\n",
      "Epoch: 32, Batch: 30465/37625 (80.970%), Loss: 1.2043\n",
      "Epoch: 32, Batch: 30721/37625 (81.650%), Loss: 0.6541\n",
      "Epoch: 32, Batch: 30977/37625 (82.331%), Loss: 1.2324\n",
      "Epoch: 32, Batch: 31233/37625 (83.011%), Loss: 0.7186\n",
      "Epoch: 32, Batch: 31489/37625 (83.692%), Loss: 0.9319\n",
      "Epoch: 32, Batch: 31745/37625 (84.372%), Loss: 1.6139\n",
      "Epoch: 32, Batch: 32001/37625 (85.052%), Loss: 1.1120\n",
      "Epoch: 32, Batch: 32257/37625 (85.733%), Loss: 0.6196\n",
      "Epoch: 32, Batch: 32513/37625 (86.413%), Loss: 1.1545\n",
      "Epoch: 32, Batch: 32769/37625 (87.094%), Loss: 0.8480\n",
      "Epoch: 32, Batch: 33025/37625 (87.774%), Loss: 0.8811\n",
      "Epoch: 32, Batch: 33281/37625 (88.454%), Loss: 1.1005\n",
      "Epoch: 32, Batch: 33537/37625 (89.135%), Loss: 0.7998\n",
      "Epoch: 32, Batch: 33793/37625 (89.815%), Loss: 6.4842\n",
      "Epoch: 32, Batch: 34049/37625 (90.496%), Loss: 0.7079\n",
      "Epoch: 32, Batch: 34305/37625 (91.176%), Loss: 1.1769\n",
      "Epoch: 32, Batch: 34561/37625 (91.856%), Loss: 0.9664\n",
      "Epoch: 32, Batch: 34817/37625 (92.537%), Loss: 1.0033\n",
      "Epoch: 32, Batch: 35073/37625 (93.217%), Loss: 0.6423\n",
      "Epoch: 32, Batch: 35329/37625 (93.898%), Loss: 3.2014\n",
      "Epoch: 32, Batch: 35585/37625 (94.578%), Loss: 0.6096\n",
      "Epoch: 32, Batch: 35841/37625 (95.258%), Loss: 1.4851\n",
      "Epoch: 32, Batch: 36097/37625 (95.939%), Loss: 0.7086\n",
      "Epoch: 32, Batch: 36353/37625 (96.619%), Loss: 2.8577\n",
      "Epoch: 32, Batch: 36609/37625 (97.300%), Loss: 0.9843\n",
      "Epoch: 32, Batch: 36865/37625 (97.980%), Loss: 0.8052\n",
      "Epoch: 32, Batch: 37121/37625 (98.660%), Loss: 1.5946\n",
      "Epoch: 32, Batch: 37377/37625 (99.341%), Loss: 2.3761\n",
      "Epoch: 33, Batch: 1/37625 (0.003%), Loss: 1.8321\n",
      "Epoch: 33, Batch: 257/37625 (0.683%), Loss: 0.9864\n",
      "Epoch: 33, Batch: 513/37625 (1.363%), Loss: 1.0688\n",
      "Epoch: 33, Batch: 769/37625 (2.044%), Loss: 0.7569\n",
      "Epoch: 33, Batch: 1025/37625 (2.724%), Loss: 1.1510\n",
      "Epoch: 33, Batch: 1281/37625 (3.405%), Loss: 0.9695\n",
      "Epoch: 33, Batch: 1537/37625 (4.085%), Loss: 0.7676\n",
      "Epoch: 33, Batch: 1793/37625 (4.765%), Loss: 1.0558\n",
      "Epoch: 33, Batch: 2049/37625 (5.446%), Loss: 5.3818\n",
      "Epoch: 33, Batch: 2305/37625 (6.126%), Loss: 1.1069\n",
      "Epoch: 33, Batch: 2561/37625 (6.807%), Loss: 0.5510\n",
      "Epoch: 33, Batch: 2817/37625 (7.487%), Loss: 0.5024\n",
      "Epoch: 33, Batch: 3073/37625 (8.167%), Loss: 1.2409\n",
      "Epoch: 33, Batch: 3329/37625 (8.848%), Loss: 1.9547\n",
      "Epoch: 33, Batch: 3585/37625 (9.528%), Loss: 0.9023\n",
      "Epoch: 33, Batch: 3841/37625 (10.209%), Loss: 1.0573\n",
      "Epoch: 33, Batch: 4097/37625 (10.889%), Loss: 0.5526\n",
      "Epoch: 33, Batch: 4353/37625 (11.569%), Loss: 0.9739\n",
      "Epoch: 33, Batch: 4609/37625 (12.250%), Loss: 0.7556\n",
      "Epoch: 33, Batch: 4865/37625 (12.930%), Loss: 0.9483\n",
      "Epoch: 33, Batch: 5121/37625 (13.611%), Loss: 0.6487\n",
      "Epoch: 33, Batch: 5377/37625 (14.291%), Loss: 0.7634\n",
      "Epoch: 33, Batch: 5633/37625 (14.971%), Loss: 0.9720\n",
      "Epoch: 33, Batch: 5889/37625 (15.652%), Loss: 1.2509\n",
      "Epoch: 33, Batch: 6145/37625 (16.332%), Loss: 1.0855\n",
      "Epoch: 33, Batch: 6401/37625 (17.013%), Loss: 0.9853\n",
      "Epoch: 33, Batch: 6657/37625 (17.693%), Loss: 0.8709\n",
      "Epoch: 33, Batch: 6913/37625 (18.373%), Loss: 1.0205\n",
      "Epoch: 33, Batch: 7169/37625 (19.054%), Loss: 0.5983\n",
      "Epoch: 33, Batch: 7425/37625 (19.734%), Loss: 1.1137\n",
      "Epoch: 33, Batch: 7681/37625 (20.415%), Loss: 0.8471\n",
      "Epoch: 33, Batch: 7937/37625 (21.095%), Loss: 0.9409\n",
      "Epoch: 33, Batch: 8193/37625 (21.775%), Loss: 0.7592\n",
      "Epoch: 33, Batch: 8449/37625 (22.456%), Loss: 0.8435\n",
      "Epoch: 33, Batch: 8705/37625 (23.136%), Loss: 0.8216\n",
      "Epoch: 33, Batch: 8961/37625 (23.817%), Loss: 1.6976\n",
      "Epoch: 33, Batch: 9217/37625 (24.497%), Loss: 0.5894\n",
      "Epoch: 33, Batch: 9473/37625 (25.177%), Loss: 0.8326\n",
      "Epoch: 33, Batch: 9729/37625 (25.858%), Loss: 0.7600\n",
      "Epoch: 33, Batch: 9985/37625 (26.538%), Loss: 0.7475\n",
      "Epoch: 33, Batch: 10241/37625 (27.219%), Loss: 1.0260\n",
      "Epoch: 33, Batch: 10497/37625 (27.899%), Loss: 1.0371\n",
      "Epoch: 33, Batch: 10753/37625 (28.579%), Loss: 0.8561\n",
      "Epoch: 33, Batch: 11009/37625 (29.260%), Loss: 0.7352\n",
      "Epoch: 33, Batch: 11265/37625 (29.940%), Loss: 0.7474\n",
      "Epoch: 33, Batch: 11521/37625 (30.621%), Loss: 0.8451\n",
      "Epoch: 33, Batch: 11777/37625 (31.301%), Loss: 0.8959\n",
      "Epoch: 33, Batch: 12033/37625 (31.981%), Loss: 0.9396\n",
      "Epoch: 33, Batch: 12289/37625 (32.662%), Loss: 0.8483\n",
      "Epoch: 33, Batch: 12545/37625 (33.342%), Loss: 4.4142\n",
      "Epoch: 33, Batch: 12801/37625 (34.023%), Loss: 1.1374\n",
      "Epoch: 33, Batch: 13057/37625 (34.703%), Loss: 0.5542\n",
      "Epoch: 33, Batch: 13313/37625 (35.383%), Loss: 0.6723\n",
      "Epoch: 33, Batch: 13569/37625 (36.064%), Loss: 1.2425\n",
      "Epoch: 33, Batch: 13825/37625 (36.744%), Loss: 1.1404\n",
      "Epoch: 33, Batch: 14081/37625 (37.425%), Loss: 1.2730\n",
      "Epoch: 33, Batch: 14337/37625 (38.105%), Loss: 0.5958\n",
      "Epoch: 33, Batch: 14593/37625 (38.785%), Loss: 0.8415\n",
      "Epoch: 33, Batch: 14849/37625 (39.466%), Loss: 0.8943\n",
      "Epoch: 33, Batch: 15105/37625 (40.146%), Loss: 0.6189\n",
      "Epoch: 33, Batch: 15361/37625 (40.827%), Loss: 1.1336\n",
      "Epoch: 33, Batch: 15617/37625 (41.507%), Loss: 0.7654\n",
      "Epoch: 33, Batch: 15873/37625 (42.187%), Loss: 0.6852\n",
      "Epoch: 33, Batch: 16129/37625 (42.868%), Loss: 1.1108\n",
      "Epoch: 33, Batch: 16385/37625 (43.548%), Loss: 1.0830\n",
      "Epoch: 33, Batch: 16641/37625 (44.229%), Loss: 1.6971\n",
      "Epoch: 33, Batch: 16897/37625 (44.909%), Loss: 1.7176\n",
      "Epoch: 33, Batch: 17153/37625 (45.589%), Loss: 1.1100\n",
      "Epoch: 33, Batch: 17409/37625 (46.270%), Loss: 1.6477\n",
      "Epoch: 33, Batch: 17665/37625 (46.950%), Loss: 3.6842\n",
      "Epoch: 33, Batch: 17921/37625 (47.631%), Loss: 1.2557\n",
      "Epoch: 33, Batch: 18177/37625 (48.311%), Loss: 1.3931\n",
      "Epoch: 33, Batch: 18433/37625 (48.991%), Loss: 0.5522\n",
      "Epoch: 33, Batch: 18689/37625 (49.672%), Loss: 1.4621\n",
      "Epoch: 33, Batch: 18945/37625 (50.352%), Loss: 0.7613\n",
      "Epoch: 33, Batch: 19201/37625 (51.033%), Loss: 0.8438\n",
      "Epoch: 33, Batch: 19457/37625 (51.713%), Loss: 1.2712\n",
      "Epoch: 33, Batch: 19713/37625 (52.393%), Loss: 1.3937\n",
      "Epoch: 33, Batch: 19969/37625 (53.074%), Loss: 4.4131\n",
      "Epoch: 33, Batch: 20225/37625 (53.754%), Loss: 5.0653\n",
      "Epoch: 33, Batch: 20481/37625 (54.435%), Loss: 0.6029\n",
      "Epoch: 33, Batch: 20737/37625 (55.115%), Loss: 0.9187\n",
      "Epoch: 33, Batch: 20993/37625 (55.795%), Loss: 1.3283\n",
      "Epoch: 33, Batch: 21249/37625 (56.476%), Loss: 0.7845\n",
      "Epoch: 33, Batch: 21505/37625 (57.156%), Loss: 0.9968\n",
      "Epoch: 33, Batch: 21761/37625 (57.837%), Loss: 0.7125\n",
      "Epoch: 33, Batch: 22017/37625 (58.517%), Loss: 0.9154\n",
      "Epoch: 33, Batch: 22273/37625 (59.197%), Loss: 1.7821\n",
      "Epoch: 33, Batch: 22529/37625 (59.878%), Loss: 0.7668\n",
      "Epoch: 33, Batch: 22785/37625 (60.558%), Loss: 1.1063\n",
      "Epoch: 33, Batch: 23041/37625 (61.239%), Loss: 0.7443\n",
      "Epoch: 33, Batch: 23297/37625 (61.919%), Loss: 0.8316\n",
      "Epoch: 33, Batch: 23553/37625 (62.599%), Loss: 0.6836\n",
      "Epoch: 33, Batch: 23809/37625 (63.280%), Loss: 0.8818\n",
      "Epoch: 33, Batch: 24065/37625 (63.960%), Loss: 0.7135\n",
      "Epoch: 33, Batch: 24321/37625 (64.641%), Loss: 1.0895\n",
      "Epoch: 33, Batch: 24577/37625 (65.321%), Loss: 0.7434\n",
      "Epoch: 33, Batch: 24833/37625 (66.001%), Loss: 0.8057\n",
      "Epoch: 33, Batch: 25089/37625 (66.682%), Loss: 0.9197\n",
      "Epoch: 33, Batch: 25345/37625 (67.362%), Loss: 0.7899\n",
      "Epoch: 33, Batch: 25601/37625 (68.043%), Loss: 0.7983\n",
      "Epoch: 33, Batch: 25857/37625 (68.723%), Loss: 0.8868\n",
      "Epoch: 33, Batch: 26113/37625 (69.403%), Loss: 1.3865\n",
      "Epoch: 33, Batch: 26369/37625 (70.084%), Loss: 0.8487\n",
      "Epoch: 33, Batch: 26625/37625 (70.764%), Loss: 0.8445\n",
      "Epoch: 33, Batch: 26881/37625 (71.445%), Loss: 0.9279\n",
      "Epoch: 33, Batch: 27137/37625 (72.125%), Loss: 0.8563\n",
      "Epoch: 33, Batch: 27393/37625 (72.805%), Loss: 1.0547\n",
      "Epoch: 33, Batch: 27649/37625 (73.486%), Loss: 0.8711\n",
      "Epoch: 33, Batch: 27905/37625 (74.166%), Loss: 1.1263\n",
      "Epoch: 33, Batch: 28161/37625 (74.847%), Loss: 0.8234\n",
      "Epoch: 33, Batch: 28417/37625 (75.527%), Loss: 0.7141\n",
      "Epoch: 33, Batch: 28673/37625 (76.207%), Loss: 0.8139\n",
      "Epoch: 33, Batch: 28929/37625 (76.888%), Loss: 0.7874\n",
      "Epoch: 33, Batch: 29185/37625 (77.568%), Loss: 1.4814\n",
      "Epoch: 33, Batch: 29441/37625 (78.249%), Loss: 0.5865\n",
      "Epoch: 33, Batch: 29697/37625 (78.929%), Loss: 2.3919\n",
      "Epoch: 33, Batch: 29953/37625 (79.609%), Loss: 0.8947\n",
      "Epoch: 33, Batch: 30209/37625 (80.290%), Loss: 1.4868\n",
      "Epoch: 33, Batch: 30465/37625 (80.970%), Loss: 1.2995\n",
      "Epoch: 33, Batch: 30721/37625 (81.650%), Loss: 0.7884\n",
      "Epoch: 33, Batch: 30977/37625 (82.331%), Loss: 0.9695\n",
      "Epoch: 33, Batch: 31233/37625 (83.011%), Loss: 0.6289\n",
      "Epoch: 33, Batch: 31489/37625 (83.692%), Loss: 1.1148\n",
      "Epoch: 33, Batch: 31745/37625 (84.372%), Loss: 1.1277\n",
      "Epoch: 33, Batch: 32001/37625 (85.052%), Loss: 1.0265\n",
      "Epoch: 33, Batch: 32257/37625 (85.733%), Loss: 0.8080\n",
      "Epoch: 33, Batch: 32513/37625 (86.413%), Loss: 1.4516\n",
      "Epoch: 33, Batch: 32769/37625 (87.094%), Loss: 1.0513\n",
      "Epoch: 33, Batch: 33025/37625 (87.774%), Loss: 0.8144\n",
      "Epoch: 33, Batch: 33281/37625 (88.454%), Loss: 0.6159\n",
      "Epoch: 33, Batch: 33537/37625 (89.135%), Loss: 0.6894\n",
      "Epoch: 33, Batch: 33793/37625 (89.815%), Loss: 0.6620\n",
      "Epoch: 33, Batch: 34049/37625 (90.496%), Loss: 0.8315\n",
      "Epoch: 33, Batch: 34305/37625 (91.176%), Loss: 0.9756\n",
      "Epoch: 33, Batch: 34561/37625 (91.856%), Loss: 0.6345\n",
      "Epoch: 33, Batch: 34817/37625 (92.537%), Loss: 0.9785\n",
      "Epoch: 33, Batch: 35073/37625 (93.217%), Loss: 0.7882\n",
      "Epoch: 33, Batch: 35329/37625 (93.898%), Loss: 0.9671\n",
      "Epoch: 33, Batch: 35585/37625 (94.578%), Loss: 0.7314\n",
      "Epoch: 33, Batch: 35841/37625 (95.258%), Loss: 1.4310\n",
      "Epoch: 33, Batch: 36097/37625 (95.939%), Loss: 1.7396\n",
      "Epoch: 33, Batch: 36353/37625 (96.619%), Loss: 1.0313\n",
      "Epoch: 33, Batch: 36609/37625 (97.300%), Loss: 0.7109\n",
      "Epoch: 33, Batch: 36865/37625 (97.980%), Loss: 2.6153\n",
      "Epoch: 33, Batch: 37121/37625 (98.660%), Loss: 0.6956\n",
      "Epoch: 33, Batch: 37377/37625 (99.341%), Loss: 1.8921\n",
      "Epoch: 34, Batch: 1/37625 (0.003%), Loss: 0.8916\n",
      "Epoch: 34, Batch: 257/37625 (0.683%), Loss: 0.6299\n",
      "Epoch: 34, Batch: 513/37625 (1.363%), Loss: 0.6111\n",
      "Epoch: 34, Batch: 769/37625 (2.044%), Loss: 0.9266\n",
      "Epoch: 34, Batch: 1025/37625 (2.724%), Loss: 1.2304\n",
      "Epoch: 34, Batch: 1281/37625 (3.405%), Loss: 1.0237\n",
      "Epoch: 34, Batch: 1537/37625 (4.085%), Loss: 1.1102\n",
      "Epoch: 34, Batch: 1793/37625 (4.765%), Loss: 0.8884\n",
      "Epoch: 34, Batch: 2049/37625 (5.446%), Loss: 1.0120\n",
      "Epoch: 34, Batch: 2305/37625 (6.126%), Loss: 1.4860\n",
      "Epoch: 34, Batch: 2561/37625 (6.807%), Loss: 1.2585\n",
      "Epoch: 34, Batch: 2817/37625 (7.487%), Loss: 0.6211\n",
      "Epoch: 34, Batch: 3073/37625 (8.167%), Loss: 0.6999\n",
      "Epoch: 34, Batch: 3329/37625 (8.848%), Loss: 0.9036\n",
      "Epoch: 34, Batch: 3585/37625 (9.528%), Loss: 0.7153\n",
      "Epoch: 34, Batch: 3841/37625 (10.209%), Loss: 1.3127\n",
      "Epoch: 34, Batch: 4097/37625 (10.889%), Loss: 1.1290\n",
      "Epoch: 34, Batch: 4353/37625 (11.569%), Loss: 1.0827\n",
      "Epoch: 34, Batch: 4609/37625 (12.250%), Loss: 1.0744\n",
      "Epoch: 34, Batch: 4865/37625 (12.930%), Loss: 1.5798\n",
      "Epoch: 34, Batch: 5121/37625 (13.611%), Loss: 0.8726\n",
      "Epoch: 34, Batch: 5377/37625 (14.291%), Loss: 0.7941\n",
      "Epoch: 34, Batch: 5633/37625 (14.971%), Loss: 2.0591\n",
      "Epoch: 34, Batch: 5889/37625 (15.652%), Loss: 0.6308\n",
      "Epoch: 34, Batch: 6145/37625 (16.332%), Loss: 0.6614\n",
      "Epoch: 34, Batch: 6401/37625 (17.013%), Loss: 0.5908\n",
      "Epoch: 34, Batch: 6657/37625 (17.693%), Loss: 1.3173\n",
      "Epoch: 34, Batch: 6913/37625 (18.373%), Loss: 1.0102\n",
      "Epoch: 34, Batch: 7169/37625 (19.054%), Loss: 2.7331\n",
      "Epoch: 34, Batch: 7425/37625 (19.734%), Loss: 0.8894\n",
      "Epoch: 34, Batch: 7681/37625 (20.415%), Loss: 0.8866\n",
      "Epoch: 34, Batch: 7937/37625 (21.095%), Loss: 0.6338\n",
      "Epoch: 34, Batch: 8193/37625 (21.775%), Loss: 1.0135\n",
      "Epoch: 34, Batch: 8449/37625 (22.456%), Loss: 0.8333\n",
      "Epoch: 34, Batch: 8705/37625 (23.136%), Loss: 0.9829\n",
      "Epoch: 34, Batch: 8961/37625 (23.817%), Loss: 1.7070\n",
      "Epoch: 34, Batch: 9217/37625 (24.497%), Loss: 0.6942\n",
      "Epoch: 34, Batch: 9473/37625 (25.177%), Loss: 0.9616\n",
      "Epoch: 34, Batch: 9729/37625 (25.858%), Loss: 1.2399\n",
      "Epoch: 34, Batch: 9985/37625 (26.538%), Loss: 0.8720\n",
      "Epoch: 34, Batch: 10241/37625 (27.219%), Loss: 1.4168\n",
      "Epoch: 34, Batch: 10497/37625 (27.899%), Loss: 0.9633\n",
      "Epoch: 34, Batch: 10753/37625 (28.579%), Loss: 0.5826\n",
      "Epoch: 34, Batch: 11009/37625 (29.260%), Loss: 0.5887\n",
      "Epoch: 34, Batch: 11265/37625 (29.940%), Loss: 0.6496\n",
      "Epoch: 34, Batch: 11521/37625 (30.621%), Loss: 2.7177\n",
      "Epoch: 34, Batch: 11777/37625 (31.301%), Loss: 1.4012\n",
      "Epoch: 34, Batch: 12033/37625 (31.981%), Loss: 0.7569\n",
      "Epoch: 34, Batch: 12289/37625 (32.662%), Loss: 1.1924\n",
      "Epoch: 34, Batch: 12545/37625 (33.342%), Loss: 1.3236\n",
      "Epoch: 34, Batch: 12801/37625 (34.023%), Loss: 0.7582\n",
      "Epoch: 34, Batch: 13057/37625 (34.703%), Loss: 0.7834\n",
      "Epoch: 34, Batch: 13313/37625 (35.383%), Loss: 1.1696\n",
      "Epoch: 34, Batch: 13569/37625 (36.064%), Loss: 0.7393\n",
      "Epoch: 34, Batch: 13825/37625 (36.744%), Loss: 0.9196\n",
      "Epoch: 34, Batch: 14081/37625 (37.425%), Loss: 0.9824\n",
      "Epoch: 34, Batch: 14337/37625 (38.105%), Loss: 0.7556\n",
      "Epoch: 34, Batch: 14593/37625 (38.785%), Loss: 0.7383\n",
      "Epoch: 34, Batch: 14849/37625 (39.466%), Loss: 1.0077\n",
      "Epoch: 34, Batch: 15105/37625 (40.146%), Loss: 0.7102\n",
      "Epoch: 34, Batch: 15361/37625 (40.827%), Loss: 0.9063\n",
      "Epoch: 34, Batch: 15617/37625 (41.507%), Loss: 1.0055\n",
      "Epoch: 34, Batch: 15873/37625 (42.187%), Loss: 1.2031\n",
      "Epoch: 34, Batch: 16129/37625 (42.868%), Loss: 0.6270\n",
      "Epoch: 34, Batch: 16385/37625 (43.548%), Loss: 1.1423\n",
      "Epoch: 34, Batch: 16641/37625 (44.229%), Loss: 3.1431\n",
      "Epoch: 34, Batch: 16897/37625 (44.909%), Loss: 1.1363\n",
      "Epoch: 34, Batch: 17153/37625 (45.589%), Loss: 0.5925\n",
      "Epoch: 34, Batch: 17409/37625 (46.270%), Loss: 1.3011\n",
      "Epoch: 34, Batch: 17665/37625 (46.950%), Loss: 1.0906\n",
      "Epoch: 34, Batch: 17921/37625 (47.631%), Loss: 0.5763\n",
      "Epoch: 34, Batch: 18177/37625 (48.311%), Loss: 0.7849\n",
      "Epoch: 34, Batch: 18433/37625 (48.991%), Loss: 1.2654\n",
      "Epoch: 34, Batch: 18689/37625 (49.672%), Loss: 0.7734\n",
      "Epoch: 34, Batch: 18945/37625 (50.352%), Loss: 1.1331\n",
      "Epoch: 34, Batch: 19201/37625 (51.033%), Loss: 0.8394\n",
      "Epoch: 34, Batch: 19457/37625 (51.713%), Loss: 0.6633\n",
      "Epoch: 34, Batch: 19713/37625 (52.393%), Loss: 0.6898\n",
      "Epoch: 34, Batch: 19969/37625 (53.074%), Loss: 0.8608\n",
      "Epoch: 34, Batch: 20225/37625 (53.754%), Loss: 1.0444\n",
      "Epoch: 34, Batch: 20481/37625 (54.435%), Loss: 2.3864\n",
      "Epoch: 34, Batch: 20737/37625 (55.115%), Loss: 0.7882\n",
      "Epoch: 34, Batch: 20993/37625 (55.795%), Loss: 1.5287\n",
      "Epoch: 34, Batch: 21249/37625 (56.476%), Loss: 0.6798\n",
      "Epoch: 34, Batch: 21505/37625 (57.156%), Loss: 0.8569\n",
      "Epoch: 34, Batch: 21761/37625 (57.837%), Loss: 1.3763\n",
      "Epoch: 34, Batch: 22017/37625 (58.517%), Loss: 1.5436\n",
      "Epoch: 34, Batch: 22273/37625 (59.197%), Loss: 2.3473\n",
      "Epoch: 34, Batch: 22529/37625 (59.878%), Loss: 5.4336\n",
      "Epoch: 34, Batch: 22785/37625 (60.558%), Loss: 1.2705\n",
      "Epoch: 34, Batch: 23041/37625 (61.239%), Loss: 1.2540\n",
      "Epoch: 34, Batch: 23297/37625 (61.919%), Loss: 0.6890\n",
      "Epoch: 34, Batch: 23553/37625 (62.599%), Loss: 0.5817\n",
      "Epoch: 34, Batch: 23809/37625 (63.280%), Loss: 1.4631\n",
      "Epoch: 34, Batch: 24065/37625 (63.960%), Loss: 0.9955\n",
      "Epoch: 34, Batch: 24321/37625 (64.641%), Loss: 0.5189\n",
      "Epoch: 34, Batch: 24577/37625 (65.321%), Loss: 0.8432\n",
      "Epoch: 34, Batch: 24833/37625 (66.001%), Loss: 0.8103\n",
      "Epoch: 34, Batch: 25089/37625 (66.682%), Loss: 0.5683\n",
      "Epoch: 34, Batch: 25345/37625 (67.362%), Loss: 1.0892\n",
      "Epoch: 34, Batch: 25601/37625 (68.043%), Loss: 4.3150\n",
      "Epoch: 34, Batch: 25857/37625 (68.723%), Loss: 0.9211\n",
      "Epoch: 34, Batch: 26113/37625 (69.403%), Loss: 0.8119\n",
      "Epoch: 34, Batch: 26369/37625 (70.084%), Loss: 1.0697\n",
      "Epoch: 34, Batch: 26625/37625 (70.764%), Loss: 0.7049\n",
      "Epoch: 34, Batch: 26881/37625 (71.445%), Loss: 1.0391\n",
      "Epoch: 34, Batch: 27137/37625 (72.125%), Loss: 1.0112\n",
      "Epoch: 34, Batch: 27393/37625 (72.805%), Loss: 0.7477\n",
      "Epoch: 34, Batch: 27649/37625 (73.486%), Loss: 1.3461\n",
      "Epoch: 34, Batch: 27905/37625 (74.166%), Loss: 0.6217\n",
      "Epoch: 34, Batch: 28161/37625 (74.847%), Loss: 0.9621\n",
      "Epoch: 34, Batch: 28417/37625 (75.527%), Loss: 0.7089\n",
      "Epoch: 34, Batch: 28673/37625 (76.207%), Loss: 0.5853\n",
      "Epoch: 34, Batch: 28929/37625 (76.888%), Loss: 1.3380\n",
      "Epoch: 34, Batch: 29185/37625 (77.568%), Loss: 0.9348\n",
      "Epoch: 34, Batch: 29441/37625 (78.249%), Loss: 0.8041\n",
      "Epoch: 34, Batch: 29697/37625 (78.929%), Loss: 1.0592\n",
      "Epoch: 34, Batch: 29953/37625 (79.609%), Loss: 1.2163\n",
      "Epoch: 34, Batch: 30209/37625 (80.290%), Loss: 0.9802\n",
      "Epoch: 34, Batch: 30465/37625 (80.970%), Loss: 0.5183\n",
      "Epoch: 34, Batch: 30721/37625 (81.650%), Loss: 0.6234\n",
      "Epoch: 34, Batch: 30977/37625 (82.331%), Loss: 1.0700\n",
      "Epoch: 34, Batch: 31233/37625 (83.011%), Loss: 1.4766\n",
      "Epoch: 34, Batch: 31489/37625 (83.692%), Loss: 0.8578\n",
      "Epoch: 34, Batch: 31745/37625 (84.372%), Loss: 0.8528\n",
      "Epoch: 34, Batch: 32001/37625 (85.052%), Loss: 0.9214\n",
      "Epoch: 34, Batch: 32257/37625 (85.733%), Loss: 1.3769\n",
      "Epoch: 34, Batch: 32513/37625 (86.413%), Loss: 0.8642\n",
      "Epoch: 34, Batch: 32769/37625 (87.094%), Loss: 0.9862\n",
      "Epoch: 34, Batch: 33025/37625 (87.774%), Loss: 3.5611\n",
      "Epoch: 34, Batch: 33281/37625 (88.454%), Loss: 0.6182\n",
      "Epoch: 34, Batch: 33537/37625 (89.135%), Loss: 0.6614\n",
      "Epoch: 34, Batch: 33793/37625 (89.815%), Loss: 0.7763\n",
      "Epoch: 34, Batch: 34049/37625 (90.496%), Loss: 0.9343\n",
      "Epoch: 34, Batch: 34305/37625 (91.176%), Loss: 0.5249\n",
      "Epoch: 34, Batch: 34561/37625 (91.856%), Loss: 5.5386\n",
      "Epoch: 34, Batch: 34817/37625 (92.537%), Loss: 0.8749\n",
      "Epoch: 34, Batch: 35073/37625 (93.217%), Loss: 1.8417\n",
      "Epoch: 34, Batch: 35329/37625 (93.898%), Loss: 0.8344\n",
      "Epoch: 34, Batch: 35585/37625 (94.578%), Loss: 0.9279\n",
      "Epoch: 34, Batch: 35841/37625 (95.258%), Loss: 0.8796\n",
      "Epoch: 34, Batch: 36097/37625 (95.939%), Loss: 0.7222\n",
      "Epoch: 34, Batch: 36353/37625 (96.619%), Loss: 0.6355\n",
      "Epoch: 34, Batch: 36609/37625 (97.300%), Loss: 1.2887\n",
      "Epoch: 34, Batch: 36865/37625 (97.980%), Loss: 0.5820\n",
      "Epoch: 34, Batch: 37121/37625 (98.660%), Loss: 1.2237\n",
      "Epoch: 34, Batch: 37377/37625 (99.341%), Loss: 1.0921\n",
      "Epoch: 35, Batch: 1/37625 (0.003%), Loss: 0.8499\n",
      "Epoch: 35, Batch: 257/37625 (0.683%), Loss: 0.7364\n",
      "Epoch: 35, Batch: 513/37625 (1.363%), Loss: 0.8628\n",
      "Epoch: 35, Batch: 769/37625 (2.044%), Loss: 1.3557\n",
      "Epoch: 35, Batch: 1025/37625 (2.724%), Loss: 0.7509\n",
      "Epoch: 35, Batch: 1281/37625 (3.405%), Loss: 1.2683\n",
      "Epoch: 35, Batch: 1537/37625 (4.085%), Loss: 1.5969\n",
      "Epoch: 35, Batch: 1793/37625 (4.765%), Loss: 0.8740\n",
      "Epoch: 35, Batch: 2049/37625 (5.446%), Loss: 0.9018\n",
      "Epoch: 35, Batch: 2305/37625 (6.126%), Loss: 0.5425\n",
      "Epoch: 35, Batch: 2561/37625 (6.807%), Loss: 0.9961\n",
      "Epoch: 35, Batch: 2817/37625 (7.487%), Loss: 0.6526\n",
      "Epoch: 35, Batch: 3073/37625 (8.167%), Loss: 0.6466\n",
      "Epoch: 35, Batch: 3329/37625 (8.848%), Loss: 0.7264\n",
      "Epoch: 35, Batch: 3585/37625 (9.528%), Loss: 0.7134\n",
      "Epoch: 35, Batch: 3841/37625 (10.209%), Loss: 0.5779\n",
      "Epoch: 35, Batch: 4097/37625 (10.889%), Loss: 0.9412\n",
      "Epoch: 35, Batch: 4353/37625 (11.569%), Loss: 1.7542\n",
      "Epoch: 35, Batch: 4609/37625 (12.250%), Loss: 0.8604\n",
      "Epoch: 35, Batch: 4865/37625 (12.930%), Loss: 3.2060\n",
      "Epoch: 35, Batch: 5121/37625 (13.611%), Loss: 0.8494\n",
      "Epoch: 35, Batch: 5377/37625 (14.291%), Loss: 0.9090\n",
      "Epoch: 35, Batch: 5633/37625 (14.971%), Loss: 0.5833\n",
      "Epoch: 35, Batch: 5889/37625 (15.652%), Loss: 0.7180\n",
      "Epoch: 35, Batch: 6145/37625 (16.332%), Loss: 0.9827\n",
      "Epoch: 35, Batch: 6401/37625 (17.013%), Loss: 1.6002\n",
      "Epoch: 35, Batch: 6657/37625 (17.693%), Loss: 1.1934\n",
      "Epoch: 35, Batch: 6913/37625 (18.373%), Loss: 0.6220\n",
      "Epoch: 35, Batch: 7169/37625 (19.054%), Loss: 1.0248\n",
      "Epoch: 35, Batch: 7425/37625 (19.734%), Loss: 0.9429\n",
      "Epoch: 35, Batch: 7681/37625 (20.415%), Loss: 0.8467\n",
      "Epoch: 35, Batch: 7937/37625 (21.095%), Loss: 0.7670\n",
      "Epoch: 35, Batch: 8193/37625 (21.775%), Loss: 0.8468\n",
      "Epoch: 35, Batch: 8449/37625 (22.456%), Loss: 0.7355\n",
      "Epoch: 35, Batch: 8705/37625 (23.136%), Loss: 3.1635\n",
      "Epoch: 35, Batch: 8961/37625 (23.817%), Loss: 0.6060\n",
      "Epoch: 35, Batch: 9217/37625 (24.497%), Loss: 0.7484\n",
      "Epoch: 35, Batch: 9473/37625 (25.177%), Loss: 1.2880\n",
      "Epoch: 35, Batch: 9729/37625 (25.858%), Loss: 1.4308\n",
      "Epoch: 35, Batch: 9985/37625 (26.538%), Loss: 4.4077\n",
      "Epoch: 35, Batch: 10241/37625 (27.219%), Loss: 0.8561\n",
      "Epoch: 35, Batch: 10497/37625 (27.899%), Loss: 0.9847\n",
      "Epoch: 35, Batch: 10753/37625 (28.579%), Loss: 1.0525\n",
      "Epoch: 35, Batch: 11009/37625 (29.260%), Loss: 0.7496\n",
      "Epoch: 35, Batch: 11265/37625 (29.940%), Loss: 2.0273\n",
      "Epoch: 35, Batch: 11521/37625 (30.621%), Loss: 0.9521\n",
      "Epoch: 35, Batch: 11777/37625 (31.301%), Loss: 0.5032\n",
      "Epoch: 35, Batch: 12033/37625 (31.981%), Loss: 0.7537\n",
      "Epoch: 35, Batch: 12289/37625 (32.662%), Loss: 1.8981\n",
      "Epoch: 35, Batch: 12545/37625 (33.342%), Loss: 1.3737\n",
      "Epoch: 35, Batch: 12801/37625 (34.023%), Loss: 1.3404\n",
      "Epoch: 35, Batch: 13057/37625 (34.703%), Loss: 0.7191\n",
      "Epoch: 35, Batch: 13313/37625 (35.383%), Loss: 0.8472\n",
      "Epoch: 35, Batch: 13569/37625 (36.064%), Loss: 1.3457\n",
      "Epoch: 35, Batch: 13825/37625 (36.744%), Loss: 0.7180\n",
      "Epoch: 35, Batch: 14081/37625 (37.425%), Loss: 1.0378\n",
      "Epoch: 35, Batch: 14337/37625 (38.105%), Loss: 1.4224\n",
      "Epoch: 35, Batch: 14593/37625 (38.785%), Loss: 1.1092\n",
      "Epoch: 35, Batch: 14849/37625 (39.466%), Loss: 0.8520\n",
      "Epoch: 35, Batch: 15105/37625 (40.146%), Loss: 0.9881\n",
      "Epoch: 35, Batch: 15361/37625 (40.827%), Loss: 0.8531\n",
      "Epoch: 35, Batch: 15617/37625 (41.507%), Loss: 1.5999\n",
      "Epoch: 35, Batch: 15873/37625 (42.187%), Loss: 0.5017\n",
      "Epoch: 35, Batch: 16129/37625 (42.868%), Loss: 0.8930\n",
      "Epoch: 35, Batch: 16385/37625 (43.548%), Loss: 0.7933\n",
      "Epoch: 35, Batch: 16641/37625 (44.229%), Loss: 0.7980\n",
      "Epoch: 35, Batch: 16897/37625 (44.909%), Loss: 0.8064\n",
      "Epoch: 35, Batch: 17153/37625 (45.589%), Loss: 0.6606\n",
      "Epoch: 35, Batch: 17409/37625 (46.270%), Loss: 0.6926\n",
      "Epoch: 35, Batch: 17665/37625 (46.950%), Loss: 0.9012\n",
      "Epoch: 35, Batch: 17921/37625 (47.631%), Loss: 0.9414\n",
      "Epoch: 35, Batch: 18177/37625 (48.311%), Loss: 0.6042\n",
      "Epoch: 35, Batch: 18433/37625 (48.991%), Loss: 1.1461\n",
      "Epoch: 35, Batch: 18689/37625 (49.672%), Loss: 1.2879\n",
      "Epoch: 35, Batch: 18945/37625 (50.352%), Loss: 0.7983\n",
      "Epoch: 35, Batch: 19201/37625 (51.033%), Loss: 0.8807\n",
      "Epoch: 35, Batch: 19457/37625 (51.713%), Loss: 0.9134\n",
      "Epoch: 35, Batch: 19713/37625 (52.393%), Loss: 1.5448\n",
      "Epoch: 35, Batch: 19969/37625 (53.074%), Loss: 0.8668\n",
      "Epoch: 35, Batch: 20225/37625 (53.754%), Loss: 0.9178\n",
      "Epoch: 35, Batch: 20481/37625 (54.435%), Loss: 1.4059\n",
      "Epoch: 35, Batch: 20737/37625 (55.115%), Loss: 0.5578\n",
      "Epoch: 35, Batch: 20993/37625 (55.795%), Loss: 0.7411\n",
      "Epoch: 35, Batch: 21249/37625 (56.476%), Loss: 0.7742\n",
      "Epoch: 35, Batch: 21505/37625 (57.156%), Loss: 0.7797\n",
      "Epoch: 35, Batch: 21761/37625 (57.837%), Loss: 0.8695\n",
      "Epoch: 35, Batch: 22017/37625 (58.517%), Loss: 0.7063\n",
      "Epoch: 35, Batch: 22273/37625 (59.197%), Loss: 0.5788\n",
      "Epoch: 35, Batch: 22529/37625 (59.878%), Loss: 1.3192\n",
      "Epoch: 35, Batch: 22785/37625 (60.558%), Loss: 1.2137\n",
      "Epoch: 35, Batch: 23041/37625 (61.239%), Loss: 0.9333\n",
      "Epoch: 35, Batch: 23297/37625 (61.919%), Loss: 1.0411\n",
      "Epoch: 35, Batch: 23553/37625 (62.599%), Loss: 0.9225\n",
      "Epoch: 35, Batch: 23809/37625 (63.280%), Loss: 0.8653\n",
      "Epoch: 35, Batch: 24065/37625 (63.960%), Loss: 2.9743\n",
      "Epoch: 35, Batch: 24321/37625 (64.641%), Loss: 0.7396\n",
      "Epoch: 35, Batch: 24577/37625 (65.321%), Loss: 1.2342\n",
      "Epoch: 35, Batch: 24833/37625 (66.001%), Loss: 0.7607\n",
      "Epoch: 35, Batch: 25089/37625 (66.682%), Loss: 1.6822\n",
      "Epoch: 35, Batch: 25345/37625 (67.362%), Loss: 1.1757\n",
      "Epoch: 35, Batch: 25601/37625 (68.043%), Loss: 0.9553\n",
      "Epoch: 35, Batch: 25857/37625 (68.723%), Loss: 0.8249\n",
      "Epoch: 35, Batch: 26113/37625 (69.403%), Loss: 0.7622\n",
      "Epoch: 35, Batch: 26369/37625 (70.084%), Loss: 0.8740\n",
      "Epoch: 35, Batch: 26625/37625 (70.764%), Loss: 0.6094\n",
      "Epoch: 35, Batch: 26881/37625 (71.445%), Loss: 5.0151\n",
      "Epoch: 35, Batch: 27137/37625 (72.125%), Loss: 0.6488\n",
      "Epoch: 35, Batch: 27393/37625 (72.805%), Loss: 2.0839\n",
      "Epoch: 35, Batch: 27649/37625 (73.486%), Loss: 0.5619\n",
      "Epoch: 35, Batch: 27905/37625 (74.166%), Loss: 0.9863\n",
      "Epoch: 35, Batch: 28161/37625 (74.847%), Loss: 2.1182\n",
      "Epoch: 35, Batch: 28417/37625 (75.527%), Loss: 0.6885\n",
      "Epoch: 35, Batch: 28673/37625 (76.207%), Loss: 1.9768\n",
      "Epoch: 35, Batch: 28929/37625 (76.888%), Loss: 1.0251\n",
      "Epoch: 35, Batch: 29185/37625 (77.568%), Loss: 0.8137\n",
      "Epoch: 35, Batch: 29441/37625 (78.249%), Loss: 1.1147\n",
      "Epoch: 35, Batch: 29697/37625 (78.929%), Loss: 0.9872\n",
      "Epoch: 35, Batch: 29953/37625 (79.609%), Loss: 1.1416\n",
      "Epoch: 35, Batch: 30209/37625 (80.290%), Loss: 1.0159\n",
      "Epoch: 35, Batch: 30465/37625 (80.970%), Loss: 0.9067\n",
      "Epoch: 35, Batch: 30721/37625 (81.650%), Loss: 1.1198\n",
      "Epoch: 35, Batch: 30977/37625 (82.331%), Loss: 0.9496\n",
      "Epoch: 35, Batch: 31233/37625 (83.011%), Loss: 1.1452\n",
      "Epoch: 35, Batch: 31489/37625 (83.692%), Loss: 0.8171\n",
      "Epoch: 35, Batch: 31745/37625 (84.372%), Loss: 1.4391\n",
      "Epoch: 35, Batch: 32001/37625 (85.052%), Loss: 0.4562\n",
      "Epoch: 35, Batch: 32257/37625 (85.733%), Loss: 0.5931\n",
      "Epoch: 35, Batch: 32513/37625 (86.413%), Loss: 0.9309\n",
      "Epoch: 35, Batch: 32769/37625 (87.094%), Loss: 0.8007\n",
      "Epoch: 35, Batch: 33025/37625 (87.774%), Loss: 2.9010\n",
      "Epoch: 35, Batch: 33281/37625 (88.454%), Loss: 0.8492\n",
      "Epoch: 35, Batch: 33537/37625 (89.135%), Loss: 5.7362\n",
      "Epoch: 35, Batch: 33793/37625 (89.815%), Loss: 0.8652\n",
      "Epoch: 35, Batch: 34049/37625 (90.496%), Loss: 0.9260\n",
      "Epoch: 35, Batch: 34305/37625 (91.176%), Loss: 0.6307\n",
      "Epoch: 35, Batch: 34561/37625 (91.856%), Loss: 1.0816\n",
      "Epoch: 35, Batch: 34817/37625 (92.537%), Loss: 1.0888\n",
      "Epoch: 35, Batch: 35073/37625 (93.217%), Loss: 1.0096\n",
      "Epoch: 35, Batch: 35329/37625 (93.898%), Loss: 1.1728\n",
      "Epoch: 35, Batch: 35585/37625 (94.578%), Loss: 0.8113\n",
      "Epoch: 35, Batch: 35841/37625 (95.258%), Loss: 1.1871\n",
      "Epoch: 35, Batch: 36097/37625 (95.939%), Loss: 0.6824\n",
      "Epoch: 35, Batch: 36353/37625 (96.619%), Loss: 1.4911\n",
      "Epoch: 35, Batch: 36609/37625 (97.300%), Loss: 1.4748\n",
      "Epoch: 35, Batch: 36865/37625 (97.980%), Loss: 0.5928\n",
      "Epoch: 35, Batch: 37121/37625 (98.660%), Loss: 0.8189\n",
      "Epoch: 35, Batch: 37377/37625 (99.341%), Loss: 0.7964\n",
      "Epoch: 36, Batch: 1/37625 (0.003%), Loss: 1.1198\n",
      "Epoch: 36, Batch: 257/37625 (0.683%), Loss: 0.6484\n",
      "Epoch: 36, Batch: 513/37625 (1.363%), Loss: 0.8123\n",
      "Epoch: 36, Batch: 769/37625 (2.044%), Loss: 0.8593\n",
      "Epoch: 36, Batch: 1025/37625 (2.724%), Loss: 4.7630\n",
      "Epoch: 36, Batch: 1281/37625 (3.405%), Loss: 2.0078\n",
      "Epoch: 36, Batch: 1537/37625 (4.085%), Loss: 0.7539\n",
      "Epoch: 36, Batch: 1793/37625 (4.765%), Loss: 1.3985\n",
      "Epoch: 36, Batch: 2049/37625 (5.446%), Loss: 0.9193\n",
      "Epoch: 36, Batch: 2305/37625 (6.126%), Loss: 0.9916\n",
      "Epoch: 36, Batch: 2561/37625 (6.807%), Loss: 0.7449\n",
      "Epoch: 36, Batch: 2817/37625 (7.487%), Loss: 0.5572\n",
      "Epoch: 36, Batch: 3073/37625 (8.167%), Loss: 2.8120\n",
      "Epoch: 36, Batch: 3329/37625 (8.848%), Loss: 0.7810\n",
      "Epoch: 36, Batch: 3585/37625 (9.528%), Loss: 1.7665\n",
      "Epoch: 36, Batch: 3841/37625 (10.209%), Loss: 0.8109\n",
      "Epoch: 36, Batch: 4097/37625 (10.889%), Loss: 1.4276\n",
      "Epoch: 36, Batch: 4353/37625 (11.569%), Loss: 0.8978\n",
      "Epoch: 36, Batch: 4609/37625 (12.250%), Loss: 0.8354\n",
      "Epoch: 36, Batch: 4865/37625 (12.930%), Loss: 0.6159\n",
      "Epoch: 36, Batch: 5121/37625 (13.611%), Loss: 0.9774\n",
      "Epoch: 36, Batch: 5377/37625 (14.291%), Loss: 0.8644\n",
      "Epoch: 36, Batch: 5633/37625 (14.971%), Loss: 0.7973\n",
      "Epoch: 36, Batch: 5889/37625 (15.652%), Loss: 1.1374\n",
      "Epoch: 36, Batch: 6145/37625 (16.332%), Loss: 1.4064\n",
      "Epoch: 36, Batch: 6401/37625 (17.013%), Loss: 0.6907\n",
      "Epoch: 36, Batch: 6657/37625 (17.693%), Loss: 0.5555\n",
      "Epoch: 36, Batch: 6913/37625 (18.373%), Loss: 1.0857\n",
      "Epoch: 36, Batch: 7169/37625 (19.054%), Loss: 1.2362\n",
      "Epoch: 36, Batch: 7425/37625 (19.734%), Loss: 0.9511\n",
      "Epoch: 36, Batch: 7681/37625 (20.415%), Loss: 1.3369\n",
      "Epoch: 36, Batch: 7937/37625 (21.095%), Loss: 0.5587\n",
      "Epoch: 36, Batch: 8193/37625 (21.775%), Loss: 0.6759\n",
      "Epoch: 36, Batch: 8449/37625 (22.456%), Loss: 0.9862\n",
      "Epoch: 36, Batch: 8705/37625 (23.136%), Loss: 0.8230\n",
      "Epoch: 36, Batch: 8961/37625 (23.817%), Loss: 0.8352\n",
      "Epoch: 36, Batch: 9217/37625 (24.497%), Loss: 1.0968\n",
      "Epoch: 36, Batch: 9473/37625 (25.177%), Loss: 0.9111\n",
      "Epoch: 36, Batch: 9729/37625 (25.858%), Loss: 0.7681\n",
      "Epoch: 36, Batch: 9985/37625 (26.538%), Loss: 3.0704\n",
      "Epoch: 36, Batch: 10241/37625 (27.219%), Loss: 0.8959\n",
      "Epoch: 36, Batch: 10497/37625 (27.899%), Loss: 1.2415\n",
      "Epoch: 36, Batch: 10753/37625 (28.579%), Loss: 0.8500\n",
      "Epoch: 36, Batch: 11009/37625 (29.260%), Loss: 0.5856\n",
      "Epoch: 36, Batch: 11265/37625 (29.940%), Loss: 0.8869\n",
      "Epoch: 36, Batch: 11521/37625 (30.621%), Loss: 5.3611\n",
      "Epoch: 36, Batch: 11777/37625 (31.301%), Loss: 1.0628\n",
      "Epoch: 36, Batch: 12033/37625 (31.981%), Loss: 0.6604\n",
      "Epoch: 36, Batch: 12289/37625 (32.662%), Loss: 1.2320\n",
      "Epoch: 36, Batch: 12545/37625 (33.342%), Loss: 2.8557\n",
      "Epoch: 36, Batch: 12801/37625 (34.023%), Loss: 0.7508\n",
      "Epoch: 36, Batch: 13057/37625 (34.703%), Loss: 1.0998\n",
      "Epoch: 36, Batch: 13313/37625 (35.383%), Loss: 0.7242\n",
      "Epoch: 36, Batch: 13569/37625 (36.064%), Loss: 0.6954\n",
      "Epoch: 36, Batch: 13825/37625 (36.744%), Loss: 1.3672\n",
      "Epoch: 36, Batch: 14081/37625 (37.425%), Loss: 0.9131\n",
      "Epoch: 36, Batch: 14337/37625 (38.105%), Loss: 1.5387\n",
      "Epoch: 36, Batch: 14593/37625 (38.785%), Loss: 0.7926\n",
      "Epoch: 36, Batch: 14849/37625 (39.466%), Loss: 0.8483\n",
      "Epoch: 36, Batch: 15105/37625 (40.146%), Loss: 0.9982\n",
      "Epoch: 36, Batch: 15361/37625 (40.827%), Loss: 1.5563\n",
      "Epoch: 36, Batch: 15617/37625 (41.507%), Loss: 1.6061\n",
      "Epoch: 36, Batch: 15873/37625 (42.187%), Loss: 1.0954\n",
      "Epoch: 36, Batch: 16129/37625 (42.868%), Loss: 1.3036\n",
      "Epoch: 36, Batch: 16385/37625 (43.548%), Loss: 3.1555\n",
      "Epoch: 36, Batch: 16641/37625 (44.229%), Loss: 1.1492\n",
      "Epoch: 36, Batch: 16897/37625 (44.909%), Loss: 0.5903\n",
      "Epoch: 36, Batch: 17153/37625 (45.589%), Loss: 1.0899\n",
      "Epoch: 36, Batch: 17409/37625 (46.270%), Loss: 1.3000\n",
      "Epoch: 36, Batch: 17665/37625 (46.950%), Loss: 0.8650\n",
      "Epoch: 36, Batch: 17921/37625 (47.631%), Loss: 2.3189\n",
      "Epoch: 36, Batch: 18177/37625 (48.311%), Loss: 1.4207\n",
      "Epoch: 36, Batch: 18433/37625 (48.991%), Loss: 1.0025\n",
      "Epoch: 36, Batch: 18689/37625 (49.672%), Loss: 1.1947\n",
      "Epoch: 36, Batch: 18945/37625 (50.352%), Loss: 0.8531\n",
      "Epoch: 36, Batch: 19201/37625 (51.033%), Loss: 0.5394\n",
      "Epoch: 36, Batch: 19457/37625 (51.713%), Loss: 1.2001\n",
      "Epoch: 36, Batch: 19713/37625 (52.393%), Loss: 0.8440\n",
      "Epoch: 36, Batch: 19969/37625 (53.074%), Loss: 0.9223\n",
      "Epoch: 36, Batch: 20225/37625 (53.754%), Loss: 0.9252\n",
      "Epoch: 36, Batch: 20481/37625 (54.435%), Loss: 1.4944\n",
      "Epoch: 36, Batch: 20737/37625 (55.115%), Loss: 0.8744\n",
      "Epoch: 36, Batch: 20993/37625 (55.795%), Loss: 0.8861\n",
      "Epoch: 36, Batch: 21249/37625 (56.476%), Loss: 0.7486\n",
      "Epoch: 36, Batch: 21505/37625 (57.156%), Loss: 1.4321\n",
      "Epoch: 36, Batch: 21761/37625 (57.837%), Loss: 0.7817\n",
      "Epoch: 36, Batch: 22017/37625 (58.517%), Loss: 1.0841\n",
      "Epoch: 36, Batch: 22273/37625 (59.197%), Loss: 0.5618\n",
      "Epoch: 36, Batch: 22529/37625 (59.878%), Loss: 0.9061\n",
      "Epoch: 36, Batch: 22785/37625 (60.558%), Loss: 0.6239\n",
      "Epoch: 36, Batch: 23041/37625 (61.239%), Loss: 0.7177\n",
      "Epoch: 36, Batch: 23297/37625 (61.919%), Loss: 0.8104\n",
      "Epoch: 36, Batch: 23553/37625 (62.599%), Loss: 0.6937\n",
      "Epoch: 36, Batch: 23809/37625 (63.280%), Loss: 0.9645\n",
      "Epoch: 36, Batch: 24065/37625 (63.960%), Loss: 0.7510\n",
      "Epoch: 36, Batch: 24321/37625 (64.641%), Loss: 0.7295\n",
      "Epoch: 36, Batch: 24577/37625 (65.321%), Loss: 0.6541\n",
      "Epoch: 36, Batch: 24833/37625 (66.001%), Loss: 0.6899\n",
      "Epoch: 36, Batch: 25089/37625 (66.682%), Loss: 1.8600\n",
      "Epoch: 36, Batch: 25345/37625 (67.362%), Loss: 1.0424\n",
      "Epoch: 36, Batch: 25601/37625 (68.043%), Loss: 0.6278\n",
      "Epoch: 36, Batch: 25857/37625 (68.723%), Loss: 1.1838\n",
      "Epoch: 36, Batch: 26113/37625 (69.403%), Loss: 0.9014\n",
      "Epoch: 36, Batch: 26369/37625 (70.084%), Loss: 0.6480\n",
      "Epoch: 36, Batch: 26625/37625 (70.764%), Loss: 0.6620\n",
      "Epoch: 36, Batch: 26881/37625 (71.445%), Loss: 0.9147\n",
      "Epoch: 36, Batch: 27137/37625 (72.125%), Loss: 0.7297\n",
      "Epoch: 36, Batch: 27393/37625 (72.805%), Loss: 0.8720\n",
      "Epoch: 36, Batch: 27649/37625 (73.486%), Loss: 0.9178\n",
      "Epoch: 36, Batch: 27905/37625 (74.166%), Loss: 1.0032\n",
      "Epoch: 36, Batch: 28161/37625 (74.847%), Loss: 0.7501\n",
      "Epoch: 36, Batch: 28417/37625 (75.527%), Loss: 0.7068\n",
      "Epoch: 36, Batch: 28673/37625 (76.207%), Loss: 0.7413\n",
      "Epoch: 36, Batch: 28929/37625 (76.888%), Loss: 1.1912\n",
      "Epoch: 36, Batch: 29185/37625 (77.568%), Loss: 0.7694\n",
      "Epoch: 36, Batch: 29441/37625 (78.249%), Loss: 0.8791\n",
      "Epoch: 36, Batch: 29697/37625 (78.929%), Loss: 1.8767\n",
      "Epoch: 36, Batch: 29953/37625 (79.609%), Loss: 0.5584\n",
      "Epoch: 36, Batch: 30209/37625 (80.290%), Loss: 0.6250\n",
      "Epoch: 36, Batch: 30465/37625 (80.970%), Loss: 1.0573\n",
      "Epoch: 36, Batch: 30721/37625 (81.650%), Loss: 1.0750\n",
      "Epoch: 36, Batch: 30977/37625 (82.331%), Loss: 1.2595\n",
      "Epoch: 36, Batch: 31233/37625 (83.011%), Loss: 1.3353\n",
      "Epoch: 36, Batch: 31489/37625 (83.692%), Loss: 1.0904\n",
      "Epoch: 36, Batch: 31745/37625 (84.372%), Loss: 0.8293\n",
      "Epoch: 36, Batch: 32001/37625 (85.052%), Loss: 0.6574\n",
      "Epoch: 36, Batch: 32257/37625 (85.733%), Loss: 1.2622\n",
      "Epoch: 36, Batch: 32513/37625 (86.413%), Loss: 0.5505\n",
      "Epoch: 36, Batch: 32769/37625 (87.094%), Loss: 0.7567\n",
      "Epoch: 36, Batch: 33025/37625 (87.774%), Loss: 1.0841\n",
      "Epoch: 36, Batch: 33281/37625 (88.454%), Loss: 0.7552\n",
      "Epoch: 36, Batch: 33537/37625 (89.135%), Loss: 0.9252\n",
      "Epoch: 36, Batch: 33793/37625 (89.815%), Loss: 0.8222\n",
      "Epoch: 36, Batch: 34049/37625 (90.496%), Loss: 1.2882\n",
      "Epoch: 36, Batch: 34305/37625 (91.176%), Loss: 0.6312\n",
      "Epoch: 36, Batch: 34561/37625 (91.856%), Loss: 0.7359\n",
      "Epoch: 36, Batch: 34817/37625 (92.537%), Loss: 0.7792\n",
      "Epoch: 36, Batch: 35073/37625 (93.217%), Loss: 0.9633\n",
      "Epoch: 36, Batch: 35329/37625 (93.898%), Loss: 1.0242\n",
      "Epoch: 36, Batch: 35585/37625 (94.578%), Loss: 5.7331\n",
      "Epoch: 36, Batch: 35841/37625 (95.258%), Loss: 0.7896\n",
      "Epoch: 36, Batch: 36097/37625 (95.939%), Loss: 0.9965\n",
      "Epoch: 36, Batch: 36353/37625 (96.619%), Loss: 1.0566\n",
      "Epoch: 36, Batch: 36609/37625 (97.300%), Loss: 0.9264\n",
      "Epoch: 36, Batch: 36865/37625 (97.980%), Loss: 1.6318\n",
      "Epoch: 36, Batch: 37121/37625 (98.660%), Loss: 1.6127\n",
      "Epoch: 36, Batch: 37377/37625 (99.341%), Loss: 0.6886\n",
      "Epoch: 37, Batch: 1/37625 (0.003%), Loss: 1.0351\n",
      "Epoch: 37, Batch: 257/37625 (0.683%), Loss: 0.8836\n",
      "Epoch: 37, Batch: 513/37625 (1.363%), Loss: 0.8757\n",
      "Epoch: 37, Batch: 769/37625 (2.044%), Loss: 0.4837\n",
      "Epoch: 37, Batch: 1025/37625 (2.724%), Loss: 1.2430\n",
      "Epoch: 37, Batch: 1281/37625 (3.405%), Loss: 1.0117\n",
      "Epoch: 37, Batch: 1537/37625 (4.085%), Loss: 1.0573\n",
      "Epoch: 37, Batch: 1793/37625 (4.765%), Loss: 0.7111\n",
      "Epoch: 37, Batch: 2049/37625 (5.446%), Loss: 0.8964\n",
      "Epoch: 37, Batch: 2305/37625 (6.126%), Loss: 0.6931\n",
      "Epoch: 37, Batch: 2561/37625 (6.807%), Loss: 1.5885\n",
      "Epoch: 37, Batch: 2817/37625 (7.487%), Loss: 1.1379\n",
      "Epoch: 37, Batch: 3073/37625 (8.167%), Loss: 0.9410\n",
      "Epoch: 37, Batch: 3329/37625 (8.848%), Loss: 0.8342\n",
      "Epoch: 37, Batch: 3585/37625 (9.528%), Loss: 0.7504\n",
      "Epoch: 37, Batch: 3841/37625 (10.209%), Loss: 2.1481\n",
      "Epoch: 37, Batch: 4097/37625 (10.889%), Loss: 0.9050\n",
      "Epoch: 37, Batch: 4353/37625 (11.569%), Loss: 1.0759\n",
      "Epoch: 37, Batch: 4609/37625 (12.250%), Loss: 0.5808\n",
      "Epoch: 37, Batch: 4865/37625 (12.930%), Loss: 0.6097\n",
      "Epoch: 37, Batch: 5121/37625 (13.611%), Loss: 1.6173\n",
      "Epoch: 37, Batch: 5377/37625 (14.291%), Loss: 1.4358\n",
      "Epoch: 37, Batch: 5633/37625 (14.971%), Loss: 0.9556\n",
      "Epoch: 37, Batch: 5889/37625 (15.652%), Loss: 0.7618\n",
      "Epoch: 37, Batch: 6145/37625 (16.332%), Loss: 0.5423\n",
      "Epoch: 37, Batch: 6401/37625 (17.013%), Loss: 1.0569\n",
      "Epoch: 37, Batch: 6657/37625 (17.693%), Loss: 1.1606\n",
      "Epoch: 37, Batch: 6913/37625 (18.373%), Loss: 0.7687\n",
      "Epoch: 37, Batch: 7169/37625 (19.054%), Loss: 0.8564\n",
      "Epoch: 37, Batch: 7425/37625 (19.734%), Loss: 0.9435\n",
      "Epoch: 37, Batch: 7681/37625 (20.415%), Loss: 0.7218\n",
      "Epoch: 37, Batch: 7937/37625 (21.095%), Loss: 1.1272\n",
      "Epoch: 37, Batch: 8193/37625 (21.775%), Loss: 1.4581\n",
      "Epoch: 37, Batch: 8449/37625 (22.456%), Loss: 0.6704\n",
      "Epoch: 37, Batch: 8705/37625 (23.136%), Loss: 0.6150\n",
      "Epoch: 37, Batch: 8961/37625 (23.817%), Loss: 0.9327\n",
      "Epoch: 37, Batch: 9217/37625 (24.497%), Loss: 0.5589\n",
      "Epoch: 37, Batch: 9473/37625 (25.177%), Loss: 5.3309\n",
      "Epoch: 37, Batch: 9729/37625 (25.858%), Loss: 0.7071\n",
      "Epoch: 37, Batch: 9985/37625 (26.538%), Loss: 0.8811\n",
      "Epoch: 37, Batch: 10241/37625 (27.219%), Loss: 0.5114\n",
      "Epoch: 37, Batch: 10497/37625 (27.899%), Loss: 0.7326\n",
      "Epoch: 37, Batch: 10753/37625 (28.579%), Loss: 0.7552\n",
      "Epoch: 37, Batch: 11009/37625 (29.260%), Loss: 0.6272\n",
      "Epoch: 37, Batch: 11265/37625 (29.940%), Loss: 5.1160\n",
      "Epoch: 37, Batch: 11521/37625 (30.621%), Loss: 1.0060\n",
      "Epoch: 37, Batch: 11777/37625 (31.301%), Loss: 0.7307\n",
      "Epoch: 37, Batch: 12033/37625 (31.981%), Loss: 0.7580\n",
      "Epoch: 37, Batch: 12289/37625 (32.662%), Loss: 1.3307\n",
      "Epoch: 37, Batch: 12545/37625 (33.342%), Loss: 0.6492\n",
      "Epoch: 37, Batch: 12801/37625 (34.023%), Loss: 1.0311\n",
      "Epoch: 37, Batch: 13057/37625 (34.703%), Loss: 1.1975\n",
      "Epoch: 37, Batch: 13313/37625 (35.383%), Loss: 0.9313\n",
      "Epoch: 37, Batch: 13569/37625 (36.064%), Loss: 0.5604\n",
      "Epoch: 37, Batch: 13825/37625 (36.744%), Loss: 1.3724\n",
      "Epoch: 37, Batch: 14081/37625 (37.425%), Loss: 0.8886\n",
      "Epoch: 37, Batch: 14337/37625 (38.105%), Loss: 0.5915\n",
      "Epoch: 37, Batch: 14593/37625 (38.785%), Loss: 0.7950\n",
      "Epoch: 37, Batch: 14849/37625 (39.466%), Loss: 1.6630\n",
      "Epoch: 37, Batch: 15105/37625 (40.146%), Loss: 0.5979\n",
      "Epoch: 37, Batch: 15361/37625 (40.827%), Loss: 0.6993\n",
      "Epoch: 37, Batch: 15617/37625 (41.507%), Loss: 0.9262\n",
      "Epoch: 37, Batch: 15873/37625 (42.187%), Loss: 1.3680\n",
      "Epoch: 37, Batch: 16129/37625 (42.868%), Loss: 0.7080\n",
      "Epoch: 37, Batch: 16385/37625 (43.548%), Loss: 0.7804\n",
      "Epoch: 37, Batch: 16641/37625 (44.229%), Loss: 0.6449\n",
      "Epoch: 37, Batch: 16897/37625 (44.909%), Loss: 0.9036\n",
      "Epoch: 37, Batch: 17153/37625 (45.589%), Loss: 0.7398\n",
      "Epoch: 37, Batch: 17409/37625 (46.270%), Loss: 1.1535\n",
      "Epoch: 37, Batch: 17665/37625 (46.950%), Loss: 3.8779\n",
      "Epoch: 37, Batch: 17921/37625 (47.631%), Loss: 0.7492\n",
      "Epoch: 37, Batch: 18177/37625 (48.311%), Loss: 1.0449\n",
      "Epoch: 37, Batch: 18433/37625 (48.991%), Loss: 1.6725\n",
      "Epoch: 37, Batch: 18689/37625 (49.672%), Loss: 0.9199\n",
      "Epoch: 37, Batch: 18945/37625 (50.352%), Loss: 0.5690\n",
      "Epoch: 37, Batch: 19201/37625 (51.033%), Loss: 1.1712\n",
      "Epoch: 37, Batch: 19457/37625 (51.713%), Loss: 1.6717\n",
      "Epoch: 37, Batch: 19713/37625 (52.393%), Loss: 1.1737\n",
      "Epoch: 37, Batch: 19969/37625 (53.074%), Loss: 1.1601\n",
      "Epoch: 37, Batch: 20225/37625 (53.754%), Loss: 0.9660\n",
      "Epoch: 37, Batch: 20481/37625 (54.435%), Loss: 0.9273\n",
      "Epoch: 37, Batch: 20737/37625 (55.115%), Loss: 0.9280\n",
      "Epoch: 37, Batch: 20993/37625 (55.795%), Loss: 1.0149\n",
      "Epoch: 37, Batch: 21249/37625 (56.476%), Loss: 1.2261\n",
      "Epoch: 37, Batch: 21505/37625 (57.156%), Loss: 0.7937\n",
      "Epoch: 37, Batch: 21761/37625 (57.837%), Loss: 1.0193\n",
      "Epoch: 37, Batch: 22017/37625 (58.517%), Loss: 0.8185\n",
      "Epoch: 37, Batch: 22273/37625 (59.197%), Loss: 0.9121\n",
      "Epoch: 37, Batch: 22529/37625 (59.878%), Loss: 0.8706\n",
      "Epoch: 37, Batch: 22785/37625 (60.558%), Loss: 1.3721\n",
      "Epoch: 37, Batch: 23041/37625 (61.239%), Loss: 0.7761\n",
      "Epoch: 37, Batch: 23297/37625 (61.919%), Loss: 2.6463\n",
      "Epoch: 37, Batch: 23553/37625 (62.599%), Loss: 0.8064\n",
      "Epoch: 37, Batch: 23809/37625 (63.280%), Loss: 0.7196\n",
      "Epoch: 37, Batch: 24065/37625 (63.960%), Loss: 1.1243\n",
      "Epoch: 37, Batch: 24321/37625 (64.641%), Loss: 0.6924\n",
      "Epoch: 37, Batch: 24577/37625 (65.321%), Loss: 1.2255\n",
      "Epoch: 37, Batch: 24833/37625 (66.001%), Loss: 0.7842\n",
      "Epoch: 37, Batch: 25089/37625 (66.682%), Loss: 1.3174\n",
      "Epoch: 37, Batch: 25345/37625 (67.362%), Loss: 0.8581\n",
      "Epoch: 37, Batch: 25601/37625 (68.043%), Loss: 0.6776\n",
      "Epoch: 37, Batch: 25857/37625 (68.723%), Loss: 0.9921\n",
      "Epoch: 37, Batch: 26113/37625 (69.403%), Loss: 0.7974\n",
      "Epoch: 37, Batch: 26369/37625 (70.084%), Loss: 1.5891\n",
      "Epoch: 37, Batch: 26625/37625 (70.764%), Loss: 1.2267\n",
      "Epoch: 37, Batch: 26881/37625 (71.445%), Loss: 1.3882\n",
      "Epoch: 37, Batch: 27137/37625 (72.125%), Loss: 0.6070\n",
      "Epoch: 37, Batch: 27393/37625 (72.805%), Loss: 0.6331\n",
      "Epoch: 37, Batch: 27649/37625 (73.486%), Loss: 0.8712\n",
      "Epoch: 37, Batch: 27905/37625 (74.166%), Loss: 0.6853\n",
      "Epoch: 37, Batch: 28161/37625 (74.847%), Loss: 0.8449\n",
      "Epoch: 37, Batch: 28417/37625 (75.527%), Loss: 0.5642\n",
      "Epoch: 37, Batch: 28673/37625 (76.207%), Loss: 1.1275\n",
      "Epoch: 37, Batch: 28929/37625 (76.888%), Loss: 1.5239\n",
      "Epoch: 37, Batch: 29185/37625 (77.568%), Loss: 0.8400\n",
      "Epoch: 37, Batch: 29441/37625 (78.249%), Loss: 1.0265\n",
      "Epoch: 37, Batch: 29697/37625 (78.929%), Loss: 0.9648\n",
      "Epoch: 37, Batch: 29953/37625 (79.609%), Loss: 0.7758\n",
      "Epoch: 37, Batch: 30209/37625 (80.290%), Loss: 0.6427\n",
      "Epoch: 37, Batch: 30465/37625 (80.970%), Loss: 0.8525\n",
      "Epoch: 37, Batch: 30721/37625 (81.650%), Loss: 0.8461\n",
      "Epoch: 37, Batch: 30977/37625 (82.331%), Loss: 0.7481\n",
      "Epoch: 37, Batch: 31233/37625 (83.011%), Loss: 2.0566\n",
      "Epoch: 37, Batch: 31489/37625 (83.692%), Loss: 0.8046\n",
      "Epoch: 37, Batch: 31745/37625 (84.372%), Loss: 1.3794\n",
      "Epoch: 37, Batch: 32001/37625 (85.052%), Loss: 0.6816\n",
      "Epoch: 37, Batch: 32257/37625 (85.733%), Loss: 1.4015\n",
      "Epoch: 37, Batch: 32513/37625 (86.413%), Loss: 0.6730\n",
      "Epoch: 37, Batch: 32769/37625 (87.094%), Loss: 0.6392\n",
      "Epoch: 37, Batch: 33025/37625 (87.774%), Loss: 5.2454\n",
      "Epoch: 37, Batch: 33281/37625 (88.454%), Loss: 0.7178\n",
      "Epoch: 37, Batch: 33537/37625 (89.135%), Loss: 1.6268\n",
      "Epoch: 37, Batch: 33793/37625 (89.815%), Loss: 0.6585\n",
      "Epoch: 37, Batch: 34049/37625 (90.496%), Loss: 0.5314\n",
      "Epoch: 37, Batch: 34305/37625 (91.176%), Loss: 0.8395\n",
      "Epoch: 37, Batch: 34561/37625 (91.856%), Loss: 0.7084\n",
      "Epoch: 37, Batch: 34817/37625 (92.537%), Loss: 1.8334\n",
      "Epoch: 37, Batch: 35073/37625 (93.217%), Loss: 0.7409\n",
      "Epoch: 37, Batch: 35329/37625 (93.898%), Loss: 3.0739\n",
      "Epoch: 37, Batch: 35585/37625 (94.578%), Loss: 1.0865\n",
      "Epoch: 37, Batch: 35841/37625 (95.258%), Loss: 0.6399\n",
      "Epoch: 37, Batch: 36097/37625 (95.939%), Loss: 1.4253\n",
      "Epoch: 37, Batch: 36353/37625 (96.619%), Loss: 1.2846\n",
      "Epoch: 37, Batch: 36609/37625 (97.300%), Loss: 0.9382\n",
      "Epoch: 37, Batch: 36865/37625 (97.980%), Loss: 0.9609\n",
      "Epoch: 37, Batch: 37121/37625 (98.660%), Loss: 4.5175\n",
      "Epoch: 37, Batch: 37377/37625 (99.341%), Loss: 0.9366\n",
      "Epoch: 38, Batch: 1/37625 (0.003%), Loss: 0.7882\n",
      "Epoch: 38, Batch: 257/37625 (0.683%), Loss: 0.8282\n",
      "Epoch: 38, Batch: 513/37625 (1.363%), Loss: 0.7082\n",
      "Epoch: 38, Batch: 769/37625 (2.044%), Loss: 0.7099\n",
      "Epoch: 38, Batch: 1025/37625 (2.724%), Loss: 1.5457\n",
      "Epoch: 38, Batch: 1281/37625 (3.405%), Loss: 0.9659\n",
      "Epoch: 38, Batch: 1537/37625 (4.085%), Loss: 2.3579\n",
      "Epoch: 38, Batch: 1793/37625 (4.765%), Loss: 0.7661\n",
      "Epoch: 38, Batch: 2049/37625 (5.446%), Loss: 0.5834\n",
      "Epoch: 38, Batch: 2305/37625 (6.126%), Loss: 0.8830\n",
      "Epoch: 38, Batch: 2561/37625 (6.807%), Loss: 0.6520\n",
      "Epoch: 38, Batch: 2817/37625 (7.487%), Loss: 0.9334\n",
      "Epoch: 38, Batch: 3073/37625 (8.167%), Loss: 3.1100\n",
      "Epoch: 38, Batch: 3329/37625 (8.848%), Loss: 1.0311\n",
      "Epoch: 38, Batch: 3585/37625 (9.528%), Loss: 1.0049\n",
      "Epoch: 38, Batch: 3841/37625 (10.209%), Loss: 0.8409\n",
      "Epoch: 38, Batch: 4097/37625 (10.889%), Loss: 0.7877\n",
      "Epoch: 38, Batch: 4353/37625 (11.569%), Loss: 0.7500\n",
      "Epoch: 38, Batch: 4609/37625 (12.250%), Loss: 3.3926\n",
      "Epoch: 38, Batch: 4865/37625 (12.930%), Loss: 1.2039\n",
      "Epoch: 38, Batch: 5121/37625 (13.611%), Loss: 0.8196\n",
      "Epoch: 38, Batch: 5377/37625 (14.291%), Loss: 0.5625\n",
      "Epoch: 38, Batch: 5633/37625 (14.971%), Loss: 2.9858\n",
      "Epoch: 38, Batch: 5889/37625 (15.652%), Loss: 0.7284\n",
      "Epoch: 38, Batch: 6145/37625 (16.332%), Loss: 0.7888\n",
      "Epoch: 38, Batch: 6401/37625 (17.013%), Loss: 1.2690\n",
      "Epoch: 38, Batch: 6657/37625 (17.693%), Loss: 1.9685\n",
      "Epoch: 38, Batch: 6913/37625 (18.373%), Loss: 0.9608\n",
      "Epoch: 38, Batch: 7169/37625 (19.054%), Loss: 1.1824\n",
      "Epoch: 38, Batch: 7425/37625 (19.734%), Loss: 0.8192\n",
      "Epoch: 38, Batch: 7681/37625 (20.415%), Loss: 0.8934\n",
      "Epoch: 38, Batch: 7937/37625 (21.095%), Loss: 0.9970\n",
      "Epoch: 38, Batch: 8193/37625 (21.775%), Loss: 0.8573\n",
      "Epoch: 38, Batch: 8449/37625 (22.456%), Loss: 1.2490\n",
      "Epoch: 38, Batch: 8705/37625 (23.136%), Loss: 0.8407\n",
      "Epoch: 38, Batch: 8961/37625 (23.817%), Loss: 0.9118\n",
      "Epoch: 38, Batch: 9217/37625 (24.497%), Loss: 5.3975\n",
      "Epoch: 38, Batch: 9473/37625 (25.177%), Loss: 2.1325\n",
      "Epoch: 38, Batch: 9729/37625 (25.858%), Loss: 0.8837\n",
      "Epoch: 38, Batch: 9985/37625 (26.538%), Loss: 0.8608\n",
      "Epoch: 38, Batch: 10241/37625 (27.219%), Loss: 1.0894\n",
      "Epoch: 38, Batch: 10497/37625 (27.899%), Loss: 1.2078\n",
      "Epoch: 38, Batch: 10753/37625 (28.579%), Loss: 0.6540\n",
      "Epoch: 38, Batch: 11009/37625 (29.260%), Loss: 0.9244\n",
      "Epoch: 38, Batch: 11265/37625 (29.940%), Loss: 0.8589\n",
      "Epoch: 38, Batch: 11521/37625 (30.621%), Loss: 0.9572\n",
      "Epoch: 38, Batch: 11777/37625 (31.301%), Loss: 0.8820\n",
      "Epoch: 38, Batch: 12033/37625 (31.981%), Loss: 0.6168\n",
      "Epoch: 38, Batch: 12289/37625 (32.662%), Loss: 1.5439\n",
      "Epoch: 38, Batch: 12545/37625 (33.342%), Loss: 1.0211\n",
      "Epoch: 38, Batch: 12801/37625 (34.023%), Loss: 0.9429\n",
      "Epoch: 38, Batch: 13057/37625 (34.703%), Loss: 0.9566\n",
      "Epoch: 38, Batch: 13313/37625 (35.383%), Loss: 0.7229\n",
      "Epoch: 38, Batch: 13569/37625 (36.064%), Loss: 1.0335\n",
      "Epoch: 38, Batch: 13825/37625 (36.744%), Loss: 0.7599\n",
      "Epoch: 38, Batch: 14081/37625 (37.425%), Loss: 0.7546\n",
      "Epoch: 38, Batch: 14337/37625 (38.105%), Loss: 1.0751\n",
      "Epoch: 38, Batch: 14593/37625 (38.785%), Loss: 0.9671\n",
      "Epoch: 38, Batch: 14849/37625 (39.466%), Loss: 1.4740\n",
      "Epoch: 38, Batch: 15105/37625 (40.146%), Loss: 0.6780\n",
      "Epoch: 38, Batch: 15361/37625 (40.827%), Loss: 0.5681\n",
      "Epoch: 38, Batch: 15617/37625 (41.507%), Loss: 0.9182\n",
      "Epoch: 38, Batch: 15873/37625 (42.187%), Loss: 1.4023\n",
      "Epoch: 38, Batch: 16129/37625 (42.868%), Loss: 0.8636\n",
      "Epoch: 38, Batch: 16385/37625 (43.548%), Loss: 1.0722\n",
      "Epoch: 38, Batch: 16641/37625 (44.229%), Loss: 1.2349\n",
      "Epoch: 38, Batch: 16897/37625 (44.909%), Loss: 0.8211\n",
      "Epoch: 38, Batch: 17153/37625 (45.589%), Loss: 0.7502\n",
      "Epoch: 38, Batch: 17409/37625 (46.270%), Loss: 0.9809\n",
      "Epoch: 38, Batch: 17665/37625 (46.950%), Loss: 0.8788\n",
      "Epoch: 38, Batch: 17921/37625 (47.631%), Loss: 0.5938\n",
      "Epoch: 38, Batch: 18177/37625 (48.311%), Loss: 1.1588\n",
      "Epoch: 38, Batch: 18433/37625 (48.991%), Loss: 1.2955\n",
      "Epoch: 38, Batch: 18689/37625 (49.672%), Loss: 1.0642\n",
      "Epoch: 38, Batch: 18945/37625 (50.352%), Loss: 0.9541\n",
      "Epoch: 38, Batch: 19201/37625 (51.033%), Loss: 0.9071\n",
      "Epoch: 38, Batch: 19457/37625 (51.713%), Loss: 2.2820\n",
      "Epoch: 38, Batch: 19713/37625 (52.393%), Loss: 1.2191\n",
      "Epoch: 38, Batch: 19969/37625 (53.074%), Loss: 1.1116\n",
      "Epoch: 38, Batch: 20225/37625 (53.754%), Loss: 0.8739\n",
      "Epoch: 38, Batch: 20481/37625 (54.435%), Loss: 0.8955\n",
      "Epoch: 38, Batch: 20737/37625 (55.115%), Loss: 0.5965\n",
      "Epoch: 38, Batch: 20993/37625 (55.795%), Loss: 0.6478\n",
      "Epoch: 38, Batch: 21249/37625 (56.476%), Loss: 0.6214\n",
      "Epoch: 38, Batch: 21505/37625 (57.156%), Loss: 0.5946\n",
      "Epoch: 38, Batch: 21761/37625 (57.837%), Loss: 1.3795\n",
      "Epoch: 38, Batch: 22017/37625 (58.517%), Loss: 3.1822\n",
      "Epoch: 38, Batch: 22273/37625 (59.197%), Loss: 4.6157\n",
      "Epoch: 38, Batch: 22529/37625 (59.878%), Loss: 1.0302\n",
      "Epoch: 38, Batch: 22785/37625 (60.558%), Loss: 1.1660\n",
      "Epoch: 38, Batch: 23041/37625 (61.239%), Loss: 0.8511\n",
      "Epoch: 38, Batch: 23297/37625 (61.919%), Loss: 0.8114\n",
      "Epoch: 38, Batch: 23553/37625 (62.599%), Loss: 0.8183\n",
      "Epoch: 38, Batch: 23809/37625 (63.280%), Loss: 0.8599\n",
      "Epoch: 38, Batch: 24065/37625 (63.960%), Loss: 0.7829\n",
      "Epoch: 38, Batch: 24321/37625 (64.641%), Loss: 1.2175\n",
      "Epoch: 38, Batch: 24577/37625 (65.321%), Loss: 1.2317\n",
      "Epoch: 38, Batch: 24833/37625 (66.001%), Loss: 0.8065\n",
      "Epoch: 38, Batch: 25089/37625 (66.682%), Loss: 1.0569\n",
      "Epoch: 38, Batch: 25345/37625 (67.362%), Loss: 1.1256\n",
      "Epoch: 38, Batch: 25601/37625 (68.043%), Loss: 1.5245\n",
      "Epoch: 38, Batch: 25857/37625 (68.723%), Loss: 0.6710\n",
      "Epoch: 38, Batch: 26113/37625 (69.403%), Loss: 0.7839\n",
      "Epoch: 38, Batch: 26369/37625 (70.084%), Loss: 1.3908\n",
      "Epoch: 38, Batch: 26625/37625 (70.764%), Loss: 0.6543\n",
      "Epoch: 38, Batch: 26881/37625 (71.445%), Loss: 0.7434\n",
      "Epoch: 38, Batch: 27137/37625 (72.125%), Loss: 1.7593\n",
      "Epoch: 38, Batch: 27393/37625 (72.805%), Loss: 0.8080\n",
      "Epoch: 38, Batch: 27649/37625 (73.486%), Loss: 0.8565\n",
      "Epoch: 38, Batch: 27905/37625 (74.166%), Loss: 0.8120\n",
      "Epoch: 38, Batch: 28161/37625 (74.847%), Loss: 0.5235\n",
      "Epoch: 38, Batch: 28417/37625 (75.527%), Loss: 1.3431\n",
      "Epoch: 38, Batch: 28673/37625 (76.207%), Loss: 0.8866\n",
      "Epoch: 38, Batch: 28929/37625 (76.888%), Loss: 0.9006\n",
      "Epoch: 38, Batch: 29185/37625 (77.568%), Loss: 1.7028\n",
      "Epoch: 38, Batch: 29441/37625 (78.249%), Loss: 0.6431\n",
      "Epoch: 38, Batch: 29697/37625 (78.929%), Loss: 0.6205\n",
      "Epoch: 38, Batch: 29953/37625 (79.609%), Loss: 0.6921\n",
      "Epoch: 38, Batch: 30209/37625 (80.290%), Loss: 1.5569\n",
      "Epoch: 38, Batch: 30465/37625 (80.970%), Loss: 1.0315\n",
      "Epoch: 38, Batch: 30721/37625 (81.650%), Loss: 0.5899\n",
      "Epoch: 38, Batch: 30977/37625 (82.331%), Loss: 0.6203\n",
      "Epoch: 38, Batch: 31233/37625 (83.011%), Loss: 0.9880\n",
      "Epoch: 38, Batch: 31489/37625 (83.692%), Loss: 0.7533\n",
      "Epoch: 38, Batch: 31745/37625 (84.372%), Loss: 1.1391\n",
      "Epoch: 38, Batch: 32001/37625 (85.052%), Loss: 0.6908\n",
      "Epoch: 38, Batch: 32257/37625 (85.733%), Loss: 1.0999\n",
      "Epoch: 38, Batch: 32513/37625 (86.413%), Loss: 0.5573\n",
      "Epoch: 38, Batch: 32769/37625 (87.094%), Loss: 1.6366\n",
      "Epoch: 38, Batch: 33025/37625 (87.774%), Loss: 4.9857\n",
      "Epoch: 38, Batch: 33281/37625 (88.454%), Loss: 1.0925\n",
      "Epoch: 38, Batch: 33537/37625 (89.135%), Loss: 1.3504\n",
      "Epoch: 38, Batch: 33793/37625 (89.815%), Loss: 0.8282\n",
      "Epoch: 38, Batch: 34049/37625 (90.496%), Loss: 0.7614\n",
      "Epoch: 38, Batch: 34305/37625 (91.176%), Loss: 0.8403\n",
      "Epoch: 38, Batch: 34561/37625 (91.856%), Loss: 1.0127\n",
      "Epoch: 38, Batch: 34817/37625 (92.537%), Loss: 0.8170\n",
      "Epoch: 38, Batch: 35073/37625 (93.217%), Loss: 0.6253\n",
      "Epoch: 38, Batch: 35329/37625 (93.898%), Loss: 0.7697\n",
      "Epoch: 38, Batch: 35585/37625 (94.578%), Loss: 0.7242\n",
      "Epoch: 38, Batch: 35841/37625 (95.258%), Loss: 1.4086\n",
      "Epoch: 38, Batch: 36097/37625 (95.939%), Loss: 0.9340\n",
      "Epoch: 38, Batch: 36353/37625 (96.619%), Loss: 0.8053\n",
      "Epoch: 38, Batch: 36609/37625 (97.300%), Loss: 1.0307\n",
      "Epoch: 38, Batch: 36865/37625 (97.980%), Loss: 0.6950\n",
      "Epoch: 38, Batch: 37121/37625 (98.660%), Loss: 1.1708\n",
      "Epoch: 38, Batch: 37377/37625 (99.341%), Loss: 0.6156\n",
      "Epoch: 39, Batch: 1/37625 (0.003%), Loss: 0.5245\n",
      "Epoch: 39, Batch: 257/37625 (0.683%), Loss: 0.7671\n",
      "Epoch: 39, Batch: 513/37625 (1.363%), Loss: 0.6025\n",
      "Epoch: 39, Batch: 769/37625 (2.044%), Loss: 0.6740\n",
      "Epoch: 39, Batch: 1025/37625 (2.724%), Loss: 1.5102\n",
      "Epoch: 39, Batch: 1281/37625 (3.405%), Loss: 4.9554\n",
      "Epoch: 39, Batch: 1537/37625 (4.085%), Loss: 0.9997\n",
      "Epoch: 39, Batch: 1793/37625 (4.765%), Loss: 0.8536\n",
      "Epoch: 39, Batch: 2049/37625 (5.446%), Loss: 0.8577\n",
      "Epoch: 39, Batch: 2305/37625 (6.126%), Loss: 1.1549\n",
      "Epoch: 39, Batch: 2561/37625 (6.807%), Loss: 0.9626\n",
      "Epoch: 39, Batch: 2817/37625 (7.487%), Loss: 0.8699\n",
      "Epoch: 39, Batch: 3073/37625 (8.167%), Loss: 0.9822\n",
      "Epoch: 39, Batch: 3329/37625 (8.848%), Loss: 0.5979\n",
      "Epoch: 39, Batch: 3585/37625 (9.528%), Loss: 0.6613\n",
      "Epoch: 39, Batch: 3841/37625 (10.209%), Loss: 1.1474\n",
      "Epoch: 39, Batch: 4097/37625 (10.889%), Loss: 0.8198\n",
      "Epoch: 39, Batch: 4353/37625 (11.569%), Loss: 0.6058\n",
      "Epoch: 39, Batch: 4609/37625 (12.250%), Loss: 0.9542\n",
      "Epoch: 39, Batch: 4865/37625 (12.930%), Loss: 1.5285\n",
      "Epoch: 39, Batch: 5121/37625 (13.611%), Loss: 0.9056\n",
      "Epoch: 39, Batch: 5377/37625 (14.291%), Loss: 1.0838\n",
      "Epoch: 39, Batch: 5633/37625 (14.971%), Loss: 0.9569\n",
      "Epoch: 39, Batch: 5889/37625 (15.652%), Loss: 1.0884\n",
      "Epoch: 39, Batch: 6145/37625 (16.332%), Loss: 0.6581\n",
      "Epoch: 39, Batch: 6401/37625 (17.013%), Loss: 1.0846\n",
      "Epoch: 39, Batch: 6657/37625 (17.693%), Loss: 1.6633\n",
      "Epoch: 39, Batch: 6913/37625 (18.373%), Loss: 0.6624\n",
      "Epoch: 39, Batch: 7169/37625 (19.054%), Loss: 0.8576\n",
      "Epoch: 39, Batch: 7425/37625 (19.734%), Loss: 0.6459\n",
      "Epoch: 39, Batch: 7681/37625 (20.415%), Loss: 0.9979\n",
      "Epoch: 39, Batch: 7937/37625 (21.095%), Loss: 0.7723\n",
      "Epoch: 39, Batch: 8193/37625 (21.775%), Loss: 0.6776\n",
      "Epoch: 39, Batch: 8449/37625 (22.456%), Loss: 0.7732\n",
      "Epoch: 39, Batch: 8705/37625 (23.136%), Loss: 0.9728\n",
      "Epoch: 39, Batch: 8961/37625 (23.817%), Loss: 1.2156\n",
      "Epoch: 39, Batch: 9217/37625 (24.497%), Loss: 1.2386\n",
      "Epoch: 39, Batch: 9473/37625 (25.177%), Loss: 1.4071\n",
      "Epoch: 39, Batch: 9729/37625 (25.858%), Loss: 1.0028\n",
      "Epoch: 39, Batch: 9985/37625 (26.538%), Loss: 0.7824\n",
      "Epoch: 39, Batch: 10241/37625 (27.219%), Loss: 0.7861\n",
      "Epoch: 39, Batch: 10497/37625 (27.899%), Loss: 0.6716\n",
      "Epoch: 39, Batch: 10753/37625 (28.579%), Loss: 1.0621\n",
      "Epoch: 39, Batch: 11009/37625 (29.260%), Loss: 0.6837\n",
      "Epoch: 39, Batch: 11265/37625 (29.940%), Loss: 0.7612\n",
      "Epoch: 39, Batch: 11521/37625 (30.621%), Loss: 1.4863\n",
      "Epoch: 39, Batch: 11777/37625 (31.301%), Loss: 1.0709\n",
      "Epoch: 39, Batch: 12033/37625 (31.981%), Loss: 0.8803\n",
      "Epoch: 39, Batch: 12289/37625 (32.662%), Loss: 0.8246\n",
      "Epoch: 39, Batch: 12545/37625 (33.342%), Loss: 0.9009\n",
      "Epoch: 39, Batch: 12801/37625 (34.023%), Loss: 3.4435\n",
      "Epoch: 39, Batch: 13057/37625 (34.703%), Loss: 0.7510\n",
      "Epoch: 39, Batch: 13313/37625 (35.383%), Loss: 0.9434\n",
      "Epoch: 39, Batch: 13569/37625 (36.064%), Loss: 0.9705\n",
      "Epoch: 39, Batch: 13825/37625 (36.744%), Loss: 0.6769\n",
      "Epoch: 39, Batch: 14081/37625 (37.425%), Loss: 1.0616\n",
      "Epoch: 39, Batch: 14337/37625 (38.105%), Loss: 1.3187\n",
      "Epoch: 39, Batch: 14593/37625 (38.785%), Loss: 0.6363\n",
      "Epoch: 39, Batch: 14849/37625 (39.466%), Loss: 0.7105\n",
      "Epoch: 39, Batch: 15105/37625 (40.146%), Loss: 0.7543\n",
      "Epoch: 39, Batch: 15361/37625 (40.827%), Loss: 1.1042\n",
      "Epoch: 39, Batch: 15617/37625 (41.507%), Loss: 0.8774\n",
      "Epoch: 39, Batch: 15873/37625 (42.187%), Loss: 1.3649\n",
      "Epoch: 39, Batch: 16129/37625 (42.868%), Loss: 1.1333\n",
      "Epoch: 39, Batch: 16385/37625 (43.548%), Loss: 0.6796\n",
      "Epoch: 39, Batch: 16641/37625 (44.229%), Loss: 1.4173\n",
      "Epoch: 39, Batch: 16897/37625 (44.909%), Loss: 4.1299\n",
      "Epoch: 39, Batch: 17153/37625 (45.589%), Loss: 0.5305\n",
      "Epoch: 39, Batch: 17409/37625 (46.270%), Loss: 0.6531\n",
      "Epoch: 39, Batch: 17665/37625 (46.950%), Loss: 0.7622\n",
      "Epoch: 39, Batch: 17921/37625 (47.631%), Loss: 1.3696\n",
      "Epoch: 39, Batch: 18177/37625 (48.311%), Loss: 0.5997\n",
      "Epoch: 39, Batch: 18433/37625 (48.991%), Loss: 0.6819\n",
      "Epoch: 39, Batch: 18689/37625 (49.672%), Loss: 1.1414\n",
      "Epoch: 39, Batch: 18945/37625 (50.352%), Loss: 0.8246\n",
      "Epoch: 39, Batch: 19201/37625 (51.033%), Loss: 1.1892\n",
      "Epoch: 39, Batch: 19457/37625 (51.713%), Loss: 0.8082\n",
      "Epoch: 39, Batch: 19713/37625 (52.393%), Loss: 1.0267\n",
      "Epoch: 39, Batch: 19969/37625 (53.074%), Loss: 0.7692\n",
      "Epoch: 39, Batch: 20225/37625 (53.754%), Loss: 1.3268\n",
      "Epoch: 39, Batch: 20481/37625 (54.435%), Loss: 1.0151\n",
      "Epoch: 39, Batch: 20737/37625 (55.115%), Loss: 0.5429\n",
      "Epoch: 39, Batch: 20993/37625 (55.795%), Loss: 1.2676\n",
      "Epoch: 39, Batch: 21249/37625 (56.476%), Loss: 2.2358\n",
      "Epoch: 39, Batch: 21505/37625 (57.156%), Loss: 3.5469\n",
      "Epoch: 39, Batch: 21761/37625 (57.837%), Loss: 1.2037\n",
      "Epoch: 39, Batch: 22017/37625 (58.517%), Loss: 0.8396\n",
      "Epoch: 39, Batch: 22273/37625 (59.197%), Loss: 1.3612\n",
      "Epoch: 39, Batch: 22529/37625 (59.878%), Loss: 1.1284\n",
      "Epoch: 39, Batch: 22785/37625 (60.558%), Loss: 1.4778\n",
      "Epoch: 39, Batch: 23041/37625 (61.239%), Loss: 3.1568\n",
      "Epoch: 39, Batch: 23297/37625 (61.919%), Loss: 0.8131\n",
      "Epoch: 39, Batch: 23553/37625 (62.599%), Loss: 0.9096\n",
      "Epoch: 39, Batch: 23809/37625 (63.280%), Loss: 0.6898\n",
      "Epoch: 39, Batch: 24065/37625 (63.960%), Loss: 0.5195\n",
      "Epoch: 39, Batch: 24321/37625 (64.641%), Loss: 0.8395\n",
      "Epoch: 39, Batch: 24577/37625 (65.321%), Loss: 0.9404\n",
      "Epoch: 39, Batch: 24833/37625 (66.001%), Loss: 0.7063\n",
      "Epoch: 39, Batch: 25089/37625 (66.682%), Loss: 0.8505\n",
      "Epoch: 39, Batch: 25345/37625 (67.362%), Loss: 1.7202\n",
      "Epoch: 39, Batch: 25601/37625 (68.043%), Loss: 1.0102\n",
      "Epoch: 39, Batch: 25857/37625 (68.723%), Loss: 1.0059\n",
      "Epoch: 39, Batch: 26113/37625 (69.403%), Loss: 0.6961\n",
      "Epoch: 39, Batch: 26369/37625 (70.084%), Loss: 0.6267\n",
      "Epoch: 39, Batch: 26625/37625 (70.764%), Loss: 0.8098\n",
      "Epoch: 39, Batch: 26881/37625 (71.445%), Loss: 2.0878\n",
      "Epoch: 39, Batch: 27137/37625 (72.125%), Loss: 0.6097\n",
      "Epoch: 39, Batch: 27393/37625 (72.805%), Loss: 0.7087\n",
      "Epoch: 39, Batch: 27649/37625 (73.486%), Loss: 0.7709\n",
      "Epoch: 39, Batch: 27905/37625 (74.166%), Loss: 0.8931\n",
      "Epoch: 39, Batch: 28161/37625 (74.847%), Loss: 0.7510\n",
      "Epoch: 39, Batch: 28417/37625 (75.527%), Loss: 0.7705\n",
      "Epoch: 39, Batch: 28673/37625 (76.207%), Loss: 0.9441\n",
      "Epoch: 39, Batch: 28929/37625 (76.888%), Loss: 0.9519\n",
      "Epoch: 39, Batch: 29185/37625 (77.568%), Loss: 0.7941\n",
      "Epoch: 39, Batch: 29441/37625 (78.249%), Loss: 0.7807\n",
      "Epoch: 39, Batch: 29697/37625 (78.929%), Loss: 0.8172\n",
      "Epoch: 39, Batch: 29953/37625 (79.609%), Loss: 1.3416\n",
      "Epoch: 39, Batch: 30209/37625 (80.290%), Loss: 0.6894\n",
      "Epoch: 39, Batch: 30465/37625 (80.970%), Loss: 5.4187\n",
      "Epoch: 39, Batch: 30721/37625 (81.650%), Loss: 0.9386\n",
      "Epoch: 39, Batch: 30977/37625 (82.331%), Loss: 0.7481\n",
      "Epoch: 39, Batch: 31233/37625 (83.011%), Loss: 0.8415\n",
      "Epoch: 39, Batch: 31489/37625 (83.692%), Loss: 0.6801\n",
      "Epoch: 39, Batch: 31745/37625 (84.372%), Loss: 1.3688\n",
      "Epoch: 39, Batch: 32001/37625 (85.052%), Loss: 1.1179\n",
      "Epoch: 39, Batch: 32257/37625 (85.733%), Loss: 0.7476\n",
      "Epoch: 39, Batch: 32513/37625 (86.413%), Loss: 1.0128\n",
      "Epoch: 39, Batch: 32769/37625 (87.094%), Loss: 0.6840\n",
      "Epoch: 39, Batch: 33025/37625 (87.774%), Loss: 0.8054\n",
      "Epoch: 39, Batch: 33281/37625 (88.454%), Loss: 0.7592\n",
      "Epoch: 39, Batch: 33537/37625 (89.135%), Loss: 1.0522\n",
      "Epoch: 39, Batch: 33793/37625 (89.815%), Loss: 4.4520\n",
      "Epoch: 39, Batch: 34049/37625 (90.496%), Loss: 0.6667\n",
      "Epoch: 39, Batch: 34305/37625 (91.176%), Loss: 2.0774\n",
      "Epoch: 39, Batch: 34561/37625 (91.856%), Loss: 1.6643\n",
      "Epoch: 39, Batch: 34817/37625 (92.537%), Loss: 1.3966\n",
      "Epoch: 39, Batch: 35073/37625 (93.217%), Loss: 1.0215\n",
      "Epoch: 39, Batch: 35329/37625 (93.898%), Loss: 0.8679\n",
      "Epoch: 39, Batch: 35585/37625 (94.578%), Loss: 1.2841\n",
      "Epoch: 39, Batch: 35841/37625 (95.258%), Loss: 0.8364\n",
      "Epoch: 39, Batch: 36097/37625 (95.939%), Loss: 0.9340\n",
      "Epoch: 39, Batch: 36353/37625 (96.619%), Loss: 1.2653\n",
      "Epoch: 39, Batch: 36609/37625 (97.300%), Loss: 0.8685\n",
      "Epoch: 39, Batch: 36865/37625 (97.980%), Loss: 0.9768\n",
      "Epoch: 39, Batch: 37121/37625 (98.660%), Loss: 1.2911\n",
      "Epoch: 39, Batch: 37377/37625 (99.341%), Loss: 0.9053\n",
      "Epoch: 40, Batch: 1/37625 (0.003%), Loss: 0.8657\n",
      "Epoch: 40, Batch: 257/37625 (0.683%), Loss: 0.7333\n",
      "Epoch: 40, Batch: 513/37625 (1.363%), Loss: 0.8972\n",
      "Epoch: 40, Batch: 769/37625 (2.044%), Loss: 1.0771\n",
      "Epoch: 40, Batch: 1025/37625 (2.724%), Loss: 1.2617\n",
      "Epoch: 40, Batch: 1281/37625 (3.405%), Loss: 1.1901\n",
      "Epoch: 40, Batch: 1537/37625 (4.085%), Loss: 0.7078\n",
      "Epoch: 40, Batch: 1793/37625 (4.765%), Loss: 0.7388\n",
      "Epoch: 40, Batch: 2049/37625 (5.446%), Loss: 0.8927\n",
      "Epoch: 40, Batch: 2305/37625 (6.126%), Loss: 0.5829\n",
      "Epoch: 40, Batch: 2561/37625 (6.807%), Loss: 0.8800\n",
      "Epoch: 40, Batch: 2817/37625 (7.487%), Loss: 1.7030\n",
      "Epoch: 40, Batch: 3073/37625 (8.167%), Loss: 0.7456\n",
      "Epoch: 40, Batch: 3329/37625 (8.848%), Loss: 0.8400\n",
      "Epoch: 40, Batch: 3585/37625 (9.528%), Loss: 4.4954\n",
      "Epoch: 40, Batch: 3841/37625 (10.209%), Loss: 0.7060\n",
      "Epoch: 40, Batch: 4097/37625 (10.889%), Loss: 0.7172\n",
      "Epoch: 40, Batch: 4353/37625 (11.569%), Loss: 0.7119\n",
      "Epoch: 40, Batch: 4609/37625 (12.250%), Loss: 0.9965\n",
      "Epoch: 40, Batch: 4865/37625 (12.930%), Loss: 0.7975\n",
      "Epoch: 40, Batch: 5121/37625 (13.611%), Loss: 1.5162\n",
      "Epoch: 40, Batch: 5377/37625 (14.291%), Loss: 1.0505\n",
      "Epoch: 40, Batch: 5633/37625 (14.971%), Loss: 0.8039\n",
      "Epoch: 40, Batch: 5889/37625 (15.652%), Loss: 0.8739\n",
      "Epoch: 40, Batch: 6145/37625 (16.332%), Loss: 1.0287\n",
      "Epoch: 40, Batch: 6401/37625 (17.013%), Loss: 0.9767\n",
      "Epoch: 40, Batch: 6657/37625 (17.693%), Loss: 0.5613\n",
      "Epoch: 40, Batch: 6913/37625 (18.373%), Loss: 2.1822\n",
      "Epoch: 40, Batch: 7169/37625 (19.054%), Loss: 1.8181\n",
      "Epoch: 40, Batch: 7425/37625 (19.734%), Loss: 1.4849\n",
      "Epoch: 40, Batch: 7681/37625 (20.415%), Loss: 7.6061\n",
      "Epoch: 40, Batch: 7937/37625 (21.095%), Loss: 0.8592\n",
      "Epoch: 40, Batch: 8193/37625 (21.775%), Loss: 1.2595\n",
      "Epoch: 40, Batch: 8449/37625 (22.456%), Loss: 0.7452\n",
      "Epoch: 40, Batch: 8705/37625 (23.136%), Loss: 0.7372\n",
      "Epoch: 40, Batch: 8961/37625 (23.817%), Loss: 0.6012\n",
      "Epoch: 40, Batch: 9217/37625 (24.497%), Loss: 0.7971\n",
      "Epoch: 40, Batch: 9473/37625 (25.177%), Loss: 0.5422\n",
      "Epoch: 40, Batch: 9729/37625 (25.858%), Loss: 0.6466\n",
      "Epoch: 40, Batch: 9985/37625 (26.538%), Loss: 0.5925\n",
      "Epoch: 40, Batch: 10241/37625 (27.219%), Loss: 1.0465\n",
      "Epoch: 40, Batch: 10497/37625 (27.899%), Loss: 0.8395\n",
      "Epoch: 40, Batch: 10753/37625 (28.579%), Loss: 0.8297\n",
      "Epoch: 40, Batch: 11009/37625 (29.260%), Loss: 0.9923\n",
      "Epoch: 40, Batch: 11265/37625 (29.940%), Loss: 0.8783\n",
      "Epoch: 40, Batch: 11521/37625 (30.621%), Loss: 1.0164\n",
      "Epoch: 40, Batch: 11777/37625 (31.301%), Loss: 0.8265\n",
      "Epoch: 40, Batch: 12033/37625 (31.981%), Loss: 1.0027\n",
      "Epoch: 40, Batch: 12289/37625 (32.662%), Loss: 1.7291\n",
      "Epoch: 40, Batch: 12545/37625 (33.342%), Loss: 1.2972\n",
      "Epoch: 40, Batch: 12801/37625 (34.023%), Loss: 0.5200\n",
      "Epoch: 40, Batch: 13057/37625 (34.703%), Loss: 0.8557\n",
      "Epoch: 40, Batch: 13313/37625 (35.383%), Loss: 0.9814\n",
      "Epoch: 40, Batch: 13569/37625 (36.064%), Loss: 0.9312\n",
      "Epoch: 40, Batch: 13825/37625 (36.744%), Loss: 0.5881\n",
      "Epoch: 40, Batch: 14081/37625 (37.425%), Loss: 0.9048\n",
      "Epoch: 40, Batch: 14337/37625 (38.105%), Loss: 1.4337\n",
      "Epoch: 40, Batch: 14593/37625 (38.785%), Loss: 3.9363\n",
      "Epoch: 40, Batch: 14849/37625 (39.466%), Loss: 0.7577\n",
      "Epoch: 40, Batch: 15105/37625 (40.146%), Loss: 0.8732\n",
      "Epoch: 40, Batch: 15361/37625 (40.827%), Loss: 0.6549\n",
      "Epoch: 40, Batch: 15617/37625 (41.507%), Loss: 0.8090\n",
      "Epoch: 40, Batch: 15873/37625 (42.187%), Loss: 0.6804\n",
      "Epoch: 40, Batch: 16129/37625 (42.868%), Loss: 0.7455\n",
      "Epoch: 40, Batch: 16385/37625 (43.548%), Loss: 0.9589\n",
      "Epoch: 40, Batch: 16641/37625 (44.229%), Loss: 0.5574\n",
      "Epoch: 40, Batch: 16897/37625 (44.909%), Loss: 0.8560\n",
      "Epoch: 40, Batch: 17153/37625 (45.589%), Loss: 1.0304\n",
      "Epoch: 40, Batch: 17409/37625 (46.270%), Loss: 1.0317\n",
      "Epoch: 40, Batch: 17665/37625 (46.950%), Loss: 1.3197\n",
      "Epoch: 40, Batch: 17921/37625 (47.631%), Loss: 1.2289\n",
      "Epoch: 40, Batch: 18177/37625 (48.311%), Loss: 0.6631\n",
      "Epoch: 40, Batch: 18433/37625 (48.991%), Loss: 0.8927\n",
      "Epoch: 40, Batch: 18689/37625 (49.672%), Loss: 0.6458\n",
      "Epoch: 40, Batch: 18945/37625 (50.352%), Loss: 1.0790\n",
      "Epoch: 40, Batch: 19201/37625 (51.033%), Loss: 1.5772\n",
      "Epoch: 40, Batch: 19457/37625 (51.713%), Loss: 1.2585\n",
      "Epoch: 40, Batch: 19713/37625 (52.393%), Loss: 0.7722\n",
      "Epoch: 40, Batch: 19969/37625 (53.074%), Loss: 0.7906\n",
      "Epoch: 40, Batch: 20225/37625 (53.754%), Loss: 2.1066\n",
      "Epoch: 40, Batch: 20481/37625 (54.435%), Loss: 0.7550\n",
      "Epoch: 40, Batch: 20737/37625 (55.115%), Loss: 1.6171\n",
      "Epoch: 40, Batch: 20993/37625 (55.795%), Loss: 1.1058\n",
      "Epoch: 40, Batch: 21249/37625 (56.476%), Loss: 1.0982\n",
      "Epoch: 40, Batch: 21505/37625 (57.156%), Loss: 0.7597\n",
      "Epoch: 40, Batch: 21761/37625 (57.837%), Loss: 1.3031\n",
      "Epoch: 40, Batch: 22017/37625 (58.517%), Loss: 0.6890\n",
      "Epoch: 40, Batch: 22273/37625 (59.197%), Loss: 0.8439\n",
      "Epoch: 40, Batch: 22529/37625 (59.878%), Loss: 1.3116\n",
      "Epoch: 40, Batch: 22785/37625 (60.558%), Loss: 1.2294\n",
      "Epoch: 40, Batch: 23041/37625 (61.239%), Loss: 0.5431\n",
      "Epoch: 40, Batch: 23297/37625 (61.919%), Loss: 1.1146\n",
      "Epoch: 40, Batch: 23553/37625 (62.599%), Loss: 1.0760\n",
      "Epoch: 40, Batch: 23809/37625 (63.280%), Loss: 0.8872\n",
      "Epoch: 40, Batch: 24065/37625 (63.960%), Loss: 0.8916\n",
      "Epoch: 40, Batch: 24321/37625 (64.641%), Loss: 0.7397\n",
      "Epoch: 40, Batch: 24577/37625 (65.321%), Loss: 5.4456\n",
      "Epoch: 40, Batch: 24833/37625 (66.001%), Loss: 0.5612\n",
      "Epoch: 40, Batch: 25089/37625 (66.682%), Loss: 0.9807\n",
      "Epoch: 40, Batch: 25345/37625 (67.362%), Loss: 0.8701\n",
      "Epoch: 40, Batch: 25601/37625 (68.043%), Loss: 0.6287\n",
      "Epoch: 40, Batch: 25857/37625 (68.723%), Loss: 0.6739\n",
      "Epoch: 40, Batch: 26113/37625 (69.403%), Loss: 1.0249\n",
      "Epoch: 40, Batch: 26369/37625 (70.084%), Loss: 0.9864\n",
      "Epoch: 40, Batch: 26625/37625 (70.764%), Loss: 1.3860\n",
      "Epoch: 40, Batch: 26881/37625 (71.445%), Loss: 0.7615\n",
      "Epoch: 40, Batch: 27137/37625 (72.125%), Loss: 0.7523\n",
      "Epoch: 40, Batch: 27393/37625 (72.805%), Loss: 1.0237\n",
      "Epoch: 40, Batch: 27649/37625 (73.486%), Loss: 0.9727\n",
      "Epoch: 40, Batch: 27905/37625 (74.166%), Loss: 2.5728\n",
      "Epoch: 40, Batch: 28161/37625 (74.847%), Loss: 1.2255\n",
      "Epoch: 40, Batch: 28417/37625 (75.527%), Loss: 0.8709\n",
      "Epoch: 40, Batch: 28673/37625 (76.207%), Loss: 0.8960\n",
      "Epoch: 40, Batch: 28929/37625 (76.888%), Loss: 1.0883\n",
      "Epoch: 40, Batch: 29185/37625 (77.568%), Loss: 0.9655\n",
      "Epoch: 40, Batch: 29441/37625 (78.249%), Loss: 2.4223\n",
      "Epoch: 40, Batch: 29697/37625 (78.929%), Loss: 0.7607\n",
      "Epoch: 40, Batch: 29953/37625 (79.609%), Loss: 0.9032\n",
      "Epoch: 40, Batch: 30209/37625 (80.290%), Loss: 1.0447\n",
      "Epoch: 40, Batch: 30465/37625 (80.970%), Loss: 1.7276\n",
      "Epoch: 40, Batch: 30721/37625 (81.650%), Loss: 0.9409\n",
      "Epoch: 40, Batch: 30977/37625 (82.331%), Loss: 1.0666\n",
      "Epoch: 40, Batch: 31233/37625 (83.011%), Loss: 0.7925\n",
      "Epoch: 40, Batch: 31489/37625 (83.692%), Loss: 0.7758\n",
      "Epoch: 40, Batch: 31745/37625 (84.372%), Loss: 1.0104\n",
      "Epoch: 40, Batch: 32001/37625 (85.052%), Loss: 0.8329\n",
      "Epoch: 40, Batch: 32257/37625 (85.733%), Loss: 1.1247\n",
      "Epoch: 40, Batch: 32513/37625 (86.413%), Loss: 1.2373\n",
      "Epoch: 40, Batch: 32769/37625 (87.094%), Loss: 2.6094\n",
      "Epoch: 40, Batch: 33025/37625 (87.774%), Loss: 0.7464\n",
      "Epoch: 40, Batch: 33281/37625 (88.454%), Loss: 1.7481\n",
      "Epoch: 40, Batch: 33537/37625 (89.135%), Loss: 0.8103\n",
      "Epoch: 40, Batch: 33793/37625 (89.815%), Loss: 0.9103\n",
      "Epoch: 40, Batch: 34049/37625 (90.496%), Loss: 0.9172\n",
      "Epoch: 40, Batch: 34305/37625 (91.176%), Loss: 1.1280\n",
      "Epoch: 40, Batch: 34561/37625 (91.856%), Loss: 0.9030\n",
      "Epoch: 40, Batch: 34817/37625 (92.537%), Loss: 1.4313\n",
      "Epoch: 40, Batch: 35073/37625 (93.217%), Loss: 0.6268\n",
      "Epoch: 40, Batch: 35329/37625 (93.898%), Loss: 0.8649\n",
      "Epoch: 40, Batch: 35585/37625 (94.578%), Loss: 0.5146\n",
      "Epoch: 40, Batch: 35841/37625 (95.258%), Loss: 1.0577\n",
      "Epoch: 40, Batch: 36097/37625 (95.939%), Loss: 0.8795\n",
      "Epoch: 40, Batch: 36353/37625 (96.619%), Loss: 1.1020\n",
      "Epoch: 40, Batch: 36609/37625 (97.300%), Loss: 0.6792\n",
      "Epoch: 40, Batch: 36865/37625 (97.980%), Loss: 0.9593\n",
      "Epoch: 40, Batch: 37121/37625 (98.660%), Loss: 0.8113\n",
      "Epoch: 40, Batch: 37377/37625 (99.341%), Loss: 0.6477\n",
      "Epoch: 41, Batch: 1/37625 (0.003%), Loss: 0.8115\n",
      "Epoch: 41, Batch: 257/37625 (0.683%), Loss: 0.6948\n",
      "Epoch: 41, Batch: 513/37625 (1.363%), Loss: 5.8041\n",
      "Epoch: 41, Batch: 769/37625 (2.044%), Loss: 1.4448\n",
      "Epoch: 41, Batch: 1025/37625 (2.724%), Loss: 1.4371\n",
      "Epoch: 41, Batch: 1281/37625 (3.405%), Loss: 0.7020\n",
      "Epoch: 41, Batch: 1537/37625 (4.085%), Loss: 0.7704\n",
      "Epoch: 41, Batch: 1793/37625 (4.765%), Loss: 1.3121\n",
      "Epoch: 41, Batch: 2049/37625 (5.446%), Loss: 1.3572\n",
      "Epoch: 41, Batch: 2305/37625 (6.126%), Loss: 0.4842\n",
      "Epoch: 41, Batch: 2561/37625 (6.807%), Loss: 0.8068\n",
      "Epoch: 41, Batch: 2817/37625 (7.487%), Loss: 0.7382\n",
      "Epoch: 41, Batch: 3073/37625 (8.167%), Loss: 0.9548\n",
      "Epoch: 41, Batch: 3329/37625 (8.848%), Loss: 1.0912\n",
      "Epoch: 41, Batch: 3585/37625 (9.528%), Loss: 1.0911\n",
      "Epoch: 41, Batch: 3841/37625 (10.209%), Loss: 1.0195\n",
      "Epoch: 41, Batch: 4097/37625 (10.889%), Loss: 0.8119\n",
      "Epoch: 41, Batch: 4353/37625 (11.569%), Loss: 0.8512\n",
      "Epoch: 41, Batch: 4609/37625 (12.250%), Loss: 0.6580\n",
      "Epoch: 41, Batch: 4865/37625 (12.930%), Loss: 0.7874\n",
      "Epoch: 41, Batch: 5121/37625 (13.611%), Loss: 0.8552\n",
      "Epoch: 41, Batch: 5377/37625 (14.291%), Loss: 1.5981\n",
      "Epoch: 41, Batch: 5633/37625 (14.971%), Loss: 0.8717\n",
      "Epoch: 41, Batch: 5889/37625 (15.652%), Loss: 0.8351\n",
      "Epoch: 41, Batch: 6145/37625 (16.332%), Loss: 0.8256\n",
      "Epoch: 41, Batch: 6401/37625 (17.013%), Loss: 1.4245\n",
      "Epoch: 41, Batch: 6657/37625 (17.693%), Loss: 0.8512\n",
      "Epoch: 41, Batch: 6913/37625 (18.373%), Loss: 0.6159\n",
      "Epoch: 41, Batch: 7169/37625 (19.054%), Loss: 0.9300\n",
      "Epoch: 41, Batch: 7425/37625 (19.734%), Loss: 0.8446\n",
      "Epoch: 41, Batch: 7681/37625 (20.415%), Loss: 1.0044\n",
      "Epoch: 41, Batch: 7937/37625 (21.095%), Loss: 1.3478\n",
      "Epoch: 41, Batch: 8193/37625 (21.775%), Loss: 1.0647\n",
      "Epoch: 41, Batch: 8449/37625 (22.456%), Loss: 0.8122\n",
      "Epoch: 41, Batch: 8705/37625 (23.136%), Loss: 3.3356\n",
      "Epoch: 41, Batch: 8961/37625 (23.817%), Loss: 0.7403\n",
      "Epoch: 41, Batch: 9217/37625 (24.497%), Loss: 0.9832\n",
      "Epoch: 41, Batch: 9473/37625 (25.177%), Loss: 0.9792\n",
      "Epoch: 41, Batch: 9729/37625 (25.858%), Loss: 0.9562\n",
      "Epoch: 41, Batch: 9985/37625 (26.538%), Loss: 0.6423\n",
      "Epoch: 41, Batch: 10241/37625 (27.219%), Loss: 2.0374\n",
      "Epoch: 41, Batch: 10497/37625 (27.899%), Loss: 4.1289\n",
      "Epoch: 41, Batch: 10753/37625 (28.579%), Loss: 1.2158\n",
      "Epoch: 41, Batch: 11009/37625 (29.260%), Loss: 1.2142\n",
      "Epoch: 41, Batch: 11265/37625 (29.940%), Loss: 0.8808\n",
      "Epoch: 41, Batch: 11521/37625 (30.621%), Loss: 1.2866\n",
      "Epoch: 41, Batch: 11777/37625 (31.301%), Loss: 0.6779\n",
      "Epoch: 41, Batch: 12033/37625 (31.981%), Loss: 0.7011\n",
      "Epoch: 41, Batch: 12289/37625 (32.662%), Loss: 0.7923\n",
      "Epoch: 41, Batch: 12545/37625 (33.342%), Loss: 1.0709\n",
      "Epoch: 41, Batch: 12801/37625 (34.023%), Loss: 1.3640\n",
      "Epoch: 41, Batch: 13057/37625 (34.703%), Loss: 0.9421\n",
      "Epoch: 41, Batch: 13313/37625 (35.383%), Loss: 0.8853\n",
      "Epoch: 41, Batch: 13569/37625 (36.064%), Loss: 1.1456\n",
      "Epoch: 41, Batch: 13825/37625 (36.744%), Loss: 0.7998\n",
      "Epoch: 41, Batch: 14081/37625 (37.425%), Loss: 1.2595\n",
      "Epoch: 41, Batch: 14337/37625 (38.105%), Loss: 0.8423\n",
      "Epoch: 41, Batch: 14593/37625 (38.785%), Loss: 2.5691\n",
      "Epoch: 41, Batch: 14849/37625 (39.466%), Loss: 0.5865\n",
      "Epoch: 41, Batch: 15105/37625 (40.146%), Loss: 0.8018\n",
      "Epoch: 41, Batch: 15361/37625 (40.827%), Loss: 0.7583\n",
      "Epoch: 41, Batch: 15617/37625 (41.507%), Loss: 0.4559\n",
      "Epoch: 41, Batch: 15873/37625 (42.187%), Loss: 0.9176\n",
      "Epoch: 41, Batch: 16129/37625 (42.868%), Loss: 0.7895\n",
      "Epoch: 41, Batch: 16385/37625 (43.548%), Loss: 5.0211\n",
      "Epoch: 41, Batch: 16641/37625 (44.229%), Loss: 0.7158\n",
      "Epoch: 41, Batch: 16897/37625 (44.909%), Loss: 1.8334\n",
      "Epoch: 41, Batch: 17153/37625 (45.589%), Loss: 1.6877\n",
      "Epoch: 41, Batch: 17409/37625 (46.270%), Loss: 0.6762\n",
      "Epoch: 41, Batch: 17665/37625 (46.950%), Loss: 0.9906\n",
      "Epoch: 41, Batch: 17921/37625 (47.631%), Loss: 0.7811\n",
      "Epoch: 41, Batch: 18177/37625 (48.311%), Loss: 1.1258\n",
      "Epoch: 41, Batch: 18433/37625 (48.991%), Loss: 1.0340\n",
      "Epoch: 41, Batch: 18689/37625 (49.672%), Loss: 0.7963\n",
      "Epoch: 41, Batch: 18945/37625 (50.352%), Loss: 1.2245\n",
      "Epoch: 41, Batch: 19201/37625 (51.033%), Loss: 1.5931\n",
      "Epoch: 41, Batch: 19457/37625 (51.713%), Loss: 0.7682\n",
      "Epoch: 41, Batch: 19713/37625 (52.393%), Loss: 1.0874\n",
      "Epoch: 41, Batch: 19969/37625 (53.074%), Loss: 0.9127\n",
      "Epoch: 41, Batch: 20225/37625 (53.754%), Loss: 0.9294\n",
      "Epoch: 41, Batch: 20481/37625 (54.435%), Loss: 1.1635\n",
      "Epoch: 41, Batch: 20737/37625 (55.115%), Loss: 1.2426\n",
      "Epoch: 41, Batch: 20993/37625 (55.795%), Loss: 2.2016\n",
      "Epoch: 41, Batch: 21249/37625 (56.476%), Loss: 0.9103\n",
      "Epoch: 41, Batch: 21505/37625 (57.156%), Loss: 0.7945\n",
      "Epoch: 41, Batch: 21761/37625 (57.837%), Loss: 1.0496\n",
      "Epoch: 41, Batch: 22017/37625 (58.517%), Loss: 2.7278\n",
      "Epoch: 41, Batch: 22273/37625 (59.197%), Loss: 0.8720\n",
      "Epoch: 41, Batch: 22529/37625 (59.878%), Loss: 1.1491\n",
      "Epoch: 41, Batch: 22785/37625 (60.558%), Loss: 0.6044\n",
      "Epoch: 41, Batch: 23041/37625 (61.239%), Loss: 2.7389\n",
      "Epoch: 41, Batch: 23297/37625 (61.919%), Loss: 1.1532\n",
      "Epoch: 41, Batch: 23553/37625 (62.599%), Loss: 1.1688\n",
      "Epoch: 41, Batch: 23809/37625 (63.280%), Loss: 0.9736\n",
      "Epoch: 41, Batch: 24065/37625 (63.960%), Loss: 0.5254\n",
      "Epoch: 41, Batch: 24321/37625 (64.641%), Loss: 0.6179\n",
      "Epoch: 41, Batch: 24577/37625 (65.321%), Loss: 0.9316\n",
      "Epoch: 41, Batch: 24833/37625 (66.001%), Loss: 0.7940\n",
      "Epoch: 41, Batch: 25089/37625 (66.682%), Loss: 0.6554\n",
      "Epoch: 41, Batch: 25345/37625 (67.362%), Loss: 0.7949\n",
      "Epoch: 41, Batch: 25601/37625 (68.043%), Loss: 0.6057\n",
      "Epoch: 41, Batch: 25857/37625 (68.723%), Loss: 1.1349\n",
      "Epoch: 41, Batch: 26113/37625 (69.403%), Loss: 0.7405\n",
      "Epoch: 41, Batch: 26369/37625 (70.084%), Loss: 0.8637\n",
      "Epoch: 41, Batch: 26625/37625 (70.764%), Loss: 1.0013\n",
      "Epoch: 41, Batch: 26881/37625 (71.445%), Loss: 0.9672\n",
      "Epoch: 41, Batch: 27137/37625 (72.125%), Loss: 1.4527\n",
      "Epoch: 41, Batch: 27393/37625 (72.805%), Loss: 0.9791\n",
      "Epoch: 41, Batch: 27649/37625 (73.486%), Loss: 0.6264\n",
      "Epoch: 41, Batch: 27905/37625 (74.166%), Loss: 1.2505\n",
      "Epoch: 41, Batch: 28161/37625 (74.847%), Loss: 0.7888\n",
      "Epoch: 41, Batch: 28417/37625 (75.527%), Loss: 1.2101\n",
      "Epoch: 41, Batch: 28673/37625 (76.207%), Loss: 0.6918\n",
      "Epoch: 41, Batch: 28929/37625 (76.888%), Loss: 0.6851\n",
      "Epoch: 41, Batch: 29185/37625 (77.568%), Loss: 0.8587\n",
      "Epoch: 41, Batch: 29441/37625 (78.249%), Loss: 1.2976\n",
      "Epoch: 41, Batch: 29697/37625 (78.929%), Loss: 0.6864\n",
      "Epoch: 41, Batch: 29953/37625 (79.609%), Loss: 1.2227\n",
      "Epoch: 41, Batch: 30209/37625 (80.290%), Loss: 1.1719\n",
      "Epoch: 41, Batch: 30465/37625 (80.970%), Loss: 0.9240\n",
      "Epoch: 41, Batch: 30721/37625 (81.650%), Loss: 1.0276\n",
      "Epoch: 41, Batch: 30977/37625 (82.331%), Loss: 0.9383\n",
      "Epoch: 41, Batch: 31233/37625 (83.011%), Loss: 1.0449\n",
      "Epoch: 41, Batch: 31489/37625 (83.692%), Loss: 0.6591\n",
      "Epoch: 41, Batch: 31745/37625 (84.372%), Loss: 0.8187\n",
      "Epoch: 41, Batch: 32001/37625 (85.052%), Loss: 0.7545\n",
      "Epoch: 41, Batch: 32257/37625 (85.733%), Loss: 0.7769\n",
      "Epoch: 41, Batch: 32513/37625 (86.413%), Loss: 0.6623\n",
      "Epoch: 41, Batch: 32769/37625 (87.094%), Loss: 1.6658\n",
      "Epoch: 41, Batch: 33025/37625 (87.774%), Loss: 0.6846\n",
      "Epoch: 41, Batch: 33281/37625 (88.454%), Loss: 0.4536\n",
      "Epoch: 41, Batch: 33537/37625 (89.135%), Loss: 1.0511\n",
      "Epoch: 41, Batch: 33793/37625 (89.815%), Loss: 0.8732\n",
      "Epoch: 41, Batch: 34049/37625 (90.496%), Loss: 0.5853\n",
      "Epoch: 41, Batch: 34305/37625 (91.176%), Loss: 1.0558\n",
      "Epoch: 41, Batch: 34561/37625 (91.856%), Loss: 0.8768\n",
      "Epoch: 41, Batch: 34817/37625 (92.537%), Loss: 1.2359\n",
      "Epoch: 41, Batch: 35073/37625 (93.217%), Loss: 0.7383\n",
      "Epoch: 41, Batch: 35329/37625 (93.898%), Loss: 0.6774\n",
      "Epoch: 41, Batch: 35585/37625 (94.578%), Loss: 1.3890\n",
      "Epoch: 41, Batch: 35841/37625 (95.258%), Loss: 0.7658\n",
      "Epoch: 41, Batch: 36097/37625 (95.939%), Loss: 0.7483\n",
      "Epoch: 41, Batch: 36353/37625 (96.619%), Loss: 3.5864\n",
      "Epoch: 41, Batch: 36609/37625 (97.300%), Loss: 0.8871\n",
      "Epoch: 41, Batch: 36865/37625 (97.980%), Loss: 1.1850\n",
      "Epoch: 41, Batch: 37121/37625 (98.660%), Loss: 0.7251\n",
      "Epoch: 41, Batch: 37377/37625 (99.341%), Loss: 1.2356\n",
      "Epoch: 42, Batch: 1/37625 (0.003%), Loss: 1.0557\n",
      "Epoch: 42, Batch: 257/37625 (0.683%), Loss: 1.0829\n",
      "Epoch: 42, Batch: 513/37625 (1.363%), Loss: 0.7342\n",
      "Epoch: 42, Batch: 769/37625 (2.044%), Loss: 1.2360\n",
      "Epoch: 42, Batch: 1025/37625 (2.724%), Loss: 1.0277\n",
      "Epoch: 42, Batch: 1281/37625 (3.405%), Loss: 0.8617\n",
      "Epoch: 42, Batch: 1537/37625 (4.085%), Loss: 0.6123\n",
      "Epoch: 42, Batch: 1793/37625 (4.765%), Loss: 1.9005\n",
      "Epoch: 42, Batch: 2049/37625 (5.446%), Loss: 1.2092\n",
      "Epoch: 42, Batch: 2305/37625 (6.126%), Loss: 2.0162\n",
      "Epoch: 42, Batch: 2561/37625 (6.807%), Loss: 1.1046\n",
      "Epoch: 42, Batch: 2817/37625 (7.487%), Loss: 0.8181\n",
      "Epoch: 42, Batch: 3073/37625 (8.167%), Loss: 1.9466\n",
      "Epoch: 42, Batch: 3329/37625 (8.848%), Loss: 5.3955\n",
      "Epoch: 42, Batch: 3585/37625 (9.528%), Loss: 1.1389\n",
      "Epoch: 42, Batch: 3841/37625 (10.209%), Loss: 0.8361\n",
      "Epoch: 42, Batch: 4097/37625 (10.889%), Loss: 0.7201\n",
      "Epoch: 42, Batch: 4353/37625 (11.569%), Loss: 0.6486\n",
      "Epoch: 42, Batch: 4609/37625 (12.250%), Loss: 1.0723\n",
      "Epoch: 42, Batch: 4865/37625 (12.930%), Loss: 3.6226\n",
      "Epoch: 42, Batch: 5121/37625 (13.611%), Loss: 0.6576\n",
      "Epoch: 42, Batch: 5377/37625 (14.291%), Loss: 0.7472\n",
      "Epoch: 42, Batch: 5633/37625 (14.971%), Loss: 0.6704\n",
      "Epoch: 42, Batch: 5889/37625 (15.652%), Loss: 1.3441\n",
      "Epoch: 42, Batch: 6145/37625 (16.332%), Loss: 1.0825\n",
      "Epoch: 42, Batch: 6401/37625 (17.013%), Loss: 0.9356\n",
      "Epoch: 42, Batch: 6657/37625 (17.693%), Loss: 0.8078\n",
      "Epoch: 42, Batch: 6913/37625 (18.373%), Loss: 1.0061\n",
      "Epoch: 42, Batch: 7169/37625 (19.054%), Loss: 1.1699\n",
      "Epoch: 42, Batch: 7425/37625 (19.734%), Loss: 0.6967\n",
      "Epoch: 42, Batch: 7681/37625 (20.415%), Loss: 1.8495\n",
      "Epoch: 42, Batch: 7937/37625 (21.095%), Loss: 1.0862\n",
      "Epoch: 42, Batch: 8193/37625 (21.775%), Loss: 1.8151\n",
      "Epoch: 42, Batch: 8449/37625 (22.456%), Loss: 0.7528\n",
      "Epoch: 42, Batch: 8705/37625 (23.136%), Loss: 0.7705\n",
      "Epoch: 42, Batch: 8961/37625 (23.817%), Loss: 0.5162\n",
      "Epoch: 42, Batch: 9217/37625 (24.497%), Loss: 1.0850\n",
      "Epoch: 42, Batch: 9473/37625 (25.177%), Loss: 0.8029\n",
      "Epoch: 42, Batch: 9729/37625 (25.858%), Loss: 0.7596\n",
      "Epoch: 42, Batch: 9985/37625 (26.538%), Loss: 0.8703\n",
      "Epoch: 42, Batch: 10241/37625 (27.219%), Loss: 0.7286\n",
      "Epoch: 42, Batch: 10497/37625 (27.899%), Loss: 1.2798\n",
      "Epoch: 42, Batch: 10753/37625 (28.579%), Loss: 1.3670\n",
      "Epoch: 42, Batch: 11009/37625 (29.260%), Loss: 0.9879\n",
      "Epoch: 42, Batch: 11265/37625 (29.940%), Loss: 0.7068\n",
      "Epoch: 42, Batch: 11521/37625 (30.621%), Loss: 1.1918\n",
      "Epoch: 42, Batch: 11777/37625 (31.301%), Loss: 0.8440\n",
      "Epoch: 42, Batch: 12033/37625 (31.981%), Loss: 1.3290\n",
      "Epoch: 42, Batch: 12289/37625 (32.662%), Loss: 1.1302\n",
      "Epoch: 42, Batch: 12545/37625 (33.342%), Loss: 1.0682\n",
      "Epoch: 42, Batch: 12801/37625 (34.023%), Loss: 0.6129\n",
      "Epoch: 42, Batch: 13057/37625 (34.703%), Loss: 0.8212\n",
      "Epoch: 42, Batch: 13313/37625 (35.383%), Loss: 0.9282\n",
      "Epoch: 42, Batch: 13569/37625 (36.064%), Loss: 0.5841\n",
      "Epoch: 42, Batch: 13825/37625 (36.744%), Loss: 0.6474\n",
      "Epoch: 42, Batch: 14081/37625 (37.425%), Loss: 1.2580\n",
      "Epoch: 42, Batch: 14337/37625 (38.105%), Loss: 1.1449\n",
      "Epoch: 42, Batch: 14593/37625 (38.785%), Loss: 0.7777\n",
      "Epoch: 42, Batch: 14849/37625 (39.466%), Loss: 1.0321\n",
      "Epoch: 42, Batch: 15105/37625 (40.146%), Loss: 1.0993\n",
      "Epoch: 42, Batch: 15361/37625 (40.827%), Loss: 0.6166\n",
      "Epoch: 42, Batch: 15617/37625 (41.507%), Loss: 0.7839\n",
      "Epoch: 42, Batch: 15873/37625 (42.187%), Loss: 0.6907\n",
      "Epoch: 42, Batch: 16129/37625 (42.868%), Loss: 0.8955\n",
      "Epoch: 42, Batch: 16385/37625 (43.548%), Loss: 1.0060\n",
      "Epoch: 42, Batch: 16641/37625 (44.229%), Loss: 1.1419\n",
      "Epoch: 42, Batch: 16897/37625 (44.909%), Loss: 0.5656\n",
      "Epoch: 42, Batch: 17153/37625 (45.589%), Loss: 1.0386\n",
      "Epoch: 42, Batch: 17409/37625 (46.270%), Loss: 0.9366\n",
      "Epoch: 42, Batch: 17665/37625 (46.950%), Loss: 0.5240\n",
      "Epoch: 42, Batch: 17921/37625 (47.631%), Loss: 0.8525\n",
      "Epoch: 42, Batch: 18177/37625 (48.311%), Loss: 0.9258\n",
      "Epoch: 42, Batch: 18433/37625 (48.991%), Loss: 2.3653\n",
      "Epoch: 42, Batch: 18689/37625 (49.672%), Loss: 1.0320\n",
      "Epoch: 42, Batch: 18945/37625 (50.352%), Loss: 1.0449\n",
      "Epoch: 42, Batch: 19201/37625 (51.033%), Loss: 1.2023\n",
      "Epoch: 42, Batch: 19457/37625 (51.713%), Loss: 1.0019\n",
      "Epoch: 42, Batch: 19713/37625 (52.393%), Loss: 0.9930\n",
      "Epoch: 42, Batch: 19969/37625 (53.074%), Loss: 1.0018\n",
      "Epoch: 42, Batch: 20225/37625 (53.754%), Loss: 0.8154\n",
      "Epoch: 42, Batch: 20481/37625 (54.435%), Loss: 0.9412\n",
      "Epoch: 42, Batch: 20737/37625 (55.115%), Loss: 0.6425\n",
      "Epoch: 42, Batch: 20993/37625 (55.795%), Loss: 0.8303\n",
      "Epoch: 42, Batch: 21249/37625 (56.476%), Loss: 0.7176\n",
      "Epoch: 42, Batch: 21505/37625 (57.156%), Loss: 1.0094\n",
      "Epoch: 42, Batch: 21761/37625 (57.837%), Loss: 0.7790\n",
      "Epoch: 42, Batch: 22017/37625 (58.517%), Loss: 0.8327\n",
      "Epoch: 42, Batch: 22273/37625 (59.197%), Loss: 1.0924\n",
      "Epoch: 42, Batch: 22529/37625 (59.878%), Loss: 0.8896\n",
      "Epoch: 42, Batch: 22785/37625 (60.558%), Loss: 0.7073\n",
      "Epoch: 42, Batch: 23041/37625 (61.239%), Loss: 0.8005\n",
      "Epoch: 42, Batch: 23297/37625 (61.919%), Loss: 1.1020\n",
      "Epoch: 42, Batch: 23553/37625 (62.599%), Loss: 1.1932\n",
      "Epoch: 42, Batch: 23809/37625 (63.280%), Loss: 1.2788\n",
      "Epoch: 42, Batch: 24065/37625 (63.960%), Loss: 0.8376\n",
      "Epoch: 42, Batch: 24321/37625 (64.641%), Loss: 0.6140\n",
      "Epoch: 42, Batch: 24577/37625 (65.321%), Loss: 0.6219\n",
      "Epoch: 42, Batch: 24833/37625 (66.001%), Loss: 1.3780\n",
      "Epoch: 42, Batch: 25089/37625 (66.682%), Loss: 0.9843\n",
      "Epoch: 42, Batch: 25345/37625 (67.362%), Loss: 0.7760\n",
      "Epoch: 42, Batch: 25601/37625 (68.043%), Loss: 1.2055\n",
      "Epoch: 42, Batch: 25857/37625 (68.723%), Loss: 1.3022\n",
      "Epoch: 42, Batch: 26113/37625 (69.403%), Loss: 5.0749\n",
      "Epoch: 42, Batch: 26369/37625 (70.084%), Loss: 2.3534\n",
      "Epoch: 42, Batch: 26625/37625 (70.764%), Loss: 0.5871\n",
      "Epoch: 42, Batch: 26881/37625 (71.445%), Loss: 1.2372\n",
      "Epoch: 42, Batch: 27137/37625 (72.125%), Loss: 0.7471\n",
      "Epoch: 42, Batch: 27393/37625 (72.805%), Loss: 0.9073\n",
      "Epoch: 42, Batch: 27649/37625 (73.486%), Loss: 1.2915\n",
      "Epoch: 42, Batch: 27905/37625 (74.166%), Loss: 1.0629\n",
      "Epoch: 42, Batch: 28161/37625 (74.847%), Loss: 0.6303\n",
      "Epoch: 42, Batch: 28417/37625 (75.527%), Loss: 2.5561\n",
      "Epoch: 42, Batch: 28673/37625 (76.207%), Loss: 0.9048\n",
      "Epoch: 42, Batch: 28929/37625 (76.888%), Loss: 1.0139\n",
      "Epoch: 42, Batch: 29185/37625 (77.568%), Loss: 0.8949\n",
      "Epoch: 42, Batch: 29441/37625 (78.249%), Loss: 0.7458\n",
      "Epoch: 42, Batch: 29697/37625 (78.929%), Loss: 0.6837\n",
      "Epoch: 42, Batch: 29953/37625 (79.609%), Loss: 1.1040\n",
      "Epoch: 42, Batch: 30209/37625 (80.290%), Loss: 0.7641\n",
      "Epoch: 42, Batch: 30465/37625 (80.970%), Loss: 0.7185\n",
      "Epoch: 42, Batch: 30721/37625 (81.650%), Loss: 0.9212\n",
      "Epoch: 42, Batch: 30977/37625 (82.331%), Loss: 0.8732\n",
      "Epoch: 42, Batch: 31233/37625 (83.011%), Loss: 0.7792\n",
      "Epoch: 42, Batch: 31489/37625 (83.692%), Loss: 1.4552\n",
      "Epoch: 42, Batch: 31745/37625 (84.372%), Loss: 0.8929\n",
      "Epoch: 42, Batch: 32001/37625 (85.052%), Loss: 1.1480\n",
      "Epoch: 42, Batch: 32257/37625 (85.733%), Loss: 0.7570\n",
      "Epoch: 42, Batch: 32513/37625 (86.413%), Loss: 0.7749\n",
      "Epoch: 42, Batch: 32769/37625 (87.094%), Loss: 0.7174\n",
      "Epoch: 42, Batch: 33025/37625 (87.774%), Loss: 0.9614\n",
      "Epoch: 42, Batch: 33281/37625 (88.454%), Loss: 0.9191\n",
      "Epoch: 42, Batch: 33537/37625 (89.135%), Loss: 1.0533\n",
      "Epoch: 42, Batch: 33793/37625 (89.815%), Loss: 0.5749\n",
      "Epoch: 42, Batch: 34049/37625 (90.496%), Loss: 1.4705\n",
      "Epoch: 42, Batch: 34305/37625 (91.176%), Loss: 0.7567\n",
      "Epoch: 42, Batch: 34561/37625 (91.856%), Loss: 0.9370\n",
      "Epoch: 42, Batch: 34817/37625 (92.537%), Loss: 1.1148\n",
      "Epoch: 42, Batch: 35073/37625 (93.217%), Loss: 1.0782\n",
      "Epoch: 42, Batch: 35329/37625 (93.898%), Loss: 3.5768\n",
      "Epoch: 42, Batch: 35585/37625 (94.578%), Loss: 1.4364\n",
      "Epoch: 42, Batch: 35841/37625 (95.258%), Loss: 0.6711\n",
      "Epoch: 42, Batch: 36097/37625 (95.939%), Loss: 0.9533\n",
      "Epoch: 42, Batch: 36353/37625 (96.619%), Loss: 1.1031\n",
      "Epoch: 42, Batch: 36609/37625 (97.300%), Loss: 1.6172\n",
      "Epoch: 42, Batch: 36865/37625 (97.980%), Loss: 0.8203\n",
      "Epoch: 42, Batch: 37121/37625 (98.660%), Loss: 4.3067\n",
      "Epoch: 42, Batch: 37377/37625 (99.341%), Loss: 0.8434\n",
      "Epoch: 43, Batch: 1/37625 (0.003%), Loss: 0.5873\n",
      "Epoch: 43, Batch: 257/37625 (0.683%), Loss: 0.6898\n",
      "Epoch: 43, Batch: 513/37625 (1.363%), Loss: 0.4675\n",
      "Epoch: 43, Batch: 769/37625 (2.044%), Loss: 0.7642\n",
      "Epoch: 43, Batch: 1025/37625 (2.724%), Loss: 0.5395\n",
      "Epoch: 43, Batch: 1281/37625 (3.405%), Loss: 0.7170\n",
      "Epoch: 43, Batch: 1537/37625 (4.085%), Loss: 0.6977\n",
      "Epoch: 43, Batch: 1793/37625 (4.765%), Loss: 1.0868\n",
      "Epoch: 43, Batch: 2049/37625 (5.446%), Loss: 1.1473\n",
      "Epoch: 43, Batch: 2305/37625 (6.126%), Loss: 5.2308\n",
      "Epoch: 43, Batch: 2561/37625 (6.807%), Loss: 0.7737\n",
      "Epoch: 43, Batch: 2817/37625 (7.487%), Loss: 0.8348\n",
      "Epoch: 43, Batch: 3073/37625 (8.167%), Loss: 0.7677\n",
      "Epoch: 43, Batch: 3329/37625 (8.848%), Loss: 1.1973\n",
      "Epoch: 43, Batch: 3585/37625 (9.528%), Loss: 1.1983\n",
      "Epoch: 43, Batch: 3841/37625 (10.209%), Loss: 1.3005\n",
      "Epoch: 43, Batch: 4097/37625 (10.889%), Loss: 0.8373\n",
      "Epoch: 43, Batch: 4353/37625 (11.569%), Loss: 1.2225\n",
      "Epoch: 43, Batch: 4609/37625 (12.250%), Loss: 0.8620\n",
      "Epoch: 43, Batch: 4865/37625 (12.930%), Loss: 0.8552\n",
      "Epoch: 43, Batch: 5121/37625 (13.611%), Loss: 1.1410\n",
      "Epoch: 43, Batch: 5377/37625 (14.291%), Loss: 1.0407\n",
      "Epoch: 43, Batch: 5633/37625 (14.971%), Loss: 1.4193\n",
      "Epoch: 43, Batch: 5889/37625 (15.652%), Loss: 1.1192\n",
      "Epoch: 43, Batch: 6145/37625 (16.332%), Loss: 2.1004\n",
      "Epoch: 43, Batch: 6401/37625 (17.013%), Loss: 0.7502\n",
      "Epoch: 43, Batch: 6657/37625 (17.693%), Loss: 0.7564\n",
      "Epoch: 43, Batch: 6913/37625 (18.373%), Loss: 1.0518\n",
      "Epoch: 43, Batch: 7169/37625 (19.054%), Loss: 0.6471\n",
      "Epoch: 43, Batch: 7425/37625 (19.734%), Loss: 1.0686\n",
      "Epoch: 43, Batch: 7681/37625 (20.415%), Loss: 1.0114\n",
      "Epoch: 43, Batch: 7937/37625 (21.095%), Loss: 1.2224\n",
      "Epoch: 43, Batch: 8193/37625 (21.775%), Loss: 0.8632\n",
      "Epoch: 43, Batch: 8449/37625 (22.456%), Loss: 0.7502\n",
      "Epoch: 43, Batch: 8705/37625 (23.136%), Loss: 0.5296\n",
      "Epoch: 43, Batch: 8961/37625 (23.817%), Loss: 0.6275\n",
      "Epoch: 43, Batch: 9217/37625 (24.497%), Loss: 0.5489\n",
      "Epoch: 43, Batch: 9473/37625 (25.177%), Loss: 1.0006\n",
      "Epoch: 43, Batch: 9729/37625 (25.858%), Loss: 1.4533\n",
      "Epoch: 43, Batch: 9985/37625 (26.538%), Loss: 0.5996\n",
      "Epoch: 43, Batch: 10241/37625 (27.219%), Loss: 0.7557\n",
      "Epoch: 43, Batch: 10497/37625 (27.899%), Loss: 1.0536\n",
      "Epoch: 43, Batch: 10753/37625 (28.579%), Loss: 0.8558\n",
      "Epoch: 43, Batch: 11009/37625 (29.260%), Loss: 1.1967\n",
      "Epoch: 43, Batch: 11265/37625 (29.940%), Loss: 1.0951\n",
      "Epoch: 43, Batch: 11521/37625 (30.621%), Loss: 0.9523\n",
      "Epoch: 43, Batch: 11777/37625 (31.301%), Loss: 0.7283\n",
      "Epoch: 43, Batch: 12033/37625 (31.981%), Loss: 0.8988\n",
      "Epoch: 43, Batch: 12289/37625 (32.662%), Loss: 1.1685\n",
      "Epoch: 43, Batch: 12545/37625 (33.342%), Loss: 1.0988\n",
      "Epoch: 43, Batch: 12801/37625 (34.023%), Loss: 3.0711\n",
      "Epoch: 43, Batch: 13057/37625 (34.703%), Loss: 0.9643\n",
      "Epoch: 43, Batch: 13313/37625 (35.383%), Loss: 1.5586\n",
      "Epoch: 43, Batch: 13569/37625 (36.064%), Loss: 1.4885\n",
      "Epoch: 43, Batch: 13825/37625 (36.744%), Loss: 0.6905\n",
      "Epoch: 43, Batch: 14081/37625 (37.425%), Loss: 1.2678\n",
      "Epoch: 43, Batch: 14337/37625 (38.105%), Loss: 0.6376\n",
      "Epoch: 43, Batch: 14593/37625 (38.785%), Loss: 0.7706\n",
      "Epoch: 43, Batch: 14849/37625 (39.466%), Loss: 1.4103\n",
      "Epoch: 43, Batch: 15105/37625 (40.146%), Loss: 0.7163\n",
      "Epoch: 43, Batch: 15361/37625 (40.827%), Loss: 0.8803\n",
      "Epoch: 43, Batch: 15617/37625 (41.507%), Loss: 0.8750\n",
      "Epoch: 43, Batch: 15873/37625 (42.187%), Loss: 1.1390\n",
      "Epoch: 43, Batch: 16129/37625 (42.868%), Loss: 1.2722\n",
      "Epoch: 43, Batch: 16385/37625 (43.548%), Loss: 1.1913\n",
      "Epoch: 43, Batch: 16641/37625 (44.229%), Loss: 1.0210\n",
      "Epoch: 43, Batch: 16897/37625 (44.909%), Loss: 0.7060\n",
      "Epoch: 43, Batch: 17153/37625 (45.589%), Loss: 1.2946\n",
      "Epoch: 43, Batch: 17409/37625 (46.270%), Loss: 0.8837\n",
      "Epoch: 43, Batch: 17665/37625 (46.950%), Loss: 0.5949\n",
      "Epoch: 43, Batch: 17921/37625 (47.631%), Loss: 0.5880\n",
      "Epoch: 43, Batch: 18177/37625 (48.311%), Loss: 1.3442\n",
      "Epoch: 43, Batch: 18433/37625 (48.991%), Loss: 0.7439\n",
      "Epoch: 43, Batch: 18689/37625 (49.672%), Loss: 0.6618\n",
      "Epoch: 43, Batch: 18945/37625 (50.352%), Loss: 0.9805\n",
      "Epoch: 43, Batch: 19201/37625 (51.033%), Loss: 0.8772\n",
      "Epoch: 43, Batch: 19457/37625 (51.713%), Loss: 0.6542\n",
      "Epoch: 43, Batch: 19713/37625 (52.393%), Loss: 1.0114\n",
      "Epoch: 43, Batch: 19969/37625 (53.074%), Loss: 1.1027\n",
      "Epoch: 43, Batch: 20225/37625 (53.754%), Loss: 0.6654\n",
      "Epoch: 43, Batch: 20481/37625 (54.435%), Loss: 0.7171\n",
      "Epoch: 43, Batch: 20737/37625 (55.115%), Loss: 0.5730\n",
      "Epoch: 43, Batch: 20993/37625 (55.795%), Loss: 0.9051\n",
      "Epoch: 43, Batch: 21249/37625 (56.476%), Loss: 1.6860\n",
      "Epoch: 43, Batch: 21505/37625 (57.156%), Loss: 0.9883\n",
      "Epoch: 43, Batch: 21761/37625 (57.837%), Loss: 1.7147\n",
      "Epoch: 43, Batch: 22017/37625 (58.517%), Loss: 0.6844\n",
      "Epoch: 43, Batch: 22273/37625 (59.197%), Loss: 0.6834\n",
      "Epoch: 43, Batch: 22529/37625 (59.878%), Loss: 1.3444\n",
      "Epoch: 43, Batch: 22785/37625 (60.558%), Loss: 0.8623\n",
      "Epoch: 43, Batch: 23041/37625 (61.239%), Loss: 0.7489\n",
      "Epoch: 43, Batch: 23297/37625 (61.919%), Loss: 4.2099\n",
      "Epoch: 43, Batch: 23553/37625 (62.599%), Loss: 1.7085\n",
      "Epoch: 43, Batch: 23809/37625 (63.280%), Loss: 1.0637\n",
      "Epoch: 43, Batch: 24065/37625 (63.960%), Loss: 0.5438\n",
      "Epoch: 43, Batch: 24321/37625 (64.641%), Loss: 0.7099\n",
      "Epoch: 43, Batch: 24577/37625 (65.321%), Loss: 0.6748\n",
      "Epoch: 43, Batch: 24833/37625 (66.001%), Loss: 1.6956\n",
      "Epoch: 43, Batch: 25089/37625 (66.682%), Loss: 0.8891\n",
      "Epoch: 43, Batch: 25345/37625 (67.362%), Loss: 0.5654\n",
      "Epoch: 43, Batch: 25601/37625 (68.043%), Loss: 1.3612\n",
      "Epoch: 43, Batch: 25857/37625 (68.723%), Loss: 0.6271\n",
      "Epoch: 43, Batch: 26113/37625 (69.403%), Loss: 1.9685\n",
      "Epoch: 43, Batch: 26369/37625 (70.084%), Loss: 0.6276\n",
      "Epoch: 43, Batch: 26625/37625 (70.764%), Loss: 0.8848\n",
      "Epoch: 43, Batch: 26881/37625 (71.445%), Loss: 1.5501\n",
      "Epoch: 43, Batch: 27137/37625 (72.125%), Loss: 0.8329\n",
      "Epoch: 43, Batch: 27393/37625 (72.805%), Loss: 1.1734\n",
      "Epoch: 43, Batch: 27649/37625 (73.486%), Loss: 1.5227\n",
      "Epoch: 43, Batch: 27905/37625 (74.166%), Loss: 0.6206\n",
      "Epoch: 43, Batch: 28161/37625 (74.847%), Loss: 1.1355\n",
      "Epoch: 43, Batch: 28417/37625 (75.527%), Loss: 0.6533\n",
      "Epoch: 43, Batch: 28673/37625 (76.207%), Loss: 1.6798\n",
      "Epoch: 43, Batch: 28929/37625 (76.888%), Loss: 0.7109\n",
      "Epoch: 43, Batch: 29185/37625 (77.568%), Loss: 0.9362\n",
      "Epoch: 43, Batch: 29441/37625 (78.249%), Loss: 1.1912\n",
      "Epoch: 43, Batch: 29697/37625 (78.929%), Loss: 0.6155\n",
      "Epoch: 43, Batch: 29953/37625 (79.609%), Loss: 0.9216\n",
      "Epoch: 43, Batch: 30209/37625 (80.290%), Loss: 1.4637\n",
      "Epoch: 43, Batch: 30465/37625 (80.970%), Loss: 0.6463\n",
      "Epoch: 43, Batch: 30721/37625 (81.650%), Loss: 0.9214\n",
      "Epoch: 43, Batch: 30977/37625 (82.331%), Loss: 0.6548\n",
      "Epoch: 43, Batch: 31233/37625 (83.011%), Loss: 0.8704\n",
      "Epoch: 43, Batch: 31489/37625 (83.692%), Loss: 5.5316\n",
      "Epoch: 43, Batch: 31745/37625 (84.372%), Loss: 0.9494\n",
      "Epoch: 43, Batch: 32001/37625 (85.052%), Loss: 2.4630\n",
      "Epoch: 43, Batch: 32257/37625 (85.733%), Loss: 1.6261\n",
      "Epoch: 43, Batch: 32513/37625 (86.413%), Loss: 1.5636\n",
      "Epoch: 43, Batch: 32769/37625 (87.094%), Loss: 2.2869\n",
      "Epoch: 43, Batch: 33025/37625 (87.774%), Loss: 1.7131\n",
      "Epoch: 43, Batch: 33281/37625 (88.454%), Loss: 0.6024\n",
      "Epoch: 43, Batch: 33537/37625 (89.135%), Loss: 0.7689\n",
      "Epoch: 43, Batch: 33793/37625 (89.815%), Loss: 1.0491\n",
      "Epoch: 43, Batch: 34049/37625 (90.496%), Loss: 0.8760\n",
      "Epoch: 43, Batch: 34305/37625 (91.176%), Loss: 1.2140\n",
      "Epoch: 43, Batch: 34561/37625 (91.856%), Loss: 2.9544\n",
      "Epoch: 43, Batch: 34817/37625 (92.537%), Loss: 0.8701\n",
      "Epoch: 43, Batch: 35073/37625 (93.217%), Loss: 0.7260\n",
      "Epoch: 43, Batch: 35329/37625 (93.898%), Loss: 0.6979\n",
      "Epoch: 43, Batch: 35585/37625 (94.578%), Loss: 2.4024\n",
      "Epoch: 43, Batch: 35841/37625 (95.258%), Loss: 1.1985\n",
      "Epoch: 43, Batch: 36097/37625 (95.939%), Loss: 0.8225\n",
      "Epoch: 43, Batch: 36353/37625 (96.619%), Loss: 1.2949\n",
      "Epoch: 43, Batch: 36609/37625 (97.300%), Loss: 0.6640\n",
      "Epoch: 43, Batch: 36865/37625 (97.980%), Loss: 0.8206\n",
      "Epoch: 43, Batch: 37121/37625 (98.660%), Loss: 0.9870\n",
      "Epoch: 43, Batch: 37377/37625 (99.341%), Loss: 0.7992\n",
      "Epoch: 44, Batch: 1/37625 (0.003%), Loss: 1.1227\n",
      "Epoch: 44, Batch: 257/37625 (0.683%), Loss: 1.1113\n",
      "Epoch: 44, Batch: 513/37625 (1.363%), Loss: 0.9186\n",
      "Epoch: 44, Batch: 769/37625 (2.044%), Loss: 0.7653\n",
      "Epoch: 44, Batch: 1025/37625 (2.724%), Loss: 1.4164\n",
      "Epoch: 44, Batch: 1281/37625 (3.405%), Loss: 0.9157\n",
      "Epoch: 44, Batch: 1537/37625 (4.085%), Loss: 1.1173\n",
      "Epoch: 44, Batch: 1793/37625 (4.765%), Loss: 0.5542\n",
      "Epoch: 44, Batch: 2049/37625 (5.446%), Loss: 1.5177\n",
      "Epoch: 44, Batch: 2305/37625 (6.126%), Loss: 0.9698\n",
      "Epoch: 44, Batch: 2561/37625 (6.807%), Loss: 0.7863\n",
      "Epoch: 44, Batch: 2817/37625 (7.487%), Loss: 1.2772\n",
      "Epoch: 44, Batch: 3073/37625 (8.167%), Loss: 0.8726\n",
      "Epoch: 44, Batch: 3329/37625 (8.848%), Loss: 0.7634\n",
      "Epoch: 44, Batch: 3585/37625 (9.528%), Loss: 0.9009\n",
      "Epoch: 44, Batch: 3841/37625 (10.209%), Loss: 0.6692\n",
      "Epoch: 44, Batch: 4097/37625 (10.889%), Loss: 0.6550\n",
      "Epoch: 44, Batch: 4353/37625 (11.569%), Loss: 1.3742\n",
      "Epoch: 44, Batch: 4609/37625 (12.250%), Loss: 1.7953\n",
      "Epoch: 44, Batch: 4865/37625 (12.930%), Loss: 5.0662\n",
      "Epoch: 44, Batch: 5121/37625 (13.611%), Loss: 0.9162\n",
      "Epoch: 44, Batch: 5377/37625 (14.291%), Loss: 1.4229\n",
      "Epoch: 44, Batch: 5633/37625 (14.971%), Loss: 1.1069\n",
      "Epoch: 44, Batch: 5889/37625 (15.652%), Loss: 0.8640\n",
      "Epoch: 44, Batch: 6145/37625 (16.332%), Loss: 0.7918\n",
      "Epoch: 44, Batch: 6401/37625 (17.013%), Loss: 5.4499\n",
      "Epoch: 44, Batch: 6657/37625 (17.693%), Loss: 0.9697\n",
      "Epoch: 44, Batch: 6913/37625 (18.373%), Loss: 0.6493\n",
      "Epoch: 44, Batch: 7169/37625 (19.054%), Loss: 1.0841\n",
      "Epoch: 44, Batch: 7425/37625 (19.734%), Loss: 0.6657\n",
      "Epoch: 44, Batch: 7681/37625 (20.415%), Loss: 1.0407\n",
      "Epoch: 44, Batch: 7937/37625 (21.095%), Loss: 0.6353\n",
      "Epoch: 44, Batch: 8193/37625 (21.775%), Loss: 1.3804\n",
      "Epoch: 44, Batch: 8449/37625 (22.456%), Loss: 0.9157\n",
      "Epoch: 44, Batch: 8705/37625 (23.136%), Loss: 0.5741\n",
      "Epoch: 44, Batch: 8961/37625 (23.817%), Loss: 0.5512\n",
      "Epoch: 44, Batch: 9217/37625 (24.497%), Loss: 5.2569\n",
      "Epoch: 44, Batch: 9473/37625 (25.177%), Loss: 1.7939\n",
      "Epoch: 44, Batch: 9729/37625 (25.858%), Loss: 1.0221\n",
      "Epoch: 44, Batch: 9985/37625 (26.538%), Loss: 0.7792\n",
      "Epoch: 44, Batch: 10241/37625 (27.219%), Loss: 0.8483\n",
      "Epoch: 44, Batch: 10497/37625 (27.899%), Loss: 0.8094\n",
      "Epoch: 44, Batch: 10753/37625 (28.579%), Loss: 0.7699\n",
      "Epoch: 44, Batch: 11009/37625 (29.260%), Loss: 0.9412\n",
      "Epoch: 44, Batch: 11265/37625 (29.940%), Loss: 1.0618\n",
      "Epoch: 44, Batch: 11521/37625 (30.621%), Loss: 0.9507\n",
      "Epoch: 44, Batch: 11777/37625 (31.301%), Loss: 1.1945\n",
      "Epoch: 44, Batch: 12033/37625 (31.981%), Loss: 0.5268\n",
      "Epoch: 44, Batch: 12289/37625 (32.662%), Loss: 0.8539\n",
      "Epoch: 44, Batch: 12545/37625 (33.342%), Loss: 1.1018\n",
      "Epoch: 44, Batch: 12801/37625 (34.023%), Loss: 1.9491\n",
      "Epoch: 44, Batch: 13057/37625 (34.703%), Loss: 0.7694\n",
      "Epoch: 44, Batch: 13313/37625 (35.383%), Loss: 1.2673\n",
      "Epoch: 44, Batch: 13569/37625 (36.064%), Loss: 0.9099\n",
      "Epoch: 44, Batch: 13825/37625 (36.744%), Loss: 0.6879\n",
      "Epoch: 44, Batch: 14081/37625 (37.425%), Loss: 0.7753\n",
      "Epoch: 44, Batch: 14337/37625 (38.105%), Loss: 1.8355\n",
      "Epoch: 44, Batch: 14593/37625 (38.785%), Loss: 0.9801\n",
      "Epoch: 44, Batch: 14849/37625 (39.466%), Loss: 1.0197\n",
      "Epoch: 44, Batch: 15105/37625 (40.146%), Loss: 1.0658\n",
      "Epoch: 44, Batch: 15361/37625 (40.827%), Loss: 0.9859\n",
      "Epoch: 44, Batch: 15617/37625 (41.507%), Loss: 0.7441\n",
      "Epoch: 44, Batch: 15873/37625 (42.187%), Loss: 1.3191\n",
      "Epoch: 44, Batch: 16129/37625 (42.868%), Loss: 0.7869\n",
      "Epoch: 44, Batch: 16385/37625 (43.548%), Loss: 0.6223\n",
      "Epoch: 44, Batch: 16641/37625 (44.229%), Loss: 1.7002\n",
      "Epoch: 44, Batch: 16897/37625 (44.909%), Loss: 1.0265\n",
      "Epoch: 44, Batch: 17153/37625 (45.589%), Loss: 0.9581\n",
      "Epoch: 44, Batch: 17409/37625 (46.270%), Loss: 0.7726\n",
      "Epoch: 44, Batch: 17665/37625 (46.950%), Loss: 0.8261\n",
      "Epoch: 44, Batch: 17921/37625 (47.631%), Loss: 0.8337\n",
      "Epoch: 44, Batch: 18177/37625 (48.311%), Loss: 0.6685\n",
      "Epoch: 44, Batch: 18433/37625 (48.991%), Loss: 0.7163\n",
      "Epoch: 44, Batch: 18689/37625 (49.672%), Loss: 1.5182\n",
      "Epoch: 44, Batch: 18945/37625 (50.352%), Loss: 3.1628\n",
      "Epoch: 44, Batch: 19201/37625 (51.033%), Loss: 1.2491\n",
      "Epoch: 44, Batch: 19457/37625 (51.713%), Loss: 0.9309\n",
      "Epoch: 44, Batch: 19713/37625 (52.393%), Loss: 1.1301\n",
      "Epoch: 44, Batch: 19969/37625 (53.074%), Loss: 0.9208\n",
      "Epoch: 44, Batch: 20225/37625 (53.754%), Loss: 0.9520\n",
      "Epoch: 44, Batch: 20481/37625 (54.435%), Loss: 0.9052\n",
      "Epoch: 44, Batch: 20737/37625 (55.115%), Loss: 0.8285\n",
      "Epoch: 44, Batch: 20993/37625 (55.795%), Loss: 1.0544\n",
      "Epoch: 44, Batch: 21249/37625 (56.476%), Loss: 0.6777\n",
      "Epoch: 44, Batch: 21505/37625 (57.156%), Loss: 1.1007\n",
      "Epoch: 44, Batch: 21761/37625 (57.837%), Loss: 0.9350\n",
      "Epoch: 44, Batch: 22017/37625 (58.517%), Loss: 1.6043\n",
      "Epoch: 44, Batch: 22273/37625 (59.197%), Loss: 0.8719\n",
      "Epoch: 44, Batch: 22529/37625 (59.878%), Loss: 0.7988\n",
      "Epoch: 44, Batch: 22785/37625 (60.558%), Loss: 0.7516\n",
      "Epoch: 44, Batch: 23041/37625 (61.239%), Loss: 0.6841\n",
      "Epoch: 44, Batch: 23297/37625 (61.919%), Loss: 1.0310\n",
      "Epoch: 44, Batch: 23553/37625 (62.599%), Loss: 1.3048\n",
      "Epoch: 44, Batch: 23809/37625 (63.280%), Loss: 0.6068\n",
      "Epoch: 44, Batch: 24065/37625 (63.960%), Loss: 0.5910\n",
      "Epoch: 44, Batch: 24321/37625 (64.641%), Loss: 0.9334\n",
      "Epoch: 44, Batch: 24577/37625 (65.321%), Loss: 1.1376\n",
      "Epoch: 44, Batch: 24833/37625 (66.001%), Loss: 1.2559\n",
      "Epoch: 44, Batch: 25089/37625 (66.682%), Loss: 0.6533\n",
      "Epoch: 44, Batch: 25345/37625 (67.362%), Loss: 0.9815\n",
      "Epoch: 44, Batch: 25601/37625 (68.043%), Loss: 0.9311\n",
      "Epoch: 44, Batch: 25857/37625 (68.723%), Loss: 0.7685\n",
      "Epoch: 44, Batch: 26113/37625 (69.403%), Loss: 0.5724\n",
      "Epoch: 44, Batch: 26369/37625 (70.084%), Loss: 0.8942\n",
      "Epoch: 44, Batch: 26625/37625 (70.764%), Loss: 4.6741\n",
      "Epoch: 44, Batch: 26881/37625 (71.445%), Loss: 0.7613\n",
      "Epoch: 44, Batch: 27137/37625 (72.125%), Loss: 0.7442\n",
      "Epoch: 44, Batch: 27393/37625 (72.805%), Loss: 0.8853\n",
      "Epoch: 44, Batch: 27649/37625 (73.486%), Loss: 1.0874\n",
      "Epoch: 44, Batch: 27905/37625 (74.166%), Loss: 1.2111\n",
      "Epoch: 44, Batch: 28161/37625 (74.847%), Loss: 0.6665\n",
      "Epoch: 44, Batch: 28417/37625 (75.527%), Loss: 0.8420\n",
      "Epoch: 44, Batch: 28673/37625 (76.207%), Loss: 1.3528\n",
      "Epoch: 44, Batch: 28929/37625 (76.888%), Loss: 0.8068\n",
      "Epoch: 44, Batch: 29185/37625 (77.568%), Loss: 0.9401\n",
      "Epoch: 44, Batch: 29441/37625 (78.249%), Loss: 0.8925\n",
      "Epoch: 44, Batch: 29697/37625 (78.929%), Loss: 0.8597\n",
      "Epoch: 44, Batch: 29953/37625 (79.609%), Loss: 1.2927\n",
      "Epoch: 44, Batch: 30209/37625 (80.290%), Loss: 0.5020\n",
      "Epoch: 44, Batch: 30465/37625 (80.970%), Loss: 0.8643\n",
      "Epoch: 44, Batch: 30721/37625 (81.650%), Loss: 2.1166\n",
      "Epoch: 44, Batch: 30977/37625 (82.331%), Loss: 0.9468\n",
      "Epoch: 44, Batch: 31233/37625 (83.011%), Loss: 0.7087\n",
      "Epoch: 44, Batch: 31489/37625 (83.692%), Loss: 1.0043\n",
      "Epoch: 44, Batch: 31745/37625 (84.372%), Loss: 0.8650\n",
      "Epoch: 44, Batch: 32001/37625 (85.052%), Loss: 1.0705\n",
      "Epoch: 44, Batch: 32257/37625 (85.733%), Loss: 0.7355\n",
      "Epoch: 44, Batch: 32513/37625 (86.413%), Loss: 1.1711\n",
      "Epoch: 44, Batch: 32769/37625 (87.094%), Loss: 0.9711\n",
      "Epoch: 44, Batch: 33025/37625 (87.774%), Loss: 0.7899\n",
      "Epoch: 44, Batch: 33281/37625 (88.454%), Loss: 0.9640\n",
      "Epoch: 44, Batch: 33537/37625 (89.135%), Loss: 0.9198\n",
      "Epoch: 44, Batch: 33793/37625 (89.815%), Loss: 2.8917\n",
      "Epoch: 44, Batch: 34049/37625 (90.496%), Loss: 1.0514\n",
      "Epoch: 44, Batch: 34305/37625 (91.176%), Loss: 0.8577\n",
      "Epoch: 44, Batch: 34561/37625 (91.856%), Loss: 0.7264\n",
      "Epoch: 44, Batch: 34817/37625 (92.537%), Loss: 1.1983\n",
      "Epoch: 44, Batch: 35073/37625 (93.217%), Loss: 1.2466\n",
      "Epoch: 44, Batch: 35329/37625 (93.898%), Loss: 0.8773\n",
      "Epoch: 44, Batch: 35585/37625 (94.578%), Loss: 1.1231\n",
      "Epoch: 44, Batch: 35841/37625 (95.258%), Loss: 0.7567\n",
      "Epoch: 44, Batch: 36097/37625 (95.939%), Loss: 0.9693\n",
      "Epoch: 44, Batch: 36353/37625 (96.619%), Loss: 0.9342\n",
      "Epoch: 44, Batch: 36609/37625 (97.300%), Loss: 0.7324\n",
      "Epoch: 44, Batch: 36865/37625 (97.980%), Loss: 1.5536\n",
      "Epoch: 44, Batch: 37121/37625 (98.660%), Loss: 0.7278\n",
      "Epoch: 44, Batch: 37377/37625 (99.341%), Loss: 1.0228\n",
      "Epoch: 45, Batch: 1/37625 (0.003%), Loss: 0.6247\n",
      "Epoch: 45, Batch: 257/37625 (0.683%), Loss: 0.5756\n",
      "Epoch: 45, Batch: 513/37625 (1.363%), Loss: 0.8048\n",
      "Epoch: 45, Batch: 769/37625 (2.044%), Loss: 5.4809\n",
      "Epoch: 45, Batch: 1025/37625 (2.724%), Loss: 0.9468\n",
      "Epoch: 45, Batch: 1281/37625 (3.405%), Loss: 1.0390\n",
      "Epoch: 45, Batch: 1537/37625 (4.085%), Loss: 0.5694\n",
      "Epoch: 45, Batch: 1793/37625 (4.765%), Loss: 1.1234\n",
      "Epoch: 45, Batch: 2049/37625 (5.446%), Loss: 0.6197\n",
      "Epoch: 45, Batch: 2305/37625 (6.126%), Loss: 0.7525\n",
      "Epoch: 45, Batch: 2561/37625 (6.807%), Loss: 0.5752\n",
      "Epoch: 45, Batch: 2817/37625 (7.487%), Loss: 0.9817\n",
      "Epoch: 45, Batch: 3073/37625 (8.167%), Loss: 0.5587\n",
      "Epoch: 45, Batch: 3329/37625 (8.848%), Loss: 0.8710\n",
      "Epoch: 45, Batch: 3585/37625 (9.528%), Loss: 1.5367\n",
      "Epoch: 45, Batch: 3841/37625 (10.209%), Loss: 1.2640\n",
      "Epoch: 45, Batch: 4097/37625 (10.889%), Loss: 0.6467\n",
      "Epoch: 45, Batch: 4353/37625 (11.569%), Loss: 1.2213\n",
      "Epoch: 45, Batch: 4609/37625 (12.250%), Loss: 0.8551\n",
      "Epoch: 45, Batch: 4865/37625 (12.930%), Loss: 0.8020\n",
      "Epoch: 45, Batch: 5121/37625 (13.611%), Loss: 0.8648\n",
      "Epoch: 45, Batch: 5377/37625 (14.291%), Loss: 1.2755\n",
      "Epoch: 45, Batch: 5633/37625 (14.971%), Loss: 0.7711\n",
      "Epoch: 45, Batch: 5889/37625 (15.652%), Loss: 0.9711\n",
      "Epoch: 45, Batch: 6145/37625 (16.332%), Loss: 1.0927\n",
      "Epoch: 45, Batch: 6401/37625 (17.013%), Loss: 0.8412\n",
      "Epoch: 45, Batch: 6657/37625 (17.693%), Loss: 0.7260\n",
      "Epoch: 45, Batch: 6913/37625 (18.373%), Loss: 0.9423\n",
      "Epoch: 45, Batch: 7169/37625 (19.054%), Loss: 0.9920\n",
      "Epoch: 45, Batch: 7425/37625 (19.734%), Loss: 0.8966\n",
      "Epoch: 45, Batch: 7681/37625 (20.415%), Loss: 1.3264\n",
      "Epoch: 45, Batch: 7937/37625 (21.095%), Loss: 0.7588\n",
      "Epoch: 45, Batch: 8193/37625 (21.775%), Loss: 0.7780\n",
      "Epoch: 45, Batch: 8449/37625 (22.456%), Loss: 1.6988\n",
      "Epoch: 45, Batch: 8705/37625 (23.136%), Loss: 0.6147\n",
      "Epoch: 45, Batch: 8961/37625 (23.817%), Loss: 0.9027\n",
      "Epoch: 45, Batch: 9217/37625 (24.497%), Loss: 0.8020\n",
      "Epoch: 45, Batch: 9473/37625 (25.177%), Loss: 1.3614\n",
      "Epoch: 45, Batch: 9729/37625 (25.858%), Loss: 0.7350\n",
      "Epoch: 45, Batch: 9985/37625 (26.538%), Loss: 0.4750\n",
      "Epoch: 45, Batch: 10241/37625 (27.219%), Loss: 3.1413\n",
      "Epoch: 45, Batch: 10497/37625 (27.899%), Loss: 0.6376\n",
      "Epoch: 45, Batch: 10753/37625 (28.579%), Loss: 1.4959\n",
      "Epoch: 45, Batch: 11009/37625 (29.260%), Loss: 0.7428\n",
      "Epoch: 45, Batch: 11265/37625 (29.940%), Loss: 1.0351\n",
      "Epoch: 45, Batch: 11521/37625 (30.621%), Loss: 0.9256\n",
      "Epoch: 45, Batch: 11777/37625 (31.301%), Loss: 1.1059\n",
      "Epoch: 45, Batch: 12033/37625 (31.981%), Loss: 2.2949\n",
      "Epoch: 45, Batch: 12289/37625 (32.662%), Loss: 1.0104\n",
      "Epoch: 45, Batch: 12545/37625 (33.342%), Loss: 4.2124\n",
      "Epoch: 45, Batch: 12801/37625 (34.023%), Loss: 1.1065\n",
      "Epoch: 45, Batch: 13057/37625 (34.703%), Loss: 0.6417\n",
      "Epoch: 45, Batch: 13313/37625 (35.383%), Loss: 0.8463\n",
      "Epoch: 45, Batch: 13569/37625 (36.064%), Loss: 0.5884\n",
      "Epoch: 45, Batch: 13825/37625 (36.744%), Loss: 1.1169\n",
      "Epoch: 45, Batch: 14081/37625 (37.425%), Loss: 5.6830\n",
      "Epoch: 45, Batch: 14337/37625 (38.105%), Loss: 0.5717\n",
      "Epoch: 45, Batch: 14593/37625 (38.785%), Loss: 3.4923\n",
      "Epoch: 45, Batch: 14849/37625 (39.466%), Loss: 0.9010\n",
      "Epoch: 45, Batch: 15105/37625 (40.146%), Loss: 1.0276\n",
      "Epoch: 45, Batch: 15361/37625 (40.827%), Loss: 0.8531\n",
      "Epoch: 45, Batch: 15617/37625 (41.507%), Loss: 1.0156\n",
      "Epoch: 45, Batch: 15873/37625 (42.187%), Loss: 0.9825\n",
      "Epoch: 45, Batch: 16129/37625 (42.868%), Loss: 2.0528\n",
      "Epoch: 45, Batch: 16385/37625 (43.548%), Loss: 1.1057\n",
      "Epoch: 45, Batch: 16641/37625 (44.229%), Loss: 1.6140\n",
      "Epoch: 45, Batch: 16897/37625 (44.909%), Loss: 1.4548\n",
      "Epoch: 45, Batch: 17153/37625 (45.589%), Loss: 0.8719\n",
      "Epoch: 45, Batch: 17409/37625 (46.270%), Loss: 1.0035\n",
      "Epoch: 45, Batch: 17665/37625 (46.950%), Loss: 1.2690\n",
      "Epoch: 45, Batch: 17921/37625 (47.631%), Loss: 1.0581\n",
      "Epoch: 45, Batch: 18177/37625 (48.311%), Loss: 1.0103\n",
      "Epoch: 45, Batch: 18433/37625 (48.991%), Loss: 0.7304\n",
      "Epoch: 45, Batch: 18689/37625 (49.672%), Loss: 2.4561\n",
      "Epoch: 45, Batch: 18945/37625 (50.352%), Loss: 0.9546\n",
      "Epoch: 45, Batch: 19201/37625 (51.033%), Loss: 0.8007\n",
      "Epoch: 45, Batch: 19457/37625 (51.713%), Loss: 0.8424\n",
      "Epoch: 45, Batch: 19713/37625 (52.393%), Loss: 0.6713\n",
      "Epoch: 45, Batch: 19969/37625 (53.074%), Loss: 0.8944\n",
      "Epoch: 45, Batch: 20225/37625 (53.754%), Loss: 0.9872\n",
      "Epoch: 45, Batch: 20481/37625 (54.435%), Loss: 1.2241\n",
      "Epoch: 45, Batch: 20737/37625 (55.115%), Loss: 1.7079\n",
      "Epoch: 45, Batch: 20993/37625 (55.795%), Loss: 0.6518\n",
      "Epoch: 45, Batch: 21249/37625 (56.476%), Loss: 0.7416\n",
      "Epoch: 45, Batch: 21505/37625 (57.156%), Loss: 0.6587\n",
      "Epoch: 45, Batch: 21761/37625 (57.837%), Loss: 0.7628\n",
      "Epoch: 45, Batch: 22017/37625 (58.517%), Loss: 0.8431\n",
      "Epoch: 45, Batch: 22273/37625 (59.197%), Loss: 1.1301\n",
      "Epoch: 45, Batch: 22529/37625 (59.878%), Loss: 1.0996\n",
      "Epoch: 45, Batch: 22785/37625 (60.558%), Loss: 0.7212\n",
      "Epoch: 45, Batch: 23041/37625 (61.239%), Loss: 1.0630\n",
      "Epoch: 45, Batch: 23297/37625 (61.919%), Loss: 1.7041\n",
      "Epoch: 45, Batch: 23553/37625 (62.599%), Loss: 1.2372\n",
      "Epoch: 45, Batch: 23809/37625 (63.280%), Loss: 0.8856\n",
      "Epoch: 45, Batch: 24065/37625 (63.960%), Loss: 0.8537\n",
      "Epoch: 45, Batch: 24321/37625 (64.641%), Loss: 1.2160\n",
      "Epoch: 45, Batch: 24577/37625 (65.321%), Loss: 0.8996\n",
      "Epoch: 45, Batch: 24833/37625 (66.001%), Loss: 0.8199\n",
      "Epoch: 45, Batch: 25089/37625 (66.682%), Loss: 1.0796\n",
      "Epoch: 45, Batch: 25345/37625 (67.362%), Loss: 0.7622\n",
      "Epoch: 45, Batch: 25601/37625 (68.043%), Loss: 0.5988\n",
      "Epoch: 45, Batch: 25857/37625 (68.723%), Loss: 0.6254\n",
      "Epoch: 45, Batch: 26113/37625 (69.403%), Loss: 0.6899\n",
      "Epoch: 45, Batch: 26369/37625 (70.084%), Loss: 0.9551\n",
      "Epoch: 45, Batch: 26625/37625 (70.764%), Loss: 0.8662\n",
      "Epoch: 45, Batch: 26881/37625 (71.445%), Loss: 0.6105\n",
      "Epoch: 45, Batch: 27137/37625 (72.125%), Loss: 0.5306\n",
      "Epoch: 45, Batch: 27393/37625 (72.805%), Loss: 1.0291\n",
      "Epoch: 45, Batch: 27649/37625 (73.486%), Loss: 1.7261\n",
      "Epoch: 45, Batch: 27905/37625 (74.166%), Loss: 0.7051\n",
      "Epoch: 45, Batch: 28161/37625 (74.847%), Loss: 0.6716\n",
      "Epoch: 45, Batch: 28417/37625 (75.527%), Loss: 0.7618\n",
      "Epoch: 45, Batch: 28673/37625 (76.207%), Loss: 0.8414\n",
      "Epoch: 45, Batch: 28929/37625 (76.888%), Loss: 1.5500\n",
      "Epoch: 45, Batch: 29185/37625 (77.568%), Loss: 1.2794\n",
      "Epoch: 45, Batch: 29441/37625 (78.249%), Loss: 0.8130\n",
      "Epoch: 45, Batch: 29697/37625 (78.929%), Loss: 0.9951\n",
      "Epoch: 45, Batch: 29953/37625 (79.609%), Loss: 0.7407\n",
      "Epoch: 45, Batch: 30209/37625 (80.290%), Loss: 0.9706\n",
      "Epoch: 45, Batch: 30465/37625 (80.970%), Loss: 1.1116\n",
      "Epoch: 45, Batch: 30721/37625 (81.650%), Loss: 0.8821\n",
      "Epoch: 45, Batch: 30977/37625 (82.331%), Loss: 0.6783\n",
      "Epoch: 45, Batch: 31233/37625 (83.011%), Loss: 0.9159\n",
      "Epoch: 45, Batch: 31489/37625 (83.692%), Loss: 0.8654\n",
      "Epoch: 45, Batch: 31745/37625 (84.372%), Loss: 1.6206\n",
      "Epoch: 45, Batch: 32001/37625 (85.052%), Loss: 0.9046\n",
      "Epoch: 45, Batch: 32257/37625 (85.733%), Loss: 2.0691\n",
      "Epoch: 45, Batch: 32513/37625 (86.413%), Loss: 1.3773\n",
      "Epoch: 45, Batch: 32769/37625 (87.094%), Loss: 0.6131\n",
      "Epoch: 45, Batch: 33025/37625 (87.774%), Loss: 1.5375\n",
      "Epoch: 45, Batch: 33281/37625 (88.454%), Loss: 0.8517\n",
      "Epoch: 45, Batch: 33537/37625 (89.135%), Loss: 1.2942\n",
      "Epoch: 45, Batch: 33793/37625 (89.815%), Loss: 0.8990\n",
      "Epoch: 45, Batch: 34049/37625 (90.496%), Loss: 1.2587\n",
      "Epoch: 45, Batch: 34305/37625 (91.176%), Loss: 0.8600\n",
      "Epoch: 45, Batch: 34561/37625 (91.856%), Loss: 1.1760\n",
      "Epoch: 45, Batch: 34817/37625 (92.537%), Loss: 0.7662\n",
      "Epoch: 45, Batch: 35073/37625 (93.217%), Loss: 0.9387\n",
      "Epoch: 45, Batch: 35329/37625 (93.898%), Loss: 0.9792\n",
      "Epoch: 45, Batch: 35585/37625 (94.578%), Loss: 0.9895\n",
      "Epoch: 45, Batch: 35841/37625 (95.258%), Loss: 0.7005\n",
      "Epoch: 45, Batch: 36097/37625 (95.939%), Loss: 1.1677\n",
      "Epoch: 45, Batch: 36353/37625 (96.619%), Loss: 1.3029\n",
      "Epoch: 45, Batch: 36609/37625 (97.300%), Loss: 2.3668\n",
      "Epoch: 45, Batch: 36865/37625 (97.980%), Loss: 0.9571\n",
      "Epoch: 45, Batch: 37121/37625 (98.660%), Loss: 0.8103\n",
      "Epoch: 45, Batch: 37377/37625 (99.341%), Loss: 0.9720\n",
      "Epoch: 46, Batch: 1/37625 (0.003%), Loss: 0.6815\n",
      "Epoch: 46, Batch: 257/37625 (0.683%), Loss: 0.8989\n",
      "Epoch: 46, Batch: 513/37625 (1.363%), Loss: 1.6017\n",
      "Epoch: 46, Batch: 769/37625 (2.044%), Loss: 1.1390\n",
      "Epoch: 46, Batch: 1025/37625 (2.724%), Loss: 1.7611\n",
      "Epoch: 46, Batch: 1281/37625 (3.405%), Loss: 0.8753\n",
      "Epoch: 46, Batch: 1537/37625 (4.085%), Loss: 0.6866\n",
      "Epoch: 46, Batch: 1793/37625 (4.765%), Loss: 1.2318\n",
      "Epoch: 46, Batch: 2049/37625 (5.446%), Loss: 0.8448\n",
      "Epoch: 46, Batch: 2305/37625 (6.126%), Loss: 0.5297\n",
      "Epoch: 46, Batch: 2561/37625 (6.807%), Loss: 0.7043\n",
      "Epoch: 46, Batch: 2817/37625 (7.487%), Loss: 1.0524\n",
      "Epoch: 46, Batch: 3073/37625 (8.167%), Loss: 4.3656\n",
      "Epoch: 46, Batch: 3329/37625 (8.848%), Loss: 0.6098\n",
      "Epoch: 46, Batch: 3585/37625 (9.528%), Loss: 1.2485\n",
      "Epoch: 46, Batch: 3841/37625 (10.209%), Loss: 0.6684\n",
      "Epoch: 46, Batch: 4097/37625 (10.889%), Loss: 1.1762\n",
      "Epoch: 46, Batch: 4353/37625 (11.569%), Loss: 0.7600\n",
      "Epoch: 46, Batch: 4609/37625 (12.250%), Loss: 0.5757\n",
      "Epoch: 46, Batch: 4865/37625 (12.930%), Loss: 1.0767\n",
      "Epoch: 46, Batch: 5121/37625 (13.611%), Loss: 0.9934\n",
      "Epoch: 46, Batch: 5377/37625 (14.291%), Loss: 0.9507\n",
      "Epoch: 46, Batch: 5633/37625 (14.971%), Loss: 0.5931\n",
      "Epoch: 46, Batch: 5889/37625 (15.652%), Loss: 1.4224\n",
      "Epoch: 46, Batch: 6145/37625 (16.332%), Loss: 0.6307\n",
      "Epoch: 46, Batch: 6401/37625 (17.013%), Loss: 0.8565\n",
      "Epoch: 46, Batch: 6657/37625 (17.693%), Loss: 1.0359\n",
      "Epoch: 46, Batch: 6913/37625 (18.373%), Loss: 0.9354\n",
      "Epoch: 46, Batch: 7169/37625 (19.054%), Loss: 1.7105\n",
      "Epoch: 46, Batch: 7425/37625 (19.734%), Loss: 0.7849\n",
      "Epoch: 46, Batch: 7681/37625 (20.415%), Loss: 1.0092\n",
      "Epoch: 46, Batch: 7937/37625 (21.095%), Loss: 0.9834\n",
      "Epoch: 46, Batch: 8193/37625 (21.775%), Loss: 0.7941\n",
      "Epoch: 46, Batch: 8449/37625 (22.456%), Loss: 0.8422\n",
      "Epoch: 46, Batch: 8705/37625 (23.136%), Loss: 0.8954\n",
      "Epoch: 46, Batch: 8961/37625 (23.817%), Loss: 1.0528\n",
      "Epoch: 46, Batch: 9217/37625 (24.497%), Loss: 0.6892\n",
      "Epoch: 46, Batch: 9473/37625 (25.177%), Loss: 0.6243\n",
      "Epoch: 46, Batch: 9729/37625 (25.858%), Loss: 0.9005\n",
      "Epoch: 46, Batch: 9985/37625 (26.538%), Loss: 0.7205\n",
      "Epoch: 46, Batch: 10241/37625 (27.219%), Loss: 1.0421\n",
      "Epoch: 46, Batch: 10497/37625 (27.899%), Loss: 0.9274\n",
      "Epoch: 46, Batch: 10753/37625 (28.579%), Loss: 0.6788\n",
      "Epoch: 46, Batch: 11009/37625 (29.260%), Loss: 0.7243\n",
      "Epoch: 46, Batch: 11265/37625 (29.940%), Loss: 0.7799\n",
      "Epoch: 46, Batch: 11521/37625 (30.621%), Loss: 1.7210\n",
      "Epoch: 46, Batch: 11777/37625 (31.301%), Loss: 0.7813\n",
      "Epoch: 46, Batch: 12033/37625 (31.981%), Loss: 1.3407\n",
      "Epoch: 46, Batch: 12289/37625 (32.662%), Loss: 1.0259\n",
      "Epoch: 46, Batch: 12545/37625 (33.342%), Loss: 2.0428\n",
      "Epoch: 46, Batch: 12801/37625 (34.023%), Loss: 0.9423\n",
      "Epoch: 46, Batch: 13057/37625 (34.703%), Loss: 0.5437\n",
      "Epoch: 46, Batch: 13313/37625 (35.383%), Loss: 0.8486\n",
      "Epoch: 46, Batch: 13569/37625 (36.064%), Loss: 0.9480\n",
      "Epoch: 46, Batch: 13825/37625 (36.744%), Loss: 1.3746\n",
      "Epoch: 46, Batch: 14081/37625 (37.425%), Loss: 0.7822\n",
      "Epoch: 46, Batch: 14337/37625 (38.105%), Loss: 0.8423\n",
      "Epoch: 46, Batch: 14593/37625 (38.785%), Loss: 0.7000\n",
      "Epoch: 46, Batch: 14849/37625 (39.466%), Loss: 0.7469\n",
      "Epoch: 46, Batch: 15105/37625 (40.146%), Loss: 2.3486\n",
      "Epoch: 46, Batch: 15361/37625 (40.827%), Loss: 1.7800\n",
      "Epoch: 46, Batch: 15617/37625 (41.507%), Loss: 0.8171\n",
      "Epoch: 46, Batch: 15873/37625 (42.187%), Loss: 1.0774\n",
      "Epoch: 46, Batch: 16129/37625 (42.868%), Loss: 0.6878\n",
      "Epoch: 46, Batch: 16385/37625 (43.548%), Loss: 0.7267\n",
      "Epoch: 46, Batch: 16641/37625 (44.229%), Loss: 0.8910\n",
      "Epoch: 46, Batch: 16897/37625 (44.909%), Loss: 0.7821\n",
      "Epoch: 46, Batch: 17153/37625 (45.589%), Loss: 0.6254\n",
      "Epoch: 46, Batch: 17409/37625 (46.270%), Loss: 1.0194\n",
      "Epoch: 46, Batch: 17665/37625 (46.950%), Loss: 0.9853\n",
      "Epoch: 46, Batch: 17921/37625 (47.631%), Loss: 1.6472\n",
      "Epoch: 46, Batch: 18177/37625 (48.311%), Loss: 2.1944\n",
      "Epoch: 46, Batch: 18433/37625 (48.991%), Loss: 0.7323\n",
      "Epoch: 46, Batch: 18689/37625 (49.672%), Loss: 1.2448\n",
      "Epoch: 46, Batch: 18945/37625 (50.352%), Loss: 1.0508\n",
      "Epoch: 46, Batch: 19201/37625 (51.033%), Loss: 0.7906\n",
      "Epoch: 46, Batch: 19457/37625 (51.713%), Loss: 0.7265\n",
      "Epoch: 46, Batch: 19713/37625 (52.393%), Loss: 0.9170\n",
      "Epoch: 46, Batch: 19969/37625 (53.074%), Loss: 0.8156\n",
      "Epoch: 46, Batch: 20225/37625 (53.754%), Loss: 0.8909\n",
      "Epoch: 46, Batch: 20481/37625 (54.435%), Loss: 3.4397\n",
      "Epoch: 46, Batch: 20737/37625 (55.115%), Loss: 0.9582\n",
      "Epoch: 46, Batch: 20993/37625 (55.795%), Loss: 5.5466\n",
      "Epoch: 46, Batch: 21249/37625 (56.476%), Loss: 0.9569\n",
      "Epoch: 46, Batch: 21505/37625 (57.156%), Loss: 0.8938\n",
      "Epoch: 46, Batch: 21761/37625 (57.837%), Loss: 0.7365\n",
      "Epoch: 46, Batch: 22017/37625 (58.517%), Loss: 0.6493\n",
      "Epoch: 46, Batch: 22273/37625 (59.197%), Loss: 0.6725\n",
      "Epoch: 46, Batch: 22529/37625 (59.878%), Loss: 1.9410\n",
      "Epoch: 46, Batch: 22785/37625 (60.558%), Loss: 1.0956\n",
      "Epoch: 46, Batch: 23041/37625 (61.239%), Loss: 0.7752\n",
      "Epoch: 46, Batch: 23297/37625 (61.919%), Loss: 0.8558\n",
      "Epoch: 46, Batch: 23553/37625 (62.599%), Loss: 0.5415\n",
      "Epoch: 46, Batch: 23809/37625 (63.280%), Loss: 0.7400\n",
      "Epoch: 46, Batch: 24065/37625 (63.960%), Loss: 0.6512\n",
      "Epoch: 46, Batch: 24321/37625 (64.641%), Loss: 0.7094\n",
      "Epoch: 46, Batch: 24577/37625 (65.321%), Loss: 1.2256\n",
      "Epoch: 46, Batch: 24833/37625 (66.001%), Loss: 0.8342\n",
      "Epoch: 46, Batch: 25089/37625 (66.682%), Loss: 1.0226\n",
      "Epoch: 46, Batch: 25345/37625 (67.362%), Loss: 1.4528\n",
      "Epoch: 46, Batch: 25601/37625 (68.043%), Loss: 0.8248\n",
      "Epoch: 46, Batch: 25857/37625 (68.723%), Loss: 0.8930\n",
      "Epoch: 46, Batch: 26113/37625 (69.403%), Loss: 0.8177\n",
      "Epoch: 46, Batch: 26369/37625 (70.084%), Loss: 0.6733\n",
      "Epoch: 46, Batch: 26625/37625 (70.764%), Loss: 5.4512\n",
      "Epoch: 46, Batch: 26881/37625 (71.445%), Loss: 0.8802\n",
      "Epoch: 46, Batch: 27137/37625 (72.125%), Loss: 2.3541\n",
      "Epoch: 46, Batch: 27393/37625 (72.805%), Loss: 0.9528\n",
      "Epoch: 46, Batch: 27649/37625 (73.486%), Loss: 1.2828\n",
      "Epoch: 46, Batch: 27905/37625 (74.166%), Loss: 0.6520\n",
      "Epoch: 46, Batch: 28161/37625 (74.847%), Loss: 1.1542\n",
      "Epoch: 46, Batch: 28417/37625 (75.527%), Loss: 3.2627\n",
      "Epoch: 46, Batch: 28673/37625 (76.207%), Loss: 0.9716\n",
      "Epoch: 46, Batch: 28929/37625 (76.888%), Loss: 0.9687\n",
      "Epoch: 46, Batch: 29185/37625 (77.568%), Loss: 0.6769\n",
      "Epoch: 46, Batch: 29441/37625 (78.249%), Loss: 0.7244\n",
      "Epoch: 46, Batch: 29697/37625 (78.929%), Loss: 0.9007\n",
      "Epoch: 46, Batch: 29953/37625 (79.609%), Loss: 0.8796\n",
      "Epoch: 46, Batch: 30209/37625 (80.290%), Loss: 0.6204\n",
      "Epoch: 46, Batch: 30465/37625 (80.970%), Loss: 1.1980\n",
      "Epoch: 46, Batch: 30721/37625 (81.650%), Loss: 1.4806\n",
      "Epoch: 46, Batch: 30977/37625 (82.331%), Loss: 1.2445\n",
      "Epoch: 46, Batch: 31233/37625 (83.011%), Loss: 0.6316\n",
      "Epoch: 46, Batch: 31489/37625 (83.692%), Loss: 1.8403\n",
      "Epoch: 46, Batch: 31745/37625 (84.372%), Loss: 1.0199\n",
      "Epoch: 46, Batch: 32001/37625 (85.052%), Loss: 0.7023\n",
      "Epoch: 46, Batch: 32257/37625 (85.733%), Loss: 0.8260\n",
      "Epoch: 46, Batch: 32513/37625 (86.413%), Loss: 1.2705\n",
      "Epoch: 46, Batch: 32769/37625 (87.094%), Loss: 0.6633\n",
      "Epoch: 46, Batch: 33025/37625 (87.774%), Loss: 3.0473\n",
      "Epoch: 46, Batch: 33281/37625 (88.454%), Loss: 0.7896\n",
      "Epoch: 46, Batch: 33537/37625 (89.135%), Loss: 1.0608\n",
      "Epoch: 46, Batch: 33793/37625 (89.815%), Loss: 0.6683\n",
      "Epoch: 46, Batch: 34049/37625 (90.496%), Loss: 1.1518\n",
      "Epoch: 46, Batch: 34305/37625 (91.176%), Loss: 1.5062\n",
      "Epoch: 46, Batch: 34561/37625 (91.856%), Loss: 0.8609\n",
      "Epoch: 46, Batch: 34817/37625 (92.537%), Loss: 0.6750\n",
      "Epoch: 46, Batch: 35073/37625 (93.217%), Loss: 1.0472\n",
      "Epoch: 46, Batch: 35329/37625 (93.898%), Loss: 0.7491\n",
      "Epoch: 46, Batch: 35585/37625 (94.578%), Loss: 1.2436\n",
      "Epoch: 46, Batch: 35841/37625 (95.258%), Loss: 0.8839\n",
      "Epoch: 46, Batch: 36097/37625 (95.939%), Loss: 0.8337\n",
      "Epoch: 46, Batch: 36353/37625 (96.619%), Loss: 1.0660\n",
      "Epoch: 46, Batch: 36609/37625 (97.300%), Loss: 1.2032\n",
      "Epoch: 46, Batch: 36865/37625 (97.980%), Loss: 1.1795\n",
      "Epoch: 46, Batch: 37121/37625 (98.660%), Loss: 1.1040\n",
      "Epoch: 46, Batch: 37377/37625 (99.341%), Loss: 0.7187\n",
      "Epoch: 47, Batch: 1/37625 (0.003%), Loss: 1.9064\n",
      "Epoch: 47, Batch: 257/37625 (0.683%), Loss: 1.3931\n",
      "Epoch: 47, Batch: 513/37625 (1.363%), Loss: 0.7135\n",
      "Epoch: 47, Batch: 769/37625 (2.044%), Loss: 1.1579\n",
      "Epoch: 47, Batch: 1025/37625 (2.724%), Loss: 0.7069\n",
      "Epoch: 47, Batch: 1281/37625 (3.405%), Loss: 0.9168\n",
      "Epoch: 47, Batch: 1537/37625 (4.085%), Loss: 0.7201\n",
      "Epoch: 47, Batch: 1793/37625 (4.765%), Loss: 1.3031\n",
      "Epoch: 47, Batch: 2049/37625 (5.446%), Loss: 1.6540\n",
      "Epoch: 47, Batch: 2305/37625 (6.126%), Loss: 1.2661\n",
      "Epoch: 47, Batch: 2561/37625 (6.807%), Loss: 1.4606\n",
      "Epoch: 47, Batch: 2817/37625 (7.487%), Loss: 1.0642\n",
      "Epoch: 47, Batch: 3073/37625 (8.167%), Loss: 0.6732\n",
      "Epoch: 47, Batch: 3329/37625 (8.848%), Loss: 1.0417\n",
      "Epoch: 47, Batch: 3585/37625 (9.528%), Loss: 1.0680\n",
      "Epoch: 47, Batch: 3841/37625 (10.209%), Loss: 0.9899\n",
      "Epoch: 47, Batch: 4097/37625 (10.889%), Loss: 1.0010\n",
      "Epoch: 47, Batch: 4353/37625 (11.569%), Loss: 0.9632\n",
      "Epoch: 47, Batch: 4609/37625 (12.250%), Loss: 0.7035\n",
      "Epoch: 47, Batch: 4865/37625 (12.930%), Loss: 1.1910\n",
      "Epoch: 47, Batch: 5121/37625 (13.611%), Loss: 1.0601\n",
      "Epoch: 47, Batch: 5377/37625 (14.291%), Loss: 0.7003\n",
      "Epoch: 47, Batch: 5633/37625 (14.971%), Loss: 0.7254\n",
      "Epoch: 47, Batch: 5889/37625 (15.652%), Loss: 0.9720\n",
      "Epoch: 47, Batch: 6145/37625 (16.332%), Loss: 1.2422\n",
      "Epoch: 47, Batch: 6401/37625 (17.013%), Loss: 1.0887\n",
      "Epoch: 47, Batch: 6657/37625 (17.693%), Loss: 1.0614\n",
      "Epoch: 47, Batch: 6913/37625 (18.373%), Loss: 1.0325\n",
      "Epoch: 47, Batch: 7169/37625 (19.054%), Loss: 0.7576\n",
      "Epoch: 47, Batch: 7425/37625 (19.734%), Loss: 2.5775\n",
      "Epoch: 47, Batch: 7681/37625 (20.415%), Loss: 1.9763\n",
      "Epoch: 47, Batch: 7937/37625 (21.095%), Loss: 2.6260\n",
      "Epoch: 47, Batch: 8193/37625 (21.775%), Loss: 0.5770\n",
      "Epoch: 47, Batch: 8449/37625 (22.456%), Loss: 0.8410\n",
      "Epoch: 47, Batch: 8705/37625 (23.136%), Loss: 0.7432\n",
      "Epoch: 47, Batch: 8961/37625 (23.817%), Loss: 0.7456\n",
      "Epoch: 47, Batch: 9217/37625 (24.497%), Loss: 0.8342\n",
      "Epoch: 47, Batch: 9473/37625 (25.177%), Loss: 4.4637\n",
      "Epoch: 47, Batch: 9729/37625 (25.858%), Loss: 0.9821\n",
      "Epoch: 47, Batch: 9985/37625 (26.538%), Loss: 0.8033\n",
      "Epoch: 47, Batch: 10241/37625 (27.219%), Loss: 0.6791\n",
      "Epoch: 47, Batch: 10497/37625 (27.899%), Loss: 1.0088\n",
      "Epoch: 47, Batch: 10753/37625 (28.579%), Loss: 0.9703\n",
      "Epoch: 47, Batch: 11009/37625 (29.260%), Loss: 0.7626\n",
      "Epoch: 47, Batch: 11265/37625 (29.940%), Loss: 0.9928\n",
      "Epoch: 47, Batch: 11521/37625 (30.621%), Loss: 0.7058\n",
      "Epoch: 47, Batch: 11777/37625 (31.301%), Loss: 0.7697\n",
      "Epoch: 47, Batch: 12033/37625 (31.981%), Loss: 1.0052\n",
      "Epoch: 47, Batch: 12289/37625 (32.662%), Loss: 0.6481\n",
      "Epoch: 47, Batch: 12545/37625 (33.342%), Loss: 1.3978\n",
      "Epoch: 47, Batch: 12801/37625 (34.023%), Loss: 0.8318\n",
      "Epoch: 47, Batch: 13057/37625 (34.703%), Loss: 1.1207\n",
      "Epoch: 47, Batch: 13313/37625 (35.383%), Loss: 0.8075\n",
      "Epoch: 47, Batch: 13569/37625 (36.064%), Loss: 0.6547\n",
      "Epoch: 47, Batch: 13825/37625 (36.744%), Loss: 0.7071\n",
      "Epoch: 47, Batch: 14081/37625 (37.425%), Loss: 0.6295\n",
      "Epoch: 47, Batch: 14337/37625 (38.105%), Loss: 0.7021\n",
      "Epoch: 47, Batch: 14593/37625 (38.785%), Loss: 0.7342\n",
      "Epoch: 47, Batch: 14849/37625 (39.466%), Loss: 0.8942\n",
      "Epoch: 47, Batch: 15105/37625 (40.146%), Loss: 3.5704\n",
      "Epoch: 47, Batch: 15361/37625 (40.827%), Loss: 0.6931\n",
      "Epoch: 47, Batch: 15617/37625 (41.507%), Loss: 0.6840\n",
      "Epoch: 47, Batch: 15873/37625 (42.187%), Loss: 1.3819\n",
      "Epoch: 47, Batch: 16129/37625 (42.868%), Loss: 0.7577\n",
      "Epoch: 47, Batch: 16385/37625 (43.548%), Loss: 0.8240\n",
      "Epoch: 47, Batch: 16641/37625 (44.229%), Loss: 0.7033\n",
      "Epoch: 47, Batch: 16897/37625 (44.909%), Loss: 1.6939\n",
      "Epoch: 47, Batch: 17153/37625 (45.589%), Loss: 2.1462\n",
      "Epoch: 47, Batch: 17409/37625 (46.270%), Loss: 0.7747\n",
      "Epoch: 47, Batch: 17665/37625 (46.950%), Loss: 0.9827\n",
      "Epoch: 47, Batch: 17921/37625 (47.631%), Loss: 1.5099\n",
      "Epoch: 47, Batch: 18177/37625 (48.311%), Loss: 0.6037\n",
      "Epoch: 47, Batch: 18433/37625 (48.991%), Loss: 1.3544\n",
      "Epoch: 47, Batch: 18689/37625 (49.672%), Loss: 0.7088\n",
      "Epoch: 47, Batch: 18945/37625 (50.352%), Loss: 1.0771\n",
      "Epoch: 47, Batch: 19201/37625 (51.033%), Loss: 0.7815\n",
      "Epoch: 47, Batch: 19457/37625 (51.713%), Loss: 1.1503\n",
      "Epoch: 47, Batch: 19713/37625 (52.393%), Loss: 0.8602\n",
      "Epoch: 47, Batch: 19969/37625 (53.074%), Loss: 0.8305\n",
      "Epoch: 47, Batch: 20225/37625 (53.754%), Loss: 1.8270\n",
      "Epoch: 47, Batch: 20481/37625 (54.435%), Loss: 0.8019\n",
      "Epoch: 47, Batch: 20737/37625 (55.115%), Loss: 0.6822\n",
      "Epoch: 47, Batch: 20993/37625 (55.795%), Loss: 1.4218\n",
      "Epoch: 47, Batch: 21249/37625 (56.476%), Loss: 1.4161\n",
      "Epoch: 47, Batch: 21505/37625 (57.156%), Loss: 0.9547\n",
      "Epoch: 47, Batch: 21761/37625 (57.837%), Loss: 4.9896\n",
      "Epoch: 47, Batch: 22017/37625 (58.517%), Loss: 1.4945\n",
      "Epoch: 47, Batch: 22273/37625 (59.197%), Loss: 1.2004\n",
      "Epoch: 47, Batch: 22529/37625 (59.878%), Loss: 0.6292\n",
      "Epoch: 47, Batch: 22785/37625 (60.558%), Loss: 0.8638\n",
      "Epoch: 47, Batch: 23041/37625 (61.239%), Loss: 0.7147\n",
      "Epoch: 47, Batch: 23297/37625 (61.919%), Loss: 0.6216\n",
      "Epoch: 47, Batch: 23553/37625 (62.599%), Loss: 0.5542\n",
      "Epoch: 47, Batch: 23809/37625 (63.280%), Loss: 0.8918\n",
      "Epoch: 47, Batch: 24065/37625 (63.960%), Loss: 0.9544\n",
      "Epoch: 47, Batch: 24321/37625 (64.641%), Loss: 6.7572\n",
      "Epoch: 47, Batch: 24577/37625 (65.321%), Loss: 0.9023\n",
      "Epoch: 47, Batch: 24833/37625 (66.001%), Loss: 0.7772\n",
      "Epoch: 47, Batch: 25089/37625 (66.682%), Loss: 0.5443\n",
      "Epoch: 47, Batch: 25345/37625 (67.362%), Loss: 0.9271\n",
      "Epoch: 47, Batch: 25601/37625 (68.043%), Loss: 0.9347\n",
      "Epoch: 47, Batch: 25857/37625 (68.723%), Loss: 1.0573\n",
      "Epoch: 47, Batch: 26113/37625 (69.403%), Loss: 0.6961\n",
      "Epoch: 47, Batch: 26369/37625 (70.084%), Loss: 0.8630\n",
      "Epoch: 47, Batch: 26625/37625 (70.764%), Loss: 0.7233\n",
      "Epoch: 47, Batch: 26881/37625 (71.445%), Loss: 0.8287\n",
      "Epoch: 47, Batch: 27137/37625 (72.125%), Loss: 0.9291\n",
      "Epoch: 47, Batch: 27393/37625 (72.805%), Loss: 0.6441\n",
      "Epoch: 47, Batch: 27649/37625 (73.486%), Loss: 0.9518\n",
      "Epoch: 47, Batch: 27905/37625 (74.166%), Loss: 0.7708\n",
      "Epoch: 47, Batch: 28161/37625 (74.847%), Loss: 1.0523\n",
      "Epoch: 47, Batch: 28417/37625 (75.527%), Loss: 0.8968\n",
      "Epoch: 47, Batch: 28673/37625 (76.207%), Loss: 0.8450\n",
      "Epoch: 47, Batch: 28929/37625 (76.888%), Loss: 0.7205\n",
      "Epoch: 47, Batch: 29185/37625 (77.568%), Loss: 1.0940\n",
      "Epoch: 47, Batch: 29441/37625 (78.249%), Loss: 1.6804\n",
      "Epoch: 47, Batch: 29697/37625 (78.929%), Loss: 1.4072\n",
      "Epoch: 47, Batch: 29953/37625 (79.609%), Loss: 1.0394\n",
      "Epoch: 47, Batch: 30209/37625 (80.290%), Loss: 1.1733\n",
      "Epoch: 47, Batch: 30465/37625 (80.970%), Loss: 0.7487\n",
      "Epoch: 47, Batch: 30721/37625 (81.650%), Loss: 0.6539\n",
      "Epoch: 47, Batch: 30977/37625 (82.331%), Loss: 0.8550\n",
      "Epoch: 47, Batch: 31233/37625 (83.011%), Loss: 0.5727\n",
      "Epoch: 47, Batch: 31489/37625 (83.692%), Loss: 0.7246\n",
      "Epoch: 47, Batch: 31745/37625 (84.372%), Loss: 1.7469\n",
      "Epoch: 47, Batch: 32001/37625 (85.052%), Loss: 0.7076\n",
      "Epoch: 47, Batch: 32257/37625 (85.733%), Loss: 0.6208\n",
      "Epoch: 47, Batch: 32513/37625 (86.413%), Loss: 0.8419\n",
      "Epoch: 47, Batch: 32769/37625 (87.094%), Loss: 0.8009\n",
      "Epoch: 47, Batch: 33025/37625 (87.774%), Loss: 0.6972\n",
      "Epoch: 47, Batch: 33281/37625 (88.454%), Loss: 3.9265\n",
      "Epoch: 47, Batch: 33537/37625 (89.135%), Loss: 0.9207\n",
      "Epoch: 47, Batch: 33793/37625 (89.815%), Loss: 0.6068\n",
      "Epoch: 47, Batch: 34049/37625 (90.496%), Loss: 1.3254\n",
      "Epoch: 47, Batch: 34305/37625 (91.176%), Loss: 1.8032\n",
      "Epoch: 47, Batch: 34561/37625 (91.856%), Loss: 0.9488\n",
      "Epoch: 47, Batch: 34817/37625 (92.537%), Loss: 1.0271\n",
      "Epoch: 47, Batch: 35073/37625 (93.217%), Loss: 0.6667\n",
      "Epoch: 47, Batch: 35329/37625 (93.898%), Loss: 1.0084\n",
      "Epoch: 47, Batch: 35585/37625 (94.578%), Loss: 0.9380\n",
      "Epoch: 47, Batch: 35841/37625 (95.258%), Loss: 0.6265\n",
      "Epoch: 47, Batch: 36097/37625 (95.939%), Loss: 1.3503\n",
      "Epoch: 47, Batch: 36353/37625 (96.619%), Loss: 0.7510\n",
      "Epoch: 47, Batch: 36609/37625 (97.300%), Loss: 0.9026\n",
      "Epoch: 47, Batch: 36865/37625 (97.980%), Loss: 0.6182\n",
      "Epoch: 47, Batch: 37121/37625 (98.660%), Loss: 1.3188\n",
      "Epoch: 47, Batch: 37377/37625 (99.341%), Loss: 1.0128\n",
      "Epoch: 48, Batch: 1/37625 (0.003%), Loss: 0.6812\n",
      "Epoch: 48, Batch: 257/37625 (0.683%), Loss: 0.8404\n",
      "Epoch: 48, Batch: 513/37625 (1.363%), Loss: 0.7750\n",
      "Epoch: 48, Batch: 769/37625 (2.044%), Loss: 0.4892\n",
      "Epoch: 48, Batch: 1025/37625 (2.724%), Loss: 0.6793\n",
      "Epoch: 48, Batch: 1281/37625 (3.405%), Loss: 0.8221\n",
      "Epoch: 48, Batch: 1537/37625 (4.085%), Loss: 0.6743\n",
      "Epoch: 48, Batch: 1793/37625 (4.765%), Loss: 0.5543\n",
      "Epoch: 48, Batch: 2049/37625 (5.446%), Loss: 0.9151\n",
      "Epoch: 48, Batch: 2305/37625 (6.126%), Loss: 0.9915\n",
      "Epoch: 48, Batch: 2561/37625 (6.807%), Loss: 0.9766\n",
      "Epoch: 48, Batch: 2817/37625 (7.487%), Loss: 1.0035\n",
      "Epoch: 48, Batch: 3073/37625 (8.167%), Loss: 0.7728\n",
      "Epoch: 48, Batch: 3329/37625 (8.848%), Loss: 0.9382\n",
      "Epoch: 48, Batch: 3585/37625 (9.528%), Loss: 0.7376\n",
      "Epoch: 48, Batch: 3841/37625 (10.209%), Loss: 1.8953\n",
      "Epoch: 48, Batch: 4097/37625 (10.889%), Loss: 0.8981\n",
      "Epoch: 48, Batch: 4353/37625 (11.569%), Loss: 1.2222\n",
      "Epoch: 48, Batch: 4609/37625 (12.250%), Loss: 0.9423\n",
      "Epoch: 48, Batch: 4865/37625 (12.930%), Loss: 1.2056\n",
      "Epoch: 48, Batch: 5121/37625 (13.611%), Loss: 0.9673\n",
      "Epoch: 48, Batch: 5377/37625 (14.291%), Loss: 0.8809\n",
      "Epoch: 48, Batch: 5633/37625 (14.971%), Loss: 2.6729\n",
      "Epoch: 48, Batch: 5889/37625 (15.652%), Loss: 0.5903\n",
      "Epoch: 48, Batch: 6145/37625 (16.332%), Loss: 2.9190\n",
      "Epoch: 48, Batch: 6401/37625 (17.013%), Loss: 1.7301\n",
      "Epoch: 48, Batch: 6657/37625 (17.693%), Loss: 0.5205\n",
      "Epoch: 48, Batch: 6913/37625 (18.373%), Loss: 1.1387\n",
      "Epoch: 48, Batch: 7169/37625 (19.054%), Loss: 0.6799\n",
      "Epoch: 48, Batch: 7425/37625 (19.734%), Loss: 0.7142\n",
      "Epoch: 48, Batch: 7681/37625 (20.415%), Loss: 1.0321\n",
      "Epoch: 48, Batch: 7937/37625 (21.095%), Loss: 1.0590\n",
      "Epoch: 48, Batch: 8193/37625 (21.775%), Loss: 0.9952\n",
      "Epoch: 48, Batch: 8449/37625 (22.456%), Loss: 1.0868\n",
      "Epoch: 48, Batch: 8705/37625 (23.136%), Loss: 0.6057\n",
      "Epoch: 48, Batch: 8961/37625 (23.817%), Loss: 1.1400\n",
      "Epoch: 48, Batch: 9217/37625 (24.497%), Loss: 0.6844\n",
      "Epoch: 48, Batch: 9473/37625 (25.177%), Loss: 0.9369\n",
      "Epoch: 48, Batch: 9729/37625 (25.858%), Loss: 0.9701\n",
      "Epoch: 48, Batch: 9985/37625 (26.538%), Loss: 1.4261\n",
      "Epoch: 48, Batch: 10241/37625 (27.219%), Loss: 0.6936\n",
      "Epoch: 48, Batch: 10497/37625 (27.899%), Loss: 0.9566\n",
      "Epoch: 48, Batch: 10753/37625 (28.579%), Loss: 0.7316\n",
      "Epoch: 48, Batch: 11009/37625 (29.260%), Loss: 1.2590\n",
      "Epoch: 48, Batch: 11265/37625 (29.940%), Loss: 1.2888\n",
      "Epoch: 48, Batch: 11521/37625 (30.621%), Loss: 1.4289\n",
      "Epoch: 48, Batch: 11777/37625 (31.301%), Loss: 0.6564\n",
      "Epoch: 48, Batch: 12033/37625 (31.981%), Loss: 0.8927\n",
      "Epoch: 48, Batch: 12289/37625 (32.662%), Loss: 0.8928\n",
      "Epoch: 48, Batch: 12545/37625 (33.342%), Loss: 0.6868\n",
      "Epoch: 48, Batch: 12801/37625 (34.023%), Loss: 0.8529\n",
      "Epoch: 48, Batch: 13057/37625 (34.703%), Loss: 0.7660\n",
      "Epoch: 48, Batch: 13313/37625 (35.383%), Loss: 0.7385\n",
      "Epoch: 48, Batch: 13569/37625 (36.064%), Loss: 0.7766\n",
      "Epoch: 48, Batch: 13825/37625 (36.744%), Loss: 0.8233\n",
      "Epoch: 48, Batch: 14081/37625 (37.425%), Loss: 1.0324\n",
      "Epoch: 48, Batch: 14337/37625 (38.105%), Loss: 0.5621\n",
      "Epoch: 48, Batch: 14593/37625 (38.785%), Loss: 0.8655\n",
      "Epoch: 48, Batch: 14849/37625 (39.466%), Loss: 1.3452\n",
      "Epoch: 48, Batch: 15105/37625 (40.146%), Loss: 1.0252\n",
      "Epoch: 48, Batch: 15361/37625 (40.827%), Loss: 1.0389\n",
      "Epoch: 48, Batch: 15617/37625 (41.507%), Loss: 1.0063\n",
      "Epoch: 48, Batch: 15873/37625 (42.187%), Loss: 0.8840\n",
      "Epoch: 48, Batch: 16129/37625 (42.868%), Loss: 1.2265\n",
      "Epoch: 48, Batch: 16385/37625 (43.548%), Loss: 1.1830\n",
      "Epoch: 48, Batch: 16641/37625 (44.229%), Loss: 0.9046\n",
      "Epoch: 48, Batch: 16897/37625 (44.909%), Loss: 0.5599\n",
      "Epoch: 48, Batch: 17153/37625 (45.589%), Loss: 1.8757\n",
      "Epoch: 48, Batch: 17409/37625 (46.270%), Loss: 0.5729\n",
      "Epoch: 48, Batch: 17665/37625 (46.950%), Loss: 0.5786\n",
      "Epoch: 48, Batch: 17921/37625 (47.631%), Loss: 0.5882\n",
      "Epoch: 48, Batch: 18177/37625 (48.311%), Loss: 0.8953\n",
      "Epoch: 48, Batch: 18433/37625 (48.991%), Loss: 0.9098\n",
      "Epoch: 48, Batch: 18689/37625 (49.672%), Loss: 0.6269\n",
      "Epoch: 48, Batch: 18945/37625 (50.352%), Loss: 0.8761\n",
      "Epoch: 48, Batch: 19201/37625 (51.033%), Loss: 0.9228\n",
      "Epoch: 48, Batch: 19457/37625 (51.713%), Loss: 3.4807\n",
      "Epoch: 48, Batch: 19713/37625 (52.393%), Loss: 0.7752\n",
      "Epoch: 48, Batch: 19969/37625 (53.074%), Loss: 0.7666\n",
      "Epoch: 48, Batch: 20225/37625 (53.754%), Loss: 0.6600\n",
      "Epoch: 48, Batch: 20481/37625 (54.435%), Loss: 0.8141\n",
      "Epoch: 48, Batch: 20737/37625 (55.115%), Loss: 0.6430\n",
      "Epoch: 48, Batch: 20993/37625 (55.795%), Loss: 0.6546\n",
      "Epoch: 48, Batch: 21249/37625 (56.476%), Loss: 1.7488\n",
      "Epoch: 48, Batch: 21505/37625 (57.156%), Loss: 1.7485\n",
      "Epoch: 48, Batch: 21761/37625 (57.837%), Loss: 0.9564\n",
      "Epoch: 48, Batch: 22017/37625 (58.517%), Loss: 0.6495\n",
      "Epoch: 48, Batch: 22273/37625 (59.197%), Loss: 0.9816\n",
      "Epoch: 48, Batch: 22529/37625 (59.878%), Loss: 4.9081\n",
      "Epoch: 48, Batch: 22785/37625 (60.558%), Loss: 0.7687\n",
      "Epoch: 48, Batch: 23041/37625 (61.239%), Loss: 1.1877\n",
      "Epoch: 48, Batch: 23297/37625 (61.919%), Loss: 0.9026\n",
      "Epoch: 48, Batch: 23553/37625 (62.599%), Loss: 0.7646\n",
      "Epoch: 48, Batch: 23809/37625 (63.280%), Loss: 1.1153\n",
      "Epoch: 48, Batch: 24065/37625 (63.960%), Loss: 0.5587\n",
      "Epoch: 48, Batch: 24321/37625 (64.641%), Loss: 0.8779\n",
      "Epoch: 48, Batch: 24577/37625 (65.321%), Loss: 1.0668\n",
      "Epoch: 48, Batch: 24833/37625 (66.001%), Loss: 3.5528\n",
      "Epoch: 48, Batch: 25089/37625 (66.682%), Loss: 1.2221\n",
      "Epoch: 48, Batch: 25345/37625 (67.362%), Loss: 5.7288\n",
      "Epoch: 48, Batch: 25601/37625 (68.043%), Loss: 1.2339\n",
      "Epoch: 48, Batch: 25857/37625 (68.723%), Loss: 5.4176\n",
      "Epoch: 48, Batch: 26113/37625 (69.403%), Loss: 0.6928\n",
      "Epoch: 48, Batch: 26369/37625 (70.084%), Loss: 0.7459\n",
      "Epoch: 48, Batch: 26625/37625 (70.764%), Loss: 0.5657\n",
      "Epoch: 48, Batch: 26881/37625 (71.445%), Loss: 0.9023\n",
      "Epoch: 48, Batch: 27137/37625 (72.125%), Loss: 0.8277\n",
      "Epoch: 48, Batch: 27393/37625 (72.805%), Loss: 0.6739\n",
      "Epoch: 48, Batch: 27649/37625 (73.486%), Loss: 1.3334\n",
      "Epoch: 48, Batch: 27905/37625 (74.166%), Loss: 1.2038\n",
      "Epoch: 48, Batch: 28161/37625 (74.847%), Loss: 0.8935\n",
      "Epoch: 48, Batch: 28417/37625 (75.527%), Loss: 1.0649\n",
      "Epoch: 48, Batch: 28673/37625 (76.207%), Loss: 1.2414\n",
      "Epoch: 48, Batch: 28929/37625 (76.888%), Loss: 0.7496\n",
      "Epoch: 48, Batch: 29185/37625 (77.568%), Loss: 0.7318\n",
      "Epoch: 48, Batch: 29441/37625 (78.249%), Loss: 0.9555\n",
      "Epoch: 48, Batch: 29697/37625 (78.929%), Loss: 0.8695\n",
      "Epoch: 48, Batch: 29953/37625 (79.609%), Loss: 0.8003\n",
      "Epoch: 48, Batch: 30209/37625 (80.290%), Loss: 0.8888\n",
      "Epoch: 48, Batch: 30465/37625 (80.970%), Loss: 1.1725\n",
      "Epoch: 48, Batch: 30721/37625 (81.650%), Loss: 0.7513\n",
      "Epoch: 48, Batch: 30977/37625 (82.331%), Loss: 0.7540\n",
      "Epoch: 48, Batch: 31233/37625 (83.011%), Loss: 1.2637\n",
      "Epoch: 48, Batch: 31489/37625 (83.692%), Loss: 0.4489\n",
      "Epoch: 48, Batch: 31745/37625 (84.372%), Loss: 0.8604\n",
      "Epoch: 48, Batch: 32001/37625 (85.052%), Loss: 0.7359\n",
      "Epoch: 48, Batch: 32257/37625 (85.733%), Loss: 0.8365\n",
      "Epoch: 48, Batch: 32513/37625 (86.413%), Loss: 0.9442\n",
      "Epoch: 48, Batch: 32769/37625 (87.094%), Loss: 0.9133\n",
      "Epoch: 48, Batch: 33025/37625 (87.774%), Loss: 0.6440\n",
      "Epoch: 48, Batch: 33281/37625 (88.454%), Loss: 0.6868\n",
      "Epoch: 48, Batch: 33537/37625 (89.135%), Loss: 0.9056\n",
      "Epoch: 48, Batch: 33793/37625 (89.815%), Loss: 0.8382\n",
      "Epoch: 48, Batch: 34049/37625 (90.496%), Loss: 1.4656\n",
      "Epoch: 48, Batch: 34305/37625 (91.176%), Loss: 1.5234\n",
      "Epoch: 48, Batch: 34561/37625 (91.856%), Loss: 1.7194\n",
      "Epoch: 48, Batch: 34817/37625 (92.537%), Loss: 0.8197\n",
      "Epoch: 48, Batch: 35073/37625 (93.217%), Loss: 1.0713\n",
      "Epoch: 48, Batch: 35329/37625 (93.898%), Loss: 0.8856\n",
      "Epoch: 48, Batch: 35585/37625 (94.578%), Loss: 1.1695\n",
      "Epoch: 48, Batch: 35841/37625 (95.258%), Loss: 1.0963\n",
      "Epoch: 48, Batch: 36097/37625 (95.939%), Loss: 2.1972\n",
      "Epoch: 48, Batch: 36353/37625 (96.619%), Loss: 1.2397\n",
      "Epoch: 48, Batch: 36609/37625 (97.300%), Loss: 1.3049\n",
      "Epoch: 48, Batch: 36865/37625 (97.980%), Loss: 0.9806\n",
      "Epoch: 48, Batch: 37121/37625 (98.660%), Loss: 1.0301\n",
      "Epoch: 48, Batch: 37377/37625 (99.341%), Loss: 3.5669\n",
      "Epoch: 49, Batch: 1/37625 (0.003%), Loss: 1.7698\n",
      "Epoch: 49, Batch: 257/37625 (0.683%), Loss: 0.9042\n",
      "Epoch: 49, Batch: 513/37625 (1.363%), Loss: 1.2080\n",
      "Epoch: 49, Batch: 769/37625 (2.044%), Loss: 0.6654\n",
      "Epoch: 49, Batch: 1025/37625 (2.724%), Loss: 0.7753\n",
      "Epoch: 49, Batch: 1281/37625 (3.405%), Loss: 1.8420\n",
      "Epoch: 49, Batch: 1537/37625 (4.085%), Loss: 0.6882\n",
      "Epoch: 49, Batch: 1793/37625 (4.765%), Loss: 1.2348\n",
      "Epoch: 49, Batch: 2049/37625 (5.446%), Loss: 0.5824\n",
      "Epoch: 49, Batch: 2305/37625 (6.126%), Loss: 1.0997\n",
      "Epoch: 49, Batch: 2561/37625 (6.807%), Loss: 0.8825\n",
      "Epoch: 49, Batch: 2817/37625 (7.487%), Loss: 0.6840\n",
      "Epoch: 49, Batch: 3073/37625 (8.167%), Loss: 1.3422\n",
      "Epoch: 49, Batch: 3329/37625 (8.848%), Loss: 0.9696\n",
      "Epoch: 49, Batch: 3585/37625 (9.528%), Loss: 1.2108\n",
      "Epoch: 49, Batch: 3841/37625 (10.209%), Loss: 0.7589\n",
      "Epoch: 49, Batch: 4097/37625 (10.889%), Loss: 0.9219\n",
      "Epoch: 49, Batch: 4353/37625 (11.569%), Loss: 0.7276\n",
      "Epoch: 49, Batch: 4609/37625 (12.250%), Loss: 1.0360\n",
      "Epoch: 49, Batch: 4865/37625 (12.930%), Loss: 0.9541\n",
      "Epoch: 49, Batch: 5121/37625 (13.611%), Loss: 0.9095\n",
      "Epoch: 49, Batch: 5377/37625 (14.291%), Loss: 0.9453\n",
      "Epoch: 49, Batch: 5633/37625 (14.971%), Loss: 1.0997\n",
      "Epoch: 49, Batch: 5889/37625 (15.652%), Loss: 0.6023\n",
      "Epoch: 49, Batch: 6145/37625 (16.332%), Loss: 0.6315\n",
      "Epoch: 49, Batch: 6401/37625 (17.013%), Loss: 0.8382\n",
      "Epoch: 49, Batch: 6657/37625 (17.693%), Loss: 0.9735\n",
      "Epoch: 49, Batch: 6913/37625 (18.373%), Loss: 1.6050\n",
      "Epoch: 49, Batch: 7169/37625 (19.054%), Loss: 1.2517\n",
      "Epoch: 49, Batch: 7425/37625 (19.734%), Loss: 1.1722\n",
      "Epoch: 49, Batch: 7681/37625 (20.415%), Loss: 2.2782\n",
      "Epoch: 49, Batch: 7937/37625 (21.095%), Loss: 0.7737\n",
      "Epoch: 49, Batch: 8193/37625 (21.775%), Loss: 0.8081\n",
      "Epoch: 49, Batch: 8449/37625 (22.456%), Loss: 0.7120\n",
      "Epoch: 49, Batch: 8705/37625 (23.136%), Loss: 0.6805\n",
      "Epoch: 49, Batch: 8961/37625 (23.817%), Loss: 0.7600\n",
      "Epoch: 49, Batch: 9217/37625 (24.497%), Loss: 0.7986\n",
      "Epoch: 49, Batch: 9473/37625 (25.177%), Loss: 2.2404\n",
      "Epoch: 49, Batch: 9729/37625 (25.858%), Loss: 0.8867\n",
      "Epoch: 49, Batch: 9985/37625 (26.538%), Loss: 0.7267\n",
      "Epoch: 49, Batch: 10241/37625 (27.219%), Loss: 1.0961\n",
      "Epoch: 49, Batch: 10497/37625 (27.899%), Loss: 1.0014\n",
      "Epoch: 49, Batch: 10753/37625 (28.579%), Loss: 0.6675\n",
      "Epoch: 49, Batch: 11009/37625 (29.260%), Loss: 0.7508\n",
      "Epoch: 49, Batch: 11265/37625 (29.940%), Loss: 0.9402\n",
      "Epoch: 49, Batch: 11521/37625 (30.621%), Loss: 0.9008\n",
      "Epoch: 49, Batch: 11777/37625 (31.301%), Loss: 0.9300\n",
      "Epoch: 49, Batch: 12033/37625 (31.981%), Loss: 0.7758\n",
      "Epoch: 49, Batch: 12289/37625 (32.662%), Loss: 1.0310\n",
      "Epoch: 49, Batch: 12545/37625 (33.342%), Loss: 0.7968\n",
      "Epoch: 49, Batch: 12801/37625 (34.023%), Loss: 1.4673\n",
      "Epoch: 49, Batch: 13057/37625 (34.703%), Loss: 1.1091\n",
      "Epoch: 49, Batch: 13313/37625 (35.383%), Loss: 5.3969\n",
      "Epoch: 49, Batch: 13569/37625 (36.064%), Loss: 0.9299\n",
      "Epoch: 49, Batch: 13825/37625 (36.744%), Loss: 0.9206\n",
      "Epoch: 49, Batch: 14081/37625 (37.425%), Loss: 3.3562\n",
      "Epoch: 49, Batch: 14337/37625 (38.105%), Loss: 0.7543\n",
      "Epoch: 49, Batch: 14593/37625 (38.785%), Loss: 1.6873\n",
      "Epoch: 49, Batch: 14849/37625 (39.466%), Loss: 0.9556\n",
      "Epoch: 49, Batch: 15105/37625 (40.146%), Loss: 6.2770\n",
      "Epoch: 49, Batch: 15361/37625 (40.827%), Loss: 0.8169\n",
      "Epoch: 49, Batch: 15617/37625 (41.507%), Loss: 0.7918\n",
      "Epoch: 49, Batch: 15873/37625 (42.187%), Loss: 1.0482\n",
      "Epoch: 49, Batch: 16129/37625 (42.868%), Loss: 1.2074\n",
      "Epoch: 49, Batch: 16385/37625 (43.548%), Loss: 1.1930\n",
      "Epoch: 49, Batch: 16641/37625 (44.229%), Loss: 1.1978\n",
      "Epoch: 49, Batch: 16897/37625 (44.909%), Loss: 1.6854\n",
      "Epoch: 49, Batch: 17153/37625 (45.589%), Loss: 0.8598\n",
      "Epoch: 49, Batch: 17409/37625 (46.270%), Loss: 1.0437\n",
      "Epoch: 49, Batch: 17665/37625 (46.950%), Loss: 0.8981\n",
      "Epoch: 49, Batch: 17921/37625 (47.631%), Loss: 0.9892\n",
      "Epoch: 49, Batch: 18177/37625 (48.311%), Loss: 1.4138\n",
      "Epoch: 49, Batch: 18433/37625 (48.991%), Loss: 0.6273\n",
      "Epoch: 49, Batch: 18689/37625 (49.672%), Loss: 5.1095\n",
      "Epoch: 49, Batch: 18945/37625 (50.352%), Loss: 0.5760\n",
      "Epoch: 49, Batch: 19201/37625 (51.033%), Loss: 0.7047\n",
      "Epoch: 49, Batch: 19457/37625 (51.713%), Loss: 0.9638\n",
      "Epoch: 49, Batch: 19713/37625 (52.393%), Loss: 0.8792\n",
      "Epoch: 49, Batch: 19969/37625 (53.074%), Loss: 1.5075\n",
      "Epoch: 49, Batch: 20225/37625 (53.754%), Loss: 1.0768\n",
      "Epoch: 49, Batch: 20481/37625 (54.435%), Loss: 0.8239\n",
      "Epoch: 49, Batch: 20737/37625 (55.115%), Loss: 1.3582\n",
      "Epoch: 49, Batch: 20993/37625 (55.795%), Loss: 0.6043\n",
      "Epoch: 49, Batch: 21249/37625 (56.476%), Loss: 0.8233\n",
      "Epoch: 49, Batch: 21505/37625 (57.156%), Loss: 0.5247\n",
      "Epoch: 49, Batch: 21761/37625 (57.837%), Loss: 0.8826\n",
      "Epoch: 49, Batch: 22017/37625 (58.517%), Loss: 0.7114\n",
      "Epoch: 49, Batch: 22273/37625 (59.197%), Loss: 1.4062\n",
      "Epoch: 49, Batch: 22529/37625 (59.878%), Loss: 0.5855\n",
      "Epoch: 49, Batch: 22785/37625 (60.558%), Loss: 1.2610\n",
      "Epoch: 49, Batch: 23041/37625 (61.239%), Loss: 0.9373\n",
      "Epoch: 49, Batch: 23297/37625 (61.919%), Loss: 1.1160\n",
      "Epoch: 49, Batch: 23553/37625 (62.599%), Loss: 0.7520\n",
      "Epoch: 49, Batch: 23809/37625 (63.280%), Loss: 0.6150\n",
      "Epoch: 49, Batch: 24065/37625 (63.960%), Loss: 0.6297\n",
      "Epoch: 49, Batch: 24321/37625 (64.641%), Loss: 0.7427\n",
      "Epoch: 49, Batch: 24577/37625 (65.321%), Loss: 0.8091\n",
      "Epoch: 49, Batch: 24833/37625 (66.001%), Loss: 0.9687\n",
      "Epoch: 49, Batch: 25089/37625 (66.682%), Loss: 0.8426\n",
      "Epoch: 49, Batch: 25345/37625 (67.362%), Loss: 0.6854\n",
      "Epoch: 49, Batch: 25601/37625 (68.043%), Loss: 1.2661\n",
      "Epoch: 49, Batch: 25857/37625 (68.723%), Loss: 0.6462\n",
      "Epoch: 49, Batch: 26113/37625 (69.403%), Loss: 1.0009\n",
      "Epoch: 49, Batch: 26369/37625 (70.084%), Loss: 0.7110\n",
      "Epoch: 49, Batch: 26625/37625 (70.764%), Loss: 1.1102\n",
      "Epoch: 49, Batch: 26881/37625 (71.445%), Loss: 0.8466\n",
      "Epoch: 49, Batch: 27137/37625 (72.125%), Loss: 1.5129\n",
      "Epoch: 49, Batch: 27393/37625 (72.805%), Loss: 1.2009\n",
      "Epoch: 49, Batch: 27649/37625 (73.486%), Loss: 1.1235\n",
      "Epoch: 49, Batch: 27905/37625 (74.166%), Loss: 0.6517\n",
      "Epoch: 49, Batch: 28161/37625 (74.847%), Loss: 2.3414\n",
      "Epoch: 49, Batch: 28417/37625 (75.527%), Loss: 0.4733\n",
      "Epoch: 49, Batch: 28673/37625 (76.207%), Loss: 0.8628\n",
      "Epoch: 49, Batch: 28929/37625 (76.888%), Loss: 0.8287\n",
      "Epoch: 49, Batch: 29185/37625 (77.568%), Loss: 0.8957\n",
      "Epoch: 49, Batch: 29441/37625 (78.249%), Loss: 1.5834\n",
      "Epoch: 49, Batch: 29697/37625 (78.929%), Loss: 1.4101\n",
      "Epoch: 49, Batch: 29953/37625 (79.609%), Loss: 0.9848\n",
      "Epoch: 49, Batch: 30209/37625 (80.290%), Loss: 0.7350\n",
      "Epoch: 49, Batch: 30465/37625 (80.970%), Loss: 1.2218\n",
      "Epoch: 49, Batch: 30721/37625 (81.650%), Loss: 1.0134\n",
      "Epoch: 49, Batch: 30977/37625 (82.331%), Loss: 0.7324\n",
      "Epoch: 49, Batch: 31233/37625 (83.011%), Loss: 1.4786\n",
      "Epoch: 49, Batch: 31489/37625 (83.692%), Loss: 1.1940\n",
      "Epoch: 49, Batch: 31745/37625 (84.372%), Loss: 0.7109\n",
      "Epoch: 49, Batch: 32001/37625 (85.052%), Loss: 1.8117\n",
      "Epoch: 49, Batch: 32257/37625 (85.733%), Loss: 0.7150\n",
      "Epoch: 49, Batch: 32513/37625 (86.413%), Loss: 0.9731\n",
      "Epoch: 49, Batch: 32769/37625 (87.094%), Loss: 0.8470\n",
      "Epoch: 49, Batch: 33025/37625 (87.774%), Loss: 0.7331\n",
      "Epoch: 49, Batch: 33281/37625 (88.454%), Loss: 0.7757\n",
      "Epoch: 49, Batch: 33537/37625 (89.135%), Loss: 0.7868\n",
      "Epoch: 49, Batch: 33793/37625 (89.815%), Loss: 0.7098\n",
      "Epoch: 49, Batch: 34049/37625 (90.496%), Loss: 1.0316\n",
      "Epoch: 49, Batch: 34305/37625 (91.176%), Loss: 1.0397\n",
      "Epoch: 49, Batch: 34561/37625 (91.856%), Loss: 0.5396\n",
      "Epoch: 49, Batch: 34817/37625 (92.537%), Loss: 1.1460\n",
      "Epoch: 49, Batch: 35073/37625 (93.217%), Loss: 0.5126\n",
      "Epoch: 49, Batch: 35329/37625 (93.898%), Loss: 0.7780\n",
      "Epoch: 49, Batch: 35585/37625 (94.578%), Loss: 0.9637\n",
      "Epoch: 49, Batch: 35841/37625 (95.258%), Loss: 3.1240\n",
      "Epoch: 49, Batch: 36097/37625 (95.939%), Loss: 1.1971\n",
      "Epoch: 49, Batch: 36353/37625 (96.619%), Loss: 1.2186\n",
      "Epoch: 49, Batch: 36609/37625 (97.300%), Loss: 0.9725\n",
      "Epoch: 49, Batch: 36865/37625 (97.980%), Loss: 0.8796\n",
      "Epoch: 49, Batch: 37121/37625 (98.660%), Loss: 0.9303\n",
      "Epoch: 49, Batch: 37377/37625 (99.341%), Loss: 1.1877\n",
      "Epoch: 50, Batch: 1/37625 (0.003%), Loss: 0.9986\n",
      "Epoch: 50, Batch: 257/37625 (0.683%), Loss: 0.6393\n",
      "Epoch: 50, Batch: 513/37625 (1.363%), Loss: 0.8253\n",
      "Epoch: 50, Batch: 769/37625 (2.044%), Loss: 0.7771\n",
      "Epoch: 50, Batch: 1025/37625 (2.724%), Loss: 0.7721\n",
      "Epoch: 50, Batch: 1281/37625 (3.405%), Loss: 0.5895\n",
      "Epoch: 50, Batch: 1537/37625 (4.085%), Loss: 0.7265\n",
      "Epoch: 50, Batch: 1793/37625 (4.765%), Loss: 1.2052\n",
      "Epoch: 50, Batch: 2049/37625 (5.446%), Loss: 0.7505\n",
      "Epoch: 50, Batch: 2305/37625 (6.126%), Loss: 0.6223\n",
      "Epoch: 50, Batch: 2561/37625 (6.807%), Loss: 0.6044\n",
      "Epoch: 50, Batch: 2817/37625 (7.487%), Loss: 0.7351\n",
      "Epoch: 50, Batch: 3073/37625 (8.167%), Loss: 0.8448\n",
      "Epoch: 50, Batch: 3329/37625 (8.848%), Loss: 1.0389\n",
      "Epoch: 50, Batch: 3585/37625 (9.528%), Loss: 0.9646\n",
      "Epoch: 50, Batch: 3841/37625 (10.209%), Loss: 0.5696\n",
      "Epoch: 50, Batch: 4097/37625 (10.889%), Loss: 0.9423\n",
      "Epoch: 50, Batch: 4353/37625 (11.569%), Loss: 0.6887\n",
      "Epoch: 50, Batch: 4609/37625 (12.250%), Loss: 0.8352\n",
      "Epoch: 50, Batch: 4865/37625 (12.930%), Loss: 1.0987\n",
      "Epoch: 50, Batch: 5121/37625 (13.611%), Loss: 1.0789\n",
      "Epoch: 50, Batch: 5377/37625 (14.291%), Loss: 1.3668\n",
      "Epoch: 50, Batch: 5633/37625 (14.971%), Loss: 0.9393\n",
      "Epoch: 50, Batch: 5889/37625 (15.652%), Loss: 1.5238\n",
      "Epoch: 50, Batch: 6145/37625 (16.332%), Loss: 0.8319\n",
      "Epoch: 50, Batch: 6401/37625 (17.013%), Loss: 0.6062\n",
      "Epoch: 50, Batch: 6657/37625 (17.693%), Loss: 5.6164\n",
      "Epoch: 50, Batch: 6913/37625 (18.373%), Loss: 0.7489\n",
      "Epoch: 50, Batch: 7169/37625 (19.054%), Loss: 1.0207\n",
      "Epoch: 50, Batch: 7425/37625 (19.734%), Loss: 0.6904\n",
      "Epoch: 50, Batch: 7681/37625 (20.415%), Loss: 1.2611\n",
      "Epoch: 50, Batch: 7937/37625 (21.095%), Loss: 0.8438\n",
      "Epoch: 50, Batch: 8193/37625 (21.775%), Loss: 5.1628\n",
      "Epoch: 50, Batch: 8449/37625 (22.456%), Loss: 1.0525\n",
      "Epoch: 50, Batch: 8705/37625 (23.136%), Loss: 0.5745\n",
      "Epoch: 50, Batch: 8961/37625 (23.817%), Loss: 1.2414\n",
      "Epoch: 50, Batch: 9217/37625 (24.497%), Loss: 0.5232\n",
      "Epoch: 50, Batch: 9473/37625 (25.177%), Loss: 1.6056\n",
      "Epoch: 50, Batch: 9729/37625 (25.858%), Loss: 2.3262\n",
      "Epoch: 50, Batch: 9985/37625 (26.538%), Loss: 0.7923\n",
      "Epoch: 50, Batch: 10241/37625 (27.219%), Loss: 0.6576\n",
      "Epoch: 50, Batch: 10497/37625 (27.899%), Loss: 0.8065\n",
      "Epoch: 50, Batch: 10753/37625 (28.579%), Loss: 1.1481\n",
      "Epoch: 50, Batch: 11009/37625 (29.260%), Loss: 0.9339\n",
      "Epoch: 50, Batch: 11265/37625 (29.940%), Loss: 0.5398\n",
      "Epoch: 50, Batch: 11521/37625 (30.621%), Loss: 0.6205\n",
      "Epoch: 50, Batch: 11777/37625 (31.301%), Loss: 0.6443\n",
      "Epoch: 50, Batch: 12033/37625 (31.981%), Loss: 1.4305\n",
      "Epoch: 50, Batch: 12289/37625 (32.662%), Loss: 2.3513\n",
      "Epoch: 50, Batch: 12545/37625 (33.342%), Loss: 1.2783\n",
      "Epoch: 50, Batch: 12801/37625 (34.023%), Loss: 0.5450\n",
      "Epoch: 50, Batch: 13057/37625 (34.703%), Loss: 0.9131\n",
      "Epoch: 50, Batch: 13313/37625 (35.383%), Loss: 1.2182\n",
      "Epoch: 50, Batch: 13569/37625 (36.064%), Loss: 0.9316\n",
      "Epoch: 50, Batch: 13825/37625 (36.744%), Loss: 0.8018\n",
      "Epoch: 50, Batch: 14081/37625 (37.425%), Loss: 0.9057\n",
      "Epoch: 50, Batch: 14337/37625 (38.105%), Loss: 0.8006\n",
      "Epoch: 50, Batch: 14593/37625 (38.785%), Loss: 1.2024\n",
      "Epoch: 50, Batch: 14849/37625 (39.466%), Loss: 0.7598\n",
      "Epoch: 50, Batch: 15105/37625 (40.146%), Loss: 0.7544\n",
      "Epoch: 50, Batch: 15361/37625 (40.827%), Loss: 0.5762\n",
      "Epoch: 50, Batch: 15617/37625 (41.507%), Loss: 0.7184\n",
      "Epoch: 50, Batch: 15873/37625 (42.187%), Loss: 0.9061\n",
      "Epoch: 50, Batch: 16129/37625 (42.868%), Loss: 0.7571\n",
      "Epoch: 50, Batch: 16385/37625 (43.548%), Loss: 0.6963\n",
      "Epoch: 50, Batch: 16641/37625 (44.229%), Loss: 1.1981\n",
      "Epoch: 50, Batch: 16897/37625 (44.909%), Loss: 1.0527\n",
      "Epoch: 50, Batch: 17153/37625 (45.589%), Loss: 1.2709\n",
      "Epoch: 50, Batch: 17409/37625 (46.270%), Loss: 0.8368\n",
      "Epoch: 50, Batch: 17665/37625 (46.950%), Loss: 0.6857\n",
      "Epoch: 50, Batch: 17921/37625 (47.631%), Loss: 1.3298\n",
      "Epoch: 50, Batch: 18177/37625 (48.311%), Loss: 1.0105\n",
      "Epoch: 50, Batch: 18433/37625 (48.991%), Loss: 0.8642\n",
      "Epoch: 50, Batch: 18689/37625 (49.672%), Loss: 0.5742\n",
      "Epoch: 50, Batch: 18945/37625 (50.352%), Loss: 0.9143\n",
      "Epoch: 50, Batch: 19201/37625 (51.033%), Loss: 0.7658\n",
      "Epoch: 50, Batch: 19457/37625 (51.713%), Loss: 1.0740\n",
      "Epoch: 50, Batch: 19713/37625 (52.393%), Loss: 0.7681\n",
      "Epoch: 50, Batch: 19969/37625 (53.074%), Loss: 0.9280\n",
      "Epoch: 50, Batch: 20225/37625 (53.754%), Loss: 0.6596\n",
      "Epoch: 50, Batch: 20481/37625 (54.435%), Loss: 1.1482\n",
      "Epoch: 50, Batch: 20737/37625 (55.115%), Loss: 1.2221\n",
      "Epoch: 50, Batch: 20993/37625 (55.795%), Loss: 1.5903\n",
      "Epoch: 50, Batch: 21249/37625 (56.476%), Loss: 0.6548\n",
      "Epoch: 50, Batch: 21505/37625 (57.156%), Loss: 0.7198\n",
      "Epoch: 50, Batch: 21761/37625 (57.837%), Loss: 0.8153\n",
      "Epoch: 50, Batch: 22017/37625 (58.517%), Loss: 0.6433\n",
      "Epoch: 50, Batch: 22273/37625 (59.197%), Loss: 1.2820\n",
      "Epoch: 50, Batch: 22529/37625 (59.878%), Loss: 0.8590\n",
      "Epoch: 50, Batch: 22785/37625 (60.558%), Loss: 1.0667\n",
      "Epoch: 50, Batch: 23041/37625 (61.239%), Loss: 2.3546\n",
      "Epoch: 50, Batch: 23297/37625 (61.919%), Loss: 0.5380\n",
      "Epoch: 50, Batch: 23553/37625 (62.599%), Loss: 1.2488\n",
      "Epoch: 50, Batch: 23809/37625 (63.280%), Loss: 1.0831\n",
      "Epoch: 50, Batch: 24065/37625 (63.960%), Loss: 0.6405\n",
      "Epoch: 50, Batch: 24321/37625 (64.641%), Loss: 1.0546\n",
      "Epoch: 50, Batch: 24577/37625 (65.321%), Loss: 1.3504\n",
      "Epoch: 50, Batch: 24833/37625 (66.001%), Loss: 0.6676\n",
      "Epoch: 50, Batch: 25089/37625 (66.682%), Loss: 4.3694\n",
      "Epoch: 50, Batch: 25345/37625 (67.362%), Loss: 0.6786\n",
      "Epoch: 50, Batch: 25601/37625 (68.043%), Loss: 0.7256\n",
      "Epoch: 50, Batch: 25857/37625 (68.723%), Loss: 1.0725\n",
      "Epoch: 50, Batch: 26113/37625 (69.403%), Loss: 1.1008\n",
      "Epoch: 50, Batch: 26369/37625 (70.084%), Loss: 1.6258\n",
      "Epoch: 50, Batch: 26625/37625 (70.764%), Loss: 0.8217\n",
      "Epoch: 50, Batch: 26881/37625 (71.445%), Loss: 0.7440\n",
      "Epoch: 50, Batch: 27137/37625 (72.125%), Loss: 0.5849\n",
      "Epoch: 50, Batch: 27393/37625 (72.805%), Loss: 2.1025\n",
      "Epoch: 50, Batch: 27649/37625 (73.486%), Loss: 0.7225\n",
      "Epoch: 50, Batch: 27905/37625 (74.166%), Loss: 0.8456\n",
      "Epoch: 50, Batch: 28161/37625 (74.847%), Loss: 0.7649\n",
      "Epoch: 50, Batch: 28417/37625 (75.527%), Loss: 1.0710\n",
      "Epoch: 50, Batch: 28673/37625 (76.207%), Loss: 1.0764\n",
      "Epoch: 50, Batch: 28929/37625 (76.888%), Loss: 2.1893\n",
      "Epoch: 50, Batch: 29185/37625 (77.568%), Loss: 0.9973\n",
      "Epoch: 50, Batch: 29441/37625 (78.249%), Loss: 3.4039\n",
      "Epoch: 50, Batch: 29697/37625 (78.929%), Loss: 1.1512\n",
      "Epoch: 50, Batch: 29953/37625 (79.609%), Loss: 0.8664\n",
      "Epoch: 50, Batch: 30209/37625 (80.290%), Loss: 0.5900\n",
      "Epoch: 50, Batch: 30465/37625 (80.970%), Loss: 0.6826\n",
      "Epoch: 50, Batch: 30721/37625 (81.650%), Loss: 0.8283\n",
      "Epoch: 50, Batch: 30977/37625 (82.331%), Loss: 1.0467\n",
      "Epoch: 50, Batch: 31233/37625 (83.011%), Loss: 0.9312\n",
      "Epoch: 50, Batch: 31489/37625 (83.692%), Loss: 0.8949\n",
      "Epoch: 50, Batch: 31745/37625 (84.372%), Loss: 0.6502\n",
      "Epoch: 50, Batch: 32001/37625 (85.052%), Loss: 2.3393\n",
      "Epoch: 50, Batch: 32257/37625 (85.733%), Loss: 1.4098\n",
      "Epoch: 50, Batch: 32513/37625 (86.413%), Loss: 1.0391\n",
      "Epoch: 50, Batch: 32769/37625 (87.094%), Loss: 0.6294\n",
      "Epoch: 50, Batch: 33025/37625 (87.774%), Loss: 1.3020\n",
      "Epoch: 50, Batch: 33281/37625 (88.454%), Loss: 1.2277\n",
      "Epoch: 50, Batch: 33537/37625 (89.135%), Loss: 0.8445\n",
      "Epoch: 50, Batch: 33793/37625 (89.815%), Loss: 1.0376\n",
      "Epoch: 50, Batch: 34049/37625 (90.496%), Loss: 2.1352\n",
      "Epoch: 50, Batch: 34305/37625 (91.176%), Loss: 1.6213\n",
      "Epoch: 50, Batch: 34561/37625 (91.856%), Loss: 3.7086\n",
      "Epoch: 50, Batch: 34817/37625 (92.537%), Loss: 0.8766\n",
      "Epoch: 50, Batch: 35073/37625 (93.217%), Loss: 2.5343\n",
      "Epoch: 50, Batch: 35329/37625 (93.898%), Loss: 1.1932\n",
      "Epoch: 50, Batch: 35585/37625 (94.578%), Loss: 1.0425\n",
      "Epoch: 50, Batch: 35841/37625 (95.258%), Loss: 1.0152\n",
      "Epoch: 50, Batch: 36097/37625 (95.939%), Loss: 0.7472\n",
      "Epoch: 50, Batch: 36353/37625 (96.619%), Loss: 0.8433\n",
      "Epoch: 50, Batch: 36609/37625 (97.300%), Loss: 0.9620\n",
      "Epoch: 50, Batch: 36865/37625 (97.980%), Loss: 1.4704\n",
      "Epoch: 50, Batch: 37121/37625 (98.660%), Loss: 0.8094\n",
      "Epoch: 50, Batch: 37377/37625 (99.341%), Loss: 0.6279\n"
     ]
    }
   ],
   "source": [
    "class NeuralNet(torch.nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.neural_net = torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.input_size, 16), \n",
    "            torch.nn.ReLU(), \n",
    "            torch.nn.Linear(16, 4), \n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(4, 1)\n",
    "        )\n",
    "        # initialize weights using Xavier He initialization\n",
    "        torch.nn.init.xavier_uniform_(self.neural_net[0].weight)\n",
    "    def forward(self, x):\n",
    "        res = torch.zeros(x.shape[0], 1)\n",
    "        for i in range(x.shape[0]):\n",
    "            res[i] = self.neural_net(x[i].float())\n",
    "        return res\n",
    "    def predict(self, x):\n",
    "        return self.forward(x)\n",
    "    def loss_fn(self, y_pred, y_true):\n",
    "        return torch.mean((y_pred - y_true)**2)\n",
    "def train(model, X, y, epochs, batch_size, lr, optimizer, scheduler):\n",
    "    # storing loss values\n",
    "    loss_values = []\n",
    "    overall_loss =[]\n",
    "    for epoch in range(epochs):\n",
    "        # shuffle the data\n",
    "        idx = torch.randperm(X.shape[0])\n",
    "        X = X[idx]\n",
    "        y = y[idx]\n",
    "        # iterate over batches\n",
    "        for i in range(0, X.shape[0], batch_size):\n",
    "            X_batch = X[i:i+batch_size]\n",
    "            y_batch = y[i:i+batch_size]\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(X_batch)\n",
    "            loss = model.loss_fn(y_pred, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step(loss)\n",
    "            print(f\"Epoch: {epoch+1}, Batch: {i+1}/{X.shape[0]} ({100*(i+1)/X.shape[0]:.3f}%), Loss: {loss.item():.4f}\")\n",
    "            loss_values.append(loss.item())\n",
    "        overall_loss.append(loss.item())\n",
    "    return loss_values, overall_loss\n",
    "# move model to GPU if CUDA is available\n",
    "model = NeuralNet(num_of_features).to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, mode='max', verbose=True)\n",
    "\n",
    "loss, overall_loss = train(model, X_train, y_train, num_of_epochs, 256, learning_rate, optimizer, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.9733015298843384\n"
     ]
    }
   ],
   "source": [
    "# testing the model\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_loss = model.loss_fn(y_pred, y_test)\n",
    "print('Loss: ', y_pred_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the loss values\n",
    "plt.plot(loss)\n",
    "plt.xlabel('Batch Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the overall loss values\n",
    "plt.plot(overall_loss)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the model\n",
    "torch.save(model.state_dict(), 'Baseline_model2/model.pt')\n",
    "torch.save(optimizer.state_dict(), 'Baseline_model2/optimizer.pt')\n",
    "torch.save(scheduler.state_dict(), 'Baseline_model2/scheduler.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learnml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
